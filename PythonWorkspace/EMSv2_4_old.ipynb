{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Julian-Banks/EEE4022S_BNKJUL001_Thesis/blob/main/PythonWorkspace/EMSv2_4_old.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "V6yT1Kii6fZb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Version Notes**\n",
        "\n",
        "# **v2.4**\n",
        "* going to have shorter episodes (one month long)\n",
        "* hope the agent can learn to expect the demand charge every 30 days.\n",
        "* fixed a bug with the purchase_price\n",
        "\n",
        "# **v2.3**\n",
        "* Flattening observation space\n",
        "* increasing learning rates\n",
        "* decreasing vf_coef\n",
        "\n",
        "# **v2.2**\n",
        " **Added:**\n",
        " * normalising values. it is time to do this.....\n",
        "\n",
        "# **v2.1**\n",
        "\n",
        "**Added:**\n",
        " * changed reward structure to give a penalty every time the agent reaches a new max demand.\n",
        " * changed obs to include max_demand\n",
        "\n",
        "# **v2.0**\n",
        "*\n",
        "Adding a continous action space! Yolo\n",
        "\n",
        "# **v1.2**\n",
        "**Added:**\n",
        "* Diesel Generator action to mitigate unmet-load\n",
        "* reward based off real prices + demand charge - Demand charge has fucked the agent cause it buys in bulk! - might be time for the continous action space so it can decide how much to buy......\n",
        "\n",
        "**To Do:**\n",
        "* impliment a priority load - not gonna do this, just gonna have unmet load\n",
        "\n",
        "* Add in actual predictions, eish\n",
        "\n",
        "* figure out how to have more episodes!! I think it will have big performance boosts on the training :)\n",
        "\n",
        "* thinking that maybe I should change obs space back to what it was cause I dont actully need to know individual loads and gens!!!!\n",
        "\n",
        "# **v1.1**\n",
        "\n",
        "**Added:**\n",
        "* rect and inverter power tracking\n",
        "* reward logging in my own logging func\n",
        "* changed logging vars to arrays\n",
        "*\n",
        "\n",
        "**To Do**\n",
        "\n",
        "* battery charging rates - I think my assumption is fine.\n",
        "\n",
        "* tweak visualisation to show bar graphs at the end of training/testing. Maybe just print graphs at the end? I have added plt.show() - remember to play if it doesnt work!\n",
        "\n",
        "* impliment a generator!!!!!\n",
        "* impliment a priority load\n",
        "\n",
        "* NB figure out how to have more episodes!! I think it will have big performance boosts on the training :)\n",
        "\n",
        "* thinking that maybe I should change obs space back to what it was cause I dont actully need to know individual loads and gens!!!!\n",
        "\n",
        "# **v1.0**\n",
        "\n",
        "**Added:**\n",
        "* AC and DC load\n",
        "* Wind Gen\n",
        "* changed obs space to hold new loads\n",
        "* re wrote standby and purchase functions\n",
        "\n",
        "**To DO**\n",
        "* thinking that maybe I should change obs space back to what it was cause I dont actully need to know individual loads and gens!!!!\n",
        "* Add in rectifier & inverter power tracking\n",
        "* battery charging rates\n",
        "\n",
        "\n",
        "# **v0.3**\n",
        "**Added:**\n",
        "* loadshedding\n",
        "* New reward structure\n",
        "* added Vec_env\n",
        "* added eval callbacks to validate training\n",
        "* added in logging\n",
        "\n",
        "**Parameters:**\n",
        "* Added in loadshedding forecast\n",
        "\n",
        "**To do:**\n",
        "* find out about battery charging rates  & impliment\n",
        "* Find out if I need to normalise\n",
        "* Try dqn\n",
        "* Find out how the bounds for the obs_space box effect things\n",
        "* Try play with DummyVec wrapper (didnt work in last version)\n",
        "\n",
        "# **v0.2_1**\n",
        "**Added:**\n",
        "*  Monitor wrapper\n",
        "*  DummyVec wrapper\n",
        "*  Wand (weights and bais) enabled\n",
        "\n",
        "**Parameters:**\n",
        "* lowered to 3 predictions  \n",
        "\n",
        "**To do:**\n",
        "* Try to use hyperparameter Optimisation - decided Im only going to do on the final version\n",
        "* Try normalise\n",
        "* Try differnet models\n",
        "* Find out how the bounds for the obs_space box effect things\n",
        "\n",
        "# **v0.2**\n",
        "**Added:**\n",
        "*  simplified load_forecast and gen_forecast to be power_bal_forecasts.\n",
        "*  combined current_load and current_gen to also show current_power_balance\n",
        "*  added proper evaluate call\n",
        "\n",
        "**Parameters:**\n",
        "* No changes  \n",
        "\n",
        "**Results:**\n",
        "* 5% savings on PPO deterministic = true\n",
        "* 4.3% savings on PPO determnistic = false\n",
        "\n",
        "**To do:**\n",
        "* Try to use hyperparameter Optimisation\n",
        "* Try normalise\n",
        "* Try differnet models\n",
        "* Try see if discount rate can be tweaked - at good level.\n",
        "* Find out how the bounds for the obs_space box effect things\n",
        "\n",
        "# **v0.1**\n",
        "**Added:**\n",
        "* added real loads, gen, tou_id's\n",
        "\n",
        "**Parameters:**\n",
        "* training episode = 6000 timesteps\n",
        "* testing episode  = 2760 timesteps\n",
        "* bat_threshold = 100\n",
        "* bat_cap = 500\n",
        "* battery_level at reset = bat_cap/2\n",
        "* num_preds = 24\n",
        "* Trained PPO for 1.65mil timesteps\n",
        "* Trained A2C for 1.2 mil timesteps\n",
        "\n",
        "**Results:**\n",
        "* PP0 - 3.7% improvement from standby mode Deterministic = False\n",
        "* PPO - 6.1% Deterministic =  True\n",
        "* A2C  - -0.3% improvement. And the models after this got worse as training progressed!\n",
        "**To do:**\n",
        "* Try lower num_preds\n",
        "* Try to use hyperparameter Optimisation\n",
        "* Try normalise\n",
        "* Try differnet models\n",
        "* Try see if discount rate can be tweaked\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5DZFnZnzStt1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nI52iVVCCPaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "a1cbe5ad-00b1-455e-fdfb-1939790f6e95"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4e867f4f9160>\u001b[0m in \u001b[0;36m<cell line: 41>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m#mount the drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    190\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mountpoint must not be a symlink'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mountpoint must not already contain files'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mountpoint must either be a directory or not exist'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Mountpoint must not already contain files"
          ]
        }
      ],
      "source": [
        "%%capture\n",
        "#install dependancies\n",
        "!pip install gymnasium\n",
        "!pip install stable_baselines3[extra]\n",
        "!pip install wandb\n",
        "!pip install sklearn\n",
        "%load_ext tensorboard\n",
        "\n",
        "#clone repository\n",
        "! git clone https://github.com/Julian-Banks/EEE4022S_BNKJUL001_Thesis\n",
        "\n",
        "#to update the rep\n",
        "%cd /content/EEE4022S_BNKJUL001_Thesis\n",
        "! git pull\n",
        "#import needed libarys\n",
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "from gymnasium import spaces\n",
        "import datetime\n",
        "from stable_baselines3 import PPO, A2C, DQN,DDPG\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from stable_baselines3.common.callbacks import EvalCallback\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.vec_env import VecVideoRecorder\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.animation import FuncAnimation\n",
        "from gym.wrappers import FlattenObservation\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "import wandb\n",
        "from wandb.integration.sb3 import WandbCallback\n",
        "from gymnasium.envs.registration import register\n",
        "\n",
        "\n",
        "\n",
        "#mount the drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#define paths to logs and model saves\n",
        "model_type = \"PPO\"\n",
        "version    = \"EMSv2_3\"\n",
        "model_dir = f\"/content/drive/MyDrive/Colab Notebooks/{version}/models/{model_type}/\"\n",
        "log_dir   = f\"/content/drive/MyDrive/Colab Notebooks/{version}/models/{model_type}logs/\"\n",
        "animation_dir = f\"/content/drive/MyDrive/Colab Notebooks/{version}/models/{model_type}/animation/\"\n",
        "\n",
        "#make the appropriate directory if it does not exist\n",
        "if not os.path.exists(model_dir):\n",
        "    os.makedirs(model_dir)\n",
        "if not os.path.exists(log_dir):\n",
        "    os.makedirs(log_dir)\n",
        "if not os.path.exists(animation_dir):\n",
        "    os.makedirs(animation_dir)"
      ],
      "metadata": {
        "id": "SIpnNCVVRTV8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5edd0f9-68aa-461f-ebef-b2f4dcfe3ff6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define our environment class!!**"
      ],
      "metadata": {
        "id": "Q99_jLMvwuZZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "s2iW-k26FIbm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d7a0c67-9cb9-475b-82e8-d8cf1ee77009"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/env_checker.py:428: UserWarning: We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) cf. https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "class EMSv2_3(gym.Env):\n",
        "    \"\"\"Custom Environment that follows gym interface.\"\"\"\n",
        "\n",
        "    metadata = {\"render_modes\": [\"human\",\"rgb_array\"], \"render_fps\": 30}\n",
        "\n",
        "    def __init__(self,bat_threshold = 0.1, bat_cap = 1, actual_load = \"none\", actual_gen = \"none\", purchase_price = [1,1,1,1,1,1,1,1,2,2,2,2] , episode_len = 8760,num_preds = 24,render_mode = \"rgb_array\", load_shedding = \"none\", wandb_log = False,train_log = True, gen_size = 100,demand_charge = 252.92):\n",
        "\n",
        "        super(EMSv2_3, self).__init__()\n",
        "        #define render_mode\n",
        "        self.render_mode = render_mode\n",
        "        #define wandb\n",
        "        self.wandb_log = wandb_log\n",
        "        self.train_log = train_log\n",
        "        #define time frame\n",
        "        self.current_step = 0\n",
        "        self.final_step = int(episode_len)-num_preds-2\n",
        "\n",
        "        #Might make a function for these\n",
        "        #fill all of the actual loads NB!!! is just random for now NB!!! is normalised 0-1\n",
        "        if isinstance(actual_load,str) :\n",
        "            self.actual_load = np.random.rand(self.final_step+num_preds+1,2).astype(np.float32) #will load from a file or something\n",
        "        else:\n",
        "            self.actual_load  = actual_load[:episode_len,:]\n",
        "\n",
        "        self.load_scaler = MinMaxScaler(feature_range=(0,1))\n",
        "        self.actual_load = self.load_scaler.fit_transform(self.actual_load)\n",
        "\n",
        "\n",
        "\n",
        "        #fill all of the actual generation steps.\n",
        "        if isinstance(actual_gen,str):\n",
        "            self.actual_gen  = np.random.rand(self.final_step+num_preds+1,2).astype(np.float32) #will load from file or something\n",
        "        else:\n",
        "            self.actual_gen  = actual_gen[:episode_len,:]\n",
        "\n",
        "        self.gen_scaler = MinMaxScaler(feature_range = (0,1))\n",
        "        self.actual_gen = self.gen_scaler.fit_transform(self.actual_gen)\n",
        "\n",
        "        #Fill the loadShedding indicator\n",
        "        if isinstance(load_shedding,str):\n",
        "            num_shedding   = np.random.randint(int(0.02*episode_len), int(0.05*episode_len))\n",
        "            load_shed      = np.array([1]*num_shedding + [0]*(episode_len - num_shedding))\n",
        "            np.random.shuffle(load_shed)\n",
        "            self.load_shed = load_shed\n",
        "        else:\n",
        "            self.load_shed = load_shedding[:episode_len]\n",
        "\n",
        "        #define vars for render\n",
        "        self.off_peak_purchases = np.zeros(self.final_step)\n",
        "        self.standard_purchases = np.zeros(self.final_step)\n",
        "        self.peak_purchases     = np.zeros(self.final_step)\n",
        "\n",
        "        self.off_peak_num       = 0\n",
        "        self.peak_num           = 0\n",
        "        self.standard           = 0\n",
        "\n",
        "        self.unmet_load_total   = 0\n",
        "        self.frames = []\n",
        "\n",
        "        #Define a var for unmet load no that there is loadshedding\n",
        "        self.step_unmet_load = np.zeros(self.final_step)\n",
        "\n",
        "        #define the purchase price for every step of the year\n",
        "        purchase_price = np.array(purchase_price).astype(np.float32)\n",
        "        repetitions    = (self.final_step+num_preds+1) // len(purchase_price)\n",
        "        remainder      = (self.final_step+num_preds+1) % len(purchase_price)\n",
        "        self.purchase_price =np.concatenate([purchase_price]*repetitions+[purchase_price[:remainder]])#need to read in from somewhere\n",
        "        price_scaler = MinMaxScaler(feature_range=(0,1))\n",
        "        self.purchase_price = price_scaler.fit_transform(self.purchase_price.reshape(-1, 1))\n",
        "        self.price_scaler = price_scaler\n",
        "        #define demand charge\n",
        "        self.demand_charge = demand_charge\n",
        "        #define var for storing the excess gen\n",
        "        self.excess_gen = np.zeros(self.final_step)\n",
        "        #define the size of the diesel_gen\n",
        "        self.gen_size = gen_size\n",
        "        #define a var for determine amount purchased per step (dont want to make it total as this will incure growing penalties for the Agent if used in reward structure)\n",
        "        self.step_purchased = np.zeros(self.final_step)\n",
        "        self.purchased_total = 0\n",
        "        #define the battery max capacity\n",
        "        self.bat_cap = bat_cap\n",
        "        #define the battery low threshold\n",
        "        self.bat_threshold = np.float32(bat_threshold)\n",
        "\n",
        "        bat_scaler = MinMaxScaler(feature_range = (0,1))\n",
        "        [bat_threshold_norm, bat_cap_norm] = bat_scaler.fit_transform(np.array([np.float32(bat_threshold), np.float32(bat_cap)]).reshape(-1,1))\n",
        "        self.bat_scaler = bat_scaler\n",
        "        self.battery_level = np.zeros(self.final_step+1)\n",
        "\n",
        "\n",
        "        self.action_scaler = MinMaxScaler(feature_range = (0,1))\n",
        "        self.action_scaler.fit_transform(np.array([0, self.bat_cap -  self.bat_threshold + np.max(self.load_scaler.inverse_transform(self.actual_load))]).reshape(-1,1))\n",
        "\n",
        "        self.num_preds = num_preds # day ahead predictions\n",
        "        #define how many different loads and generators there are\n",
        "        self.num_loads = self.actual_load.shape[1]\n",
        "        #define the size of the action space\n",
        "        self.action_space = gym.spaces.Box(low= 0 , high =1)\n",
        "        # Dict space to store all the different things\n",
        "\n",
        "        self.observation_space = spaces.Dict({\n",
        "                \"power_bal_forecast\" : gym.spaces.Box(low=-np.inf, high=np.inf, shape=(1,num_preds), dtype=np.float32),\n",
        "                \"price_forecast\"     : gym.spaces.Box(low=0, high=1, shape=(1,num_preds+1), dtype=np.float32),\n",
        "                \"island_forecast\"    : gym.spaces.Box(low=0, high=1, shape=(1,num_preds+1), dtype=np.float32),\n",
        "                \"bat_level\"          : gym.spaces.Box(low=0, high=1, shape=(1,), dtype=np.float32),\n",
        "                \"current_power_bal\"  : gym.spaces.Box(low=-np.inf, high=np.inf, shape=(1,), dtype=np.float32)\n",
        "                })\n",
        "        self.observation_space = spaces.flatten_space(self.observation_space)\n",
        "        #\"max_demand\"         : gym.spaces.Box(low=0, high = np.inf, shape = (1,),dtype=np.float32)\n",
        "\n",
        "    def step(self, action):\n",
        "\n",
        "        #update the current state with the action (needs to be done before current_step is inc since we want to apply the action to the previous step to get the current state)\n",
        "        self.update_state(action)\n",
        "        #Calculate reward from the action\n",
        "        self.reward[self.current_step] = self.calc_reward()\n",
        "        #print(f\"calc_reward: {self.calc_reward()}\")\n",
        "        #print(f\"self.reward[current_step]: {self.reward[self.current_step]}\")\n",
        "        reward = self.reward[self.current_step]\n",
        "        #Wand log, if its set to true(so that it only gets run when wandb is initialised)\n",
        "        if self.wandb_log == True:\n",
        "            #doing this for training logging\n",
        "            if self.train_log == True:\n",
        "                if self.current_step == self.final_step:\n",
        "                    self.wandb_logger()\n",
        "            else:\n",
        "                self.wandb_logger()\n",
        "\n",
        "        #inc time step into Future\n",
        "        self.current_step += 1\n",
        "        #get next observation (for next time step)\n",
        "        observation = self.get_obs()\n",
        "        #Set terminated to False since there are no failure states\n",
        "        self.terminated = False\n",
        "        #Check if timelimit reached\n",
        "        self.truncated = False if self.current_step<self.final_step else True\n",
        "\n",
        "        if self.truncated and self.wandb_log:\n",
        "            self.wandb_logger()\n",
        "\n",
        "        #dont know what to put into info for now\n",
        "        info = {}\n",
        "        return observation, reward, self.terminated, self.truncated, info\n",
        "    '''\n",
        "    def reset(self, seed=None, options=None):\n",
        "        super().reset(seed = seed, options=options)\n",
        "        self.current_step = 0\n",
        "        self.terminated = False\n",
        "        self.truncated = False\n",
        "        #reset the state\n",
        "        self.battery_level[0]   = self.bat_scaler.transform(np.array(self.bat_cap/2).reshape(-1,1))\n",
        "        self.excess_gen         = np.zeros(self.final_step+1)\n",
        "        self.step_purchased     = np.zeros(self.final_step+1)\n",
        "        self.step_unmet_load    = np.zeros(self.final_step+1)\n",
        "        self.off_peak_purchases = np.zeros(self.final_step+1)\n",
        "        self.peak_purchases     = np.zeros(self.final_step+1)\n",
        "        self.standard_purchases = np.zeros(self.final_step+1)\n",
        "        self.diesel_count       = np.zeros(self.final_step+1)\n",
        "        self.reward             = np.zeros(self.final_step+1)\n",
        "        self.step_invt          = np.zeros(self.final_step+1)\n",
        "        self.step_rect          = np.zeros(self.final_step+1)\n",
        "        self.diesel_gen         = np.zeros(self.final_step+1)\n",
        "        self.action_purchase    = np.zeros(self.final_step+1)\n",
        "        self.money_spent        = np.zeros(self.final_step+1)\n",
        "\n",
        "        #get the first observation\n",
        "        observation = self.get_obs()\n",
        "        #Still don't know what to do with info\n",
        "        info = {}\n",
        "        return observation, info\n",
        "        '''\n",
        "    def reset(self, seed=None, options=None):\n",
        "        super().reset(seed = seed, options=options)\n",
        "        if seed is not None:\n",
        "            #random.seed(seed)\n",
        "        if self.train_log:\n",
        "            self.current_step = random.randint(0, self.final_step-30*24)\n",
        "            self.final_step   = self.current_step + 30*24\n",
        "        else:\n",
        "            self.current_step = 0\n",
        "\n",
        "        self.terminated = False\n",
        "        self.truncated = False\n",
        "        #reset the state\n",
        "        self.battery_level[0]   = self.bat_scaler.transform(np.array(self.bat_cap/2).reshape(-1,1))\n",
        "        self.excess_gen         = np.zeros(self.final_step+1)\n",
        "        self.step_purchased     = np.zeros(self.final_step+1)\n",
        "        self.step_unmet_load    = np.zeros(self.final_step+1)\n",
        "        self.off_peak_purchases = np.zeros(self.final_step+1)\n",
        "        self.peak_purchases     = np.zeros(self.final_step+1)\n",
        "        self.standard_purchases = np.zeros(self.final_step+1)\n",
        "        self.diesel_count       = np.zeros(self.final_step+1)\n",
        "        self.reward             = np.zeros(self.final_step+1)\n",
        "        self.step_invt          = np.zeros(self.final_step+1)\n",
        "        self.step_rect          = np.zeros(self.final_step+1)\n",
        "        self.diesel_gen         = np.zeros(self.final_step+1)\n",
        "        self.action_purchase    = np.zeros(self.final_step+1)\n",
        "        self.money_spent        = np.zeros(self.final_step+1)\n",
        "\n",
        "        #get the first observation\n",
        "        observation = self.get_obs()\n",
        "        #Still don't know what to do with info\n",
        "        info = {}\n",
        "        return observation, info\n",
        "\n",
        "\n",
        "    def render(self, mode='rgb_array', save_path=None):\n",
        "\n",
        "        plt.clf()\n",
        "        values = [self.off_peak_purchases, self.standard_purchases, self.purchase_price[self.peak_purchases]]\n",
        "        colors = ['green', 'orange','red']\n",
        "        labels = ['Off Peak', 'Standard', 'Peak']\n",
        "        plt.xlim(0,1.6)\n",
        "        plt.ylim(0,100)\n",
        "        plt.bar(list(range(3)),values, color=colors, tick_label=labels)\n",
        "        self.frames.append(plt.gcf().canvas.tostring_rgb())\n",
        "        plt.pause(0.000001)\n",
        "\n",
        "    def wandb_logger(self):\n",
        "        bat_scaler = self.bat_scaler\n",
        "        load_scaler = self.load_scaler\n",
        "        gen_scaler = self.gen_scaler\n",
        "\n",
        "        action = self.action_scaler.inverse_transform(self.action_purchase.reshape(-1,1)).flatten()\n",
        "        train_log_dict={\n",
        "                    \"Excess Generation\"         :np.sum(self.excess_gen),\n",
        "                    \"Unmet Load\"                :np.sum(self.step_unmet_load),\n",
        "                    \"Off-Peak Purchases\"        :np.sum(self.off_peak_purchases),\n",
        "                    \"Standard Purchases\"        :np.sum(self.standard_purchases),\n",
        "                    \"Peak Purchases\"            :np.sum(self.peak_purchases),\n",
        "                    \"Num Off-Peak Purchases\"    :np.count_nonzero(self.off_peak_purchases),\n",
        "                    \"Num Standard Purchases\"    :np.count_nonzero(self.standard_purchases),\n",
        "                    \"Num Peak Purchases\"        :np.count_nonzero(self.peak_purchases),\n",
        "                    \"Total Elec Purchase\"       :np.sum(self.step_purchased),\n",
        "                    \"Total Purchase Requested\"  :np.sum(action),\n",
        "                    \"Num Diesel Gen Actions\"    :np.count_nonzero(self.diesel_count),\n",
        "                    \"Total Reward\"              :np.sum(self.reward),\n",
        "                    \"Total Money spent\"         :np.sum(self.money_spent),\n",
        "                    \"Rectifier total power flow\":np.sum(self.step_rect),\n",
        "                    \"Inverter total power flow\" :np.sum(self.step_invt),\n",
        "                    \"Diesel Generator\"          :np.sum(self.diesel_gen),\n",
        "                    \"Max Demand\"                :np.max(self.step_purchased),\n",
        "                    \"total Purchased Elec\"      :np.sum(self.step_purchased)\n",
        "                    }\n",
        "        load = load_scaler.inverse_transform(self.actual_load[self.current_step,:].reshape(-1,2)).flatten()\n",
        "        gen  = gen_scaler.inverse_transform(self.actual_gen[self.current_step,:].reshape(-1,2)).flatten()\n",
        "        eval_log_dict={\n",
        "                    \"battery_level\"             :bat_scaler.inverse_transform(self.battery_level[self.current_step].reshape(-1,1)).flatten(),\n",
        "                    \"AC load\"                   :load[0],\n",
        "                    \"DC load\"                   :load[1],\n",
        "                    \"Wind generation\"           :gen[0],\n",
        "                    \"PV generation\"             :gen[1],\n",
        "                    \"Excess Generation\"         :self.excess_gen[self.current_step],\n",
        "                    \"Unmet Load\"                :self.step_unmet_load[self.current_step],\n",
        "                    \"LoadShedding\"              :self.load_shed[self.current_step],\n",
        "                    \"Off-Peak Purchases\"        :self.off_peak_purchases[self.current_step],\n",
        "                    \"Standard Purchases\"        :self.standard_purchases[self.current_step],\n",
        "                    \"Peak Purchases\"            :self.peak_purchases[self.current_step],\n",
        "                    \"Num Off-Peak Purchases\"    :np.count_nonzero(self.off_peak_purchases),\n",
        "                    \"Num Standard Purchases\"    :np.count_nonzero(self.standard_purchases),\n",
        "                    \"Num Peak Purchases\"        :np.count_nonzero(self.peak_purchases),\n",
        "                    \"Step Purchased\"            :self.step_purchased[self.current_step],\n",
        "                    \"Purchase Requested\"        :self.action_purchase[self.current_step],\n",
        "                    \"Num Diesel Gen Actions\"    :np.count_nonzero(self.diesel_count),\n",
        "                    \"Total Reward\"              :self.reward[self.current_step],\n",
        "                    \"Money Spent\"               :self.money_spent[self.current_step],\n",
        "                    \"Rectifier total power flow\":self.step_rect[self.current_step],\n",
        "                    \"Inverter total power flow\" :self.step_invt[self.current_step],\n",
        "                    \"Diesel Generator\"          :self.diesel_gen[self.current_step],\n",
        "\n",
        "                    }\n",
        "\n",
        "        if self.train_log:\n",
        "            wandb.log(train_log_dict)\n",
        "        else:\n",
        "            wandb.log(eval_log_dict)\n",
        "\n",
        "        if self.train_log == False and self.current_step == self.final_step:\n",
        "\n",
        "\n",
        "            values = [[np.sum(self.off_peak_purchases),'Off Peak'], [np.sum(self.standard_purchases),'Standard'], [np.sum(self.peak_purchases),'Peak']]\n",
        "            table = wandb.Table(columns = [\"values\",\"labels\"],data=values)\n",
        "            Tou_purchases = wandb.plot.bar(table,\"labels\",\"values\", title=\"kWh purchased per TOU tariff\")\n",
        "\n",
        "            values = [[np.max(self.step_purchased),'Max demand'], [np.max(self.diesel_gen),'Max diesel gen'], [np.max(self.step_rect),'Max rectifier power'], [np.max(self.step_invt),'Max inverter power']]\n",
        "            table = wandb.Table(columns = [\"values\",\"labels\"],data=values)\n",
        "            max_metrics = wandb.plot.bar(table,\"labels\",\"values\", title=\"Sizing Metrics\")\n",
        "\n",
        "            values = [[np.sum(self.step_purchased),'Total Purchased'], [np.sum(self.action_purchase),'Total requested purchases'],[np.sum(self.excess_gen),'Total excess generation']]\n",
        "            table = wandb.Table(columns = [\"values\",\"labels\"],data=values)\n",
        "            total_metrics = wandb.plot.bar(table,\"labels\",\"values\", title=\"Total Metrics\")\n",
        "\n",
        "            values = [[np.sum(self.diesel_gen),'Total diesel generation'], [np.sum(self.step_unmet_load),'Total unmet load']]\n",
        "            table = wandb.Table(columns = [\"values\",\"labels\"],data=values)\n",
        "            total_diesel_unmet = wandb.plot.bar(table,\"labels\",\"values\", title=\"Total diesel and unmet load\")\n",
        "\n",
        "            values = [[np.sum(self.reward),'Total reward accumulated'], [np.sum(self.money_spent),'Total money spent']]\n",
        "            table = wandb.Table(columns = [\"values\",\"labels\"],data=values)\n",
        "            total_reward = wandb.plot.bar(table,\"labels\",\"values\", title=\"Total reward and money spent\")\n",
        "\n",
        "\n",
        "            wandb.log({ \"kWh purchased per TOU tariff\"  : Tou_purchases,\n",
        "                        \"Max sizing metrics\"            : max_metrics,\n",
        "                        \"Total metrics\"                 : total_metrics,\n",
        "                        \"Total diesel and unmet load\"   : total_diesel_unmet,\n",
        "                        \"Total reward and money spent\"  :total_reward\n",
        "                        })\n",
        "\n",
        "\n",
        "            '''\n",
        "            plt.clf()\n",
        "            values = [np.sum(self.off_peak_purchases), np.sum(self.standard_purchases), np.sum(self.peak_purchases)]\n",
        "            colors = ['green', 'orange','red']\n",
        "            plt.xlim(0,2)\n",
        "            plt.ylim(0,120000)\n",
        "            plt.bar(list(range(3)),values, color=colors, tick_label=labels)\n",
        "            plt.xlabel('Tariff Rate')\n",
        "            plt.ylabel('Electricity Purchased (units)')\n",
        "            plt.title('Electricity Purchased per Tariff Rate')\n",
        "\n",
        "            save_name = animation_dir + \"TOU_purchases_\"+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")+\".png\"\n",
        "            plt.savefig(save_name)\n",
        "            wandb.log({\"Electricity purchased per Tariff rate\": wandb.Image(save_name)})\n",
        "            '''\n",
        "    def close(self):\n",
        "        #don't think i need this for my application\n",
        "        pass\n",
        "\n",
        "    def update_state(self, action):\n",
        "\n",
        "        self.standby(purchase_amount = action)\n",
        "        self.action_purchase[self.current_step] = self.action_scaler.transform(np.array([action]).reshape(-1,1))\n",
        "\n",
        "        self.tou_purchase_inc()\n",
        "        #Calculate the flow of power (this is max absorb, the min need is just dc_power_bal)\n",
        "        #fetch info from grids\n",
        "        ac_power_bal, avail_grid = self.AC_bus()\n",
        "        dc_power_bal, avail_bat, avail_stor = self.DC_bus()\n",
        "        self.calc_power_flow(dc_power_bal,ac_power_bal,avail_stor)\n",
        "\n",
        "    def calc_reward(self):\n",
        "        #Calculate reward based on the state\n",
        "        #Summer Months: 5.92, 2.09, 1.33\n",
        "        #Winter Months: 2.22, 1.66, 1.21\n",
        "        #Demand Charge: 252.92\n",
        "\n",
        "        petrol_per_kw  = 0.4*23\n",
        "        diesel_cost     = petrol_per_kw*self.diesel_gen[self.current_step] #0.4l per kwh produced multipled by a cost of 23 rand per litre. Very rough values\n",
        "        elec_purchase   = self.step_purchased[self.current_step]*self.price_scaler.inverse_transform(self.purchase_price[self.current_step].reshape(-1,1)).flatten()\n",
        "        if self.off_peak_purchases[self.current_step] >0 :\n",
        "            bonus = self.step_purchased[self.current_step]*0.8\n",
        "        else:\n",
        "            bonus = 0\n",
        "\n",
        "        unmet_load_pen  = self.step_unmet_load[self.current_step]*20\n",
        "\n",
        "        if self.current_step > 30*24:\n",
        "            start_index = self.current_step - self.current_step % (24*30)\n",
        "            current_max  = np.max(self.step_purchased[start_index:])\n",
        "        elif self.current_step> 0:\n",
        "            current_max = np.max(self.step_purchased[:self.current_step])\n",
        "        else:\n",
        "            current_max = self.step_purchased[self.current_step]\n",
        "\n",
        "        if self.step_purchased[self.current_step] > current_max:\n",
        "            max_demand_pen  = (self.step_purchased[self.current_step] - current_max)*self.demand_charge\n",
        "        else:\n",
        "            max_demand_pen = 0\n",
        "\n",
        "        reward = -elec_purchase - unmet_load_pen - diesel_cost #- max_demand_pen + bonus\n",
        "\n",
        "        self.money_spent[self.current_step] =  elec_purchase +  diesel_cost\n",
        "        #if a month has past, then impliment the demand charge\n",
        "        if self.current_step % (24*30) == 0 and self.current_step != 0:\n",
        "            max_grid_demand = np.max(self.step_purchased[self.current_step-(24*30):self.current_step])\n",
        "            reward = reward #- max_grid_demand * self.demand_charge\n",
        "            self.money_spent[self.current_step] =  self.money_spent[self.current_step] + max_grid_demand*self.demand_charge\n",
        "\n",
        "        return reward\n",
        "\n",
        "    def get_obs(self):\n",
        "        #Fill the observation space with the next observation\n",
        "\n",
        "        #Get Forecasts Will probaly write a function for this? idk maybe a schlep to return all the info\n",
        "        load_forecast  = np.array( [self.actual_load[self.current_step+1: self.current_step + self.num_preds+1,:]] , dtype = np.float32) #will load from a file or something\n",
        "        gen_forecast   = np.array( [self.actual_gen[self.current_step+1: self.current_step + self.num_preds+1,:]] , dtype = np.float32) #will load from a file or something\n",
        "        #calculate the power forecast\n",
        "        power_bal_forecast = gen_forecast-load_forecast\n",
        "        power_bal_forecast = power_bal_forecast.sum(axis=2)\n",
        "        #get the prices for the current frame and the next 24 hours. Maybe will cut this down since that seems like a lot of info\n",
        "        price_forecast = np.array( [self.purchase_price[self.current_step:self.current_step+self.num_preds+1]] , dtype = np.float32).reshape(1,self.num_preds+1)\n",
        "        #Just for readibility of the dict object\n",
        "        bat_level      = np.array([self.battery_level[self.current_step]] , dtype= np.float32)\n",
        "        if bat_level < 0:\n",
        "            #print(f\"Battery Level was less than 0!!! Bat_level{bat_level}\")\n",
        "            bat_level = np.array( [0] , dtype= np.float32)\n",
        "\n",
        "        #island forecasst, same as tou forecast\n",
        "        island_forecast =np.array( [self.load_shed[self.current_step:self.current_step+self.num_preds+1]] , dtype = np.float32)\n",
        "\n",
        "        #calculate the current power balance\n",
        "        current_load   = np.array([self.actual_load[self.current_step,:]], dtype = np.float32)\n",
        "        current_gen    = np.array([self.actual_gen[self.current_step,:]], dtype  = np.float32)\n",
        "        current_power_bal = current_gen - current_load\n",
        "        current_power_bal = current_power_bal.sum(axis=1)\n",
        "\n",
        "        if self.current_step>30*24:\n",
        "            max_demand = np.array([np.max(self.step_purchased[self.current_step-(24*30):self.current_step])],dtype = np.float32)\n",
        "        else:\n",
        "            max_demand = np.array([np.max(self.step_purchased)],dtype = np.float32)\n",
        "\n",
        "        if self.current_step > 30*24:\n",
        "            start_index = self.current_step - self.current_step % (24*30)\n",
        "            current_max  = np.max(self.step_purchased[start_index:])\n",
        "        elif self.current_step> 0:\n",
        "            current_max = np.max(self.step_purchased[:self.current_step])\n",
        "        else:\n",
        "            current_max = self.step_purchased[self.current_step]\n",
        "\n",
        "        if self.step_purchased[self.current_step] > current_max:\n",
        "            max_demand  = (self.step_purchased[self.current_step-1] - current_max)\n",
        "            max_demand  = np.array([max_demand],dtype = np.float32)\n",
        "        else:\n",
        "            max_demand  = np.array([0],dtype = np.float32)\n",
        "\n",
        "        # \"max_demand\"    : max_demand\n",
        "        obs = dict({\n",
        "                \"bat_level\":      bat_level,\n",
        "                \"current_power_bal\" :   current_power_bal,\n",
        "                \"island_forecast\": island_forecast,\n",
        "                \"power_bal_forecast\":  power_bal_forecast,\n",
        "                \"price_forecast\": price_forecast,\n",
        "\n",
        "        })\n",
        "        obs = np.concatenate([obs[key].flatten() for key in obs.keys()])\n",
        "        return obs\n",
        "\n",
        "    def AC_bus(self):\n",
        "        #fill out info on the ac\n",
        "        ac_gen = self.gen_scaler.inverse_transform((self.actual_gen[self.current_step, :]).reshape(-1,2)).flatten()\n",
        "        ac_gen = ac_gen[0]\n",
        "        ac_load = self.load_scaler.inverse_transform(self.actual_load[self.current_step,:].reshape(-1,2)).flatten()\n",
        "        ac_load = ac_load[0]\n",
        "        ac_power_bal = ac_gen - ac_load\n",
        "        #check if there is load shedding or not\n",
        "        avail_grid = not self.load_shed[self.current_step]\n",
        "        #ac_diesel = Don't know what yet but I do want to use it for something.\n",
        "        #return relevant values\n",
        "        return ac_power_bal,avail_grid\n",
        "\n",
        "    def DC_bus(self):\n",
        "        #fill in info for DC_bus\n",
        "        dc_gen       = self.gen_scaler.inverse_transform((self.actual_gen[self.current_step,:]).reshape(-1,2)).flatten()\n",
        "        dc_gen  = dc_gen[1]\n",
        "        dc_load      = self.load_scaler.inverse_transform((self.actual_load[self.current_step,:]).reshape(-1,2)).flatten()\n",
        "        dc_load = dc_load[1]\n",
        "        dc_power_bal = dc_gen - dc_load\n",
        "        #Haven't imposed limits here but I don't think I need to. Must check.\n",
        "        avail_bat  = self.bat_scaler.inverse_transform(self.battery_level[self.current_step].reshape(-1,1)) - self.bat_threshold\n",
        "        avail_stor = self.bat_cap   - self.bat_scaler.inverse_transform(self.battery_level[self.current_step].reshape(-1,1))\n",
        "        return dc_power_bal, avail_bat, avail_stor\n",
        "\n",
        "    def standby(self,purchase_amount):\n",
        "        #fetch info from grids\n",
        "        ac_power_bal, avail_grid = self.AC_bus()\n",
        "        dc_power_bal, avail_bat, avail_stor = self.DC_bus()\n",
        "        current_battery_level =  self.bat_scaler.inverse_transform(self.battery_level[self.current_step].reshape(-1,1))\n",
        "\n",
        "        purchase_amount_unnorm = self.action_scaler.inverse_transform(np.array([purchase_amount]).reshape(-1,1))\n",
        "        if avail_grid: # if there is no loadshedding purchase the amount requested by the agent.\n",
        "            self.step_purchased[self.current_step] = purchase_amount_unnorm\n",
        "        else:\n",
        "            self.step_purchased[self.current_step] = 0\n",
        "        #calculate the immediate power_bal\n",
        "        grid_power_bal = ac_power_bal + dc_power_bal + self.step_purchased[self.current_step]\n",
        "        #determine the flow of power:\n",
        "        if grid_power_bal > 0 :\n",
        "            #increments the battery level by the minimium between avail_stor and grid_power_bal ( always keeps it in range)\n",
        "            self.battery_level[self.current_step+1] =  self.bat_scaler.transform(current_battery_level+ min(avail_stor, grid_power_bal))\n",
        "            #increments excess gen by the max ( if grid_power_bal - avail_stor is negative, there was no excess and it will add 0, else it will add the excess that wasn't stored)\n",
        "            self.excess_gen[self.current_step] = max((grid_power_bal - avail_stor), 0)\n",
        "        else:\n",
        "            #there is a shortage of power, see if we can take it from the battery.\n",
        "            # flipping the sign of the avail bat, cause that will subtracted from current balance.\n",
        "            self.battery_level[self.current_step+1] = self.bat_scaler.transform(current_battery_level + max(-avail_bat, grid_power_bal))\n",
        "            #check if we are islanded and buy elec if we arent\n",
        "            if avail_grid:\n",
        "                #if the grid is available\n",
        "                #the min power needed is 0 if the grid power bal is positive with the available batter. Otherwise it is the shortage (grid_power_bal is negative, avail_bat is positive)\n",
        "                min_power_need = - min(grid_power_bal + avail_bat, 0)\n",
        "                self.step_purchased[self.current_step] = purchase_amount_unnorm + min_power_need\n",
        "            else:\n",
        "                #if not available add to the step un_met_load.\n",
        "                unmet_load = -min(grid_power_bal + avail_bat, 0)\n",
        "                self.diesel_gen[self.current_step] = min(unmet_load,self.gen_size)\n",
        "                if self.diesel_gen[self.current_step] > 0:\n",
        "                    self.diesel_count[self.current_step] =1\n",
        "                self.step_unmet_load[self.current_step] = max(unmet_load - self.gen_size, 0)\n",
        "\n",
        "\n",
        "    def calc_power_flow(self,dc_power_bal,ac_power_bal,avail_stor):\n",
        "\n",
        "        #Calculate the flow of power (this is max absorb, the min need is just dc_power_bal)\n",
        "        dc_power_absorb = max(-dc_power_bal+avail_stor,0)\n",
        "        #ac power excess will be the power balance added to the purchase amount\n",
        "        ac_power_excess = max(ac_power_bal+self.step_purchased[self.current_step]+self.diesel_gen[self.current_step],0)\n",
        "        #the power that will flow through the rectifier is the minimum between the amount the DC grid can absorb and the excess the ac_grid has\n",
        "        rect_power = min(dc_power_absorb,ac_power_excess)\n",
        "\n",
        "        dc_power_avail = max(dc_power_bal,0) #lol just defined a new var for readability.\n",
        "        ac_power_need   = max(-ac_power_bal-self.step_purchased[self.current_step]-self.diesel_gen[self.current_step], 0) # calculate how much power the ac grid needs.\n",
        "        dc_power_excess = max(dc_power_avail - ac_power_need - avail_stor,0) #calculate how much power would be in excess if there was to be excess.\n",
        "        #inverter power is equal to the minimum val between the avail dc power and the needed power. Then since all excess power needs to go to the grid, if there is any extra energy after the ac_need has been met and the battery is fully charged, it is also sent through the inverter\n",
        "        invt_power = min(ac_power_need, dc_power_avail) + dc_power_excess\n",
        "        #set the attributes.\n",
        "        self.step_invt[self.current_step] = invt_power\n",
        "        self.step_rect[self.current_step] = rect_power\n",
        "\n",
        "    def tou_purchase_inc(self):\n",
        "        #Summer Months: 5.92, 2.09, 1.33\n",
        "        #Winter Months: 2.22, 1.66, 1.21\n",
        "        step_price = self.price_scaler.inverse_transform(self.purchase_price[self.current_step].reshape(-1,1))\n",
        "\n",
        "        if self.step_purchased[self.current_step] != 0:\n",
        "            if step_price < 1.5:\n",
        "                self.off_peak_purchases[self.current_step] = self.step_purchased[self.current_step]\n",
        "            elif step_price < 2.1:\n",
        "                self.standard_purchases[self.current_step] = self.step_purchased[self.current_step]\n",
        "            else:\n",
        "                self.peak_purchases[self.current_step] = self.step_purchased[self.current_step]\n",
        "\n",
        "\n",
        "#define a pointer (kinda, don't actually know what its called) a\n",
        "EMS = EMSv2_3\n",
        "\n",
        "# Register environment so I can use make_vec_env\n",
        "register(\n",
        "# unique identifier for the env `name-version`\n",
        "id=f\"{version}\",\n",
        "# path to the class for creating the env\n",
        "# Note: entry_point also accept a class as input (and not only a string)\n",
        "entry_point= EMS(),\n",
        "\n",
        ")\n",
        "\n",
        "#Check the environment with stable_baselines3 check_env.\n",
        "from stable_baselines3.common.env_checker import check_env\n",
        "env = EMS()\n",
        "check_env(env,warn = True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DG4gB2cM7tDY"
      },
      "source": [
        "**Load in the data for our specific microgrid.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0X9RBdXC_2PD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8474824b-be14-46b2-882e-934b1ac53526"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The reset observation space looks like: [0.         0.4765371  0.         0.         0.         0.\n",
            " 0.503227   0.17744356 0.08679992 0.09576204 0.09576204 0.09576204\n",
            " 0.09576204]\n",
            "After action 0: \n",
            "Battery level is: 0.0kWh\n",
            "Current  Power Balance 0.4765371084213257\n",
            "Forecasted  power bal 1 hour ahead: 0.5032269954681396.\n",
            "Forecasted  power bal 2 hour ahead: 0.17744356393814087. \n",
            "Forecasted  power bal 3 hour ahead: 0.08679991960525513. \n",
            "current Purchase Prcie: 0.09576204419136047.\n",
            "Forecasted  price 1 hour ahead: 0.09576204419136047. \n",
            "Forecasted  price 2 hour ahead: 0.09576204419136047. \n",
            "Forecasted  price 3 hour ahead: 0.09576204419136047. \n",
            "_________________________________________________________________________________________________________________\n",
            "\n",
            "After action 0: \n",
            "Battery level is: 1.0kWh\n",
            "Current  Power Balance 0.5032269954681396\n",
            "Forecasted  power bal 1 hour ahead: 0.17744356393814087.\n",
            "Forecasted  power bal 2 hour ahead: 0.08679991960525513. \n",
            "Forecasted  power bal 3 hour ahead: 0.08145827054977417. \n",
            "current Purchase Prcie: 0.09576204419136047.\n",
            "Forecasted  price 1 hour ahead: 0.09576204419136047. \n",
            "Forecasted  price 2 hour ahead: 0.09576204419136047. \n",
            "Forecasted  price 3 hour ahead: 0.09576204419136047. \n",
            "_________________________________________________________________________________________________________________\n",
            "\n",
            "After action 0: \n",
            "Battery level is: 1.0kWh\n",
            "Current  Power Balance 0.17744356393814087\n",
            "Forecasted  power bal 1 hour ahead: 0.08679991960525513.\n",
            "Forecasted  power bal 2 hour ahead: 0.08145827054977417. \n",
            "Forecasted  power bal 3 hour ahead: 0.0691261887550354. \n",
            "current Purchase Prcie: 0.09576204419136047.\n",
            "Forecasted  price 1 hour ahead: 0.09576204419136047. \n",
            "Forecasted  price 2 hour ahead: 0.09576204419136047. \n",
            "Forecasted  price 3 hour ahead: 0.21427208185195923. \n",
            "_________________________________________________________________________________________________________________\n",
            "\n",
            "After action 0: \n",
            "Battery level is: 1.0kWh\n",
            "Current  Power Balance 0.08679991960525513\n",
            "Forecasted  power bal 1 hour ahead: 0.08145827054977417.\n",
            "Forecasted  power bal 2 hour ahead: 0.0691261887550354. \n",
            "Forecasted  power bal 3 hour ahead: 0.11022838950157166. \n",
            "current Purchase Prcie: 0.09576204419136047.\n",
            "Forecasted  price 1 hour ahead: 0.09576204419136047. \n",
            "Forecasted  price 2 hour ahead: 0.21427208185195923. \n",
            "Forecasted  price 3 hour ahead: 0.0. \n",
            "_________________________________________________________________________________________________________________\n",
            "\n",
            "After action 100: \n",
            "Battery level is: 1.0kWh\n",
            "Current  Power Balance 0.08145827054977417\n",
            "Forecasted  power bal 1 hour ahead: 0.0691261887550354.\n",
            "Forecasted  power bal 2 hour ahead: 0.11022838950157166. \n",
            "Forecasted  power bal 3 hour ahead: 0.27048933506011963. \n",
            "current Purchase Prcie: 0.09576204419136047.\n",
            "Forecasted  price 1 hour ahead: 0.21427208185195923. \n",
            "Forecasted  price 2 hour ahead: 0.0. \n",
            "Forecasted  price 3 hour ahead: 0.09576204419136047. \n",
            "_________________________________________________________________________________________________________________\n",
            "\n",
            "Done iteration! Total reward accumulated is: -69461.25556554645\n"
          ]
        }
      ],
      "source": [
        "#need to import data from Github\n",
        "path_data = \"/content/EEE4022S_BNKJUL001_Thesis/PythonWorkspace/dataClean.csv\"\n",
        "data = pd.read_csv(path_data)\n",
        "\n",
        "path_pv_gen = \"/content/EEE4022S_BNKJUL001_Thesis/Generation/BNKJUL001_Thesis_solarGen500kWHomer.csv\"\n",
        "data_pv_gen = pd.read_csv(path_pv_gen)\n",
        "\n",
        "path_wind_gen = \"/content/EEE4022S_BNKJUL001_Thesis/Generation/BNKJUL001_Thesis_Wind500kGenHomer.csv\"\n",
        "data_wind_gen = pd.read_csv(path_wind_gen)\n",
        "\n",
        "#Not actually using this rn but will be soon :)\n",
        "path_shedding = \"/content/EEE4022S_BNKJUL001_Thesis/MatlabWorkSpace/loadShedding2022.csv\"\n",
        "data_shedding = pd.read_csv(path_shedding)\n",
        "load_shedding = data_shedding['LoadShedding'].values.astype(np.float32)\n",
        "\n",
        "wind_gen = data_wind_gen['Wind_Out'].values.astype(np.float32)\n",
        "PV_gen = data_pv_gen['PV_Out'].values.astype(np.float32)\n",
        "actual_gen = np.column_stack((wind_gen, PV_gen))\n",
        "#read in ac and DC load\n",
        "AC_load = data['AC'].values.astype(np.float32)\n",
        "DC_load = data['DC'].values.astype(np.float32)\n",
        "#stack em together for the input :)\n",
        "actual_load = np.column_stack((AC_load, DC_load))\n",
        "\n",
        "path_purchase_price = \"/content/EEE4022S_BNKJUL001_Thesis/PythonWorkspace/purchasePrice.csv\"\n",
        "data_purchase_price = pd.read_csv(path_purchase_price)\n",
        "purchase_price = data_purchase_price['Grid Power Price'].values.astype(np.float32)\n",
        "\n",
        "\n",
        "#define the base environment\n",
        "base_env = EMS(episode_len = 6000, actual_load = actual_load, actual_gen = actual_gen, bat_threshold = 100, bat_cap = 500, purchase_price = purchase_price,num_preds = 3)\n",
        "#going to print out a bunch of things to test the different spaces.\n",
        "obs,_    = base_env.reset()\n",
        "\n",
        "def print_obs(action_standby=0):\n",
        "    print(f\"After action {action_standby}: \" )\n",
        "    battery_level = obs[0]\n",
        "    print(f\"Battery level is: {battery_level}kWh\")\n",
        "    current_power_bal = obs[1]\n",
        "    print(f\"Current  Power Balance {current_power_bal}\")\n",
        "    power_forecast = obs[6:9]\n",
        "    print(f\"Forecasted  power bal 1 hour ahead: {power_forecast[0]}.\")\n",
        "    print(f\"Forecasted  power bal 2 hour ahead: {power_forecast[1]}. \")\n",
        "    print(f\"Forecasted  power bal 3 hour ahead: {power_forecast[2]}. \")\n",
        "    price = obs[9:]\n",
        "    print(f\"current Purchase Prcie: {price[0]}.\")\n",
        "    print(f\"Forecasted  price 1 hour ahead: {price[1]}. \")\n",
        "    print(f\"Forecasted  price 2 hour ahead: {price[2]}. \")\n",
        "    print(f\"Forecasted  price 3 hour ahead: {price[3]}. \")\n",
        "    print(f\"_________________________________________________________________________________________________________________\")\n",
        "    print(f\"\")\n",
        "\n",
        "print(f\"The reset observation space looks like: {obs}\")\n",
        "\n",
        "print_obs()\n",
        "\n",
        "action_standby = 0\n",
        "obs,reward,terminated,truncated,info = base_env.step(action_standby)\n",
        "\n",
        "print_obs()\n",
        "\n",
        "obs,reward,terminated,truncated,info = base_env.step(action_standby)\n",
        "\n",
        "print_obs()\n",
        "\n",
        "\n",
        "obs,reward,terminated,truncated,info = base_env.step(action_standby)\n",
        "print_obs()\n",
        "\n",
        "action_standby = 100\n",
        "obs,reward,terminated,truncated,info = base_env.step(action_standby)\n",
        "print_obs(action_standby)\n",
        "\n",
        "#Evaluate the base model (no EMS, just using standby mode)\n",
        "#A loop to get an average reward for the base model only perfoming the standby option\n",
        "#reset the environment and save the obs\n",
        "#going to run it 100 times to get a benchmark\n",
        "#reset score\n",
        "score = 0\n",
        "\n",
        "obs,_    = base_env.reset()\n",
        "#ensure that the exit condition is reset\n",
        "truncated = False\n",
        "#define the action to take\n",
        "action_standby = 0\n",
        "\n",
        "while not truncated:\n",
        "    obs,reward,terminated,truncated,info = base_env.step(action_standby)\n",
        "    score += reward\n",
        "\n",
        "print(f\"Done iteration! Total reward accumulated is: {score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pAj6-n04zyt"
      },
      "source": [
        "**LOAD OR MAKE MODEL HERE!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "gQDhUNGWeum4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "46b46ec0-2792-4437-a0f5-d89f8dff2034"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/notebook/utils.py:280: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
            "  return LooseVersion(v) >= LooseVersion(check)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbnkjul001_work\u001b[0m (\u001b[33m4022_intelligent_ems\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.12"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/EEE4022S_BNKJUL001_Thesis/wandb/run-20231017_211044-yh76b6nl</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/yh76b6nl' target=\"_blank\">fast-river-209</a></strong> to <a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems' target=\"_blank\">https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/yh76b6nl' target=\"_blank\">https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/yh76b6nl</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "Logging to runs/yh76b6nl/EMSv2_3_PPO_train20231017-211047_0\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 720       |\n",
            "|    ep_rew_mean     | -2.72e+05 |\n",
            "| time/              |           |\n",
            "|    fps             | 246       |\n",
            "|    iterations      | 1         |\n",
            "|    time_elapsed    | 41        |\n",
            "|    total_timesteps | 10240     |\n",
            "----------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 720         |\n",
            "|    ep_rew_mean          | -2.37e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 286         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 71          |\n",
            "|    total_timesteps      | 20480       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.023503179 |\n",
            "|    clip_fraction        | 0.246       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.35       |\n",
            "|    explained_variance   | -1.79e-06   |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 6.72e+06    |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0241     |\n",
            "|    std                  | 0.931       |\n",
            "|    value_loss           | 3.46e+07    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 720         |\n",
            "|    ep_rew_mean          | -2.08e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 306         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 100         |\n",
            "|    total_timesteps      | 30720       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.026968896 |\n",
            "|    clip_fraction        | 0.241       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.26       |\n",
            "|    explained_variance   | 3.58e-07    |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 2.43e+06    |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0271     |\n",
            "|    std                  | 0.861       |\n",
            "|    value_loss           | 1.65e+07    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 720         |\n",
            "|    ep_rew_mean          | -1.84e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 313         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 130         |\n",
            "|    total_timesteps      | 40960       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.027174134 |\n",
            "|    clip_fraction        | 0.225       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.17       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 1.11e+06    |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0254     |\n",
            "|    std                  | 0.765       |\n",
            "|    value_loss           | 7.75e+06    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 720         |\n",
            "|    ep_rew_mean          | -1.63e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 320         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 159         |\n",
            "|    total_timesteps      | 51200       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.024190193 |\n",
            "|    clip_fraction        | 0.208       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.06       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 3.78e+05    |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0192     |\n",
            "|    std                  | 0.68        |\n",
            "|    value_loss           | 3.24e+06    |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 720       |\n",
            "|    ep_rew_mean          | -2.18e+05 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 322       |\n",
            "|    iterations           | 6         |\n",
            "|    time_elapsed         | 190       |\n",
            "|    total_timesteps      | 61440     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 20.558367 |\n",
            "|    clip_fraction        | 0.293     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -1.01     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.01      |\n",
            "|    loss                 | 1.63e+05  |\n",
            "|    n_updates            | 50        |\n",
            "|    policy_gradient_loss | 0.0261    |\n",
            "|    std                  | 1.32      |\n",
            "|    value_loss           | 1.2e+06   |\n",
            "---------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 720          |\n",
            "|    ep_rew_mean          | -2.51e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 326          |\n",
            "|    iterations           | 7            |\n",
            "|    time_elapsed         | 219          |\n",
            "|    total_timesteps      | 71680        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022325087 |\n",
            "|    clip_fraction        | 0.0234       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.69        |\n",
            "|    explained_variance   | 5.96e-08     |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 2.27e+07     |\n",
            "|    n_updates            | 60           |\n",
            "|    policy_gradient_loss | 0.00033      |\n",
            "|    std                  | 1.31         |\n",
            "|    value_loss           | 1.3e+08      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 720          |\n",
            "|    ep_rew_mean          | -2.9e+05     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 325          |\n",
            "|    iterations           | 8            |\n",
            "|    time_elapsed         | 251          |\n",
            "|    total_timesteps      | 81920        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025317117 |\n",
            "|    clip_fraction        | 0.0127       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.69        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 2.96e+07     |\n",
            "|    n_updates            | 70           |\n",
            "|    policy_gradient_loss | -0.00144     |\n",
            "|    std                  | 1.3          |\n",
            "|    value_loss           | 1.3e+08      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 720          |\n",
            "|    ep_rew_mean          | -3.37e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 327          |\n",
            "|    iterations           | 9            |\n",
            "|    time_elapsed         | 281          |\n",
            "|    total_timesteps      | 92160        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026662226 |\n",
            "|    clip_fraction        | 0.019        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.68        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 2.11e+07     |\n",
            "|    n_updates            | 80           |\n",
            "|    policy_gradient_loss | -0.000408    |\n",
            "|    std                  | 1.3          |\n",
            "|    value_loss           | 1.32e+08     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 720          |\n",
            "|    ep_rew_mean          | -3.92e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 329          |\n",
            "|    iterations           | 10           |\n",
            "|    time_elapsed         | 310          |\n",
            "|    total_timesteps      | 102400       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040597315 |\n",
            "|    clip_fraction        | 0.0259       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.67        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 2.13e+07     |\n",
            "|    n_updates            | 90           |\n",
            "|    policy_gradient_loss | -0.000444    |\n",
            "|    std                  | 1.27         |\n",
            "|    value_loss           | 1.31e+08     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 720          |\n",
            "|    ep_rew_mean          | -4.54e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 331          |\n",
            "|    iterations           | 11           |\n",
            "|    time_elapsed         | 339          |\n",
            "|    total_timesteps      | 112640       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030537364 |\n",
            "|    clip_fraction        | 0.0316       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.65        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 1.89e+07     |\n",
            "|    n_updates            | 100          |\n",
            "|    policy_gradient_loss | -5.54e-05    |\n",
            "|    std                  | 1.27         |\n",
            "|    value_loss           | 1.3e+08      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 720          |\n",
            "|    ep_rew_mean          | -5.2e+05     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 330          |\n",
            "|    iterations           | 12           |\n",
            "|    time_elapsed         | 371          |\n",
            "|    total_timesteps      | 122880       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0053349826 |\n",
            "|    clip_fraction        | 0.0529       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.64        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 2.26e+07     |\n",
            "|    n_updates            | 110          |\n",
            "|    policy_gradient_loss | -0.000178    |\n",
            "|    std                  | 1.24         |\n",
            "|    value_loss           | 1.22e+08     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 720         |\n",
            "|    ep_rew_mean          | -5.28e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 332         |\n",
            "|    iterations           | 13          |\n",
            "|    time_elapsed         | 400         |\n",
            "|    total_timesteps      | 133120      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005414798 |\n",
            "|    clip_fraction        | 0.0468      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.62       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 2.04e+07    |\n",
            "|    n_updates            | 120         |\n",
            "|    policy_gradient_loss | 0.00087     |\n",
            "|    std                  | 1.23        |\n",
            "|    value_loss           | 1.13e+08    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 720          |\n",
            "|    ep_rew_mean          | -5.28e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 333          |\n",
            "|    iterations           | 14           |\n",
            "|    time_elapsed         | 430          |\n",
            "|    total_timesteps      | 143360       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0058587343 |\n",
            "|    clip_fraction        | 0.0549       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.61        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 2.26e+07     |\n",
            "|    n_updates            | 130          |\n",
            "|    policy_gradient_loss | 0.00105      |\n",
            "|    std                  | 1.21         |\n",
            "|    value_loss           | 1.07e+08     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 720         |\n",
            "|    ep_rew_mean          | -5.29e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 333         |\n",
            "|    iterations           | 15          |\n",
            "|    time_elapsed         | 461         |\n",
            "|    total_timesteps      | 153600      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005394154 |\n",
            "|    clip_fraction        | 0.0555      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.61       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 2.27e+07    |\n",
            "|    n_updates            | 140         |\n",
            "|    policy_gradient_loss | 0.00124     |\n",
            "|    std                  | 1.22        |\n",
            "|    value_loss           | 1.09e+08    |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 720        |\n",
            "|    ep_rew_mean          | -5.29e+05  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 334        |\n",
            "|    iterations           | 16         |\n",
            "|    time_elapsed         | 490        |\n",
            "|    total_timesteps      | 163840     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00458051 |\n",
            "|    clip_fraction        | 0.051      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.62      |\n",
            "|    explained_variance   | -1.19e-07  |\n",
            "|    learning_rate        | 0.01       |\n",
            "|    loss                 | 1.89e+07   |\n",
            "|    n_updates            | 150        |\n",
            "|    policy_gradient_loss | 0.000426   |\n",
            "|    std                  | 1.22       |\n",
            "|    value_loss           | 1.11e+08   |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 720          |\n",
            "|    ep_rew_mean          | -5.29e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 335          |\n",
            "|    iterations           | 17           |\n",
            "|    time_elapsed         | 519          |\n",
            "|    total_timesteps      | 174080       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0051398585 |\n",
            "|    clip_fraction        | 0.0503       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.63        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 1.69e+07     |\n",
            "|    n_updates            | 160          |\n",
            "|    policy_gradient_loss | 0.00143      |\n",
            "|    std                  | 1.25         |\n",
            "|    value_loss           | 1.09e+08     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 720         |\n",
            "|    ep_rew_mean          | -5.29e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 336         |\n",
            "|    iterations           | 18          |\n",
            "|    time_elapsed         | 547         |\n",
            "|    total_timesteps      | 184320      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006952224 |\n",
            "|    clip_fraction        | 0.063       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.61       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 1.95e+07    |\n",
            "|    n_updates            | 170         |\n",
            "|    policy_gradient_loss | -0.00114    |\n",
            "|    std                  | 1.23        |\n",
            "|    value_loss           | 1.07e+08    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 720         |\n",
            "|    ep_rew_mean          | -5.28e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 335         |\n",
            "|    iterations           | 19          |\n",
            "|    time_elapsed         | 579         |\n",
            "|    total_timesteps      | 194560      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006079086 |\n",
            "|    clip_fraction        | 0.0666      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.63       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 2.27e+07    |\n",
            "|    n_updates            | 180         |\n",
            "|    policy_gradient_loss | -0.0002     |\n",
            "|    std                  | 1.23        |\n",
            "|    value_loss           | 9.72e+07    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 720          |\n",
            "|    ep_rew_mean          | -5.28e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 336          |\n",
            "|    iterations           | 20           |\n",
            "|    time_elapsed         | 607          |\n",
            "|    total_timesteps      | 204800       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0069799805 |\n",
            "|    clip_fraction        | 0.0607       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.61        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 1.44e+07     |\n",
            "|    n_updates            | 190          |\n",
            "|    policy_gradient_loss | 0.000522     |\n",
            "|    std                  | 1.2          |\n",
            "|    value_loss           | 8.87e+07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 720          |\n",
            "|    ep_rew_mean          | -5.28e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 336          |\n",
            "|    iterations           | 21           |\n",
            "|    time_elapsed         | 639          |\n",
            "|    total_timesteps      | 215040       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0052125654 |\n",
            "|    clip_fraction        | 0.0534       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.59        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 1.81e+07     |\n",
            "|    n_updates            | 200          |\n",
            "|    policy_gradient_loss | 0.00082      |\n",
            "|    std                  | 1.19         |\n",
            "|    value_loss           | 9.09e+07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 720          |\n",
            "|    ep_rew_mean          | -5.28e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 336          |\n",
            "|    iterations           | 22           |\n",
            "|    time_elapsed         | 669          |\n",
            "|    total_timesteps      | 225280       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0072302595 |\n",
            "|    clip_fraction        | 0.0644       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.57        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 1.71e+07     |\n",
            "|    n_updates            | 210          |\n",
            "|    policy_gradient_loss | 0.000122     |\n",
            "|    std                  | 1.16         |\n",
            "|    value_loss           | 9.14e+07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 720          |\n",
            "|    ep_rew_mean          | -5.28e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 337          |\n",
            "|    iterations           | 23           |\n",
            "|    time_elapsed         | 698          |\n",
            "|    total_timesteps      | 235520       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0057864436 |\n",
            "|    clip_fraction        | 0.0635       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.58        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 1.65e+07     |\n",
            "|    n_updates            | 220          |\n",
            "|    policy_gradient_loss | 0.000451     |\n",
            "|    std                  | 1.18         |\n",
            "|    value_loss           | 9.09e+07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 720          |\n",
            "|    ep_rew_mean          | -5.28e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 338          |\n",
            "|    iterations           | 24           |\n",
            "|    time_elapsed         | 726          |\n",
            "|    total_timesteps      | 245760       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0061585275 |\n",
            "|    clip_fraction        | 0.0514       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.58        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 1.75e+07     |\n",
            "|    n_updates            | 230          |\n",
            "|    policy_gradient_loss | 0.00058      |\n",
            "|    std                  | 1.17         |\n",
            "|    value_loss           | 8.96e+07     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 720         |\n",
            "|    ep_rew_mean          | -5.28e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 337         |\n",
            "|    iterations           | 25          |\n",
            "|    time_elapsed         | 758         |\n",
            "|    total_timesteps      | 256000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004419811 |\n",
            "|    clip_fraction        | 0.0645      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.57       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 1.47e+07    |\n",
            "|    n_updates            | 240         |\n",
            "|    policy_gradient_loss | 0.00087     |\n",
            "|    std                  | 1.14        |\n",
            "|    value_loss           | 8.38e+07    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 720          |\n",
            "|    ep_rew_mean          | -5.29e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 338          |\n",
            "|    iterations           | 26           |\n",
            "|    time_elapsed         | 787          |\n",
            "|    total_timesteps      | 266240       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0072612045 |\n",
            "|    clip_fraction        | 0.0815       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.53        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 1.57e+07     |\n",
            "|    n_updates            | 250          |\n",
            "|    policy_gradient_loss | 0.00128      |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 7.55e+07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 720          |\n",
            "|    ep_rew_mean          | -5.29e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 338          |\n",
            "|    iterations           | 27           |\n",
            "|    time_elapsed         | 816          |\n",
            "|    total_timesteps      | 276480       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0075516314 |\n",
            "|    clip_fraction        | 0.0811       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.52        |\n",
            "|    explained_variance   | 5.96e-08     |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 1.31e+07     |\n",
            "|    n_updates            | 260          |\n",
            "|    policy_gradient_loss | 0.00174      |\n",
            "|    std                  | 1.13         |\n",
            "|    value_loss           | 7.26e+07     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 720         |\n",
            "|    ep_rew_mean          | -5.29e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 338         |\n",
            "|    iterations           | 28          |\n",
            "|    time_elapsed         | 847         |\n",
            "|    total_timesteps      | 286720      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006030758 |\n",
            "|    clip_fraction        | 0.0686      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.54       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 1.25e+07    |\n",
            "|    n_updates            | 270         |\n",
            "|    policy_gradient_loss | 0.00187     |\n",
            "|    std                  | 1.12        |\n",
            "|    value_loss           | 7.47e+07    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 720         |\n",
            "|    ep_rew_mean          | -5.29e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 338         |\n",
            "|    iterations           | 29          |\n",
            "|    time_elapsed         | 876         |\n",
            "|    total_timesteps      | 296960      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005774268 |\n",
            "|    clip_fraction        | 0.0646      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.54       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 1.63e+07    |\n",
            "|    n_updates            | 280         |\n",
            "|    policy_gradient_loss | 0.00169     |\n",
            "|    std                  | 1.12        |\n",
            "|    value_loss           | 7.59e+07    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 720         |\n",
            "|    ep_rew_mean          | -5.29e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 339         |\n",
            "|    iterations           | 30          |\n",
            "|    time_elapsed         | 905         |\n",
            "|    total_timesteps      | 307200      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007308365 |\n",
            "|    clip_fraction        | 0.0696      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.52       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 1.28e+07    |\n",
            "|    n_updates            | 290         |\n",
            "|    policy_gradient_loss | 0.00127     |\n",
            "|    std                  | 1.09        |\n",
            "|    value_loss           | 7.41e+07    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 720         |\n",
            "|    ep_rew_mean          | -5.28e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 339         |\n",
            "|    iterations           | 31          |\n",
            "|    time_elapsed         | 935         |\n",
            "|    total_timesteps      | 317440      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008674994 |\n",
            "|    clip_fraction        | 0.0765      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.5        |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 1.37e+07    |\n",
            "|    n_updates            | 300         |\n",
            "|    policy_gradient_loss | 0.00243     |\n",
            "|    std                  | 1.08        |\n",
            "|    value_loss           | 7.17e+07    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 720         |\n",
            "|    ep_rew_mean          | -5.28e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 339         |\n",
            "|    iterations           | 32          |\n",
            "|    time_elapsed         | 965         |\n",
            "|    total_timesteps      | 327680      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006870657 |\n",
            "|    clip_fraction        | 0.0808      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.5        |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 1.35e+07    |\n",
            "|    n_updates            | 310         |\n",
            "|    policy_gradient_loss | 0.00252     |\n",
            "|    std                  | 1.08        |\n",
            "|    value_loss           | 6.43e+07    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 720         |\n",
            "|    ep_rew_mean          | -5.28e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 339         |\n",
            "|    iterations           | 33          |\n",
            "|    time_elapsed         | 995         |\n",
            "|    total_timesteps      | 337920      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007300203 |\n",
            "|    clip_fraction        | 0.0727      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.49       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 1.14e+07    |\n",
            "|    n_updates            | 320         |\n",
            "|    policy_gradient_loss | 0.00231     |\n",
            "|    std                  | 1.07        |\n",
            "|    value_loss           | 5.81e+07    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 720         |\n",
            "|    ep_rew_mean          | -5.28e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 339         |\n",
            "|    iterations           | 34          |\n",
            "|    time_elapsed         | 1026        |\n",
            "|    total_timesteps      | 348160      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007526794 |\n",
            "|    clip_fraction        | 0.0878      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.47       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 1.24e+07    |\n",
            "|    n_updates            | 330         |\n",
            "|    policy_gradient_loss | 0.0045      |\n",
            "|    std                  | 1.06        |\n",
            "|    value_loss           | 6.1e+07     |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 720          |\n",
            "|    ep_rew_mean          | -5.28e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 339          |\n",
            "|    iterations           | 35           |\n",
            "|    time_elapsed         | 1055         |\n",
            "|    total_timesteps      | 358400       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0073530674 |\n",
            "|    clip_fraction        | 0.0824       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.46        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 1.01e+07     |\n",
            "|    n_updates            | 340          |\n",
            "|    policy_gradient_loss | 0.00237      |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 6.06e+07     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 720         |\n",
            "|    ep_rew_mean          | -5.28e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 339         |\n",
            "|    iterations           | 36          |\n",
            "|    time_elapsed         | 1085        |\n",
            "|    total_timesteps      | 368640      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013375106 |\n",
            "|    clip_fraction        | 0.106       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.44       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 1.09e+07    |\n",
            "|    n_updates            | 350         |\n",
            "|    policy_gradient_loss | 0.00144     |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 6.05e+07    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 720         |\n",
            "|    ep_rew_mean          | -5.28e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 340         |\n",
            "|    iterations           | 37          |\n",
            "|    time_elapsed         | 1114        |\n",
            "|    total_timesteps      | 378880      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010925463 |\n",
            "|    clip_fraction        | 0.099       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.42       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 9.08e+06    |\n",
            "|    n_updates            | 360         |\n",
            "|    policy_gradient_loss | 0.00283     |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 5.89e+07    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 720          |\n",
            "|    ep_rew_mean          | -5.28e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 339          |\n",
            "|    iterations           | 38           |\n",
            "|    time_elapsed         | 1145         |\n",
            "|    total_timesteps      | 389120       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0137480395 |\n",
            "|    clip_fraction        | 0.11         |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.41        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 9.54e+06     |\n",
            "|    n_updates            | 370          |\n",
            "|    policy_gradient_loss | 0.00403      |\n",
            "|    std                  | 0.999        |\n",
            "|    value_loss           | 5.39e+07     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 720         |\n",
            "|    ep_rew_mean          | -5.28e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 339         |\n",
            "|    iterations           | 39          |\n",
            "|    time_elapsed         | 1175        |\n",
            "|    total_timesteps      | 399360      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012113662 |\n",
            "|    clip_fraction        | 0.111       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.41       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 8.21e+06    |\n",
            "|    n_updates            | 380         |\n",
            "|    policy_gradient_loss | 0.00392     |\n",
            "|    std                  | 0.991       |\n",
            "|    value_loss           | 4.83e+07    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 720         |\n",
            "|    ep_rew_mean          | -5.28e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 339         |\n",
            "|    iterations           | 40          |\n",
            "|    time_elapsed         | 1205        |\n",
            "|    total_timesteps      | 409600      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012652801 |\n",
            "|    clip_fraction        | 0.104       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.4        |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 8.03e+06    |\n",
            "|    n_updates            | 390         |\n",
            "|    policy_gradient_loss | 0.00442     |\n",
            "|    std                  | 0.957       |\n",
            "|    value_loss           | 4.76e+07    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 720         |\n",
            "|    ep_rew_mean          | -5.27e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 339         |\n",
            "|    iterations           | 41          |\n",
            "|    time_elapsed         | 1234        |\n",
            "|    total_timesteps      | 419840      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009433998 |\n",
            "|    clip_fraction        | 0.0986      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.38       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 8.72e+06    |\n",
            "|    n_updates            | 400         |\n",
            "|    policy_gradient_loss | 0.00453     |\n",
            "|    std                  | 0.956       |\n",
            "|    value_loss           | 4.89e+07    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 720         |\n",
            "|    ep_rew_mean          | -5.27e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 340         |\n",
            "|    iterations           | 42          |\n",
            "|    time_elapsed         | 1264        |\n",
            "|    total_timesteps      | 430080      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010001302 |\n",
            "|    clip_fraction        | 0.103       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.36       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 9.87e+06    |\n",
            "|    n_updates            | 410         |\n",
            "|    policy_gradient_loss | 0.00317     |\n",
            "|    std                  | 0.932       |\n",
            "|    value_loss           | 4.89e+07    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 720         |\n",
            "|    ep_rew_mean          | -5.26e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 340         |\n",
            "|    iterations           | 43          |\n",
            "|    time_elapsed         | 1293        |\n",
            "|    total_timesteps      | 440320      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010171642 |\n",
            "|    clip_fraction        | 0.108       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.35       |\n",
            "|    explained_variance   | 5.96e-08    |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 9.41e+06    |\n",
            "|    n_updates            | 420         |\n",
            "|    policy_gradient_loss | 0.00477     |\n",
            "|    std                  | 0.914       |\n",
            "|    value_loss           | 4.7e+07     |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 720        |\n",
            "|    ep_rew_mean          | -5.26e+05  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 340        |\n",
            "|    iterations           | 44         |\n",
            "|    time_elapsed         | 1323       |\n",
            "|    total_timesteps      | 450560     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01414365 |\n",
            "|    clip_fraction        | 0.123      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.31      |\n",
            "|    explained_variance   | 0          |\n",
            "|    learning_rate        | 0.01       |\n",
            "|    loss                 | 7.8e+06    |\n",
            "|    n_updates            | 430        |\n",
            "|    policy_gradient_loss | 0.00545    |\n",
            "|    std                  | 0.902      |\n",
            "|    value_loss           | 4.47e+07   |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 720         |\n",
            "|    ep_rew_mean          | -5.25e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 340         |\n",
            "|    iterations           | 45          |\n",
            "|    time_elapsed         | 1353        |\n",
            "|    total_timesteps      | 460800      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019672599 |\n",
            "|    clip_fraction        | 0.148       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.33       |\n",
            "|    explained_variance   | 1.79e-07    |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 5.88e+06    |\n",
            "|    n_updates            | 440         |\n",
            "|    policy_gradient_loss | 0.0069      |\n",
            "|    std                  | 0.91        |\n",
            "|    value_loss           | 4.05e+07    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 720         |\n",
            "|    ep_rew_mean          | -5.25e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 340         |\n",
            "|    iterations           | 46          |\n",
            "|    time_elapsed         | 1382        |\n",
            "|    total_timesteps      | 471040      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019133296 |\n",
            "|    clip_fraction        | 0.157       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.31       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 6.4e+06     |\n",
            "|    n_updates            | 450         |\n",
            "|    policy_gradient_loss | 0.00768     |\n",
            "|    std                  | 0.916       |\n",
            "|    value_loss           | 3.69e+07    |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 720        |\n",
            "|    ep_rew_mean          | -5.27e+05  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 340        |\n",
            "|    iterations           | 47         |\n",
            "|    time_elapsed         | 1413       |\n",
            "|    total_timesteps      | 481280     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.12791571 |\n",
            "|    clip_fraction        | 0.144      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.33      |\n",
            "|    explained_variance   | 1.19e-07   |\n",
            "|    learning_rate        | 0.01       |\n",
            "|    loss                 | 8.47e+06   |\n",
            "|    n_updates            | 460        |\n",
            "|    policy_gradient_loss | 0.0106     |\n",
            "|    std                  | 0.925      |\n",
            "|    value_loss           | 3.92e+07   |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 720         |\n",
            "|    ep_rew_mean          | -5.29e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 340         |\n",
            "|    iterations           | 48          |\n",
            "|    time_elapsed         | 1442        |\n",
            "|    total_timesteps      | 491520      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012458399 |\n",
            "|    clip_fraction        | 0.11        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.34       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 7.57e+06    |\n",
            "|    n_updates            | 470         |\n",
            "|    policy_gradient_loss | 0.00584     |\n",
            "|    std                  | 0.933       |\n",
            "|    value_loss           | 4.22e+07    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 720         |\n",
            "|    ep_rew_mean          | -5.32e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 340         |\n",
            "|    iterations           | 49          |\n",
            "|    time_elapsed         | 1471        |\n",
            "|    total_timesteps      | 501760      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012452377 |\n",
            "|    clip_fraction        | 0.119       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.33       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 7.01e+06    |\n",
            "|    n_updates            | 480         |\n",
            "|    policy_gradient_loss | 0.00617     |\n",
            "|    std                  | 0.91        |\n",
            "|    value_loss           | 4.22e+07    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 720         |\n",
            "|    ep_rew_mean          | -5.35e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 341         |\n",
            "|    iterations           | 50          |\n",
            "|    time_elapsed         | 1501        |\n",
            "|    total_timesteps      | 512000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013945499 |\n",
            "|    clip_fraction        | 0.133       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.32       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 7.05e+06    |\n",
            "|    n_updates            | 490         |\n",
            "|    policy_gradient_loss | 0.00738     |\n",
            "|    std                  | 0.915       |\n",
            "|    value_loss           | 4.06e+07    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 720         |\n",
            "|    ep_rew_mean          | -5.37e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 340         |\n",
            "|    iterations           | 51          |\n",
            "|    time_elapsed         | 1533        |\n",
            "|    total_timesteps      | 522240      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.020881647 |\n",
            "|    clip_fraction        | 0.133       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.32       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 6.11e+06    |\n",
            "|    n_updates            | 500         |\n",
            "|    policy_gradient_loss | 0.0064      |\n",
            "|    std                  | 0.932       |\n",
            "|    value_loss           | 3.76e+07    |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 720       |\n",
            "|    ep_rew_mean          | -5.4e+05  |\n",
            "| time/                   |           |\n",
            "|    fps                  | 340       |\n",
            "|    iterations           | 52        |\n",
            "|    time_elapsed         | 1562      |\n",
            "|    total_timesteps      | 532480    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.9757002 |\n",
            "|    clip_fraction        | 0.2       |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -1.37     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.01      |\n",
            "|    loss                 | 6.51e+06  |\n",
            "|    n_updates            | 510       |\n",
            "|    policy_gradient_loss | 0.0255    |\n",
            "|    std                  | 0.96      |\n",
            "|    value_loss           | 3.39e+07  |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 720         |\n",
            "|    ep_rew_mean          | -5.44e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 340         |\n",
            "|    iterations           | 53          |\n",
            "|    time_elapsed         | 1593        |\n",
            "|    total_timesteps      | 542720      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.035310797 |\n",
            "|    clip_fraction        | 0.13        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.38       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 5.46e+06    |\n",
            "|    n_updates            | 520         |\n",
            "|    policy_gradient_loss | 0.00638     |\n",
            "|    std                  | 0.959       |\n",
            "|    value_loss           | 3.47e+07    |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 720        |\n",
            "|    ep_rew_mean          | -5.46e+05  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 340        |\n",
            "|    iterations           | 54         |\n",
            "|    time_elapsed         | 1622       |\n",
            "|    total_timesteps      | 552960     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.02736843 |\n",
            "|    clip_fraction        | 0.141      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.37      |\n",
            "|    explained_variance   | 1.79e-07   |\n",
            "|    learning_rate        | 0.01       |\n",
            "|    loss                 | 6.17e+06   |\n",
            "|    n_updates            | 530        |\n",
            "|    policy_gradient_loss | 0.00601    |\n",
            "|    std                  | 0.942      |\n",
            "|    value_loss           | 3.51e+07   |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 720         |\n",
            "|    ep_rew_mean          | -5.46e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 341         |\n",
            "|    iterations           | 55          |\n",
            "|    time_elapsed         | 1651        |\n",
            "|    total_timesteps      | 563200      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.030928154 |\n",
            "|    clip_fraction        | 0.147       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.34       |\n",
            "|    explained_variance   | 1.79e-07    |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 7.44e+06    |\n",
            "|    n_updates            | 540         |\n",
            "|    policy_gradient_loss | 0.00627     |\n",
            "|    std                  | 0.929       |\n",
            "|    value_loss           | 3.46e+07    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 720         |\n",
            "|    ep_rew_mean          | -5.46e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 341         |\n",
            "|    iterations           | 56          |\n",
            "|    time_elapsed         | 1680        |\n",
            "|    total_timesteps      | 573440      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019293794 |\n",
            "|    clip_fraction        | 0.139       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.32       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 5.16e+06    |\n",
            "|    n_updates            | 550         |\n",
            "|    policy_gradient_loss | 0.0068      |\n",
            "|    std                  | 0.901       |\n",
            "|    value_loss           | 3.24e+07    |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 720       |\n",
            "|    ep_rew_mean          | -5.46e+05 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 341       |\n",
            "|    iterations           | 57        |\n",
            "|    time_elapsed         | 1711      |\n",
            "|    total_timesteps      | 583680    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 21.485111 |\n",
            "|    clip_fraction        | 0.306     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -1.32     |\n",
            "|    explained_variance   | -1.19e-07 |\n",
            "|    learning_rate        | 0.01      |\n",
            "|    loss                 | 5.74e+06  |\n",
            "|    n_updates            | 560       |\n",
            "|    policy_gradient_loss | 0.063     |\n",
            "|    std                  | 0.982     |\n",
            "|    value_loss           | 3.14e+07  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 720       |\n",
            "|    ep_rew_mean          | -5.39e+05 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 341       |\n",
            "|    iterations           | 58        |\n",
            "|    time_elapsed         | 1740      |\n",
            "|    total_timesteps      | 593920    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 45.107414 |\n",
            "|    clip_fraction        | 0.325     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -1.46     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.01      |\n",
            "|    loss                 | 5.27e+06  |\n",
            "|    n_updates            | 570       |\n",
            "|    policy_gradient_loss | 0.0647    |\n",
            "|    std                  | 1.47      |\n",
            "|    value_loss           | 2.85e+07  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 720       |\n",
            "|    ep_rew_mean          | -5.33e+05 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 340       |\n",
            "|    iterations           | 59        |\n",
            "|    time_elapsed         | 1772      |\n",
            "|    total_timesteps      | 604160    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 13.449654 |\n",
            "|    clip_fraction        | 0.981     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.59     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.01      |\n",
            "|    loss                 | 4.07e+06  |\n",
            "|    n_updates            | 580       |\n",
            "|    policy_gradient_loss | 0.269     |\n",
            "|    std                  | 2.87      |\n",
            "|    value_loss           | 2.12e+07  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 720       |\n",
            "|    ep_rew_mean          | -5.28e+05 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 341       |\n",
            "|    iterations           | 60        |\n",
            "|    time_elapsed         | 1801      |\n",
            "|    total_timesteps      | 614400    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 1.6919155 |\n",
            "|    clip_fraction        | 0.251     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.49     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.01      |\n",
            "|    loss                 | 4.95e+06  |\n",
            "|    n_updates            | 590       |\n",
            "|    policy_gradient_loss | 0.0465    |\n",
            "|    std                  | 3.01      |\n",
            "|    value_loss           | 2.87e+07  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 720       |\n",
            "|    ep_rew_mean          | -5.34e+05 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 341       |\n",
            "|    iterations           | 61        |\n",
            "|    time_elapsed         | 1831      |\n",
            "|    total_timesteps      | 624640    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 10.930405 |\n",
            "|    clip_fraction        | 0.35      |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.6      |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.01      |\n",
            "|    loss                 | 5.39e+06  |\n",
            "|    n_updates            | 600       |\n",
            "|    policy_gradient_loss | 0.0893    |\n",
            "|    std                  | 4.33      |\n",
            "|    value_loss           | 2.79e+07  |\n",
            "---------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 720          |\n",
            "|    ep_rew_mean          | -5.44e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 341          |\n",
            "|    iterations           | 62           |\n",
            "|    time_elapsed         | 1860         |\n",
            "|    total_timesteps      | 634880       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022948906 |\n",
            "|    clip_fraction        | 0.0179       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.89        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 5.61e+06     |\n",
            "|    n_updates            | 610          |\n",
            "|    policy_gradient_loss | -0.000228    |\n",
            "|    std                  | 4.35         |\n",
            "|    value_loss           | 3e+07        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 720          |\n",
            "|    ep_rew_mean          | -5.54e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 340          |\n",
            "|    iterations           | 63           |\n",
            "|    time_elapsed         | 1892         |\n",
            "|    total_timesteps      | 645120       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028244085 |\n",
            "|    clip_fraction        | 0.0153       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.89        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 4.14e+06     |\n",
            "|    n_updates            | 620          |\n",
            "|    policy_gradient_loss | -0.00141     |\n",
            "|    std                  | 4.34         |\n",
            "|    value_loss           | 2.88e+07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 720          |\n",
            "|    ep_rew_mean          | -5.64e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 340          |\n",
            "|    iterations           | 64           |\n",
            "|    time_elapsed         | 1921         |\n",
            "|    total_timesteps      | 655360       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031330853 |\n",
            "|    clip_fraction        | 0.0156       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.88        |\n",
            "|    explained_variance   | 1.19e-07     |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 5.65e+06     |\n",
            "|    n_updates            | 630          |\n",
            "|    policy_gradient_loss | -9.5e-05     |\n",
            "|    std                  | 4.3          |\n",
            "|    value_loss           | 2.62e+07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 720          |\n",
            "|    ep_rew_mean          | -5.77e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 340          |\n",
            "|    iterations           | 65           |\n",
            "|    time_elapsed         | 1953         |\n",
            "|    total_timesteps      | 665600       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0047533326 |\n",
            "|    clip_fraction        | 0.0268       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.87        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 3.96e+06     |\n",
            "|    n_updates            | 640          |\n",
            "|    policy_gradient_loss | -0.000524    |\n",
            "|    std                  | 4.18         |\n",
            "|    value_loss           | 2.44e+07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 720          |\n",
            "|    ep_rew_mean          | -5.92e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 340          |\n",
            "|    iterations           | 66           |\n",
            "|    time_elapsed         | 1982         |\n",
            "|    total_timesteps      | 675840       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0058622276 |\n",
            "|    clip_fraction        | 0.0357       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.83        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 4.36e+06     |\n",
            "|    n_updates            | 650          |\n",
            "|    policy_gradient_loss | -0.000153    |\n",
            "|    std                  | 4.17         |\n",
            "|    value_loss           | 2.46e+07     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 720         |\n",
            "|    ep_rew_mean          | -6.06e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 340         |\n",
            "|    iterations           | 67          |\n",
            "|    time_elapsed         | 2011        |\n",
            "|    total_timesteps      | 686080      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006361539 |\n",
            "|    clip_fraction        | 0.0463      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.82       |\n",
            "|    explained_variance   | -1.19e-07   |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 5.07e+06    |\n",
            "|    n_updates            | 660         |\n",
            "|    policy_gradient_loss | -0.00102    |\n",
            "|    std                  | 4.16        |\n",
            "|    value_loss           | 2.47e+07    |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 720        |\n",
            "|    ep_rew_mean          | -6.12e+05  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 341        |\n",
            "|    iterations           | 68         |\n",
            "|    time_elapsed         | 2040       |\n",
            "|    total_timesteps      | 696320     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.18326363 |\n",
            "|    clip_fraction        | 0.0791     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -2.83      |\n",
            "|    explained_variance   | 0          |\n",
            "|    learning_rate        | 0.01       |\n",
            "|    loss                 | 3.69e+06   |\n",
            "|    n_updates            | 670        |\n",
            "|    policy_gradient_loss | 0.00477    |\n",
            "|    std                  | 4.83       |\n",
            "|    value_loss           | 2.44e+07   |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 720         |\n",
            "|    ep_rew_mean          | -6.15e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 341         |\n",
            "|    iterations           | 69          |\n",
            "|    time_elapsed         | 2071        |\n",
            "|    total_timesteps      | 706560      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004157054 |\n",
            "|    clip_fraction        | 0.0351      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.97       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 4.06e+06    |\n",
            "|    n_updates            | 680         |\n",
            "|    policy_gradient_loss | -0.00193    |\n",
            "|    std                  | 4.71        |\n",
            "|    value_loss           | 2.25e+07    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 720          |\n",
            "|    ep_rew_mean          | -6.18e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 341          |\n",
            "|    iterations           | 70           |\n",
            "|    time_elapsed         | 2100         |\n",
            "|    total_timesteps      | 716800       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035764042 |\n",
            "|    clip_fraction        | 0.0322       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.97        |\n",
            "|    explained_variance   | 1.19e-07     |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 3.63e+06     |\n",
            "|    n_updates            | 690          |\n",
            "|    policy_gradient_loss | -5.97e-05    |\n",
            "|    std                  | 4.66         |\n",
            "|    value_loss           | 2.03e+07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 720          |\n",
            "|    ep_rew_mean          | -6.2e+05     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 341          |\n",
            "|    iterations           | 71           |\n",
            "|    time_elapsed         | 2131         |\n",
            "|    total_timesteps      | 727040       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0062196013 |\n",
            "|    clip_fraction        | 0.0441       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.96        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 3.46e+06     |\n",
            "|    n_updates            | 700          |\n",
            "|    policy_gradient_loss | 0.000444     |\n",
            "|    std                  | 4.65         |\n",
            "|    value_loss           | 1.93e+07     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 720         |\n",
            "|    ep_rew_mean          | -6.2e+05    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 341         |\n",
            "|    iterations           | 72          |\n",
            "|    time_elapsed         | 2161        |\n",
            "|    total_timesteps      | 737280      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.027978797 |\n",
            "|    clip_fraction        | 0.0537      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.96       |\n",
            "|    explained_variance   | -1.19e-07   |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 3.19e+06    |\n",
            "|    n_updates            | 710         |\n",
            "|    policy_gradient_loss | 0.000345    |\n",
            "|    std                  | 5.44        |\n",
            "|    value_loss           | 1.82e+07    |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 720       |\n",
            "|    ep_rew_mean          | -6.21e+05 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 341       |\n",
            "|    iterations           | 73        |\n",
            "|    time_elapsed         | 2189      |\n",
            "|    total_timesteps      | 747520    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 4.269919  |\n",
            "|    clip_fraction        | 0.349     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -3.16     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.01      |\n",
            "|    loss                 | 3.65e+06  |\n",
            "|    n_updates            | 720       |\n",
            "|    policy_gradient_loss | 0.0689    |\n",
            "|    std                  | 7.7       |\n",
            "|    value_loss           | 2.07e+07  |\n",
            "---------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 720          |\n",
            "|    ep_rew_mean          | -6.24e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 341          |\n",
            "|    iterations           | 74           |\n",
            "|    time_elapsed         | 2218         |\n",
            "|    total_timesteps      | 757760       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0056949006 |\n",
            "|    clip_fraction        | 0.0237       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.45        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 4.11e+06     |\n",
            "|    n_updates            | 730          |\n",
            "|    policy_gradient_loss | 0.00172      |\n",
            "|    std                  | 7.52         |\n",
            "|    value_loss           | 2.38e+07     |\n",
            "------------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 720       |\n",
            "|    ep_rew_mean          | -6.13e+05 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 341       |\n",
            "|    iterations           | 75        |\n",
            "|    time_elapsed         | 2247      |\n",
            "|    total_timesteps      | 768000    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 1.9878814 |\n",
            "|    clip_fraction        | 0.0922    |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -3.44     |\n",
            "|    explained_variance   | 1.19e-07  |\n",
            "|    learning_rate        | 0.01      |\n",
            "|    loss                 | 4.4e+06   |\n",
            "|    n_updates            | 740       |\n",
            "|    policy_gradient_loss | 0.0208    |\n",
            "|    std                  | 8.41      |\n",
            "|    value_loss           | 2.11e+07  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 720       |\n",
            "|    ep_rew_mean          | -5.95e+05 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 341       |\n",
            "|    iterations           | 76        |\n",
            "|    time_elapsed         | 2278      |\n",
            "|    total_timesteps      | 778240    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.7799753 |\n",
            "|    clip_fraction        | 0.458     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -3.46     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.01      |\n",
            "|    loss                 | 4.79e+06  |\n",
            "|    n_updates            | 750       |\n",
            "|    policy_gradient_loss | 0.127     |\n",
            "|    std                  | 7.98      |\n",
            "|    value_loss           | 2.5e+07   |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 720       |\n",
            "|    ep_rew_mean          | -5.67e+05 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 341       |\n",
            "|    iterations           | 77        |\n",
            "|    time_elapsed         | 2309      |\n",
            "|    total_timesteps      | 788480    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 3.1132972 |\n",
            "|    clip_fraction        | 0.382     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -3.56     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.01      |\n",
            "|    loss                 | 4.91e+06  |\n",
            "|    n_updates            | 760       |\n",
            "|    policy_gradient_loss | 0.0859    |\n",
            "|    std                  | 8.12      |\n",
            "|    value_loss           | 2.94e+07  |\n",
            "---------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 720          |\n",
            "|    ep_rew_mean          | -5.47e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 341          |\n",
            "|    iterations           | 78           |\n",
            "|    time_elapsed         | 2338         |\n",
            "|    total_timesteps      | 798720       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017597616 |\n",
            "|    clip_fraction        | 0.00521      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.51        |\n",
            "|    explained_variance   | 1.19e-07     |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 4.59e+06     |\n",
            "|    n_updates            | 770          |\n",
            "|    policy_gradient_loss | -0.00107     |\n",
            "|    std                  | 8.02         |\n",
            "|    value_loss           | 2.67e+07     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 720         |\n",
            "|    ep_rew_mean          | -5.21e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 341         |\n",
            "|    iterations           | 79          |\n",
            "|    time_elapsed         | 2368        |\n",
            "|    total_timesteps      | 808960      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003995997 |\n",
            "|    clip_fraction        | 0.01        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.49       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 4.84e+06    |\n",
            "|    n_updates            | 780         |\n",
            "|    policy_gradient_loss | -0.00144    |\n",
            "|    std                  | 7.98        |\n",
            "|    value_loss           | 2.7e+07     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 720         |\n",
            "|    ep_rew_mean          | -4.93e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 341         |\n",
            "|    iterations           | 80          |\n",
            "|    time_elapsed         | 2397        |\n",
            "|    total_timesteps      | 819200      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.032409955 |\n",
            "|    clip_fraction        | 0.0642      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.49       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 3.57e+06    |\n",
            "|    n_updates            | 790         |\n",
            "|    policy_gradient_loss | 0.00404     |\n",
            "|    std                  | 7.77        |\n",
            "|    value_loss           | 2.47e+07    |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 720        |\n",
            "|    ep_rew_mean          | -4.59e+05  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 341        |\n",
            "|    iterations           | 81         |\n",
            "|    time_elapsed         | 2426       |\n",
            "|    total_timesteps      | 829440     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.31171662 |\n",
            "|    clip_fraction        | 0.193      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.52      |\n",
            "|    explained_variance   | 0          |\n",
            "|    learning_rate        | 0.01       |\n",
            "|    loss                 | 4.56e+06   |\n",
            "|    n_updates            | 800        |\n",
            "|    policy_gradient_loss | 0.0321     |\n",
            "|    std                  | 8.28       |\n",
            "|    value_loss           | 2.42e+07   |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 720        |\n",
            "|    ep_rew_mean          | -4.36e+05  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 341        |\n",
            "|    iterations           | 82         |\n",
            "|    time_elapsed         | 2457       |\n",
            "|    total_timesteps      | 839680     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.07974888 |\n",
            "|    clip_fraction        | 0.0349     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.52      |\n",
            "|    explained_variance   | 0          |\n",
            "|    learning_rate        | 0.01       |\n",
            "|    loss                 | 3.57e+06   |\n",
            "|    n_updates            | 810        |\n",
            "|    policy_gradient_loss | 0.00182    |\n",
            "|    std                  | 9.08       |\n",
            "|    value_loss           | 2.34e+07   |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 720          |\n",
            "|    ep_rew_mean          | -4.21e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 341          |\n",
            "|    iterations           | 83           |\n",
            "|    time_elapsed         | 2486         |\n",
            "|    total_timesteps      | 849920       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041948087 |\n",
            "|    clip_fraction        | 0.0286       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.62        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 4.21e+06     |\n",
            "|    n_updates            | 820          |\n",
            "|    policy_gradient_loss | 0.000249     |\n",
            "|    std                  | 9.02         |\n",
            "|    value_loss           | 2.44e+07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 720          |\n",
            "|    ep_rew_mean          | -4.17e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 341          |\n",
            "|    iterations           | 84           |\n",
            "|    time_elapsed         | 2518         |\n",
            "|    total_timesteps      | 860160       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0086304825 |\n",
            "|    clip_fraction        | 0.0194       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.62        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 4.09e+06     |\n",
            "|    n_updates            | 830          |\n",
            "|    policy_gradient_loss | 0.000429     |\n",
            "|    std                  | 9.52         |\n",
            "|    value_loss           | 2.4e+07      |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 720        |\n",
            "|    ep_rew_mean          | -4.11e+05  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 341        |\n",
            "|    iterations           | 85         |\n",
            "|    time_elapsed         | 2546       |\n",
            "|    total_timesteps      | 870400     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.06362302 |\n",
            "|    clip_fraction        | 0.0401     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.67      |\n",
            "|    explained_variance   | 0          |\n",
            "|    learning_rate        | 0.01       |\n",
            "|    loss                 | 4.72e+06   |\n",
            "|    n_updates            | 840        |\n",
            "|    policy_gradient_loss | 0.00258    |\n",
            "|    std                  | 9.29       |\n",
            "|    value_loss           | 2.4e+07    |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 720          |\n",
            "|    ep_rew_mean          | -4.05e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 341          |\n",
            "|    iterations           | 86           |\n",
            "|    time_elapsed         | 2575         |\n",
            "|    total_timesteps      | 880640       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030038978 |\n",
            "|    clip_fraction        | 0.0139       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.64        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 4.06e+06     |\n",
            "|    n_updates            | 850          |\n",
            "|    policy_gradient_loss | 6.23e-05     |\n",
            "|    std                  | 9.07         |\n",
            "|    value_loss           | 2.26e+07     |\n",
            "------------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 720       |\n",
            "|    ep_rew_mean          | -3.97e+05 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 342       |\n",
            "|    iterations           | 87        |\n",
            "|    time_elapsed         | 2604      |\n",
            "|    total_timesteps      | 890880    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.3616109 |\n",
            "|    clip_fraction        | 0.0828    |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -3.63     |\n",
            "|    explained_variance   | 1.19e-07  |\n",
            "|    learning_rate        | 0.01      |\n",
            "|    loss                 | 3.31e+06  |\n",
            "|    n_updates            | 860       |\n",
            "|    policy_gradient_loss | 0.00721   |\n",
            "|    std                  | 8.5       |\n",
            "|    value_loss           | 2.09e+07  |\n",
            "---------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 720          |\n",
            "|    ep_rew_mean          | -3.91e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 341          |\n",
            "|    iterations           | 88           |\n",
            "|    time_elapsed         | 2634         |\n",
            "|    total_timesteps      | 901120       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0049529104 |\n",
            "|    clip_fraction        | 0.0505       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.56        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 3.25e+06     |\n",
            "|    n_updates            | 870          |\n",
            "|    policy_gradient_loss | 0.00464      |\n",
            "|    std                  | 8.75         |\n",
            "|    value_loss           | 2.14e+07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 720          |\n",
            "|    ep_rew_mean          | -3.84e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 342          |\n",
            "|    iterations           | 89           |\n",
            "|    time_elapsed         | 2663         |\n",
            "|    total_timesteps      | 911360       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0078441175 |\n",
            "|    clip_fraction        | 0.0264       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.59        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 4.42e+06     |\n",
            "|    n_updates            | 880          |\n",
            "|    policy_gradient_loss | -0.000747    |\n",
            "|    std                  | 8.76         |\n",
            "|    value_loss           | 2.18e+07     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 720         |\n",
            "|    ep_rew_mean          | -3.77e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 342         |\n",
            "|    iterations           | 90          |\n",
            "|    time_elapsed         | 2694        |\n",
            "|    total_timesteps      | 921600      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003175127 |\n",
            "|    clip_fraction        | 0.0259      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.58       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 3.9e+06     |\n",
            "|    n_updates            | 890         |\n",
            "|    policy_gradient_loss | -0.000703   |\n",
            "|    std                  | 8.45        |\n",
            "|    value_loss           | 2.14e+07    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 720          |\n",
            "|    ep_rew_mean          | -3.73e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 342          |\n",
            "|    iterations           | 91           |\n",
            "|    time_elapsed         | 2722         |\n",
            "|    total_timesteps      | 931840       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041396143 |\n",
            "|    clip_fraction        | 0.0166       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.56        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 4.19e+06     |\n",
            "|    n_updates            | 900          |\n",
            "|    policy_gradient_loss | -0.000398    |\n",
            "|    std                  | 8.43         |\n",
            "|    value_loss           | 2.04e+07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 720          |\n",
            "|    ep_rew_mean          | -3.67e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 342          |\n",
            "|    iterations           | 92           |\n",
            "|    time_elapsed         | 2751         |\n",
            "|    total_timesteps      | 942080       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0067478716 |\n",
            "|    clip_fraction        | 0.0375       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.54        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 3.92e+06     |\n",
            "|    n_updates            | 910          |\n",
            "|    policy_gradient_loss | 0.000385     |\n",
            "|    std                  | 8.31         |\n",
            "|    value_loss           | 2.11e+07     |\n",
            "------------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 720       |\n",
            "|    ep_rew_mean          | -3.75e+05 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 342       |\n",
            "|    iterations           | 93        |\n",
            "|    time_elapsed         | 2780      |\n",
            "|    total_timesteps      | 952320    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 2.9677627 |\n",
            "|    clip_fraction        | 0.422     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -3.42     |\n",
            "|    explained_variance   | 1.19e-07  |\n",
            "|    learning_rate        | 0.01      |\n",
            "|    loss                 | 3.52e+06  |\n",
            "|    n_updates            | 920       |\n",
            "|    policy_gradient_loss | 0.154     |\n",
            "|    std                  | 7.85      |\n",
            "|    value_loss           | 1.91e+07  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 720       |\n",
            "|    ep_rew_mean          | -3.96e+05 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 342       |\n",
            "|    iterations           | 94        |\n",
            "|    time_elapsed         | 2811      |\n",
            "|    total_timesteps      | 962560    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 1.4510789 |\n",
            "|    clip_fraction        | 0.286     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -3.55     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.01      |\n",
            "|    loss                 | 5.13e+06  |\n",
            "|    n_updates            | 930       |\n",
            "|    policy_gradient_loss | 0.0592    |\n",
            "|    std                  | 8.23      |\n",
            "|    value_loss           | 2.57e+07  |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 720         |\n",
            "|    ep_rew_mean          | -4.19e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 342         |\n",
            "|    iterations           | 95          |\n",
            "|    time_elapsed         | 2840        |\n",
            "|    total_timesteps      | 972800      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004988955 |\n",
            "|    clip_fraction        | 0.0328      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.51       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 6.08e+06    |\n",
            "|    n_updates            | 940         |\n",
            "|    policy_gradient_loss | -0.000427   |\n",
            "|    std                  | 8.01        |\n",
            "|    value_loss           | 2.87e+07    |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 720        |\n",
            "|    ep_rew_mean          | -4.41e+05  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 342        |\n",
            "|    iterations           | 96         |\n",
            "|    time_elapsed         | 2871       |\n",
            "|    total_timesteps      | 983040     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.06829437 |\n",
            "|    clip_fraction        | 0.142      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.49      |\n",
            "|    explained_variance   | 0          |\n",
            "|    learning_rate        | 0.01       |\n",
            "|    loss                 | 6.08e+06   |\n",
            "|    n_updates            | 950        |\n",
            "|    policy_gradient_loss | 0.0133     |\n",
            "|    std                  | 8.1        |\n",
            "|    value_loss           | 2.89e+07   |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 720       |\n",
            "|    ep_rew_mean          | -4.56e+05 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 342       |\n",
            "|    iterations           | 97        |\n",
            "|    time_elapsed         | 2900      |\n",
            "|    total_timesteps      | 993280    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.078387  |\n",
            "|    clip_fraction        | 0.195     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -3.53     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.01      |\n",
            "|    loss                 | 5.52e+06  |\n",
            "|    n_updates            | 960       |\n",
            "|    policy_gradient_loss | 0.0223    |\n",
            "|    std                  | 7.78      |\n",
            "|    value_loss           | 2.68e+07  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 720       |\n",
            "|    ep_rew_mean          | -4.77e+05 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 342       |\n",
            "|    iterations           | 98        |\n",
            "|    time_elapsed         | 2928      |\n",
            "|    total_timesteps      | 1003520   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.5400322 |\n",
            "|    clip_fraction        | 0.38      |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -3.38     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.01      |\n",
            "|    loss                 | 5.81e+06  |\n",
            "|    n_updates            | 970       |\n",
            "|    policy_gradient_loss | 0.0558    |\n",
            "|    std                  | 6.41      |\n",
            "|    value_loss           | 2.73e+07  |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 720       |\n",
            "|    ep_rew_mean          | -4.83e+05 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 342       |\n",
            "|    iterations           | 99        |\n",
            "|    time_elapsed         | 2957      |\n",
            "|    total_timesteps      | 1013760   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 7.7990456 |\n",
            "|    clip_fraction        | 0.559     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -3.36     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.01      |\n",
            "|    loss                 | 5.9e+06   |\n",
            "|    n_updates            | 980       |\n",
            "|    policy_gradient_loss | 0.125     |\n",
            "|    std                  | 6.51      |\n",
            "|    value_loss           | 2.56e+07  |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 720        |\n",
            "|    ep_rew_mean          | -4.72e+05  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 342        |\n",
            "|    iterations           | 100        |\n",
            "|    time_elapsed         | 2988       |\n",
            "|    total_timesteps      | 1024000    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.06542202 |\n",
            "|    clip_fraction        | 0.0779     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.3       |\n",
            "|    explained_variance   | 0          |\n",
            "|    learning_rate        | 0.01       |\n",
            "|    loss                 | 2.73e+06   |\n",
            "|    n_updates            | 990        |\n",
            "|    policy_gradient_loss | 0.00213    |\n",
            "|    std                  | 6.77       |\n",
            "|    value_loss           | 1.73e+07   |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 720         |\n",
            "|    ep_rew_mean          | -4.42e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 342         |\n",
            "|    iterations           | 101         |\n",
            "|    time_elapsed         | 3017        |\n",
            "|    total_timesteps      | 1034240     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.057521306 |\n",
            "|    clip_fraction        | 0.166       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.37       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 2.21e+06    |\n",
            "|    n_updates            | 1000        |\n",
            "|    policy_gradient_loss | 0.0193      |\n",
            "|    std                  | 6.97        |\n",
            "|    value_loss           | 1.54e+07    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 720         |\n",
            "|    ep_rew_mean          | -4.04e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 342         |\n",
            "|    iterations           | 102         |\n",
            "|    time_elapsed         | 3048        |\n",
            "|    total_timesteps      | 1044480     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010018297 |\n",
            "|    clip_fraction        | 0.0868      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.38       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 3.04e+06    |\n",
            "|    n_updates            | 1010        |\n",
            "|    policy_gradient_loss | -0.00824    |\n",
            "|    std                  | 7.23        |\n",
            "|    value_loss           | 1.82e+07    |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 720        |\n",
            "|    ep_rew_mean          | -3.76e+05  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 342        |\n",
            "|    iterations           | 103        |\n",
            "|    time_elapsed         | 3077       |\n",
            "|    total_timesteps      | 1054720    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00723394 |\n",
            "|    clip_fraction        | 0.0867     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.4       |\n",
            "|    explained_variance   | 1.79e-07   |\n",
            "|    learning_rate        | 0.01       |\n",
            "|    loss                 | 3.28e+06   |\n",
            "|    n_updates            | 1020       |\n",
            "|    policy_gradient_loss | -0.00807   |\n",
            "|    std                  | 7.32       |\n",
            "|    value_loss           | 2.08e+07   |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 720          |\n",
            "|    ep_rew_mean          | -3.33e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 342          |\n",
            "|    iterations           | 104          |\n",
            "|    time_elapsed         | 3106         |\n",
            "|    total_timesteps      | 1064960      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0112000415 |\n",
            "|    clip_fraction        | 0.119        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.43        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 3.37e+06     |\n",
            "|    n_updates            | 1030         |\n",
            "|    policy_gradient_loss | -0.0117      |\n",
            "|    std                  | 7.56         |\n",
            "|    value_loss           | 2.22e+07     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 720         |\n",
            "|    ep_rew_mean          | -2.85e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 342         |\n",
            "|    iterations           | 105         |\n",
            "|    time_elapsed         | 3142        |\n",
            "|    total_timesteps      | 1075200     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009787515 |\n",
            "|    clip_fraction        | 0.124       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.47       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 3.99e+06    |\n",
            "|    n_updates            | 1040        |\n",
            "|    policy_gradient_loss | -0.0128     |\n",
            "|    std                  | 7.83        |\n",
            "|    value_loss           | 2.48e+07    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 720         |\n",
            "|    ep_rew_mean          | -2.5e+05    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 342         |\n",
            "|    iterations           | 106         |\n",
            "|    time_elapsed         | 3173        |\n",
            "|    total_timesteps      | 1085440     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010162739 |\n",
            "|    clip_fraction        | 0.127       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.45       |\n",
            "|    explained_variance   | 1.19e-07    |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 4.63e+06    |\n",
            "|    n_updates            | 1050        |\n",
            "|    policy_gradient_loss | -0.013      |\n",
            "|    std                  | 7.55        |\n",
            "|    value_loss           | 2.69e+07    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 720         |\n",
            "|    ep_rew_mean          | -2.14e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 341         |\n",
            "|    iterations           | 107         |\n",
            "|    time_elapsed         | 3206        |\n",
            "|    total_timesteps      | 1095680     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011623929 |\n",
            "|    clip_fraction        | 0.136       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.41       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 4.58e+06    |\n",
            "|    n_updates            | 1060        |\n",
            "|    policy_gradient_loss | -0.0148     |\n",
            "|    std                  | 7.34        |\n",
            "|    value_loss           | 2.92e+07    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 720         |\n",
            "|    ep_rew_mean          | -1.85e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 341         |\n",
            "|    iterations           | 108         |\n",
            "|    time_elapsed         | 3237        |\n",
            "|    total_timesteps      | 1105920     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012032432 |\n",
            "|    clip_fraction        | 0.115       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.37       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 5.02e+06    |\n",
            "|    n_updates            | 1070        |\n",
            "|    policy_gradient_loss | -0.0136     |\n",
            "|    std                  | 7.03        |\n",
            "|    value_loss           | 3.34e+07    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 720         |\n",
            "|    ep_rew_mean          | -1.58e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 341         |\n",
            "|    iterations           | 109         |\n",
            "|    time_elapsed         | 3266        |\n",
            "|    total_timesteps      | 1116160     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011074298 |\n",
            "|    clip_fraction        | 0.104       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.32       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 6.05e+06    |\n",
            "|    n_updates            | 1080        |\n",
            "|    policy_gradient_loss | -0.0145     |\n",
            "|    std                  | 6.62        |\n",
            "|    value_loss           | 3.73e+07    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 720         |\n",
            "|    ep_rew_mean          | -1.41e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 341         |\n",
            "|    iterations           | 110         |\n",
            "|    time_elapsed         | 3294        |\n",
            "|    total_timesteps      | 1126400     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007049978 |\n",
            "|    clip_fraction        | 0.0734      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.27       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 6.78e+06    |\n",
            "|    n_updates            | 1090        |\n",
            "|    policy_gradient_loss | -0.00962    |\n",
            "|    std                  | 6.49        |\n",
            "|    value_loss           | 4.11e+07    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 720         |\n",
            "|    ep_rew_mean          | -1.18e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 341         |\n",
            "|    iterations           | 111         |\n",
            "|    time_elapsed         | 3323        |\n",
            "|    total_timesteps      | 1136640     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008563875 |\n",
            "|    clip_fraction        | 0.084       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.26       |\n",
            "|    explained_variance   | -1.19e-07   |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 7.25e+06    |\n",
            "|    n_updates            | 1100        |\n",
            "|    policy_gradient_loss | -0.011      |\n",
            "|    std                  | 6.29        |\n",
            "|    value_loss           | 4.24e+07    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 720          |\n",
            "|    ep_rew_mean          | -9.89e+04    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 341          |\n",
            "|    iterations           | 112          |\n",
            "|    time_elapsed         | 3354         |\n",
            "|    total_timesteps      | 1146880      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0054834043 |\n",
            "|    clip_fraction        | 0.053        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.21        |\n",
            "|    explained_variance   | 1.19e-07     |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 6.99e+06     |\n",
            "|    n_updates            | 1110         |\n",
            "|    policy_gradient_loss | -0.00735     |\n",
            "|    std                  | 6.1          |\n",
            "|    value_loss           | 4.19e+07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 720          |\n",
            "|    ep_rew_mean          | -8.25e+04    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 341          |\n",
            "|    iterations           | 113          |\n",
            "|    time_elapsed         | 3384         |\n",
            "|    total_timesteps      | 1157120      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0065876385 |\n",
            "|    clip_fraction        | 0.0606       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.19        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 7.32e+06     |\n",
            "|    n_updates            | 1120         |\n",
            "|    policy_gradient_loss | -0.00684     |\n",
            "|    std                  | 5.93         |\n",
            "|    value_loss           | 4.17e+07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 720          |\n",
            "|    ep_rew_mean          | -6.97e+04    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 341          |\n",
            "|    iterations           | 114          |\n",
            "|    time_elapsed         | 3413         |\n",
            "|    total_timesteps      | 1167360      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0050832657 |\n",
            "|    clip_fraction        | 0.047        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.17        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 6.93e+06     |\n",
            "|    n_updates            | 1130         |\n",
            "|    policy_gradient_loss | -0.00443     |\n",
            "|    std                  | 5.77         |\n",
            "|    value_loss           | 4.14e+07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 720          |\n",
            "|    ep_rew_mean          | -5.95e+04    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 342          |\n",
            "|    iterations           | 115          |\n",
            "|    time_elapsed         | 3441         |\n",
            "|    total_timesteps      | 1177600      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032086652 |\n",
            "|    clip_fraction        | 0.0272       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.14        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 6.71e+06     |\n",
            "|    n_updates            | 1140         |\n",
            "|    policy_gradient_loss | -0.00242     |\n",
            "|    std                  | 5.6          |\n",
            "|    value_loss           | 4.03e+07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 720          |\n",
            "|    ep_rew_mean          | -5.53e+04    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 342          |\n",
            "|    iterations           | 116          |\n",
            "|    time_elapsed         | 3470         |\n",
            "|    total_timesteps      | 1187840      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028301657 |\n",
            "|    clip_fraction        | 0.0187       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.12        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 6.47e+06     |\n",
            "|    n_updates            | 1150         |\n",
            "|    policy_gradient_loss | -0.00174     |\n",
            "|    std                  | 5.45         |\n",
            "|    value_loss           | 3.88e+07     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 720         |\n",
            "|    ep_rew_mean          | -4.99e+04   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 342         |\n",
            "|    iterations           | 117         |\n",
            "|    time_elapsed         | 3500        |\n",
            "|    total_timesteps      | 1198080     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003116267 |\n",
            "|    clip_fraction        | 0.0216      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.11       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 6.63e+06    |\n",
            "|    n_updates            | 1160        |\n",
            "|    policy_gradient_loss | -0.00219    |\n",
            "|    std                  | 5.47        |\n",
            "|    value_loss           | 3.74e+07    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 720          |\n",
            "|    ep_rew_mean          | -4.61e+04    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 342          |\n",
            "|    iterations           | 118          |\n",
            "|    time_elapsed         | 3530         |\n",
            "|    total_timesteps      | 1208320      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028058724 |\n",
            "|    clip_fraction        | 0.0186       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.11        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 6.11e+06     |\n",
            "|    n_updates            | 1170         |\n",
            "|    policy_gradient_loss | -0.00162     |\n",
            "|    std                  | 5.39         |\n",
            "|    value_loss           | 3.54e+07     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 720         |\n",
            "|    ep_rew_mean          | -4.3e+04    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 342         |\n",
            "|    iterations           | 119         |\n",
            "|    time_elapsed         | 3561        |\n",
            "|    total_timesteps      | 1218560     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003130526 |\n",
            "|    clip_fraction        | 0.0209      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.09       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 5.07e+06    |\n",
            "|    n_updates            | 1180        |\n",
            "|    policy_gradient_loss | -0.00149    |\n",
            "|    std                  | 5.27        |\n",
            "|    value_loss           | 3.39e+07    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 720          |\n",
            "|    ep_rew_mean          | -4.1e+04     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 342          |\n",
            "|    iterations           | 120          |\n",
            "|    time_elapsed         | 3591         |\n",
            "|    total_timesteps      | 1228800      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022930647 |\n",
            "|    clip_fraction        | 0.00886      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.08        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 5.72e+06     |\n",
            "|    n_updates            | 1190         |\n",
            "|    policy_gradient_loss | -0.000178    |\n",
            "|    std                  | 5.18         |\n",
            "|    value_loss           | 3.27e+07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 720          |\n",
            "|    ep_rew_mean          | -3.96e+04    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 342          |\n",
            "|    iterations           | 121          |\n",
            "|    time_elapsed         | 3620         |\n",
            "|    total_timesteps      | 1239040      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019267105 |\n",
            "|    clip_fraction        | 0.0156       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.03        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 4.76e+06     |\n",
            "|    n_updates            | 1200         |\n",
            "|    policy_gradient_loss | -0.000748    |\n",
            "|    std                  | 4.99         |\n",
            "|    value_loss           | 3.04e+07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 720          |\n",
            "|    ep_rew_mean          | -3.89e+04    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 342          |\n",
            "|    iterations           | 122          |\n",
            "|    time_elapsed         | 3648         |\n",
            "|    total_timesteps      | 1249280      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020847141 |\n",
            "|    clip_fraction        | 0.0183       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.03        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 4.56e+06     |\n",
            "|    n_updates            | 1210         |\n",
            "|    policy_gradient_loss | -0.000776    |\n",
            "|    std                  | 5.06         |\n",
            "|    value_loss           | 2.83e+07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 720          |\n",
            "|    ep_rew_mean          | -3.85e+04    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 342          |\n",
            "|    iterations           | 123          |\n",
            "|    time_elapsed         | 3678         |\n",
            "|    total_timesteps      | 1259520      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018671621 |\n",
            "|    clip_fraction        | 0.00906      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.05        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 4.34e+06     |\n",
            "|    n_updates            | 1220         |\n",
            "|    policy_gradient_loss | 0.000131     |\n",
            "|    std                  | 5.13         |\n",
            "|    value_loss           | 2.65e+07     |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 720        |\n",
            "|    ep_rew_mean          | -3.8e+04   |\n",
            "| time/                   |            |\n",
            "|    fps                  | 342        |\n",
            "|    iterations           | 124        |\n",
            "|    time_elapsed         | 3707       |\n",
            "|    total_timesteps      | 1269760    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00243418 |\n",
            "|    clip_fraction        | 0.0194     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.02      |\n",
            "|    explained_variance   | 0          |\n",
            "|    learning_rate        | 0.01       |\n",
            "|    loss                 | 3.98e+06   |\n",
            "|    n_updates            | 1230       |\n",
            "|    policy_gradient_loss | -0.0011    |\n",
            "|    std                  | 4.89       |\n",
            "|    value_loss           | 2.49e+07   |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 720          |\n",
            "|    ep_rew_mean          | -3.75e+04    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 342          |\n",
            "|    iterations           | 125          |\n",
            "|    time_elapsed         | 3737         |\n",
            "|    total_timesteps      | 1280000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031914506 |\n",
            "|    clip_fraction        | 0.0282       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3.01        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 3.99e+06     |\n",
            "|    n_updates            | 1240         |\n",
            "|    policy_gradient_loss | -0.00136     |\n",
            "|    std                  | 4.91         |\n",
            "|    value_loss           | 2.35e+07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 720          |\n",
            "|    ep_rew_mean          | -3.74e+04    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 342          |\n",
            "|    iterations           | 126          |\n",
            "|    time_elapsed         | 3766         |\n",
            "|    total_timesteps      | 1290240      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023190754 |\n",
            "|    clip_fraction        | 0.0171       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -3           |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 3.63e+06     |\n",
            "|    n_updates            | 1250         |\n",
            "|    policy_gradient_loss | -0.000537    |\n",
            "|    std                  | 4.91         |\n",
            "|    value_loss           | 2.23e+07     |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 720        |\n",
            "|    ep_rew_mean          | -3.73e+04  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 342        |\n",
            "|    iterations           | 127        |\n",
            "|    time_elapsed         | 3795       |\n",
            "|    total_timesteps      | 1300480    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00438938 |\n",
            "|    clip_fraction        | 0.0264     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3         |\n",
            "|    explained_variance   | 0          |\n",
            "|    learning_rate        | 0.01       |\n",
            "|    loss                 | 2.92e+06   |\n",
            "|    n_updates            | 1260       |\n",
            "|    policy_gradient_loss | -0.00143   |\n",
            "|    std                  | 4.88       |\n",
            "|    value_loss           | 2.06e+07   |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 720          |\n",
            "|    ep_rew_mean          | -3.71e+04    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 342          |\n",
            "|    iterations           | 128          |\n",
            "|    time_elapsed         | 3824         |\n",
            "|    total_timesteps      | 1310720      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036377641 |\n",
            "|    clip_fraction        | 0.0249       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.98        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 3.23e+06     |\n",
            "|    n_updates            | 1270         |\n",
            "|    policy_gradient_loss | -0.00127     |\n",
            "|    std                  | 4.73         |\n",
            "|    value_loss           | 1.88e+07     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 720         |\n",
            "|    ep_rew_mean          | -3.71e+04   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 342         |\n",
            "|    iterations           | 129         |\n",
            "|    time_elapsed         | 3854        |\n",
            "|    total_timesteps      | 1320960     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002817539 |\n",
            "|    clip_fraction        | 0.0181      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.94       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 2.54e+06    |\n",
            "|    n_updates            | 1280        |\n",
            "|    policy_gradient_loss | -0.000398   |\n",
            "|    std                  | 4.53        |\n",
            "|    value_loss           | 1.71e+07    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 720          |\n",
            "|    ep_rew_mean          | -3.7e+04     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 342          |\n",
            "|    iterations           | 130          |\n",
            "|    time_elapsed         | 3883         |\n",
            "|    total_timesteps      | 1331200      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028394884 |\n",
            "|    clip_fraction        | 0.0187       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.93        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 2.25e+06     |\n",
            "|    n_updates            | 1290         |\n",
            "|    policy_gradient_loss | -0.000487    |\n",
            "|    std                  | 4.53         |\n",
            "|    value_loss           | 1.61e+07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 720          |\n",
            "|    ep_rew_mean          | -3.68e+04    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 342          |\n",
            "|    iterations           | 131          |\n",
            "|    time_elapsed         | 3914         |\n",
            "|    total_timesteps      | 1341440      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017232571 |\n",
            "|    clip_fraction        | 0.0127       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.91        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 2.33e+06     |\n",
            "|    n_updates            | 1300         |\n",
            "|    policy_gradient_loss | -0.000196    |\n",
            "|    std                  | 4.39         |\n",
            "|    value_loss           | 1.47e+07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 720          |\n",
            "|    ep_rew_mean          | -3.67e+04    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 342          |\n",
            "|    iterations           | 132          |\n",
            "|    time_elapsed         | 3943         |\n",
            "|    total_timesteps      | 1351680      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023420309 |\n",
            "|    clip_fraction        | 0.0117       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.9         |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 2.12e+06     |\n",
            "|    n_updates            | 1310         |\n",
            "|    policy_gradient_loss | 0.000298     |\n",
            "|    std                  | 4.5          |\n",
            "|    value_loss           | 1.36e+07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 720          |\n",
            "|    ep_rew_mean          | -3.66e+04    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 342          |\n",
            "|    iterations           | 133          |\n",
            "|    time_elapsed         | 3971         |\n",
            "|    total_timesteps      | 1361920      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013199364 |\n",
            "|    clip_fraction        | 0.00903      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.91        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 1.88e+06     |\n",
            "|    n_updates            | 1320         |\n",
            "|    policy_gradient_loss | 6.67e-05     |\n",
            "|    std                  | 4.36         |\n",
            "|    value_loss           | 1.26e+07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 720          |\n",
            "|    ep_rew_mean          | -3.65e+04    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 342          |\n",
            "|    iterations           | 134          |\n",
            "|    time_elapsed         | 4001         |\n",
            "|    total_timesteps      | 1372160      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019476211 |\n",
            "|    clip_fraction        | 0.012        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.88        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 1.58e+06     |\n",
            "|    n_updates            | 1330         |\n",
            "|    policy_gradient_loss | -8.31e-05    |\n",
            "|    std                  | 4.41         |\n",
            "|    value_loss           | 1.12e+07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 720          |\n",
            "|    ep_rew_mean          | -3.65e+04    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 342          |\n",
            "|    iterations           | 135          |\n",
            "|    time_elapsed         | 4032         |\n",
            "|    total_timesteps      | 1382400      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028642141 |\n",
            "|    clip_fraction        | 0.0194       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.89        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 1.38e+06     |\n",
            "|    n_updates            | 1340         |\n",
            "|    policy_gradient_loss | -0.000435    |\n",
            "|    std                  | 4.33         |\n",
            "|    value_loss           | 9.98e+06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 720         |\n",
            "|    ep_rew_mean          | -3.64e+04   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 342         |\n",
            "|    iterations           | 136         |\n",
            "|    time_elapsed         | 4061        |\n",
            "|    total_timesteps      | 1392640     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003235796 |\n",
            "|    clip_fraction        | 0.0242      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.9        |\n",
            "|    explained_variance   | 1.19e-07    |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 1.23e+06    |\n",
            "|    n_updates            | 1350        |\n",
            "|    policy_gradient_loss | -0.00033    |\n",
            "|    std                  | 4.46        |\n",
            "|    value_loss           | 9e+06       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 720          |\n",
            "|    ep_rew_mean          | -3.62e+04    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 342          |\n",
            "|    iterations           | 137          |\n",
            "|    time_elapsed         | 4092         |\n",
            "|    total_timesteps      | 1402880      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031674006 |\n",
            "|    clip_fraction        | 0.0246       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.91        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 1.1e+06      |\n",
            "|    n_updates            | 1360         |\n",
            "|    policy_gradient_loss | -0.000408    |\n",
            "|    std                  | 4.52         |\n",
            "|    value_loss           | 8.14e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 720          |\n",
            "|    ep_rew_mean          | -3.62e+04    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 342          |\n",
            "|    iterations           | 138          |\n",
            "|    time_elapsed         | 4122         |\n",
            "|    total_timesteps      | 1413120      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015837997 |\n",
            "|    clip_fraction        | 0.0137       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.93        |\n",
            "|    explained_variance   | -3.58e-07    |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 9.28e+05     |\n",
            "|    n_updates            | 1370         |\n",
            "|    policy_gradient_loss | 0.000345     |\n",
            "|    std                  | 4.52         |\n",
            "|    value_loss           | 7.35e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 720          |\n",
            "|    ep_rew_mean          | -3.61e+04    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 342          |\n",
            "|    iterations           | 139          |\n",
            "|    time_elapsed         | 4151         |\n",
            "|    total_timesteps      | 1423360      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038543374 |\n",
            "|    clip_fraction        | 0.0342       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.93        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 7.2e+05      |\n",
            "|    n_updates            | 1380         |\n",
            "|    policy_gradient_loss | -0.00145     |\n",
            "|    std                  | 4.64         |\n",
            "|    value_loss           | 6.54e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 720          |\n",
            "|    ep_rew_mean          | -3.62e+04    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 342          |\n",
            "|    iterations           | 140          |\n",
            "|    time_elapsed         | 4181         |\n",
            "|    total_timesteps      | 1433600      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031248203 |\n",
            "|    clip_fraction        | 0.0223       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.93        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 7.87e+05     |\n",
            "|    n_updates            | 1390         |\n",
            "|    policy_gradient_loss | -0.000312    |\n",
            "|    std                  | 4.58         |\n",
            "|    value_loss           | 5.68e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 720          |\n",
            "|    ep_rew_mean          | -3.62e+04    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 342          |\n",
            "|    iterations           | 141          |\n",
            "|    time_elapsed         | 4210         |\n",
            "|    total_timesteps      | 1443840      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030761345 |\n",
            "|    clip_fraction        | 0.0167       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.93        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 6e+05        |\n",
            "|    n_updates            | 1400         |\n",
            "|    policy_gradient_loss | 0.000384     |\n",
            "|    std                  | 4.71         |\n",
            "|    value_loss           | 4.81e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 720          |\n",
            "|    ep_rew_mean          | -3.62e+04    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 342          |\n",
            "|    iterations           | 142          |\n",
            "|    time_elapsed         | 4239         |\n",
            "|    total_timesteps      | 1454080      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034104832 |\n",
            "|    clip_fraction        | 0.0248       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.95        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 5.23e+05     |\n",
            "|    n_updates            | 1410         |\n",
            "|    policy_gradient_loss | -0.000343    |\n",
            "|    std                  | 4.68         |\n",
            "|    value_loss           | 3.99e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 720          |\n",
            "|    ep_rew_mean          | -3.62e+04    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 342          |\n",
            "|    iterations           | 143          |\n",
            "|    time_elapsed         | 4269         |\n",
            "|    total_timesteps      | 1464320      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030987214 |\n",
            "|    clip_fraction        | 0.0233       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.95        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 3.73e+05     |\n",
            "|    n_updates            | 1420         |\n",
            "|    policy_gradient_loss | 0.000502     |\n",
            "|    std                  | 4.65         |\n",
            "|    value_loss           | 3.48e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 720          |\n",
            "|    ep_rew_mean          | -3.62e+04    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 343          |\n",
            "|    iterations           | 144          |\n",
            "|    time_elapsed         | 4298         |\n",
            "|    total_timesteps      | 1474560      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031763013 |\n",
            "|    clip_fraction        | 0.0262       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.96        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 2.71e+05     |\n",
            "|    n_updates            | 1430         |\n",
            "|    policy_gradient_loss | 0.000257     |\n",
            "|    std                  | 4.73         |\n",
            "|    value_loss           | 2.96e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 720          |\n",
            "|    ep_rew_mean          | -3.62e+04    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 343          |\n",
            "|    iterations           | 145          |\n",
            "|    time_elapsed         | 4327         |\n",
            "|    total_timesteps      | 1484800      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034590722 |\n",
            "|    clip_fraction        | 0.0246       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.97        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 2.08e+05     |\n",
            "|    n_updates            | 1440         |\n",
            "|    policy_gradient_loss | 0.00065      |\n",
            "|    std                  | 4.68         |\n",
            "|    value_loss           | 2.5e+06      |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 720         |\n",
            "|    ep_rew_mean          | -3.62e+04   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 343         |\n",
            "|    iterations           | 146         |\n",
            "|    time_elapsed         | 4356        |\n",
            "|    total_timesteps      | 1495040     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004054223 |\n",
            "|    clip_fraction        | 0.0375      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.96       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 2.14e+05    |\n",
            "|    n_updates            | 1450        |\n",
            "|    policy_gradient_loss | 6.81e-06    |\n",
            "|    std                  | 4.85        |\n",
            "|    value_loss           | 2.09e+06    |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 720       |\n",
            "|    ep_rew_mean          | -3.63e+04 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 343       |\n",
            "|    iterations           | 147       |\n",
            "|    time_elapsed         | 4386      |\n",
            "|    total_timesteps      | 1505280   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0043655 |\n",
            "|    clip_fraction        | 0.031     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.99     |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.01      |\n",
            "|    loss                 | 1.33e+05  |\n",
            "|    n_updates            | 1460      |\n",
            "|    policy_gradient_loss | 0.000379  |\n",
            "|    std                  | 4.78      |\n",
            "|    value_loss           | 1.64e+06  |\n",
            "---------------------------------------\n"
          ]
        }
      ],
      "source": [
        "config = {\n",
        "    \"policy_type\": \"MultiInputPolicy\",\n",
        "    \"total_timesteps\": 1_500_000,\n",
        "}\n",
        "\n",
        "run = wandb.init(\n",
        "    project=\"4022_intelligent_ems\",\n",
        "    config=config,\n",
        "    sync_tensorboard=True,  # auto-upload sb3's tensorboard metrics\n",
        "    monitor_gym=True,  # auto-upload the videos of agents playing the game\n",
        "    save_code=True,  # optional\n",
        ")\n",
        "\n",
        "train_args = {\n",
        "                \"episode_len\"   : 6000,\n",
        "                \"actual_load\"   : actual_load,\n",
        "                \"actual_gen\"    : actual_gen,\n",
        "                \"bat_threshold\" : 100,\n",
        "                \"bat_cap\"       : 500,\n",
        "                \"purchase_price\": purchase_price,\n",
        "                \"num_preds\"     : 24,\n",
        "                \"load_shedding\" : load_shedding[2760:],\n",
        "                \"render_mode\"   : \"rgb_array\",\n",
        "                \"wandb_log\"     : True,\n",
        "                \"train_log\"     : True,\n",
        "\n",
        "                }\n",
        "\n",
        "eval_args = {\n",
        "                \"episode_len\"   :2760,\n",
        "                \"actual_load\"   :actual_load[6001:],\n",
        "                \"actual_gen\"    :actual_gen[6001:],\n",
        "                \"bat_threshold\" :100,\n",
        "                \"bat_cap\"       :500,\n",
        "                \"purchase_price\":purchase_price[6001:],\n",
        "                \"num_preds\"     :24,\n",
        "                \"load_shedding\" :load_shedding[6001:],\n",
        "                \"wandb_log\"     : True,\n",
        "                \"train_log\"     : False\n",
        "}\n",
        "\n",
        "#define 5 environments   for training and eval\n",
        "n_envs = 5\n",
        "n_eval_episodes =1\n",
        "train_env = make_vec_env(EMS, n_envs = n_envs,env_kwargs = train_args )\n",
        "\n",
        "\n",
        "eval_env = make_vec_env(EMS, n_envs = n_envs,env_kwargs = eval_args )\n",
        "\n",
        "\n",
        "wand_eval = f\"{version}_{model_type}_eval\"+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "wand_train = f\"{version}_{model_type}_train\"+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "wandb_callback = WandbCallback(\n",
        "                gradient_save_freq=100,\n",
        "                model_save_path=f\"models/{run.id}.{datetime.datetime.now()}\",\n",
        "                model_save_freq= 30000,\n",
        "                verbose=2,\n",
        "                log = \"all\",\n",
        "               )\n",
        "eval_callback = EvalCallback(eval_env,\n",
        "                             best_model_save_path = f\"{model_dir}{version}_{model_type}\"+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"),\n",
        "                             log_path = wand_eval,\n",
        "                             eval_freq=300,\n",
        "                             n_eval_episodes = n_eval_episodes,\n",
        "                             deterministic = True,\n",
        "                             render = False,\n",
        "                             callback_after_eval = wandb_callback)\n",
        "\n",
        "\n",
        "model = PPO(\"MlpPolicy\",train_env, verbose = 1,learning_rate = 0.01,vf_coef = 0.2, tensorboard_log = f\"runs/{run.id}\") #log_dir\n",
        "\n",
        "model.learn(total_timesteps= config[\"total_timesteps\"],\n",
        "            tb_log_name = wand_train,\n",
        "            reset_num_timesteps=False,\n",
        "            callback = wandb_callback\n",
        "            )\n",
        "\n",
        "model.save(f\"{model_dir}{version}_{model_type}\"+datetime.datetime.now().strftime(\"%m%d-%H%M%S\"))\n",
        "\n",
        "\n",
        "#c163c28885695cb2b0493ac455e296dcc8bc462a"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define a new test environment and load up the best performing model to test it.**"
      ],
      "metadata": {
        "id": "C9AGcLlsv4N7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d4ce89e0095c4f018f5f3e587f8a9d21",
            "287c19df62f948f3a6093c44efb063bf",
            "d10739df1e05473cbe66c035ea1cdfe2",
            "47e3f681ad2041ff9ec0ba2738b05dc8",
            "901f4c4ccd3b40ad91d1ecf757ea993e",
            "ba48c9a415c14f099c030dacfcb19526",
            "338309538d274ebc9233a3bc5bc4f158",
            "bfbe3e78fd194aecaf206ac3a06de415"
          ]
        },
        "id": "C0_evGgMeHvG",
        "outputId": "1e1149a2-13f7-4cd5-f18a-fb183731c904"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.807 MB of 0.807 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d4ce89e0095c4f018f5f3e587f8a9d21"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Diesel Generator</td><td></td></tr><tr><td>Excess Generation</td><td></td></tr><tr><td>Inverter total power flow</td><td></td></tr><tr><td>Max Demand</td><td></td></tr><tr><td>Num Diesel Gen Actions</td><td></td></tr><tr><td>Num Off-Peak Purchases</td><td></td></tr><tr><td>Num Peak Purchases</td><td></td></tr><tr><td>Num Standard Purchases</td><td></td></tr><tr><td>Off-Peak Purchases</td><td></td></tr><tr><td>Peak Purchases</td><td></td></tr><tr><td>Rectifier total power flow</td><td></td></tr><tr><td>Standard Purchases</td><td></td></tr><tr><td>Total Elec Purchase</td><td></td></tr><tr><td>Total Money spent</td><td></td></tr><tr><td>Total Purchase Requested</td><td></td></tr><tr><td>Total Reward</td><td></td></tr><tr><td>Unmet Load</td><td></td></tr><tr><td>global_step</td><td></td></tr><tr><td>rollout/ep_len_mean</td><td></td></tr><tr><td>rollout/ep_rew_mean</td><td></td></tr><tr><td>time/fps</td><td></td></tr><tr><td>total Purchased Elec</td><td></td></tr><tr><td>train/approx_kl</td><td></td></tr><tr><td>train/clip_fraction</td><td></td></tr><tr><td>train/clip_range</td><td></td></tr><tr><td>train/entropy_loss</td><td></td></tr><tr><td>train/explained_variance</td><td></td></tr><tr><td>train/learning_rate</td><td></td></tr><tr><td>train/loss</td><td></td></tr><tr><td>train/policy_gradient_loss</td><td></td></tr><tr><td>train/std</td><td></td></tr><tr><td>train/value_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Diesel Generator</td><td>0.0</td></tr><tr><td>Excess Generation</td><td>115423.69249</td></tr><tr><td>Inverter total power flow</td><td>57305.71145</td></tr><tr><td>Max Demand</td><td>704.46399</td></tr><tr><td>Num Diesel Gen Actions</td><td>0</td></tr><tr><td>Num Off-Peak Purchases</td><td>116</td></tr><tr><td>Num Peak Purchases</td><td>25</td></tr><tr><td>Num Standard Purchases</td><td>36</td></tr><tr><td>Off-Peak Purchases</td><td>16478.10807</td></tr><tr><td>Peak Purchases</td><td>2929.1264</td></tr><tr><td>Rectifier total power flow</td><td>21173.56566</td></tr><tr><td>Standard Purchases</td><td>6225.38106</td></tr><tr><td>Total Elec Purchase</td><td>25632.61553</td></tr><tr><td>Total Money spent</td><td>36795.6262</td></tr><tr><td>Total Purchase Requested</td><td>2.0</td></tr><tr><td>Total Reward</td><td>-36795.6262</td></tr><tr><td>Unmet Load</td><td>0.0</td></tr><tr><td>global_step</td><td>1505280</td></tr><tr><td>rollout/ep_len_mean</td><td>720.0</td></tr><tr><td>rollout/ep_rew_mean</td><td>-36252.82812</td></tr><tr><td>time/fps</td><td>343.0</td></tr><tr><td>total Purchased Elec</td><td>25632.61553</td></tr><tr><td>train/approx_kl</td><td>0.00437</td></tr><tr><td>train/clip_fraction</td><td>0.03098</td></tr><tr><td>train/clip_range</td><td>0.2</td></tr><tr><td>train/entropy_loss</td><td>-2.98919</td></tr><tr><td>train/explained_variance</td><td>0.0</td></tr><tr><td>train/learning_rate</td><td>0.01</td></tr><tr><td>train/loss</td><td>133400.95312</td></tr><tr><td>train/policy_gradient_loss</td><td>0.00038</td></tr><tr><td>train/std</td><td>4.77657</td></tr><tr><td>train/value_loss</td><td>1636601.625</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">fast-river-209</strong> at: <a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/yh76b6nl' target=\"_blank\">https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/yh76b6nl</a><br/>Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 3 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20231017_211044-yh76b6nl/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "inDHszZaxBUS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e0edddd1-f1a5-4bc6-deed-50105ee19d61"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.12"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/EEE4022S_BNKJUL001_Thesis/wandb/run-20231017_222427-rf8thwtq</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/rf8thwtq' target=\"_blank\">northern-resonance-212</a></strong> to <a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems' target=\"_blank\">https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/rf8thwtq' target=\"_blank\">https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/rf8thwtq</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>AC load</td><td></td></tr><tr><td>DC load</td><td></td></tr><tr><td>Diesel Generator</td><td></td></tr><tr><td>Excess Generation</td><td></td></tr><tr><td>Inverter total power flow</td><td></td></tr><tr><td>LoadShedding</td><td></td></tr><tr><td>Money Spent</td><td></td></tr><tr><td>Num Diesel Gen Actions</td><td></td></tr><tr><td>Num Off-Peak Purchases</td><td></td></tr><tr><td>Num Peak Purchases</td><td></td></tr><tr><td>Num Standard Purchases</td><td></td></tr><tr><td>Off-Peak Purchases</td><td></td></tr><tr><td>PV generation</td><td></td></tr><tr><td>Peak Purchases</td><td></td></tr><tr><td>Purchase Requested</td><td></td></tr><tr><td>Rectifier total power flow</td><td></td></tr><tr><td>Standard Purchases</td><td></td></tr><tr><td>Step Purchased</td><td></td></tr><tr><td>Total Reward</td><td></td></tr><tr><td>Unmet Load</td><td></td></tr><tr><td>Wind generation</td><td></td></tr><tr><td>battery_level</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>AC load</td><td>173.379</td></tr><tr><td>DC load</td><td>51.7</td></tr><tr><td>Diesel Generator</td><td>0.0</td></tr><tr><td>Excess Generation</td><td>0.0</td></tr><tr><td>Inverter total power flow</td><td>0.0</td></tr><tr><td>LoadShedding</td><td>0.0</td></tr><tr><td>Money Spent</td><td>0.0</td></tr><tr><td>Num Diesel Gen Actions</td><td>65</td></tr><tr><td>Num Off-Peak Purchases</td><td>575</td></tr><tr><td>Num Peak Purchases</td><td>100</td></tr><tr><td>Num Standard Purchases</td><td>155</td></tr><tr><td>Off-Peak Purchases</td><td>0.0</td></tr><tr><td>PV generation</td><td>98.34605</td></tr><tr><td>Peak Purchases</td><td>0.0</td></tr><tr><td>Purchase Requested</td><td>0.0</td></tr><tr><td>Rectifier total power flow</td><td>0.0</td></tr><tr><td>Standard Purchases</td><td>0.0</td></tr><tr><td>Step Purchased</td><td>0.0</td></tr><tr><td>Total Reward</td><td>0.0</td></tr><tr><td>Unmet Load</td><td>0.0</td></tr><tr><td>Wind generation</td><td>415.10031</td></tr><tr><td>battery_level</td><td>500.0</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">northern-resonance-212</strong> at: <a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/rf8thwtq' target=\"_blank\">https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/rf8thwtq</a><br/>Synced 4 W&B file(s), 25 media file(s), 7 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20231017_222427-rf8thwtq/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.12"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/EEE4022S_BNKJUL001_Thesis/wandb/run-20231017_222553-us09m2kr</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/us09m2kr' target=\"_blank\">proud-sunset-213</a></strong> to <a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems' target=\"_blank\">https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/us09m2kr' target=\"_blank\">https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/us09m2kr</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>AC load</td><td></td></tr><tr><td>DC load</td><td></td></tr><tr><td>Diesel Generator</td><td></td></tr><tr><td>Excess Generation</td><td></td></tr><tr><td>Inverter total power flow</td><td></td></tr><tr><td>LoadShedding</td><td></td></tr><tr><td>Money Spent</td><td></td></tr><tr><td>Num Diesel Gen Actions</td><td></td></tr><tr><td>Num Off-Peak Purchases</td><td></td></tr><tr><td>Num Peak Purchases</td><td></td></tr><tr><td>Num Standard Purchases</td><td></td></tr><tr><td>Off-Peak Purchases</td><td></td></tr><tr><td>PV generation</td><td></td></tr><tr><td>Peak Purchases</td><td></td></tr><tr><td>Purchase Requested</td><td></td></tr><tr><td>Rectifier total power flow</td><td></td></tr><tr><td>Standard Purchases</td><td></td></tr><tr><td>Step Purchased</td><td></td></tr><tr><td>Total Reward</td><td></td></tr><tr><td>Unmet Load</td><td></td></tr><tr><td>Wind generation</td><td></td></tr><tr><td>battery_level</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>AC load</td><td>113.37032</td></tr><tr><td>DC load</td><td>54.4</td></tr><tr><td>Diesel Generator</td><td>0.0</td></tr><tr><td>Excess Generation</td><td>0.0</td></tr><tr><td>Inverter total power flow</td><td>0.0</td></tr><tr><td>LoadShedding</td><td>0.0</td></tr><tr><td>Money Spent</td><td>0.0</td></tr><tr><td>Num Diesel Gen Actions</td><td>65</td></tr><tr><td>Num Off-Peak Purchases</td><td>568</td></tr><tr><td>Num Peak Purchases</td><td>99</td></tr><tr><td>Num Standard Purchases</td><td>154</td></tr><tr><td>Off-Peak Purchases</td><td>0.0</td></tr><tr><td>PV generation</td><td>0.0</td></tr><tr><td>Peak Purchases</td><td>0.0</td></tr><tr><td>Purchase Requested</td><td>0.0</td></tr><tr><td>Rectifier total power flow</td><td>0.0</td></tr><tr><td>Standard Purchases</td><td>0.0</td></tr><tr><td>Step Purchased</td><td>0.0</td></tr><tr><td>Total Reward</td><td>0.0</td></tr><tr><td>Unmet Load</td><td>0.0</td></tr><tr><td>Wind generation</td><td>84.94012</td></tr><tr><td>battery_level</td><td>100.0</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">proud-sunset-213</strong> at: <a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/us09m2kr' target=\"_blank\">https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/us09m2kr</a><br/>Synced 4 W&B file(s), 25 media file(s), 7 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20231017_222553-us09m2kr/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Note: The term does not refer to the cost in rands but rather to the reward as defined by the reward function!\n",
            "Done the Standby Test! Total cost accumulated is: -305275.09375\n",
            "Done applying the trained model! Total cost accumulated is: -303477.329845 +- 0.0\n",
            "The amount that was saved by applying the EMS agent: 1797.7639049999998\n",
            "This was saved over a period of 115.0 days\n",
            "The savings represents 0.5888996324319367 % of the cost if no EMS is installed\n",
            "And it represents 0.5923882043901604 % of the cost if the EMS is installed\n"
          ]
        }
      ],
      "source": [
        "config = {\n",
        "    \"policy_type\": \"MultiInputPolicy\",\n",
        "    \"total_timesteps\": 2760,\n",
        "}\n",
        "\n",
        "run = wandb.init(\n",
        "    project=\"4022_intelligent_ems\",\n",
        "    config=config,\n",
        "    sync_tensorboard=True,  # auto-upload sb3's tensorboard metrics\n",
        "    monitor_gym=True,  # auto-upload the videos of agents playing the game\n",
        "    save_code=True,  # optional\n",
        ")\n",
        "\n",
        "\n",
        "eval_args = {\n",
        "                \"episode_len\"   :2760,\n",
        "                \"actual_load\"   :actual_load[6001:],\n",
        "                \"actual_gen\"    :actual_gen[6001:],\n",
        "                \"bat_threshold\" :100,\n",
        "                \"bat_cap\"       :500,\n",
        "                \"purchase_price\":purchase_price[6001:],\n",
        "                \"num_preds\"     :6,\n",
        "                \"load_shedding\" :load_shedding[6001:],\n",
        "                \"wandb_log\"     : True,\n",
        "                \"train_log\"     : False\n",
        "}\n",
        "\n",
        "#define 5 environments   for training and eval\n",
        "\n",
        "eval_env = make_vec_env(EMS, n_envs = n_envs,env_kwargs = eval_args )\n",
        "\n",
        "\n",
        "#first run it with only standby (default)\n",
        "obs   = eval_env.reset()\n",
        "#ensure that the exit condition is reset\n",
        "done = [False]*n_envs\n",
        "#define the action to take\n",
        "action_standby = [0]*n_envs\n",
        "#reset score\n",
        "standby_score = [0]*n_envs\n",
        "standby_score = np.array(standby_score).astype(np.float32)\n",
        "while not all(done):\n",
        "    #step the model with the action\n",
        "    obs,reward,done,info = eval_env.step(action_standby)\n",
        "    #accumulate the score\n",
        "    standby_score += reward\n",
        "\n",
        "\n",
        "avg_standby_score = standby_score.mean()\n",
        "\n",
        "run.finish()\n",
        "\n",
        "eval_args = {\n",
        "                \"episode_len\"   :2760,\n",
        "                \"actual_load\"   :actual_load[6001:],\n",
        "                \"actual_gen\"    :actual_gen[6001:],\n",
        "                \"bat_threshold\" :100,\n",
        "                \"bat_cap\"       :500,\n",
        "                \"purchase_price\":purchase_price[6001:],\n",
        "                \"num_preds\"     :24,\n",
        "                \"load_shedding\" :load_shedding[6001:],\n",
        "                \"wandb_log\"     : True,\n",
        "                \"train_log\"     : False\n",
        "}\n",
        "\n",
        "#define 5 environments   for training and eval\n",
        "\n",
        "eval_env = make_vec_env(EMS, n_envs = n_envs,env_kwargs = eval_args )\n",
        "\n",
        "#Load model, fetch the latest (or whichever one you want from the model_dir)\n",
        "#Best A2C model:/content/drive/MyDrive/Colab Notebooks/EMSv1_1/models/A2C/EMSv1_1_A2C1010-081818.zip\n",
        "best_model =\"/content/drive/MyDrive/Colab Notebooks/EMSv2_1/models/PPO/EMSv2_1_PPO1017-110702.zip\"\n",
        "#best_model =\n",
        "#best_PPO_model\n",
        "#model_load = f\"{best_model}\"\n",
        "\n",
        "#model  = PPO.load(model_load, env = eval_env)\n",
        "\n",
        "run = wandb.init(\n",
        "    project=\"4022_intelligent_ems\",\n",
        "    config=config,\n",
        "    sync_tensorboard=True,  # auto-upload sb3's tensorboard metrics\n",
        "    monitor_gym=True,  # auto-upload the videos of agents playing the game\n",
        "    save_code=True,  # optional\n",
        ")\n",
        "obs   = eval_env.reset()\n",
        "EMS_reward,EMS_std_reward = evaluate_policy(model,eval_env,n_eval_episodes = 1,deterministic=True)# callback = wandb_callback\n",
        "run.finish()\n",
        "\n",
        "print(f\"Note: The term does not refer to the cost in rands but rather to the reward as defined by the reward function!\")\n",
        "print(f\"Done the Standby Test! Total cost accumulated is: {avg_standby_score}\")\n",
        "print(f\"Done applying the trained model! Total cost accumulated is: {EMS_reward} +- {EMS_std_reward}\")\n",
        "\n",
        "savings = EMS_reward - avg_standby_score\n",
        "print(f\"The amount that was saved by applying the EMS agent: {savings}\")\n",
        "print(f\"This was saved over a period of {2760/24} days\")\n",
        "print(f\"The savings represents {(savings/(-avg_standby_score))*100} % of the cost if no EMS is installed\")\n",
        "print(f\"And it represents {(savings/(-EMS_reward))*100} % of the cost if the EMS is installed\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d4ce89e0095c4f018f5f3e587f8a9d21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_287c19df62f948f3a6093c44efb063bf",
              "IPY_MODEL_d10739df1e05473cbe66c035ea1cdfe2"
            ],
            "layout": "IPY_MODEL_47e3f681ad2041ff9ec0ba2738b05dc8"
          }
        },
        "287c19df62f948f3a6093c44efb063bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_901f4c4ccd3b40ad91d1ecf757ea993e",
            "placeholder": "",
            "style": "IPY_MODEL_ba48c9a415c14f099c030dacfcb19526",
            "value": "0.807 MB of 0.807 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "d10739df1e05473cbe66c035ea1cdfe2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_338309538d274ebc9233a3bc5bc4f158",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bfbe3e78fd194aecaf206ac3a06de415",
            "value": 1
          }
        },
        "47e3f681ad2041ff9ec0ba2738b05dc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "901f4c4ccd3b40ad91d1ecf757ea993e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba48c9a415c14f099c030dacfcb19526": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "338309538d274ebc9233a3bc5bc4f158": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfbe3e78fd194aecaf206ac3a06de415": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}