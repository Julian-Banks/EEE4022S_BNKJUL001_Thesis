{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Julian-Banks/EEE4022S_BNKJUL001_Thesis/blob/main/PythonWorkspace/EMSv0_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Version Notes**\n",
        "\n",
        "# **v0.2**\n",
        "**Added:**\n",
        "*  simplified load_forecast and gen_forecast to be power_bal_forecasts.\n",
        "*  combined current_load and current_gen to also show current_power_balance\n",
        "\n",
        "**Parameters:**\n",
        "*  set num_preds = 3. Again to simplify observation space.\n",
        "*  \n",
        "\n",
        "**Results:**\n",
        "*\n",
        "\n",
        "**To do:**\n",
        "* Try to use hyperparameter Optimisation\n",
        "* Try normalise\n",
        "* Try differnet models\n",
        "* Try see if discount rate can be tweaked\n",
        "* Find out how the bounds for the obs_space box effect things\n",
        "\n",
        "# **v0.1**\n",
        "**Added:**\n",
        "* added real loads, gen, tou_id's\n",
        "\n",
        "**Parameters:**\n",
        "* training episode = 6000 timesteps\n",
        "* testing episode  = 2760 timesteps\n",
        "* bat_threshold = 100\n",
        "* bat_cap = 500\n",
        "* battery_level at reset = bat_cap/2\n",
        "* num_preds = 24\n",
        "* Trained PPO for 1.65mil timesteps\n",
        "* Trained A2C for 1.2 mil timesteps\n",
        "\n",
        "**Results:**\n",
        "* PP0 - 4% improvement from standby mode\n",
        "* A2C  - -0.3% improvement. And the models after this got worse as training progressed!\n",
        "**To do:**\n",
        "* Try lower num_preds\n",
        "* Try to use hyperparameter Optimisation\n",
        "* Try normalise\n",
        "* Try differnet models\n",
        "* Try see if discount rate can be tweaked\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5DZFnZnzStt1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MXzZxVUQFroQ"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install gymnasium\n",
        "!pip install stable_baselines3[extra]\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Hu74obFw8Gts",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04447ac2-c816-4b96-c2f6-a07ef7eeec1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'EEE4022S_BNKJUL001_Thesis'...\n",
            "remote: Enumerating objects: 483, done.\u001b[K\n",
            "remote: Counting objects: 100% (193/193), done.\u001b[K\n",
            "remote: Compressing objects: 100% (154/154), done.\u001b[K\n",
            "remote: Total 483 (delta 70), reused 150 (delta 36), pack-reused 290\u001b[K\n",
            "Receiving objects: 100% (483/483), 145.30 MiB | 25.74 MiB/s, done.\n",
            "Resolving deltas: 100% (136/136), done.\n",
            "Updating files: 100% (317/317), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/Julian-Banks/EEE4022S_BNKJUL001_Thesis\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#to update the rep\n",
        "%cd /content/EEE4022S_BNKJUL001_Thesis\n",
        "! git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IBm2Ge7rrfe",
        "outputId": "158b482c-efb4-49c9-ea61-5e4de23d070a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/EEE4022S_BNKJUL001_Thesis\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#to save the code afterwards\n",
        "'''\n",
        "%cd /content/EEE4022S_BNKJUL001_Thesis\n",
        "\n",
        "Message = \"Changes to EMSv0_2\"\n",
        "\n",
        "! git add.\n",
        "! git commit -m \"{Message}\"\n",
        "! git push\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "OYtyqOTcscTG",
        "outputId": "30000277-59a1-4386-fd5b-d84bd26733f3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n%cd /content/EEE4022S_BNKJUL001_Thesis\\n\\nMessage = \"Changes to EMSv0_2\"\\n\\n! git add.\\n! git commit -m \"{Message}\"\\n! git push\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nI52iVVCCPaf",
        "outputId": "f8731e15-224f-4816-dda3-1eac509cc6cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
            "  if not hasattr(tensorboard, \"__version__\") or LooseVersion(\n"
          ]
        }
      ],
      "source": [
        "#import needed libarys\n",
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from gymnasium import spaces\n",
        "import datetime\n",
        "from stable_baselines3 import PPO, A2C, DQN\n",
        "from google.colab import drive\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DG4gB2cM7tDY"
      },
      "source": [
        "This is very much a first working model and very simple\n",
        "First major problem is that it only has one load! no AC DC vibe\n",
        "also has no converter\n",
        "All of the loads and forecasts are random rn but I need to load in the real files.\n",
        "only one form of generation, no solar/wind difference\n",
        "\n",
        "Tech challenges:\n",
        "  If the data is normalised, how do I calculate the actual power used, in the batery exct, unless they are all normalised using the same metric,\n",
        "  could save thier normalisation values, un-normalise them to perform calculations and then renormalise them?\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "0X9RBdXC_2PD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a53bed33-bc4d-4cbc-d01c-288e2c949497"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "#need to import data from Github\n",
        "path_data = \"/content/EEE4022S_BNKJUL001_Thesis/PythonWorkspace/dataClean.csv\"\n",
        "data = pd.read_csv(path_data)\n",
        "\n",
        "path_gen = \"/content/EEE4022S_BNKJUL001_Thesis/Generation/BNKJUL001_Thesis_solarGen500kWHomer.csv\"\n",
        "data_gen = pd.read_csv(path_gen)\n",
        "\n",
        "#Not actually using this rn but will be soon :)\n",
        "path_shedding = \"/content/EEE4022S_BNKJUL001_Thesis/MatlabWorkSpace/loadShedding2022.csv\"\n",
        "data_shedding = pd.read_csv(path_shedding)\n",
        "load_shedding = data_shedding['LoadShedding'].values.astype(np.float32)\n",
        "\n",
        "actual_gen = data_gen['PV_Out'].values.astype(np.float32)\n",
        "actual_load = data['AC'].values.astype(np.float32)\n",
        "purchase_price = data['tou_id'].values.astype(np.float32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "s2iW-k26FIbm"
      },
      "outputs": [],
      "source": [
        "class EMSv0_2(gym.Env):\n",
        "    \"\"\"Custom Environment that follows gym interface.\"\"\"\n",
        "\n",
        "    metadata = {\"render_modes\": [\"human\"], \"render_fps\": 30}\n",
        "\n",
        "    def __init__(self,bat_threshold = 0.1, bat_cap = 1, actual_load = \"none\", actual_gen = \"none\", purchase_price = [1,1,1,1,1,1,1,1,2,2,2,2] , episode_len = 8760,num_preds = 24,render_mode = \"none\"):\n",
        "\n",
        "        super(EMSv0_2, self).__init__()\n",
        "\n",
        "        #define time frame\n",
        "        self.current_step = 0\n",
        "        self.final_step = int(episode_len)-num_preds-2 #one years worth of steps\n",
        "\n",
        "        #Might make a function for these\n",
        "        #fill all of the actual loads NB!!! is just random for now NB!!! is normalised 0-1\n",
        "        if isinstance(actual_load,str) :\n",
        "            self.actual_load = np.random.rand(self.final_step+num_preds+1).astype(np.float32) #will load from a file or something\n",
        "        else:\n",
        "            self.actual_load = actual_load[:episode_len]\n",
        "\n",
        "        #fill all of the actual generation steps.\n",
        "        if isinstance(actual_gen,str):\n",
        "            self.actual_gen  = np.random.rand(self.final_step+num_preds+1).astype(np.float32) #will load from file or something\n",
        "        else:\n",
        "            self.actual_gen  = actual_gen[:episode_len]\n",
        "\n",
        "        #define the purchase price for every step of the year\n",
        "        purchase_price = np.array(purchase_price).astype(np.float32)\n",
        "        repetitions    = (self.final_step+num_preds+1) // len(purchase_price)\n",
        "        remainder      = (self.final_step+num_preds+1) % len(purchase_price)\n",
        "        self.purchase_price =np.concatenate([purchase_price]*repetitions+[purchase_price[:remainder]])#need to read in from somewhere\n",
        "\n",
        "        #define var for storing the excess gen\n",
        "        self.excess_gen = 0\n",
        "        #define a var for determine amount purchased per step (dont want to make it total as this will incure growing penalties for the Agent if used in reward structure)\n",
        "        self.step_purchased = 0\n",
        "        #define the battery max capacity\n",
        "        self.bat_cap = bat_cap\n",
        "        #define the battery low threshold\n",
        "        self.bat_threshold = np.float32(bat_threshold)\n",
        "        #define default action\n",
        "        self.default_action = 0\n",
        "        #define actions and observations space\n",
        "        n_actions = 2 # keeping it simple\n",
        "\n",
        "        self.num_preds = num_preds # day ahead predictions\n",
        "        self.action_space = spaces.Discrete(n_actions)\n",
        "        # Dict space to store all the different things\n",
        "        self.observation_space = spaces.Dict({\n",
        "                \"power_bal_forecast\": gym.spaces.Box(low=-np.inf, high=np.inf, shape=(1,num_preds), dtype=np.float32),\n",
        "                \"price_forecast\": gym.spaces.Box(low=0, high=np.inf, shape=(1,num_preds+1), dtype=np.float32),\n",
        "                \"bat_level\": gym.spaces.Box(low=0, high=np.inf, shape=(1,), dtype=np.float32),\n",
        "                \"current_power_bal\": gym.spaces.Box(low=-np.inf, high=np.inf, shape=(1,), dtype=np.float32),\n",
        "                })\n",
        "\n",
        "    def step(self, action):\n",
        "\n",
        "        #update the current state with the action (needs to be done before current_step is inc since we want to apply the action to the previous step to get the current state)\n",
        "        self.update_state(action)\n",
        "        #Calculate reward from the action\n",
        "        reward = self.calc_reward()\n",
        "\n",
        "        #inc time step into Future\n",
        "        self.current_step += 1\n",
        "        #get next observation (for next time step)\n",
        "        observation = self.get_obs()\n",
        "        #Set terminated to False since there are no failure states\n",
        "        self.terminated = False\n",
        "        #Check if timelimit reached\n",
        "        self.truncated = False if self.current_step<self.final_step else True\n",
        "        #dont know what to put into info for now\n",
        "        info = {}\n",
        "        return observation, reward, self.terminated, self.truncated, info\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        super().reset(seed = seed, options=options)\n",
        "\n",
        "        self.current_step = 0\n",
        "        self.terminated = False\n",
        "        self.truncated = False\n",
        "\n",
        "        #reset these cause I dont want the model to just memorise the random data (so it gets changed every reset)\n",
        "        #fill all of the actual loads NB!!! is just random for now NB!!! is normalised 0-1\n",
        "        #self.actual_load = np.random.rand(self.final_step+self.num_preds+1).astype(np.float32) #will load from a file or something\n",
        "        #fill all of the actual generation steps.\n",
        "        #self.actual_gen   = np.random.rand(self.final_step+self.num_preds+1).astype(np.float32) #will load from file or something\n",
        "\n",
        "\n",
        "        #reset the state\n",
        "        self.battery_level = self.bat_cap/2\n",
        "        self.current_load = self.actual_load[0]\n",
        "        self.excess_gen = 0\n",
        "        self.step_purchased = 0\n",
        "        #get the first observation\n",
        "        observation = self.get_obs()\n",
        "        #Still don't know what to do with info\n",
        "        info = {}\n",
        "        return observation, info\n",
        "\n",
        "    def render(self):\n",
        "        #Reaaaaalllyyyy want to render something, Maybe the curent load as a point, the forecasts as a plot and the bat levels as bar\n",
        "        pass\n",
        "\n",
        "    def close(self):\n",
        "        #don't think i need this for my application\n",
        "        pass\n",
        "\n",
        "    def update_state(self, action):\n",
        "        #Update current state with actions\n",
        "        if action == 0: #do nothing action\n",
        "            self.standby()\n",
        "        elif action == 1: #buy from Grid\n",
        "            self.purchase()\n",
        "        else:  #error case\n",
        "            raise ValueError(\n",
        "              f\"Received invalid action = {action} which is not part of the action space.\"\n",
        "            )\n",
        "        #case list for each action?\n",
        "\n",
        "    def calc_reward(self):\n",
        "        #Calculate reward based on the state\n",
        "        reward = -self.step_purchased*self.purchase_price[self.current_step]\n",
        "\n",
        "        return reward\n",
        "\n",
        "    def get_obs(self):\n",
        "        #Fill the observation space with the next observation\n",
        "\n",
        "        #Get Forecasts Will probaly write a function for this? idk maybe a schlep to return all the info\n",
        "        load_forecast  = np.array( [self.actual_load[self.current_step+1: self.current_step + self.num_preds+1]] , dtype = np.float32) #will load from a file or something\n",
        "        if load_forecast.shape != (1,self.num_preds):\n",
        "            print(f\"load_forecast shape is {load_forecast.shape} but it should be {(1, self.num_preds)}. Current step is {self.current_step}\")\n",
        "        gen_forecast   = np.array( [self.actual_gen[self.current_step+1: self.current_step + self.num_preds+1]] , dtype = np.float32) #will load from a file or something\n",
        "        if gen_forecast.shape != (1,self.num_preds):\n",
        "            print(f\"gen_forecast shape is {gen_forecast.shape} but it should be {(1, self.num_preds)}. Current step is {self.current_step}\")\n",
        "        #calculate the power forecast\n",
        "        power_bal_forecast = gen_forecast-load_forecast\n",
        "        #get the prices for the current frame and the next 24 hours. Maybe will cut this down since that seems like a lot of info\n",
        "        price_forecast = np.array( [self.purchase_price[self.current_step:self.current_step+self.num_preds+1]] , dtype = np.float32)\n",
        "        #Just for readibility of the dict object\n",
        "        bat_level      = np.array([self.battery_level] , dtype= np.float32)\n",
        "\n",
        "        #calculate the current power balance\n",
        "        current_load   = np.array([self.actual_load[self.current_step]], dtype = np.float32)\n",
        "        current_gen    = np.array([self.actual_gen[self.current_step]], dtype  = np.float32)\n",
        "        current_power_bal = current_gen - current_load\n",
        "\n",
        "\n",
        "\n",
        "        obs = dict({\n",
        "                \"bat_level\":      bat_level,\n",
        "                \"current_power_bal\" :   current_power_bal,\n",
        "                \"power_bal_forecast\":  power_bal_forecast,\n",
        "                \"price_forecast\": price_forecast,\n",
        "        })\n",
        "        return obs\n",
        "\n",
        "    def standby(self):\n",
        "        #ems stands by, load is met by generation, battery and then grid\n",
        "        #if there is excess generation it is used to charge the batteries\n",
        "\n",
        "        #define step_gen and step_load for readability\n",
        "        step_gen  =  self.actual_gen[self.current_step]\n",
        "        step_load =  self.actual_load[self.current_step]\n",
        "        battery   =  self.battery_level\n",
        "        #check for gen meeting load\n",
        "        if step_load <= step_gen :\n",
        "            #set the purchased elect to 0 since gen meets load\n",
        "            self.step_purchased = 0\n",
        "            #calulate the excess elec that was generated\n",
        "            step_excess = step_gen - step_load\n",
        "            #check if battery needs to be charged\n",
        "            if battery < self.bat_cap :\n",
        "                #check if the excess amount that was generated is less than the available capacity\n",
        "                if self.bat_cap-battery-step_excess > 0:\n",
        "                    self.battery_level += step_excess\n",
        "                else:\n",
        "                    #if the excess is greater than the availability then charge till full\n",
        "                    self.battery_level = self.bat_cap\n",
        "                    #set step excess to excess minus the amount used to charge\n",
        "                    step_excess -= (self.bat_cap-battery)\n",
        "                    self.excess_gen += step_excess\n",
        "            else:\n",
        "                #if the battery is full then just inc excess_gen\n",
        "                self.excess_gen += step_excess\n",
        "        else:\n",
        "            #if the generation does not meet load\n",
        "            step_shortfall = step_load - step_gen\n",
        "            #checking if battery is above a threshold.\n",
        "            if battery > self.bat_threshold:\n",
        "                #check if battery has enough capacity to meet the load\n",
        "                if battery - step_shortfall >= self.bat_threshold:\n",
        "                    #if it does then subtract the shortfall from battery level\n",
        "                    self.battery_level -= step_shortfall\n",
        "                    #set the purchased variable to 0 since nothing was purchased\n",
        "                    self.step_purchased = 0\n",
        "                else:\n",
        "                    #set the battery to min value and purchase the rest from the grid\n",
        "                    self.battery_level = self.bat_threshold\n",
        "                    #calculate how much needs to be purchased\n",
        "                    step_shortfall -= (battery - self.bat_threshold)\n",
        "                    self.step_purchased = step_shortfall\n",
        "            else:\n",
        "                #no battery available, therefore everything needs to be bought from the grid.\n",
        "                self.step_purchased = step_shortfall\n",
        "\n",
        "    def purchase(self):\n",
        "        #purchase electricity to charge battery even if there is enough generation (I assume this will be used to buy at lower prices)\n",
        "        #get values for readability\n",
        "        step_load = self.actual_load[self.current_step]\n",
        "        step_gen  = self.actual_gen[self.current_step]\n",
        "        battery = self.battery_level\n",
        "\n",
        "        #calculate the total power need (the load plus the amount that the battery needs to charge)\n",
        "        total_need = step_load + (self.bat_cap-battery)\n",
        "        #if the generation is less than the need then purchase the remainder\n",
        "        if step_gen<total_need:\n",
        "            #purchashing the shortfall\n",
        "            self.step_purchased = total_need - step_gen\n",
        "            #setting the battery levels to full\n",
        "            self.battery_level = self.bat_cap\n",
        "        else:\n",
        "            #if the gen is enough then set purchase to 0\n",
        "            self.step_purchased  = 0\n",
        "            #set the battery to fully charged\n",
        "            self.battery_level = self.bat_cap\n",
        "            #inc excess_gen by caluclating the excess between the step gen and the total need (includes amount needed to charge the battery)\n",
        "            self.excess_gen += (step_gen - total_need)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RUZKr7RrN-u"
      },
      "source": [
        "Check the environment with stable_baselines3 check_env."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4GSJ8LsidPq"
      },
      "outputs": [],
      "source": [
        "from stable_baselines3.common.env_checker import check_env\n",
        "env = EMSv0_2()\n",
        "check_env(env,warn = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Kvh0dymrVgV"
      },
      "source": [
        "Evaluate the base model (no EMS, just using standby mode)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vMEdXW4otUB",
        "outputId": "ae7f995e-a2a0-4b09-aefb-65a172a52de0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The reset observation space looks like: {'bat_level': array([250.], dtype=float32), 'current_gen': array([0.], dtype=float32), 'current_load': array([96.855], dtype=float32), 'power_forecast': array([[-97.053, -97.229, -96.859]], dtype=float32), 'price_forecast': array([[1., 1., 1., 1.]], dtype=float32)}\n",
            "After action 0 the observation space looks like {'bat_level': array([153.14499], dtype=float32), 'current_gen': array([0.], dtype=float32), 'current_load': array([97.053], dtype=float32), 'power_forecast': array([[-97.229, -96.859, -98.018]], dtype=float32), 'price_forecast': array([[1., 1., 1., 1.]], dtype=float32)}\n",
            "The reward we recieved was 0.0\n"
          ]
        }
      ],
      "source": [
        "#define the base environment\n",
        "base_env = EMSv0_2(episode_len = 6000, actual_load = actual_load, actual_gen = actual_gen, bat_threshold = 100, bat_cap = 500, purchase_price = purchase_price,num_preds = 3)\n",
        "#going to print out a bunch of things to test the different spaces.\n",
        "obs,_    = base_env.reset()\n",
        "print(f\"The reset observation space looks like: {obs}\")\n",
        "action_standby = 0\n",
        "obs,reward,terminated,truncated,info = base_env.step(action_standby)\n",
        "print(f\"After action {action_standby} the observation space looks like {obs}\")\n",
        "print(f\"The reward we recieved was {reward}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A loop to get an average reward for the base model only perfoming the standby option"
      ],
      "metadata": {
        "id": "-0iOsrI-0qGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#reset the environment and save the obs\n",
        "#going to run it 100 times to get a benchmark\n",
        "#reset score\n",
        "score = 0\n",
        "for step in range(1000):\n",
        "    obs,_    = base_env.reset()\n",
        "    #ensure that the exit condition is reset\n",
        "    truncated = False\n",
        "    #define the action to take\n",
        "    action_standby = 0\n",
        "\n",
        "    while not truncated:\n",
        "        obs,reward,terminated,truncated,info = base_env.step(action_standby)\n",
        "        score += reward\n",
        "\n",
        "print(f\"Done iteration! Total reward accumulated is: {score/step}\")"
      ],
      "metadata": {
        "id": "BztNxs9w0nRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRy0KQKOriqk"
      },
      "source": [
        "Train a model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kqy-glMavKA6"
      },
      "outputs": [],
      "source": [
        "#create a new environment to train the model in.\n",
        "train_env = EMSv0_2(episode_len = 6000, actual_load = actual_load, actual_gen = actual_gen, bat_threshold = 100, bat_cap = 500, purchase_price = purchase_price)\n",
        "\n",
        "#mount the drive\n",
        "drive.mount('/content/drive')\n",
        "#define paths to logs and model saves\n",
        "model_type = \"PPO\"\n",
        "version    = \"EMSv0_2\"\n",
        "model_dir = f\"/content/drive/MyDrive/Colab Notebooks/{version}/models/{model_type}/\"\n",
        "log_dir   = f\"/content/drive/MyDrive/Colab Notebooks/{version}/models/{model_type}logs/\"\n",
        "\n",
        "#make the appropriate directory if it does not exist\n",
        "if not os.path.exists(model_dir):\n",
        "    os.makedirs(model_dir)\n",
        "if not os.path.exists(log_dir):\n",
        "    os.makedirs(log_dir)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pAj6-n04zyt"
      },
      "source": [
        "**LOAD OR MAKE MODEL HERE!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQDhUNGWeum4"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Create the model with the MultiInputPolicy, use the training env, verbose is off because tensorboard loging is enabled\n",
        "model = PPO(\"MultiInputPolicy\",train_env, verbose = 0, tensorboard_log = log_dir)\n",
        "\n",
        "#Load model, fetch the latest (or whichever one you want from the model_dir)\n",
        "#model_load = f\"{model_dir}/\"\n",
        "#model  = PPO.load(model_load, env = train_env)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5dU9TLFzhxD"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir \"{log_dir}\"\n",
        "\n",
        "\n",
        "while True:\n",
        "    #define the name for the specific log\n",
        "    log_name = f\"{version}_{model_type}\"+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "    #make the model learn, set the reset to false so that it keeps its old learning\n",
        "    model.learn(total_timesteps= 30000, tb_log_name = log_name,reset_num_timesteps=False)\n",
        "    model.save(f\"{model_dir}{log_name}\")\n",
        "    #open tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inDHszZaxBUS"
      },
      "outputs": [],
      "source": [
        "#define a test environment\n",
        "test_env = EMSv0_2(episode_len = 2760, actual_load = actual_load[6001:], actual_gen = actual_gen[6001:], bat_threshold = 100, bat_cap = 500, purchase_price = purchase_price[6001:])\n",
        "#reset the environment and save the obs\n",
        "\n",
        "#Load model, fetch the latest (or whichever one you want from the model_dir)\n",
        "#Best A2C model:\n",
        "#Best PPO model:\n",
        "\n",
        "model_type = \"PPO\"\n",
        "version    = \"EMSv0_2\"\n",
        "model_dir = f\"/content/drive/MyDrive/Colab Notebooks/{version}/models/{model_type}/\"\n",
        "log_dir   = f\"/content/drive/MyDrive/Colab Notebooks/{version}/models/{model_type}logs/\"\n",
        "\n",
        "model_load = f\"{model_dir}/\"\n",
        "model  = PPO.load(model_load, env = test_env)\n",
        "\n",
        "\n",
        "#first run it with only standby (default)\n",
        "obs,_    = test_env.reset()\n",
        "#ensure that the exit condition is reset\n",
        "truncated = False\n",
        "#define the action to take\n",
        "action_standby = 0\n",
        "#reset score\n",
        "standby_score = 0\n",
        "while not truncated:\n",
        "    #step the model with the action\n",
        "    obs,reward,terminated,truncated,info = test_env.step(action_standby)\n",
        "    #accumulate the score\n",
        "    standby_score += reward\n",
        "\n",
        "\n",
        "\n",
        "#define the action to take\n",
        "action_standby = 0\n",
        "#reset score\n",
        "EMS_score = 0\n",
        "for step in range(1000):\n",
        "    #Reset the model\n",
        "    obs,_    = test_env.reset()\n",
        "    #ensure that the exit condition is reset\n",
        "    truncated = False\n",
        "    while not truncated:\n",
        "      #predict the best next action\n",
        "      action,_ = model.predict(obs)\n",
        "      #step the model with the action\n",
        "      obs,reward,terminated,truncated,info = test_env.step(action)\n",
        "      #accumulate the score\n",
        "      EMS_score += reward\n",
        "print(f\"step: {step} score: {EMS_score}\")\n",
        "EMS_score = EMS_score/step\n",
        "print(f\"Note: The term does not refer to the cost in rands but rather to the reward as defined by the reward function!\")\n",
        "print(f\"Done the Standby Test! Total cost accumulated is: {standby_score}\")\n",
        "print(f\"Done applying the trained model! Total cost accumulated is: {EMS_score}\")\n",
        "\n",
        "savings = EMS_score - standby_score\n",
        "print(f\"The amount that was saved by applying the EMS agent: {savings}\")\n",
        "print(f\"This was saved over a period of {2760/24} days\")\n",
        "print(f\"The savings represents {(savings/(-standby_score))*100} % of the cost if no EMS is installed\")\n",
        "print(f\"And it represents {(savings/(-EMS_score))*100} % of the cost if the EMS is installed\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN5iLsG3uRRivyZ7qe07uoF",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}