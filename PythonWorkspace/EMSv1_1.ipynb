{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Julian-Banks/EEE4022S_BNKJUL001_Thesis/blob/main/PythonWorkspace/EMSv1_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Version Notes**\n",
        "\n",
        "# **v1.1**\n",
        "\n",
        "**Added:**\n",
        "* rect and inverter power tracking\n",
        "* reward logging in my own logging func\n",
        "\n",
        "**To Do**\n",
        "* NB figure out how to have more episodes!! I think it will have big performance boosts on the training :)\n",
        "* thinking that maybe I should change obs space back to what it was cause I dont actully need to know individual loads and gens!!!!\n",
        "* battery charging rates\n",
        "* thinking of changing all my logging totals to arrays that record every single value rather than just keeping a total\n",
        "# **v1.0**\n",
        "\n",
        "**Added:**\n",
        "* AC and DC load\n",
        "* Wind Gen\n",
        "* changed obs space to hold new loads\n",
        "* re wrote standby and purchase functions\n",
        "\n",
        "**To DO**\n",
        "* thinking that maybe I should change obs space back to what it was cause I dont actully need to know individual loads and gens!!!!\n",
        "* Add in rectifier & inverter power tracking\n",
        "* battery charging rates\n",
        "\n",
        "\n",
        "# **v0.3**\n",
        "**Added:**\n",
        "* loadshedding\n",
        "* New reward structure\n",
        "* added Vec_env\n",
        "* added eval callbacks to validate training\n",
        "* added in logging\n",
        "\n",
        "**Parameters:**\n",
        "* Added in loadshedding forecast\n",
        "\n",
        "**To do:**\n",
        "* find out about battery charging rates  & impliment\n",
        "* Find out if I need to normalise\n",
        "* Try dqn\n",
        "* Find out how the bounds for the obs_space box effect things\n",
        "* Try play with DummyVec wrapper (didnt work in last version)\n",
        "\n",
        "# **v0.2_1**\n",
        "**Added:**\n",
        "*  Monitor wrapper\n",
        "*  DummyVec wrapper\n",
        "*  Wand (weights and bais) enabled\n",
        "\n",
        "**Parameters:**\n",
        "* lowered to 3 predictions  \n",
        "\n",
        "**To do:**\n",
        "* Try to use hyperparameter Optimisation - decided Im only going to do on the final version\n",
        "* Try normalise\n",
        "* Try differnet models\n",
        "* Find out how the bounds for the obs_space box effect things\n",
        "\n",
        "# **v0.2**\n",
        "**Added:**\n",
        "*  simplified load_forecast and gen_forecast to be power_bal_forecasts.\n",
        "*  combined current_load and current_gen to also show current_power_balance\n",
        "*  added proper evaluate call\n",
        "\n",
        "**Parameters:**\n",
        "* No changes  \n",
        "\n",
        "**Results:**\n",
        "* 5% savings on PPO deterministic = true\n",
        "* 4.3% savings on PPO determnistic = false\n",
        "\n",
        "**To do:**\n",
        "* Try to use hyperparameter Optimisation\n",
        "* Try normalise\n",
        "* Try differnet models\n",
        "* Try see if discount rate can be tweaked - at good level.\n",
        "* Find out how the bounds for the obs_space box effect things\n",
        "\n",
        "# **v0.1**\n",
        "**Added:**\n",
        "* added real loads, gen, tou_id's\n",
        "\n",
        "**Parameters:**\n",
        "* training episode = 6000 timesteps\n",
        "* testing episode  = 2760 timesteps\n",
        "* bat_threshold = 100\n",
        "* bat_cap = 500\n",
        "* battery_level at reset = bat_cap/2\n",
        "* num_preds = 24\n",
        "* Trained PPO for 1.65mil timesteps\n",
        "* Trained A2C for 1.2 mil timesteps\n",
        "\n",
        "**Results:**\n",
        "* PP0 - 3.7% improvement from standby mode Deterministic = False\n",
        "* PPO - 6.1% Deterministic =  True\n",
        "* A2C  - -0.3% improvement. And the models after this got worse as training progressed!\n",
        "**To do:**\n",
        "* Try lower num_preds\n",
        "* Try to use hyperparameter Optimisation\n",
        "* Try normalise\n",
        "* Try differnet models\n",
        "* Try see if discount rate can be tweaked\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5DZFnZnzStt1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nI52iVVCCPaf"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "#install dependancies\n",
        "!pip install gymnasium\n",
        "!pip install stable_baselines3[extra]\n",
        "!pip install wandb\n",
        "%load_ext tensorboard\n",
        "\n",
        "#clone repository\n",
        "! git clone https://github.com/Julian-Banks/EEE4022S_BNKJUL001_Thesis\n",
        "\n",
        "#to update the rep\n",
        "%cd /content/EEE4022S_BNKJUL001_Thesis\n",
        "! git pull\n",
        "#import needed libarys\n",
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from gymnasium import spaces\n",
        "import datetime\n",
        "from stable_baselines3 import PPO, A2C, DQN\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from stable_baselines3.common.callbacks import EvalCallback\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.vec_env import VecVideoRecorder\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.animation import FuncAnimation\n",
        "from gym.wrappers import FlattenObservation\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "import wandb\n",
        "from wandb.integration.sb3 import WandbCallback\n",
        "from gymnasium.envs.registration import register\n",
        "\n",
        "\n",
        "\n",
        "#mount the drive\n",
        "drive.mount('/content/drive')\n",
        "#define paths to logs and model saves\n",
        "model_type = \"PPO\"\n",
        "version    = \"EMSv1_1\"\n",
        "model_dir = f\"/content/drive/MyDrive/Colab Notebooks/{version}/models/{model_type}/\"\n",
        "log_dir   = f\"/content/drive/MyDrive/Colab Notebooks/{version}/models/{model_type}logs/\"\n",
        "animation_dir = f\"/content/drive/MyDrive/Colab Notebooks/{version}/models/{model_type}/animation\"\n",
        "\n",
        "#make the appropriate directory if it does not exist\n",
        "if not os.path.exists(model_dir):\n",
        "    os.makedirs(model_dir)\n",
        "if not os.path.exists(log_dir):\n",
        "    os.makedirs(log_dir)\n",
        "if not os.path.exists(animation_dir):\n",
        "    os.makedirs(animation_dir)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define our environment class!!**"
      ],
      "metadata": {
        "id": "Q99_jLMvwuZZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "s2iW-k26FIbm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff09fc5c-bed2-4d54-c4f0-d46dbeb91f38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/gymnasium/envs/registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment EMSv1_1 already in registry.\u001b[0m\n",
            "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n",
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/env_checker.py:244: UserWarning: Your observation current_power_bal has an unconventional shape (neither an image, nor a 1D vector). We recommend you to flatten the observation to have only a 1D vector or use a custom policy to properly process the data.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/env_checker.py:244: UserWarning: Your observation island_forecast has an unconventional shape (neither an image, nor a 1D vector). We recommend you to flatten the observation to have only a 1D vector or use a custom policy to properly process the data.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/env_checker.py:30: UserWarning: It seems that your observation power_bal_forecast is an image but its `dtype` is (float32) whereas it has to be `np.uint8`. If your observation is not an image, we recommend you to flatten the observation to have only a 1D vector\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/env_checker.py:38: UserWarning: It seems that your observation space power_bal_forecast is an image but the upper and lower bounds are not in [0, 255]. Because the CNN policy normalize automatically the observation you may encounter issue if the values are not in that range.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/env_checker.py:51: UserWarning: The minimal resolution for an image is 36x36 for the default `CnnPolicy`. You might need to use a custom features extractor cf. https://stable-baselines3.readthedocs.io/en/master/guide/custom_policy.html\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/env_checker.py:244: UserWarning: Your observation price_forecast has an unconventional shape (neither an image, nor a 1D vector). We recommend you to flatten the observation to have only a 1D vector or use a custom policy to properly process the data.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "class EMSv1_1(gym.Env):\n",
        "    \"\"\"Custom Environment that follows gym interface.\"\"\"\n",
        "\n",
        "    metadata = {\"render_modes\": [\"human\",\"rgb_array\"], \"render_fps\": 30}\n",
        "\n",
        "    def __init__(self,bat_threshold = 0.1, bat_cap = 1, actual_load = \"none\", actual_gen = \"none\", purchase_price = [1,1,1,1,1,1,1,1,2,2,2,2] , episode_len = 8760,num_preds = 24,render_mode = \"rgb_array\", load_shedding = \"none\", wandb_log = False,train_log = True):\n",
        "\n",
        "        super(EMSv1_1, self).__init__()\n",
        "        #define render_mode\n",
        "        self.render_mode = render_mode\n",
        "        #define wandb\n",
        "        self.wandb_log = wandb_log\n",
        "        self.train_log = train_log\n",
        "        #define time frame\n",
        "        self.current_step = 0\n",
        "        self.final_step = int(episode_len)-num_preds-2 #one years worth of steps\n",
        "\n",
        "        #Might make a function for these\n",
        "        #fill all of the actual loads NB!!! is just random for now NB!!! is normalised 0-1\n",
        "        if isinstance(actual_load,str) :\n",
        "            self.actual_load = np.random.rand(self.final_step+num_preds+1,2).astype(np.float32) #will load from a file or something\n",
        "        else:\n",
        "           self.actual_load  = actual_load[:episode_len,:]\n",
        "\n",
        "        #fill all of the actual generation steps.\n",
        "        if isinstance(actual_gen,str):\n",
        "            self.actual_gen  = np.random.rand(self.final_step+num_preds+1,2).astype(np.float32) #will load from file or something\n",
        "        else:\n",
        "            self.actual_gen  = actual_gen[:episode_len,:]\n",
        "\n",
        "        #Fill the loadShedding indicator\n",
        "        if isinstance(load_shedding,str):\n",
        "            num_shedding   = np.random.randint(int(0.02*episode_len), int(0.05*episode_len))\n",
        "            load_shed      = np.array([1]*num_shedding + [0]*(episode_len - num_shedding))\n",
        "            np.random.shuffle(load_shed)\n",
        "            self.load_shed = load_shed\n",
        "        else:\n",
        "            self.load_shed = load_shedding[:episode_len]\n",
        "\n",
        "        #define vars for render\n",
        "        self.off_peak_purchases = 0\n",
        "        self.peak_purchases     = 0\n",
        "        self.standard_purchases = 0\n",
        "        self.off_peak_num       = 0\n",
        "        self.peak_num           = 0\n",
        "        self.standard           = 0\n",
        "        self.unmet_load_total   = 0\n",
        "        self.frames = []\n",
        "\n",
        "        #Define a var for unmet load no that there is loadshedding\n",
        "        self.step_unmet_load = 0\n",
        "\n",
        "        #define the purchase price for every step of the year\n",
        "        purchase_price = np.array(purchase_price).astype(np.float32)\n",
        "        repetitions    = (self.final_step+num_preds+1) // len(purchase_price)\n",
        "        remainder      = (self.final_step+num_preds+1) % len(purchase_price)\n",
        "        self.purchase_price =np.concatenate([purchase_price]*repetitions+[purchase_price[:remainder]])#need to read in from somewhere\n",
        "\n",
        "        #define var for storing the excess gen\n",
        "        self.excess_gen = 0\n",
        "        #define a var for determine amount purchased per step (dont want to make it total as this will incure growing penalties for the Agent if used in reward structure)\n",
        "        self.step_purchased = 0\n",
        "        self.purchased_total = 0\n",
        "        #define the battery max capacity\n",
        "        self.bat_cap = bat_cap\n",
        "        #define the battery low threshold\n",
        "        self.bat_threshold = np.float32(bat_threshold)\n",
        "        #define default action\n",
        "        self.default_action = 0\n",
        "        #define actions and observations space\n",
        "        n_actions = 2 # keeping it simple\n",
        "\n",
        "        self.num_preds = num_preds # day ahead predictions\n",
        "        #define how many different loads and generators there are\n",
        "        self.num_loads = self.actual_load.shape[1]\n",
        "        #define the size of the action space\n",
        "        self.action_space = spaces.Discrete(n_actions)\n",
        "        # Dict space to store all the different things\n",
        "        self.observation_space = spaces.Dict({\n",
        "                \"power_bal_forecast\": gym.spaces.Box(low=-np.inf, high=np.inf, shape=(1,num_preds,self.num_loads), dtype=np.float32),\n",
        "                \"price_forecast\": gym.spaces.Box(low=0, high=np.inf, shape=(1,num_preds+1), dtype=np.float32),\n",
        "                \"island_forecast\": gym.spaces.Box(low=0, high=1, shape=(1,num_preds+1), dtype=np.float32),\n",
        "                \"bat_level\": gym.spaces.Box(low=0, high=np.inf, shape=(1,), dtype=np.float32),\n",
        "                \"current_power_bal\": gym.spaces.Box(low=-np.inf, high=np.inf, shape=(1,self.num_loads), dtype=np.float32),\n",
        "                })\n",
        "\n",
        "    def step(self, action):\n",
        "\n",
        "        #update the current state with the action (needs to be done before current_step is inc since we want to apply the action to the previous step to get the current state)\n",
        "        self.update_state(action)\n",
        "        #Calculate reward from the action\n",
        "        self.reward = self.calc_reward()\n",
        "        self.reward_total += self.reward\n",
        "        #inc time step into Future\n",
        "        self.current_step += 1\n",
        "        #get next observation (for next time step)\n",
        "        observation = self.get_obs()\n",
        "        #Set terminated to False since there are no failure states\n",
        "        self.terminated = False\n",
        "        #Check if timelimit reached\n",
        "        self.truncated = False if self.current_step<self.final_step else True\n",
        "        #Wand log, if its set to true(so that it only gets run when wandb is initialised)\n",
        "        if self.wandb_log == True:\n",
        "            #doing this for training logging\n",
        "            if self.train_log == True:\n",
        "                if self.current_step == self.final_step:\n",
        "                    self.wandb_logger()\n",
        "            else:\n",
        "                self.wandb_logger()\n",
        "        #dont know what to put into info for now\n",
        "        info = {}\n",
        "        return observation, self.reward, self.terminated, self.truncated, info\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        super().reset(seed = seed, options=options)\n",
        "\n",
        "        self.current_step = 0\n",
        "        self.terminated = False\n",
        "        self.truncated = False\n",
        "        #reset the state\n",
        "        self.battery_level      = self.bat_cap/2\n",
        "        self.excess_gen         = 0\n",
        "        self.step_purchased     = 0\n",
        "        self.step_unmet_load    = 0\n",
        "        self.off_peak_purchases = 0\n",
        "        self.off_peak_num       = 0\n",
        "        self.peak_purchases     = 0\n",
        "        self.peak_num           = 0\n",
        "        self.standard_purchases = 0\n",
        "        self.standard_num       = 0\n",
        "        self.unmet_load_total   = 0\n",
        "        self.purchased_total    = 0\n",
        "        self.purchase_count     = 0\n",
        "        self.standby_count      = 0\n",
        "        self.reward             = 0\n",
        "        self.reward_total       = 0\n",
        "        self.step_invt          = 0\n",
        "        self.invt_total         = 0\n",
        "        self.step_rect          = 0\n",
        "        self.rect_total         = 0\n",
        "        #get the first observation\n",
        "        observation = self.get_obs()\n",
        "        #Still don't know what to do with info\n",
        "        info = {}\n",
        "        return observation, info\n",
        "\n",
        "\n",
        "\n",
        "    def render(self, mode='rgb_array', save_path=None):\n",
        "\n",
        "        plt.clf()\n",
        "        values = [self.off_peak_purchases, self.standard_purchases, self.purchase_price[self.peak_purchases]]\n",
        "        colors = ['green', 'orange','red']\n",
        "        labels = ['Off Peak', 'Standard', 'Peak']\n",
        "        plt.xlim(0,1.6)\n",
        "        plt.ylim(0,100)\n",
        "        plt.bar(list(range(3)),values, color=colors, tick_label=labels)\n",
        "        self.frames.append(plt.gcf().canvas.tostring_rgb())\n",
        "        plt.pause(0.000001)\n",
        "\n",
        "    def wandb_logger(self):\n",
        "        train_log_dict={\n",
        "                    \"Excess Generation\"         :self.excess_gen,\n",
        "                    \"Unmet Load\"                :self.unmet_load_total,\n",
        "                    \"Off-Peak Purchases\"        :self.off_peak_purchases,\n",
        "                    \"Standard Purchases\"        :self.standard_purchases,\n",
        "                    \"Peak Purchases\"            :self.peak_purchases,\n",
        "                    \"Num Off-Peak Purchases\"    :self.off_peak_num,\n",
        "                    \"Num Standard Purchases\"    :self.standard_num,\n",
        "                    \"Num Peak Purchases\"        :self.peak_num,\n",
        "                    \"Num Standby Actions\"       :self.standby_count,\n",
        "                    \"Num Purchase Actions\"      :self.purchase_count,\n",
        "                    \"Total Reward\"              :self.reward_total,\n",
        "                    \"Rectifier total power flow\":self.rect_total,\n",
        "                    \"Inverter total power flow\" :self.invt_total,\n",
        "\n",
        "\n",
        "                  }\n",
        "        eval_log_dict={\n",
        "                    \"battery_level\"     :self.battery_level,\n",
        "                    \"AC load\"           :self.actual_load[self.current_step,0],\n",
        "                    \"DC load\"           :self.actual_load[self.current_step,1],\n",
        "                    \"PV generation\"     :self.actual_gen[self.current_step,0],\n",
        "                    \"Wind generation\"   :self.actual_gen[self.current_step,1],\n",
        "                    \"Excess Generation\" :self.excess_gen,\n",
        "                    \"Unmet Load\"        :self.unmet_load_total,\n",
        "                    \"LoadShedding\"      :self.load_shed[self.current_step],\n",
        "                    \"Current_step\"      :self.current_step,\n",
        "                    \"Off-Peak Purchases\":self.off_peak_purchases,\n",
        "                    \"Standard Purchases\":self.standard_purchases,\n",
        "                    \"Peak Purchases\": self.peak_purchases,\n",
        "                    \"Num Off-Peak Purchases\":self.off_peak_num,\n",
        "                    \"Num Standard Purchases\":self.standard_num,\n",
        "                    \"Num Peak Purchases\": self.peak_num,\n",
        "                    \"Num Standby Actions\": self.standby_count,\n",
        "                    \"Num Purchase Actions\":self.purchase_count,\n",
        "                    \"Total Reward\"          : self.reward_total\n",
        "\n",
        "                  }\n",
        "\n",
        "        if self.train_log:\n",
        "            wandb.log(train_log_dict)\n",
        "        else:\n",
        "            wandb.log(eval_log_dict)\n",
        "\n",
        "\n",
        "        '''\n",
        "        plt.clf()\n",
        "        values = [self.off_peak_purchases, self.standard_purchases, self.purchase_price[self.peak_purchases]]\n",
        "        colors = ['green', 'orange','red']\n",
        "        labels = ['Off Peak', 'Standard', 'Peak']\n",
        "        plt.xlim(0,1.6)\n",
        "        plt.ylim(0,100)\n",
        "        plt.bar(list(range(3)),values, color=colors, tick_label=labels)\n",
        "        wandb.log({\"Num Purchases per Tariff rate\": plt})'''\n",
        "\n",
        "    def close(self):\n",
        "        #don't think i need this for my application\n",
        "        pass\n",
        "\n",
        "    def update_state(self, action):\n",
        "        #reset step vars\n",
        "        self.step_purchased = 0\n",
        "        self.step_unmet_load= 0\n",
        "        self.step_rect      = 0\n",
        "        self.step_invt      = 0\n",
        "        #Update current state with actions\n",
        "        if action == 0: #do nothing action\n",
        "            self.standby()\n",
        "        elif action == 1: #buy from Grid\n",
        "            self.purchase()\n",
        "        else:  #error case\n",
        "            raise ValueError(\n",
        "                f\"Received invalid action = {action} which is not part of the action space.\"\n",
        "            )\n",
        "        self.unmet_load_total += self.step_unmet_load\n",
        "        self.purchased_total += self.step_purchased\n",
        "        self.invt_total += self.step_invt\n",
        "        self.rect_total += self.step_rect\n",
        "\n",
        "        self.tou_purchase_inc()\n",
        "\n",
        "    def calc_reward(self):\n",
        "        #Calculate reward based on the state\n",
        "        reward = -self.step_purchased*self.purchase_price[self.current_step] - self.step_unmet_load*10\n",
        "\n",
        "        return reward\n",
        "\n",
        "    def get_obs(self):\n",
        "        #Fill the observation space with the next observation\n",
        "\n",
        "        #Get Forecasts Will probaly write a function for this? idk maybe a schlep to return all the info\n",
        "        load_forecast  = np.array( [self.actual_load[self.current_step+1: self.current_step + self.num_preds+1,:]] , dtype = np.float32) #will load from a file or something\n",
        "        gen_forecast   = np.array( [self.actual_gen[self.current_step+1: self.current_step + self.num_preds+1,:]] , dtype = np.float32) #will load from a file or something\n",
        "        #calculate the power forecast\n",
        "        power_bal_forecast = gen_forecast-load_forecast\n",
        "        #get the prices for the current frame and the next 24 hours. Maybe will cut this down since that seems like a lot of info\n",
        "        price_forecast = np.array( [self.purchase_price[self.current_step:self.current_step+self.num_preds+1]] , dtype = np.float32)\n",
        "        #Just for readibility of the dict object\n",
        "        bat_level      = np.array([self.battery_level] , dtype= np.float32)\n",
        "        #island forecasst, same as tou forecast\n",
        "        island_forecast =np.array( [self.load_shed[self.current_step:self.current_step+self.num_preds+1]] , dtype = np.float32)\n",
        "\n",
        "        #calculate the current power balance\n",
        "        current_load   = np.array([self.actual_load[self.current_step,:]], dtype = np.float32)\n",
        "        current_gen    = np.array([self.actual_gen[self.current_step,:]], dtype  = np.float32)\n",
        "        current_power_bal = current_gen - current_load\n",
        "\n",
        "\n",
        "\n",
        "        obs = dict({\n",
        "                \"bat_level\":      bat_level,\n",
        "                \"current_power_bal\" :   current_power_bal,\n",
        "                \"island_forecast\": island_forecast,\n",
        "                \"power_bal_forecast\":  power_bal_forecast,\n",
        "                \"price_forecast\": price_forecast,\n",
        "        })\n",
        "        return obs\n",
        "\n",
        "    def AC_bus(self):\n",
        "        #fill out info on the ac\n",
        "        ac_gen = self.actual_gen[self.current_step, 0]\n",
        "        ac_load = self.actual_load[self.current_step,0]\n",
        "        ac_power_bal = ac_gen - ac_load\n",
        "        #check if there is load shedding or not\n",
        "        avail_grid = not self.load_shed[self.current_step]\n",
        "        #ac_diesel = Don't know what yet but I do want to use it for something.\n",
        "        #return relevant values\n",
        "        return ac_power_bal,avail_grid\n",
        "\n",
        "    def DC_bus(self):\n",
        "        #fill in info for DC_bus\n",
        "        dc_gen       = self.actual_gen[self.current_step,1]\n",
        "        dc_load      = self.actual_load[self.current_step,1]\n",
        "        dc_power_bal = dc_gen - dc_load\n",
        "        #Haven't imposed limits here but I don't think I need to. Must check.\n",
        "        avail_bat  = self.battery_level - self.bat_threshold\n",
        "        avail_stor = self.bat_cap       - self.battery_level\n",
        "        return dc_power_bal, avail_bat, avail_stor\n",
        "\n",
        "    def standby(self):\n",
        "        self.standby_count+=1\n",
        "        #fetch info from grids\n",
        "        ac_power_bal, avail_grid = self.AC_bus()\n",
        "        dc_power_bal, avail_bat, avail_stor = self.DC_bus()\n",
        "        #define the flow of power from AC to DC\n",
        "        rect_power = 0\n",
        "        #define the flow of power from DC to AC\n",
        "        invt_power = 0\n",
        "\n",
        "        #calculate the immediate power_bal\n",
        "        grid_power_bal = ac_power_bal + dc_power_bal\n",
        "        #determine the flow of power:\n",
        "        if grid_power_bal > 0 :\n",
        "            #increments the battery level by the minimium between avail_stor and grid_power_bal ( always keeps it in range)\n",
        "            self.battery_level += min(avail_stor, grid_power_bal)\n",
        "            #Define the power needed by the dc grid as the powerbalance (negative so its load - gen) plus the power needed to store the battery\n",
        "            dc_power_need  = max(-dc_power_bal+avail_stor,0) #set it to zero if it doesnt need any\n",
        "            #if the DC power need is negative then it doesn't need any power from the AC grid and power will not flow through the rectifier. (rect = 0) otherwise, the amount of power needed will flow through the rect.\n",
        "            ac_excess     =  max(ac_power_bal, 0) #define the amount of excees power as 0 if AC grid needs power\n",
        "            rect_power = min(dc_power_need,ac_excess)\n",
        "            #first charge battery? is poitive that indicates an excess, which will need to flow through the inverter to the AC grid\n",
        "            dc_power_avail = max(dc_power_bal,0) #lol just defined a new var for readability.\n",
        "            ac_power_need   = max(-ac_power_bal, 0) # calculate how much power the ac grid needs.\n",
        "            dc_power_excess = max(dc_power_avail - ac_power_need - avail_stor,0) #calculate how much power would be in excess if there was to be excess.\n",
        "            #inverter power is equal to the minimum val between the avail dc power and the needed power. Then since all excess power needs to go to the grid, if there is any extra energy after the ac_need has been met and the battery is fully charged, it is also sent through the inverter\n",
        "            invt_power = min(ac_power_need, dc_power_avail) + dc_power_excess\n",
        "            #increments excess gen by the max ( if grid_power_bal - avail_stor is negative, there was no excess and it will add 0, else it will add the excess that wasn't stored)\n",
        "            self.excess_gen += max((grid_power_bal - avail_stor), 0)\n",
        "        else:\n",
        "            #there is a shortage of power, see if we can take it from the battery.\n",
        "            # flipping the sign of the grid power balance, bacause it will be negative since we have a shortage of power.\n",
        "            self.battery_level -= min(avail_bat, -grid_power_bal)\n",
        "            #check if we are islanded and buy elec if we arent\n",
        "            if avail_grid:\n",
        "                #if the grid is available (make power bal positive, minus the amount we drew from batter and take the max between that and zero)\n",
        "                self.step_purchased = max(-grid_power_bal- avail_bat, 0)\n",
        "            else:\n",
        "                #if not available add to the step un_met_load.\n",
        "                self.step_unmet_load = max(-grid_power_bal- avail_bat, 0)\n",
        "\n",
        "        #Calculate the flow of power (this is max absorb, the min need is just dc_power_bal)\n",
        "        self.calc_power_flow(dc_power_bal,ac_power_bal,avail_stor)\n",
        "\n",
        "    def calc_power_flow(self,dc_power_bal,ac_power_bal,avail_stor):\n",
        "\n",
        "        #Calculate the flow of power (this is max absorb, the min need is just dc_power_bal)\n",
        "        dc_power_absorb = max(-dc_power_bal+avail_stor,0)\n",
        "        #ac power excess will be the power balance added to the purchase amount\n",
        "        ac_power_excess = max(ac_power_bal+self.step_purchased,0)\n",
        "        #the power that will flow through the rectifier is the minimum between the amount the DC grid can absorb and the excess the ac_grid has\n",
        "        rect_power = min(dc_power_absorb,ac_power_excess)\n",
        "\n",
        "        dc_power_avail = max(dc_power_bal,0) #lol just defined a new var for readability.\n",
        "        ac_power_need   = max(-ac_power_bal-self.step_purchased, 0) # calculate how much power the ac grid needs.\n",
        "        dc_power_excess = max(dc_power_avail - ac_power_need - avail_stor,0) #calculate how much power would be in excess if there was to be excess.\n",
        "        #inverter power is equal to the minimum val between the avail dc power and the needed power. Then since all excess power needs to go to the grid, if there is any extra energy after the ac_need has been met and the battery is fully charged, it is also sent through the inverter\n",
        "        invt_power = min(ac_power_need, dc_power_avail) + dc_power_excess\n",
        "        #set the attributes.\n",
        "        self.step_invt = invt_power\n",
        "        self.step_rect = rect_power\n",
        "\n",
        "    def purchase(self):\n",
        "        self.purchase_count +=1\n",
        "        #fetch info from grids\n",
        "        ac_power_bal, avail_grid = self.AC_bus()\n",
        "        dc_power_bal, avail_bat, avail_stor = self.DC_bus()\n",
        "\n",
        "        if avail_grid:\n",
        "            grid_power_bal = ac_power_bal+dc_power_bal\n",
        "            #if we are grid connected purchase the max between the amount needed elec and 0\n",
        "            self.step_purchased = max(-grid_power_bal + avail_stor,0)\n",
        "            #set Battery to full\n",
        "            self.battery_level = self.bat_cap\n",
        "            #calculate and add the excess electricity generated.\n",
        "            self.excess_gen += max((grid_power_bal - avail_stor), 0)\n",
        "            #only calculate it if we are actually doing anything in this function, otherwise it will get called twice if we call it here and then call standby because the grid is islanded.\n",
        "            self.calc_power_flow(dc_power_bal,ac_power_bal,avail_stor)\n",
        "        else:\n",
        "            #if the grid is not available then we can't purchase and standby can handle power flow ect\n",
        "            self.standby()\n",
        "\n",
        "\n",
        "    def tou_purchase_inc(self):\n",
        "        if self.step_purchased != 0:\n",
        "            if self.purchase_price[self.current_step] == 1:\n",
        "                self.off_peak_purchases += self.step_purchased\n",
        "                self.off_peak_num       += 1\n",
        "            elif self.purchase_price[self.current_step] == 2:\n",
        "                self.standard_purchases += self.step_purchased\n",
        "                self.standard_num       += 1\n",
        "            elif self.purchase_price[self.current_step] == 3:\n",
        "                self.peak_purchases += self.step_purchased\n",
        "                self.peak_num += 1\n",
        "\n",
        "\n",
        "\n",
        "#define a pointer (kinda, don't actually know what its called) a\n",
        "EMS = EMSv1_1\n",
        "\n",
        "# Register environment so I can use make_vec_env\n",
        "register(\n",
        "# unique identifier for the env `name-version`\n",
        "id=f\"{version}\",\n",
        "# path to the class for creating the env\n",
        "# Note: entry_point also accept a class as input (and not only a string)\n",
        "entry_point= EMS(),\n",
        "\n",
        ")\n",
        "\n",
        "#Check the environment with stable_baselines3 check_env.\n",
        "from stable_baselines3.common.env_checker import check_env\n",
        "env = EMS()\n",
        "check_env(env,warn = True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DG4gB2cM7tDY"
      },
      "source": [
        "**Load in the data for our specific microgrid.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "0X9RBdXC_2PD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae148286-179f-4581-926b-a08bb1e66e24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The reset observation space looks like: {'bat_level': array([250.], dtype=float32), 'current_power_bal': array([[-35.376823, -52.2     ]], dtype=float32), 'island_forecast': array([[0., 0., 0., 0.]], dtype=float32), 'power_bal_forecast': array([[[-60.104362, -52.      ],\n",
            "        [-55.141876, -52.2     ],\n",
            "        [-12.482445, -52.2     ]]], dtype=float32), 'price_forecast': array([[1., 1., 1., 1.]], dtype=float32)}\n",
            "Battery level is: 250.0kWh\n",
            "Current AC Power Balance -35.37682342529297, Current DC Power Balance-52.20000076293945\n",
            "Forecasted AC power 1 hour ahead: -60.10436248779297. Forecasted DC power 1 hour ahead: -52.0\n",
            "Forecasted AC power 2 hour ahead: -55.141876220703125. Forecasted DC power 2 hour ahead: -52.20000076293945\n",
            "Forecasted AC power 3 hour ahead: -12.482444763183594. Forecasted DC power 3 hour ahead: -52.20000076293945\n",
            "_________________________________________________________________________________________________________________\n",
            "\n",
            "After action 0: \n",
            "Battery level is: 162.4231719970703kWh\n",
            "Current AC Power Balance -60.10436248779297, Current DC Power Balance-52.0\n",
            "Forecasted AC power 1 hour ahead: -55.141876220703125. Forecasted DC power 1 hour ahead: -52.20000076293945\n",
            "Forecasted AC power 2 hour ahead: -12.482444763183594. Forecasted DC power 2 hour ahead: -52.20000076293945\n",
            "Forecasted AC power 3 hour ahead: 69.41790008544922. Forecasted DC power 3 hour ahead: -52.20000076293945\n",
            "The reward we recieved was 0.0\n",
            "_________________________________________________________________________________________________________________\n",
            "\n",
            "After action 0: \n",
            "Battery level is: 100.0kWh\n",
            "Current AC Power Balance -55.141876220703125, Current DC Power Balance-52.20000076293945\n",
            "Forecasted AC power 1 hour ahead: -12.482444763183594. Forecasted DC power 1 hour ahead: -52.20000076293945\n",
            "Forecasted AC power 2 hour ahead: 69.41790008544922. Forecasted DC power 2 hour ahead: -52.20000076293945\n",
            "Forecasted AC power 3 hour ahead: 141.04750061035156. Forecasted DC power 3 hour ahead: -51.5\n",
            "The reward we recieved was -49.681190490722656\n",
            "_________________________________________________________________________________________________________________\n",
            "\n",
            "After action 1 : \n",
            "Battery level is: 500.0kWh\n",
            "Current AC Power Balance -12.482444763183594, Current DC Power Balance-52.20000076293945\n",
            "Forecasted AC power 1 hour ahead: 69.41790008544922. Forecasted DC power 1 hour ahead: -52.20000076293945\n",
            "Forecasted AC power 2 hour ahead: 141.04750061035156. Forecasted DC power 2 hour ahead: -51.5\n",
            "Forecasted AC power 3 hour ahead: 286.2445068359375. Forecasted DC power 3 hour ahead: -24.50701141357422\n",
            "The reward we recieved was -507.3418731689453\n",
            "_________________________________________________________________________________________________________________\n",
            "\n",
            "Done iteration! Total reward accumulated is: -876890.1130409241\n"
          ]
        }
      ],
      "source": [
        "#need to import data from Github\n",
        "path_data = \"/content/EEE4022S_BNKJUL001_Thesis/PythonWorkspace/dataClean.csv\"\n",
        "data = pd.read_csv(path_data)\n",
        "\n",
        "path_pv_gen = \"/content/EEE4022S_BNKJUL001_Thesis/Generation/BNKJUL001_Thesis_solarGen500kWHomer.csv\"\n",
        "data_pv_gen = pd.read_csv(path_pv_gen)\n",
        "\n",
        "path_wind_gen = \"/content/EEE4022S_BNKJUL001_Thesis/Generation/BNKJUL001_Thesis_Wind500kGenHomer.csv\"\n",
        "data_wind_gen = pd.read_csv(path_wind_gen)\n",
        "\n",
        "#Not actually using this rn but will be soon :)\n",
        "path_shedding = \"/content/EEE4022S_BNKJUL001_Thesis/MatlabWorkSpace/loadShedding2022.csv\"\n",
        "data_shedding = pd.read_csv(path_shedding)\n",
        "load_shedding = data_shedding['LoadShedding'].values.astype(np.float32)\n",
        "\n",
        "wind_gen = data_wind_gen['Wind_Out'].values.astype(np.float32)\n",
        "PV_gen = data_pv_gen['PV_Out'].values.astype(np.float32)\n",
        "actual_gen = np.column_stack((wind_gen, PV_gen))\n",
        "#read in ac and DC load\n",
        "AC_load = data['AC'].values.astype(np.float32)\n",
        "DC_load = data['DC'].values.astype(np.float32)\n",
        "#stack em together for the input :)\n",
        "actual_load = np.column_stack((AC_load, DC_load))\n",
        "purchase_price = data['tou_id'].values.astype(np.float32)\n",
        "\n",
        "\n",
        "#define the base environment\n",
        "base_env = EMS(episode_len = 6000, actual_load = actual_load, actual_gen = actual_gen, bat_threshold = 100, bat_cap = 500, purchase_price = purchase_price,num_preds = 3)\n",
        "#going to print out a bunch of things to test the different spaces.\n",
        "obs,_    = base_env.reset()\n",
        "print(f\"The reset observation space looks like: {obs}\")\n",
        "battery_level = obs['bat_level']\n",
        "print(f\"Battery level is: {battery_level[0]}kWh\")\n",
        "current_power_bal = obs['current_power_bal']\n",
        "print(f\"Current AC Power Balance {current_power_bal[0,0]}, Current DC Power Balance{current_power_bal[0,1]}\")\n",
        "power_forecast = obs['power_bal_forecast']\n",
        "print(f\"Forecasted AC power 1 hour ahead: {power_forecast[0,0,0]}. Forecasted DC power 1 hour ahead: {power_forecast[0,0,1]}\")\n",
        "print(f\"Forecasted AC power 2 hour ahead: {power_forecast[0,1,0]}. Forecasted DC power 2 hour ahead: {power_forecast[0,1,1]}\")\n",
        "print(f\"Forecasted AC power 3 hour ahead: {power_forecast[0,2,0]}. Forecasted DC power 3 hour ahead: {power_forecast[0,2,1]}\")\n",
        "\n",
        "print(f\"_________________________________________________________________________________________________________________\")\n",
        "print(f\"\")\n",
        "\n",
        "\n",
        "action_standby = 0\n",
        "obs,reward,terminated,truncated,info = base_env.step(action_standby)\n",
        "print(f\"After action {action_standby}: \" )\n",
        "battery_level = obs['bat_level']\n",
        "print(f\"Battery level is: {battery_level[0]}kWh\")\n",
        "current_power_bal = obs['current_power_bal']\n",
        "print(f\"Current AC Power Balance {current_power_bal[0,0]}, Current DC Power Balance{current_power_bal[0,1]}\")\n",
        "power_forecast = obs['power_bal_forecast']\n",
        "print(f\"Forecasted AC power 1 hour ahead: {power_forecast[0,0,0]}. Forecasted DC power 1 hour ahead: {power_forecast[0,0,1]}\")\n",
        "print(f\"Forecasted AC power 2 hour ahead: {power_forecast[0,1,0]}. Forecasted DC power 2 hour ahead: {power_forecast[0,1,1]}\")\n",
        "print(f\"Forecasted AC power 3 hour ahead: {power_forecast[0,2,0]}. Forecasted DC power 3 hour ahead: {power_forecast[0,2,1]}\")\n",
        "print(f\"The reward we recieved was {reward}\")\n",
        "print(f\"_________________________________________________________________________________________________________________\")\n",
        "print(f\"\")\n",
        "action_standby = 0\n",
        "obs,reward,terminated,truncated,info = base_env.step(action_standby)\n",
        "print(f\"After action {action_standby}: \" )\n",
        "battery_level = obs['bat_level']\n",
        "print(f\"Battery level is: {battery_level[0]}kWh\")\n",
        "current_power_bal = obs['current_power_bal']\n",
        "print(f\"Current AC Power Balance {current_power_bal[0,0]}, Current DC Power Balance{current_power_bal[0,1]}\")\n",
        "power_forecast = obs['power_bal_forecast']\n",
        "print(f\"Forecasted AC power 1 hour ahead: {power_forecast[0,0,0]}. Forecasted DC power 1 hour ahead: {power_forecast[0,0,1]}\")\n",
        "print(f\"Forecasted AC power 2 hour ahead: {power_forecast[0,1,0]}. Forecasted DC power 2 hour ahead: {power_forecast[0,1,1]}\")\n",
        "print(f\"Forecasted AC power 3 hour ahead: {power_forecast[0,2,0]}. Forecasted DC power 3 hour ahead: {power_forecast[0,2,1]}\")\n",
        "print(f\"The reward we recieved was {reward}\")\n",
        "print(f\"_________________________________________________________________________________________________________________\")\n",
        "print(f\"\")\n",
        "obs,reward,terminated,truncated,info = base_env.step(1)\n",
        "print(f\"After action {1} : \" )\n",
        "battery_level = obs['bat_level']\n",
        "print(f\"Battery level is: {battery_level[0]}kWh\")\n",
        "current_power_bal = obs['current_power_bal']\n",
        "print(f\"Current AC Power Balance {current_power_bal[0,0]}, Current DC Power Balance{current_power_bal[0,1]}\")\n",
        "power_forecast = obs['power_bal_forecast']\n",
        "print(f\"Forecasted AC power 1 hour ahead: {power_forecast[0,0,0]}. Forecasted DC power 1 hour ahead: {power_forecast[0,0,1]}\")\n",
        "print(f\"Forecasted AC power 2 hour ahead: {power_forecast[0,1,0]}. Forecasted DC power 2 hour ahead: {power_forecast[0,1,1]}\")\n",
        "print(f\"Forecasted AC power 3 hour ahead: {power_forecast[0,2,0]}. Forecasted DC power 3 hour ahead: {power_forecast[0,2,1]}\")\n",
        "print(f\"The reward we recieved was {reward}\")\n",
        "print(f\"_________________________________________________________________________________________________________________\")\n",
        "print(f\"\")\n",
        "#Evaluate the base model (no EMS, just using standby mode)\n",
        "#A loop to get an average reward for the base model only perfoming the standby option\n",
        "#reset the environment and save the obs\n",
        "#going to run it 100 times to get a benchmark\n",
        "#reset score\n",
        "score = 0\n",
        "\n",
        "obs,_    = base_env.reset()\n",
        "#ensure that the exit condition is reset\n",
        "truncated = False\n",
        "#define the action to take\n",
        "action_standby = 0\n",
        "\n",
        "while not truncated:\n",
        "    obs,reward,terminated,truncated,info = base_env.step(action_standby)\n",
        "    score += reward\n",
        "\n",
        "print(f\"Done iteration! Total reward accumulated is: {score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pAj6-n04zyt"
      },
      "source": [
        "**LOAD OR MAKE MODEL HERE!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gQDhUNGWeum4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "13ee1e7fdfea406eb2bef29a679aa9d9",
            "a3e822a171144b94acc21a9217a1804c",
            "fef6ad16fb4e42b0b6d992106853863e",
            "da3130908c104280b16bcdf7d1d8a7df",
            "be47693c8cf34aa18bf39a10bb4aa989",
            "02eb22397a9246e39dd9d083726854b0",
            "0b6fbe18e7234b3a84507fa53ce4fcfa",
            "27139dcab1a34dd39acfdc5baa7e3395"
          ]
        },
        "outputId": "911d1c0b-32e9-450d-9566-83ad8398f010"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/notebook/utils.py:280: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
            "  return LooseVersion(v) >= LooseVersion(check)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.12"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/EEE4022S_BNKJUL001_Thesis/wandb/run-20231009_124517-wg4wgius</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/wg4wgius' target=\"_blank\">ethereal-paper-75</a></strong> to <a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems' target=\"_blank\">https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/wg4wgius' target=\"_blank\">https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/wg4wgius</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Logging to runs/wg4wgius/EMSv1_1_PPO_train20231009-124520_0\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 2306  |\n",
            "|    iterations      | 1     |\n",
            "|    time_elapsed    | 4     |\n",
            "|    total_timesteps | 10240 |\n",
            "------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 1278        |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 16          |\n",
            "|    total_timesteps      | 20480       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009498598 |\n",
            "|    clip_fraction        | 0.00303     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.69       |\n",
            "|    explained_variance   | 0.000163    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.84e+06    |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.00141    |\n",
            "|    value_loss           | 4.31e+06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -9.01e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1239         |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 24           |\n",
            "|    total_timesteps      | 30720        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014778555 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.682       |\n",
            "|    explained_variance   | 3.56e-05     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.94e+06     |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -0.000794    |\n",
            "|    value_loss           | 9.68e+06     |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 6e+03      |\n",
            "|    ep_rew_mean          | -9.01e+05  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 1152       |\n",
            "|    iterations           | 4          |\n",
            "|    time_elapsed         | 35         |\n",
            "|    total_timesteps      | 40960      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00099763 |\n",
            "|    clip_fraction        | 0          |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.682     |\n",
            "|    explained_variance   | -2.38e-07  |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 6.21e+06   |\n",
            "|    n_updates            | 30         |\n",
            "|    policy_gradient_loss | -0.000495  |\n",
            "|    value_loss           | 1.3e+07    |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 6e+03       |\n",
            "|    ep_rew_mean          | -9.01e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1085        |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 47          |\n",
            "|    total_timesteps      | 51200       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010887112 |\n",
            "|    clip_fraction        | 0.0349      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.663      |\n",
            "|    explained_variance   | 6.26e-06    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.59e+06    |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.00384    |\n",
            "|    value_loss           | 4.52e+06    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 6e+03       |\n",
            "|    ep_rew_mean          | -8.97e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1092        |\n",
            "|    iterations           | 6           |\n",
            "|    time_elapsed         | 56          |\n",
            "|    total_timesteps      | 61440       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004587176 |\n",
            "|    clip_fraction        | 0.000732    |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.645      |\n",
            "|    explained_variance   | 4.89e-06    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.31e+06    |\n",
            "|    n_updates            | 50          |\n",
            "|    policy_gradient_loss | -0.00158    |\n",
            "|    value_loss           | 1.04e+07    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -8.97e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1070         |\n",
            "|    iterations           | 7            |\n",
            "|    time_elapsed         | 66           |\n",
            "|    total_timesteps      | 71680        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015038537 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.632       |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.46e+06     |\n",
            "|    n_updates            | 60           |\n",
            "|    policy_gradient_loss | -0.000975    |\n",
            "|    value_loss           | 1.19e+07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -8.97e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1032         |\n",
            "|    iterations           | 8            |\n",
            "|    time_elapsed         | 79           |\n",
            "|    total_timesteps      | 81920        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026120082 |\n",
            "|    clip_fraction        | 0.000732     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.63        |\n",
            "|    explained_variance   | -2.38e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.84e+06     |\n",
            "|    n_updates            | 70           |\n",
            "|    policy_gradient_loss | -0.00195     |\n",
            "|    value_loss           | 4.73e+06     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 6e+03         |\n",
            "|    ep_rew_mean          | -8.87e+05     |\n",
            "| time/                   |               |\n",
            "|    fps                  | 1039          |\n",
            "|    iterations           | 9             |\n",
            "|    time_elapsed         | 88            |\n",
            "|    total_timesteps      | 92160         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00091362593 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.636        |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 4.97e+06      |\n",
            "|    n_updates            | 80            |\n",
            "|    policy_gradient_loss | -0.00106      |\n",
            "|    value_loss           | 1.09e+07      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -8.87e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1037         |\n",
            "|    iterations           | 10           |\n",
            "|    time_elapsed         | 98           |\n",
            "|    total_timesteps      | 102400       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018397063 |\n",
            "|    clip_fraction        | 3.91e-05     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.624       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.02e+06     |\n",
            "|    n_updates            | 90           |\n",
            "|    policy_gradient_loss | -0.00171     |\n",
            "|    value_loss           | 9.71e+06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 6e+03       |\n",
            "|    ep_rew_mean          | -8.87e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1027        |\n",
            "|    iterations           | 11          |\n",
            "|    time_elapsed         | 109         |\n",
            "|    total_timesteps      | 112640      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007246873 |\n",
            "|    clip_fraction        | 0.0229      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.591      |\n",
            "|    explained_variance   | 2.38e-07    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.78e+06    |\n",
            "|    n_updates            | 100         |\n",
            "|    policy_gradient_loss | -0.00291    |\n",
            "|    value_loss           | 4.63e+06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -8.81e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1034         |\n",
            "|    iterations           | 12           |\n",
            "|    time_elapsed         | 118          |\n",
            "|    total_timesteps      | 122880       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033392198 |\n",
            "|    clip_fraction        | 0.00165      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.59        |\n",
            "|    explained_variance   | 5.96e-08     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.71e+06     |\n",
            "|    n_updates            | 110          |\n",
            "|    policy_gradient_loss | -0.00171     |\n",
            "|    value_loss           | 1.12e+07     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 6e+03       |\n",
            "|    ep_rew_mean          | -8.81e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1031        |\n",
            "|    iterations           | 13          |\n",
            "|    time_elapsed         | 129         |\n",
            "|    total_timesteps      | 133120      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001780826 |\n",
            "|    clip_fraction        | 0.00144     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.547      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.61e+06    |\n",
            "|    n_updates            | 120         |\n",
            "|    policy_gradient_loss | -0.00219    |\n",
            "|    value_loss           | 9.09e+06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -8.81e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1026         |\n",
            "|    iterations           | 14           |\n",
            "|    time_elapsed         | 139          |\n",
            "|    total_timesteps      | 143360       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015605437 |\n",
            "|    clip_fraction        | 0.00109      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.524       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.41e+06     |\n",
            "|    n_updates            | 130          |\n",
            "|    policy_gradient_loss | -0.00192     |\n",
            "|    value_loss           | 4.68e+06     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 6e+03         |\n",
            "|    ep_rew_mean          | -8.71e+05     |\n",
            "| time/                   |               |\n",
            "|    fps                  | 1034          |\n",
            "|    iterations           | 15            |\n",
            "|    time_elapsed         | 148           |\n",
            "|    total_timesteps      | 153600        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00060172146 |\n",
            "|    clip_fraction        | 0.000469      |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.548        |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 5.78e+06      |\n",
            "|    n_updates            | 140           |\n",
            "|    policy_gradient_loss | -0.00168      |\n",
            "|    value_loss           | 1.08e+07      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -8.71e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1030         |\n",
            "|    iterations           | 16           |\n",
            "|    time_elapsed         | 158          |\n",
            "|    total_timesteps      | 163840       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021907538 |\n",
            "|    clip_fraction        | 0.00424      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.493       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.71e+06     |\n",
            "|    n_updates            | 150          |\n",
            "|    policy_gradient_loss | -0.00267     |\n",
            "|    value_loss           | 7.9e+06      |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 6e+03      |\n",
            "|    ep_rew_mean          | -8.71e+05  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 1025       |\n",
            "|    iterations           | 17         |\n",
            "|    time_elapsed         | 169        |\n",
            "|    total_timesteps      | 174080     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00099461 |\n",
            "|    clip_fraction        | 0.00231    |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.484     |\n",
            "|    explained_variance   | 0          |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 2.28e+06   |\n",
            "|    n_updates            | 160        |\n",
            "|    policy_gradient_loss | -0.00219   |\n",
            "|    value_loss           | 4.68e+06   |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -8.63e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1029         |\n",
            "|    iterations           | 18           |\n",
            "|    time_elapsed         | 179          |\n",
            "|    total_timesteps      | 184320       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0005385486 |\n",
            "|    clip_fraction        | 0.00213      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.521       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.83e+06     |\n",
            "|    n_updates            | 170          |\n",
            "|    policy_gradient_loss | -0.00164     |\n",
            "|    value_loss           | 1.09e+07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -8.63e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1024         |\n",
            "|    iterations           | 19           |\n",
            "|    time_elapsed         | 189          |\n",
            "|    total_timesteps      | 194560       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025104196 |\n",
            "|    clip_fraction        | 0.00737      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.479       |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.17e+06     |\n",
            "|    n_updates            | 180          |\n",
            "|    policy_gradient_loss | -0.00296     |\n",
            "|    value_loss           | 7.37e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -8.63e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1021         |\n",
            "|    iterations           | 20           |\n",
            "|    time_elapsed         | 200          |\n",
            "|    total_timesteps      | 204800       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014667733 |\n",
            "|    clip_fraction        | 0.00521      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.463       |\n",
            "|    explained_variance   | 1.19e-07     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.76e+06     |\n",
            "|    n_updates            | 190          |\n",
            "|    policy_gradient_loss | -0.00272     |\n",
            "|    value_loss           | 4.37e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -8.56e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1027         |\n",
            "|    iterations           | 21           |\n",
            "|    time_elapsed         | 209          |\n",
            "|    total_timesteps      | 215040       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0008822397 |\n",
            "|    clip_fraction        | 0.00187      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.507       |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.6e+06      |\n",
            "|    n_updates            | 200          |\n",
            "|    policy_gradient_loss | -0.00215     |\n",
            "|    value_loss           | 1.07e+07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -8.56e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1024         |\n",
            "|    iterations           | 22           |\n",
            "|    time_elapsed         | 219          |\n",
            "|    total_timesteps      | 225280       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016698185 |\n",
            "|    clip_fraction        | 0.00249      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.457       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.32e+06     |\n",
            "|    n_updates            | 210          |\n",
            "|    policy_gradient_loss | -0.00205     |\n",
            "|    value_loss           | 7.13e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -8.56e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1020         |\n",
            "|    iterations           | 23           |\n",
            "|    time_elapsed         | 230          |\n",
            "|    total_timesteps      | 235520       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017679784 |\n",
            "|    clip_fraction        | 0.00474      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.443       |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.58e+06     |\n",
            "|    n_updates            | 220          |\n",
            "|    policy_gradient_loss | -0.00262     |\n",
            "|    value_loss           | 4.58e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -8.51e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1024         |\n",
            "|    iterations           | 24           |\n",
            "|    time_elapsed         | 239          |\n",
            "|    total_timesteps      | 245760       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0010991206 |\n",
            "|    clip_fraction        | 0.00313      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.48        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.87e+06     |\n",
            "|    n_updates            | 230          |\n",
            "|    policy_gradient_loss | -0.00267     |\n",
            "|    value_loss           | 1.11e+07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -8.51e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1020         |\n",
            "|    iterations           | 25           |\n",
            "|    time_elapsed         | 250          |\n",
            "|    total_timesteps      | 256000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0009743685 |\n",
            "|    clip_fraction        | 0.00493      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.418       |\n",
            "|    explained_variance   | 1.79e-07     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.46e+06     |\n",
            "|    n_updates            | 240          |\n",
            "|    policy_gradient_loss | -0.00202     |\n",
            "|    value_loss           | 6.31e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -8.51e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1018         |\n",
            "|    iterations           | 26           |\n",
            "|    time_elapsed         | 261          |\n",
            "|    total_timesteps      | 266240       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015340528 |\n",
            "|    clip_fraction        | 0.00386      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.434       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.81e+06     |\n",
            "|    n_updates            | 250          |\n",
            "|    policy_gradient_loss | -0.00237     |\n",
            "|    value_loss           | 5.1e+06      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -8.45e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1021         |\n",
            "|    iterations           | 27           |\n",
            "|    time_elapsed         | 270          |\n",
            "|    total_timesteps      | 276480       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021820925 |\n",
            "|    clip_fraction        | 0.00782      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.468       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.71e+06     |\n",
            "|    n_updates            | 260          |\n",
            "|    policy_gradient_loss | -0.00256     |\n",
            "|    value_loss           | 1.01e+07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -8.45e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1019         |\n",
            "|    iterations           | 28           |\n",
            "|    time_elapsed         | 281          |\n",
            "|    total_timesteps      | 286720       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023518843 |\n",
            "|    clip_fraction        | 0.0175       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.384       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.46e+06     |\n",
            "|    n_updates            | 270          |\n",
            "|    policy_gradient_loss | -0.00352     |\n",
            "|    value_loss           | 5.69e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -8.45e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1018         |\n",
            "|    iterations           | 29           |\n",
            "|    time_elapsed         | 291          |\n",
            "|    total_timesteps      | 296960       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013658148 |\n",
            "|    clip_fraction        | 0.0082       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.417       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.72e+06     |\n",
            "|    n_updates            | 280          |\n",
            "|    policy_gradient_loss | -0.00255     |\n",
            "|    value_loss           | 5.82e+06     |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 6e+03      |\n",
            "|    ep_rew_mean          | -8.4e+05   |\n",
            "| time/                   |            |\n",
            "|    fps                  | 1021       |\n",
            "|    iterations           | 30         |\n",
            "|    time_elapsed         | 300        |\n",
            "|    total_timesteps      | 307200     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00226895 |\n",
            "|    clip_fraction        | 0.009      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.429     |\n",
            "|    explained_variance   | 0          |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 4.49e+06   |\n",
            "|    n_updates            | 290        |\n",
            "|    policy_gradient_loss | -0.00266   |\n",
            "|    value_loss           | 9.77e+06   |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -8.4e+05     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1019         |\n",
            "|    iterations           | 31           |\n",
            "|    time_elapsed         | 311          |\n",
            "|    total_timesteps      | 317440       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011343897 |\n",
            "|    clip_fraction        | 0.00792      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.345       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.7e+06      |\n",
            "|    n_updates            | 300          |\n",
            "|    policy_gradient_loss | -0.00253     |\n",
            "|    value_loss           | 5.06e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -8.4e+05     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1020         |\n",
            "|    iterations           | 32           |\n",
            "|    time_elapsed         | 321          |\n",
            "|    total_timesteps      | 327680       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014258476 |\n",
            "|    clip_fraction        | 0.00801      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.387       |\n",
            "|    explained_variance   | -2.38e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.39e+06     |\n",
            "|    n_updates            | 310          |\n",
            "|    policy_gradient_loss | -0.0029      |\n",
            "|    value_loss           | 6.24e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -8.35e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1020         |\n",
            "|    iterations           | 33           |\n",
            "|    time_elapsed         | 331          |\n",
            "|    total_timesteps      | 337920       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011504588 |\n",
            "|    clip_fraction        | 0.0073       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.411       |\n",
            "|    explained_variance   | 5.96e-08     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.98e+06     |\n",
            "|    n_updates            | 320          |\n",
            "|    policy_gradient_loss | -0.00278     |\n",
            "|    value_loss           | 9.83e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -8.35e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1018         |\n",
            "|    iterations           | 34           |\n",
            "|    time_elapsed         | 341          |\n",
            "|    total_timesteps      | 348160       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019266069 |\n",
            "|    clip_fraction        | 0.011        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.325       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.97e+06     |\n",
            "|    n_updates            | 330          |\n",
            "|    policy_gradient_loss | -0.00284     |\n",
            "|    value_loss           | 4.64e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -8.35e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1019         |\n",
            "|    iterations           | 35           |\n",
            "|    time_elapsed         | 351          |\n",
            "|    total_timesteps      | 358400       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0009957062 |\n",
            "|    clip_fraction        | 0.00535      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.37        |\n",
            "|    explained_variance   | 1.19e-07     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.2e+06      |\n",
            "|    n_updates            | 340          |\n",
            "|    policy_gradient_loss | -0.0022      |\n",
            "|    value_loss           | 6.42e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -8.32e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1019         |\n",
            "|    iterations           | 36           |\n",
            "|    time_elapsed         | 361          |\n",
            "|    total_timesteps      | 368640       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017993234 |\n",
            "|    clip_fraction        | 0.00981      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.383       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5e+06        |\n",
            "|    n_updates            | 350          |\n",
            "|    policy_gradient_loss | -0.00305     |\n",
            "|    value_loss           | 1.01e+07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -8.32e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1017         |\n",
            "|    iterations           | 37           |\n",
            "|    time_elapsed         | 372          |\n",
            "|    total_timesteps      | 378880       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011574298 |\n",
            "|    clip_fraction        | 0.00968      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.288       |\n",
            "|    explained_variance   | 1.19e-07     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.66e+06     |\n",
            "|    n_updates            | 360          |\n",
            "|    policy_gradient_loss | -0.00292     |\n",
            "|    value_loss           | 3.97e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -8.32e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1020         |\n",
            "|    iterations           | 38           |\n",
            "|    time_elapsed         | 381          |\n",
            "|    total_timesteps      | 389120       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012922429 |\n",
            "|    clip_fraction        | 0.00979      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.348       |\n",
            "|    explained_variance   | 1.19e-07     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.12e+06     |\n",
            "|    n_updates            | 370          |\n",
            "|    policy_gradient_loss | -0.00223     |\n",
            "|    value_loss           | 7.09e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -8.28e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1019         |\n",
            "|    iterations           | 39           |\n",
            "|    time_elapsed         | 391          |\n",
            "|    total_timesteps      | 399360       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013240075 |\n",
            "|    clip_fraction        | 0.01         |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.377       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.27e+06     |\n",
            "|    n_updates            | 380          |\n",
            "|    policy_gradient_loss | -0.00239     |\n",
            "|    value_loss           | 1.06e+07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -8.28e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1017         |\n",
            "|    iterations           | 40           |\n",
            "|    time_elapsed         | 402          |\n",
            "|    total_timesteps      | 409600       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014950179 |\n",
            "|    clip_fraction        | 0.0121       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.268       |\n",
            "|    explained_variance   | -2.38e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.36e+06     |\n",
            "|    n_updates            | 390          |\n",
            "|    policy_gradient_loss | -0.00294     |\n",
            "|    value_loss           | 2.35e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -8.25e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1020         |\n",
            "|    iterations           | 41           |\n",
            "|    time_elapsed         | 411          |\n",
            "|    total_timesteps      | 419840       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016992368 |\n",
            "|    clip_fraction        | 0.0131       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.342       |\n",
            "|    explained_variance   | -2.38e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.44e+06     |\n",
            "|    n_updates            | 400          |\n",
            "|    policy_gradient_loss | -0.00317     |\n",
            "|    value_loss           | 6.59e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -8.25e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1018         |\n",
            "|    iterations           | 42           |\n",
            "|    time_elapsed         | 422          |\n",
            "|    total_timesteps      | 430080       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019652264 |\n",
            "|    clip_fraction        | 0.0121       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.357       |\n",
            "|    explained_variance   | 1.19e-07     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.77e+06     |\n",
            "|    n_updates            | 410          |\n",
            "|    policy_gradient_loss | -0.00355     |\n",
            "|    value_loss           | 1.07e+07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -8.25e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1016         |\n",
            "|    iterations           | 43           |\n",
            "|    time_elapsed         | 433          |\n",
            "|    total_timesteps      | 440320       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012445718 |\n",
            "|    clip_fraction        | 0.0133       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.265       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.02e+06     |\n",
            "|    n_updates            | 420          |\n",
            "|    policy_gradient_loss | -0.002       |\n",
            "|    value_loss           | 2.64e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -8.22e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1019         |\n",
            "|    iterations           | 44           |\n",
            "|    time_elapsed         | 442          |\n",
            "|    total_timesteps      | 450560       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0008891791 |\n",
            "|    clip_fraction        | 0.00536      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.341       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.36e+06     |\n",
            "|    n_updates            | 430          |\n",
            "|    policy_gradient_loss | -0.00189     |\n",
            "|    value_loss           | 7.25e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -8.22e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1017         |\n",
            "|    iterations           | 45           |\n",
            "|    time_elapsed         | 453          |\n",
            "|    total_timesteps      | 460800       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014191356 |\n",
            "|    clip_fraction        | 0.0116       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.329       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.39e+06     |\n",
            "|    n_updates            | 440          |\n",
            "|    policy_gradient_loss | -0.00239     |\n",
            "|    value_loss           | 9.04e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -8.22e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1015         |\n",
            "|    iterations           | 46           |\n",
            "|    time_elapsed         | 464          |\n",
            "|    total_timesteps      | 471040       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020819947 |\n",
            "|    clip_fraction        | 0.0157       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.263       |\n",
            "|    explained_variance   | 1.79e-07     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.01e+06     |\n",
            "|    n_updates            | 450          |\n",
            "|    policy_gradient_loss | -0.00333     |\n",
            "|    value_loss           | 2.75e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -8.19e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1004         |\n",
            "|    iterations           | 47           |\n",
            "|    time_elapsed         | 478          |\n",
            "|    total_timesteps      | 481280       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024256967 |\n",
            "|    clip_fraction        | 0.0155       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.333       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.21e+06     |\n",
            "|    n_updates            | 460          |\n",
            "|    policy_gradient_loss | -0.0026      |\n",
            "|    value_loss           | 7.69e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -8.19e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 991          |\n",
            "|    iterations           | 48           |\n",
            "|    time_elapsed         | 495          |\n",
            "|    total_timesteps      | 491520       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011894319 |\n",
            "|    clip_fraction        | 0.00777      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.305       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.35e+06     |\n",
            "|    n_updates            | 470          |\n",
            "|    policy_gradient_loss | -0.00222     |\n",
            "|    value_loss           | 8.62e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -8.19e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 979          |\n",
            "|    iterations           | 49           |\n",
            "|    time_elapsed         | 512          |\n",
            "|    total_timesteps      | 501760       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015724588 |\n",
            "|    clip_fraction        | 0.00918      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.251       |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.74e+06     |\n",
            "|    n_updates            | 480          |\n",
            "|    policy_gradient_loss | -0.00264     |\n",
            "|    value_loss           | 3.14e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -8.17e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 978          |\n",
            "|    iterations           | 50           |\n",
            "|    time_elapsed         | 523          |\n",
            "|    total_timesteps      | 512000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0010582594 |\n",
            "|    clip_fraction        | 0.00664      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.327       |\n",
            "|    explained_variance   | 5.96e-08     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.34e+06     |\n",
            "|    n_updates            | 490          |\n",
            "|    policy_gradient_loss | -0.00253     |\n",
            "|    value_loss           | 8.55e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -8.17e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 978          |\n",
            "|    iterations           | 51           |\n",
            "|    time_elapsed         | 533          |\n",
            "|    total_timesteps      | 522240       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014059043 |\n",
            "|    clip_fraction        | 0.00879      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.294       |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.65e+06     |\n",
            "|    n_updates            | 500          |\n",
            "|    policy_gradient_loss | -0.00258     |\n",
            "|    value_loss           | 7.62e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -8.17e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 977          |\n",
            "|    iterations           | 52           |\n",
            "|    time_elapsed         | 544          |\n",
            "|    total_timesteps      | 532480       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016231658 |\n",
            "|    clip_fraction        | 0.0134       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.26        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.41e+06     |\n",
            "|    n_updates            | 510          |\n",
            "|    policy_gradient_loss | -0.00345     |\n",
            "|    value_loss           | 3.16e+06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 6e+03       |\n",
            "|    ep_rew_mean          | -8.15e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 979         |\n",
            "|    iterations           | 53          |\n",
            "|    time_elapsed         | 553         |\n",
            "|    total_timesteps      | 542720      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001463723 |\n",
            "|    clip_fraction        | 0.0108      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.34       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.58e+06    |\n",
            "|    n_updates            | 520         |\n",
            "|    policy_gradient_loss | -0.00297    |\n",
            "|    value_loss           | 9.03e+06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -8.15e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 979          |\n",
            "|    iterations           | 54           |\n",
            "|    time_elapsed         | 564          |\n",
            "|    total_timesteps      | 552960       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017424002 |\n",
            "|    clip_fraction        | 0.0138       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.282       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.72e+06     |\n",
            "|    n_updates            | 530          |\n",
            "|    policy_gradient_loss | -0.00251     |\n",
            "|    value_loss           | 6.88e+06     |\n",
            "------------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 6e+03     |\n",
            "|    ep_rew_mean          | -8.15e+05 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 978       |\n",
            "|    iterations           | 55        |\n",
            "|    time_elapsed         | 575       |\n",
            "|    total_timesteps      | 563200    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.001352  |\n",
            "|    clip_fraction        | 0.0096    |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -0.258    |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 1.46e+06  |\n",
            "|    n_updates            | 540       |\n",
            "|    policy_gradient_loss | -0.00338  |\n",
            "|    value_loss           | 3.37e+06  |\n",
            "---------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -8.12e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 980          |\n",
            "|    iterations           | 56           |\n",
            "|    time_elapsed         | 584          |\n",
            "|    total_timesteps      | 573440       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011391619 |\n",
            "|    clip_fraction        | 0.00895      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.334       |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.71e+06     |\n",
            "|    n_updates            | 550          |\n",
            "|    policy_gradient_loss | -0.00215     |\n",
            "|    value_loss           | 8.8e+06      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -8.12e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 980          |\n",
            "|    iterations           | 57           |\n",
            "|    time_elapsed         | 595          |\n",
            "|    total_timesteps      | 583680       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015066699 |\n",
            "|    clip_fraction        | 0.0109       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.267       |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.6e+06      |\n",
            "|    n_updates            | 560          |\n",
            "|    policy_gradient_loss | -0.00282     |\n",
            "|    value_loss           | 6.28e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -8.12e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 980          |\n",
            "|    iterations           | 58           |\n",
            "|    time_elapsed         | 606          |\n",
            "|    total_timesteps      | 593920       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014115646 |\n",
            "|    clip_fraction        | 0.0112       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.257       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.64e+06     |\n",
            "|    n_updates            | 570          |\n",
            "|    policy_gradient_loss | -0.00225     |\n",
            "|    value_loss           | 3.34e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -8.11e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 980          |\n",
            "|    iterations           | 59           |\n",
            "|    time_elapsed         | 615          |\n",
            "|    total_timesteps      | 604160       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016032864 |\n",
            "|    clip_fraction        | 0.00838      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.321       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.66e+06     |\n",
            "|    n_updates            | 580          |\n",
            "|    policy_gradient_loss | -0.00241     |\n",
            "|    value_loss           | 9.36e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -8.11e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 980          |\n",
            "|    iterations           | 60           |\n",
            "|    time_elapsed         | 626          |\n",
            "|    total_timesteps      | 614400       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013018791 |\n",
            "|    clip_fraction        | 0.0107       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.252       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.75e+06     |\n",
            "|    n_updates            | 590          |\n",
            "|    policy_gradient_loss | -0.00299     |\n",
            "|    value_loss           | 6.13e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -8.11e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 980          |\n",
            "|    iterations           | 61           |\n",
            "|    time_elapsed         | 637          |\n",
            "|    total_timesteps      | 624640       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024493015 |\n",
            "|    clip_fraction        | 0.0196       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.24        |\n",
            "|    explained_variance   | 5.96e-08     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.35e+06     |\n",
            "|    n_updates            | 600          |\n",
            "|    policy_gradient_loss | -0.00246     |\n",
            "|    value_loss           | 3.13e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -8.04e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 982          |\n",
            "|    iterations           | 62           |\n",
            "|    time_elapsed         | 646          |\n",
            "|    total_timesteps      | 634880       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013611626 |\n",
            "|    clip_fraction        | 0.00991      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.317       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.53e+06     |\n",
            "|    n_updates            | 610          |\n",
            "|    policy_gradient_loss | -0.00242     |\n",
            "|    value_loss           | 8.76e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -8.04e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 982          |\n",
            "|    iterations           | 63           |\n",
            "|    time_elapsed         | 656          |\n",
            "|    total_timesteps      | 645120       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016921029 |\n",
            "|    clip_fraction        | 0.0124       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.25        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.49e+06     |\n",
            "|    n_updates            | 620          |\n",
            "|    policy_gradient_loss | -0.0024      |\n",
            "|    value_loss           | 5.76e+06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 6e+03       |\n",
            "|    ep_rew_mean          | -8.04e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 981         |\n",
            "|    iterations           | 64          |\n",
            "|    time_elapsed         | 667         |\n",
            "|    total_timesteps      | 655360      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003360726 |\n",
            "|    clip_fraction        | 0.0248      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.256      |\n",
            "|    explained_variance   | -1.19e-07   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.76e+06    |\n",
            "|    n_updates            | 630         |\n",
            "|    policy_gradient_loss | -0.00248    |\n",
            "|    value_loss           | 3.57e+06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.98e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 984          |\n",
            "|    iterations           | 65           |\n",
            "|    time_elapsed         | 676          |\n",
            "|    total_timesteps      | 665600       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031788342 |\n",
            "|    clip_fraction        | 0.0194       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.323       |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.25e+06     |\n",
            "|    n_updates            | 640          |\n",
            "|    policy_gradient_loss | -0.00451     |\n",
            "|    value_loss           | 9.25e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.98e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 983          |\n",
            "|    iterations           | 66           |\n",
            "|    time_elapsed         | 687          |\n",
            "|    total_timesteps      | 675840       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022730131 |\n",
            "|    clip_fraction        | 0.0183       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.245       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.77e+06     |\n",
            "|    n_updates            | 650          |\n",
            "|    policy_gradient_loss | -0.0035      |\n",
            "|    value_loss           | 5.27e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.98e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 983          |\n",
            "|    iterations           | 67           |\n",
            "|    time_elapsed         | 697          |\n",
            "|    total_timesteps      | 686080       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028764997 |\n",
            "|    clip_fraction        | 0.0181       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.281       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.68e+06     |\n",
            "|    n_updates            | 660          |\n",
            "|    policy_gradient_loss | -0.00276     |\n",
            "|    value_loss           | 4.27e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.94e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 985          |\n",
            "|    iterations           | 68           |\n",
            "|    time_elapsed         | 706          |\n",
            "|    total_timesteps      | 696320       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013493061 |\n",
            "|    clip_fraction        | 0.00903      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.316       |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.31e+06     |\n",
            "|    n_updates            | 670          |\n",
            "|    policy_gradient_loss | -0.00254     |\n",
            "|    value_loss           | 8.44e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.94e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 984          |\n",
            "|    iterations           | 69           |\n",
            "|    time_elapsed         | 717          |\n",
            "|    total_timesteps      | 706560       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022066585 |\n",
            "|    clip_fraction        | 0.0187       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.238       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.81e+06     |\n",
            "|    n_updates            | 680          |\n",
            "|    policy_gradient_loss | -0.0031      |\n",
            "|    value_loss           | 5.21e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.94e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 983          |\n",
            "|    iterations           | 70           |\n",
            "|    time_elapsed         | 728          |\n",
            "|    total_timesteps      | 716800       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029421835 |\n",
            "|    clip_fraction        | 0.0248       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.292       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.3e+06      |\n",
            "|    n_updates            | 690          |\n",
            "|    policy_gradient_loss | -0.00289     |\n",
            "|    value_loss           | 4.82e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.89e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 985          |\n",
            "|    iterations           | 71           |\n",
            "|    time_elapsed         | 737          |\n",
            "|    total_timesteps      | 727040       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016935617 |\n",
            "|    clip_fraction        | 0.00857      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.319       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.92e+06     |\n",
            "|    n_updates            | 700          |\n",
            "|    policy_gradient_loss | -0.00194     |\n",
            "|    value_loss           | 8.65e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.89e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 985          |\n",
            "|    iterations           | 72           |\n",
            "|    time_elapsed         | 748          |\n",
            "|    total_timesteps      | 737280       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021162804 |\n",
            "|    clip_fraction        | 0.0203       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.23        |\n",
            "|    explained_variance   | -2.38e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.28e+06     |\n",
            "|    n_updates            | 710          |\n",
            "|    policy_gradient_loss | -0.00284     |\n",
            "|    value_loss           | 3.85e+06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 6e+03       |\n",
            "|    ep_rew_mean          | -7.89e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 983         |\n",
            "|    iterations           | 73          |\n",
            "|    time_elapsed         | 759         |\n",
            "|    total_timesteps      | 747520      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001513179 |\n",
            "|    clip_fraction        | 0.0118      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.296      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.9e+06     |\n",
            "|    n_updates            | 720         |\n",
            "|    policy_gradient_loss | -0.00226    |\n",
            "|    value_loss           | 5.19e+06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.86e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 985          |\n",
            "|    iterations           | 74           |\n",
            "|    time_elapsed         | 768          |\n",
            "|    total_timesteps      | 757760       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017202201 |\n",
            "|    clip_fraction        | 0.014        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.321       |\n",
            "|    explained_variance   | 1.79e-07     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.1e+06      |\n",
            "|    n_updates            | 730          |\n",
            "|    policy_gradient_loss | -0.00307     |\n",
            "|    value_loss           | 9.1e+06      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.86e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 984          |\n",
            "|    iterations           | 75           |\n",
            "|    time_elapsed         | 779          |\n",
            "|    total_timesteps      | 768000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015799574 |\n",
            "|    clip_fraction        | 0.0177       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.233       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.06e+06     |\n",
            "|    n_updates            | 740          |\n",
            "|    policy_gradient_loss | -0.00327     |\n",
            "|    value_loss           | 3.52e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.86e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 984          |\n",
            "|    iterations           | 76           |\n",
            "|    time_elapsed         | 790          |\n",
            "|    total_timesteps      | 778240       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012650754 |\n",
            "|    clip_fraction        | 0.00733      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.311       |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.96e+06     |\n",
            "|    n_updates            | 750          |\n",
            "|    policy_gradient_loss | -0.00243     |\n",
            "|    value_loss           | 5.37e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.83e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 986          |\n",
            "|    iterations           | 77           |\n",
            "|    time_elapsed         | 799          |\n",
            "|    total_timesteps      | 788480       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020773173 |\n",
            "|    clip_fraction        | 0.0167       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.328       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.03e+06     |\n",
            "|    n_updates            | 760          |\n",
            "|    policy_gradient_loss | -0.00357     |\n",
            "|    value_loss           | 8.71e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.83e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 986          |\n",
            "|    iterations           | 78           |\n",
            "|    time_elapsed         | 809          |\n",
            "|    total_timesteps      | 798720       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026687304 |\n",
            "|    clip_fraction        | 0.034        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.229       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1e+06        |\n",
            "|    n_updates            | 770          |\n",
            "|    policy_gradient_loss | -0.00311     |\n",
            "|    value_loss           | 3.16e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.83e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 986          |\n",
            "|    iterations           | 79           |\n",
            "|    time_elapsed         | 820          |\n",
            "|    total_timesteps      | 808960       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019398167 |\n",
            "|    clip_fraction        | 0.02         |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.312       |\n",
            "|    explained_variance   | 1.19e-07     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.41e+06     |\n",
            "|    n_updates            | 780          |\n",
            "|    policy_gradient_loss | -0.00268     |\n",
            "|    value_loss           | 5.82e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.81e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 987          |\n",
            "|    iterations           | 80           |\n",
            "|    time_elapsed         | 829          |\n",
            "|    total_timesteps      | 819200       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015701863 |\n",
            "|    clip_fraction        | 0.0102       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.335       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.71e+06     |\n",
            "|    n_updates            | 790          |\n",
            "|    policy_gradient_loss | -0.003       |\n",
            "|    value_loss           | 9.19e+06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 6e+03       |\n",
            "|    ep_rew_mean          | -7.81e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 986         |\n",
            "|    iterations           | 81          |\n",
            "|    time_elapsed         | 840         |\n",
            "|    total_timesteps      | 829440      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002936881 |\n",
            "|    clip_fraction        | 0.0272      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.227      |\n",
            "|    explained_variance   | 5.96e-08    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.13e+06    |\n",
            "|    n_updates            | 800         |\n",
            "|    policy_gradient_loss | -0.0033     |\n",
            "|    value_loss           | 2.25e+06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.79e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 985          |\n",
            "|    iterations           | 82           |\n",
            "|    time_elapsed         | 851          |\n",
            "|    total_timesteps      | 839680       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020659235 |\n",
            "|    clip_fraction        | 0.0185       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.322       |\n",
            "|    explained_variance   | 1.19e-07     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.9e+06      |\n",
            "|    n_updates            | 810          |\n",
            "|    policy_gradient_loss | -0.00292     |\n",
            "|    value_loss           | 5.91e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.79e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 987          |\n",
            "|    iterations           | 83           |\n",
            "|    time_elapsed         | 860          |\n",
            "|    total_timesteps      | 849920       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019621174 |\n",
            "|    clip_fraction        | 0.0125       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.324       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.44e+06     |\n",
            "|    n_updates            | 820          |\n",
            "|    policy_gradient_loss | -0.00284     |\n",
            "|    value_loss           | 9.04e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.79e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 986          |\n",
            "|    iterations           | 84           |\n",
            "|    time_elapsed         | 871          |\n",
            "|    total_timesteps      | 860160       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023775673 |\n",
            "|    clip_fraction        | 0.0198       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.234       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.96e+05     |\n",
            "|    n_updates            | 830          |\n",
            "|    policy_gradient_loss | -0.00369     |\n",
            "|    value_loss           | 2.16e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.77e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 986          |\n",
            "|    iterations           | 85           |\n",
            "|    time_elapsed         | 882          |\n",
            "|    total_timesteps      | 870400       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020170421 |\n",
            "|    clip_fraction        | 0.0158       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.339       |\n",
            "|    explained_variance   | 1.19e-07     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.49e+06     |\n",
            "|    n_updates            | 840          |\n",
            "|    policy_gradient_loss | -0.003       |\n",
            "|    value_loss           | 6.58e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.77e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 987          |\n",
            "|    iterations           | 86           |\n",
            "|    time_elapsed         | 891          |\n",
            "|    total_timesteps      | 880640       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017211065 |\n",
            "|    clip_fraction        | 0.0124       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.302       |\n",
            "|    explained_variance   | 5.96e-08     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.64e+06     |\n",
            "|    n_updates            | 850          |\n",
            "|    policy_gradient_loss | -0.00286     |\n",
            "|    value_loss           | 7.58e+06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 6e+03       |\n",
            "|    ep_rew_mean          | -7.77e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 986         |\n",
            "|    iterations           | 87          |\n",
            "|    time_elapsed         | 902         |\n",
            "|    total_timesteps      | 890880      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002947439 |\n",
            "|    clip_fraction        | 0.0311      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.24       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.12e+06    |\n",
            "|    n_updates            | 860         |\n",
            "|    policy_gradient_loss | -0.00346    |\n",
            "|    value_loss           | 2.47e+06    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 6e+03       |\n",
            "|    ep_rew_mean          | -7.76e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 986         |\n",
            "|    iterations           | 88          |\n",
            "|    time_elapsed         | 913         |\n",
            "|    total_timesteps      | 901120      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002129431 |\n",
            "|    clip_fraction        | 0.013       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.316      |\n",
            "|    explained_variance   | -1.19e-07   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.57e+06    |\n",
            "|    n_updates            | 870         |\n",
            "|    policy_gradient_loss | -0.00349    |\n",
            "|    value_loss           | 6.74e+06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.76e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 988          |\n",
            "|    iterations           | 89           |\n",
            "|    time_elapsed         | 922          |\n",
            "|    total_timesteps      | 911360       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022026445 |\n",
            "|    clip_fraction        | 0.0155       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.284       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.35e+06     |\n",
            "|    n_updates            | 880          |\n",
            "|    policy_gradient_loss | -0.00222     |\n",
            "|    value_loss           | 7.49e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.76e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 987          |\n",
            "|    iterations           | 90           |\n",
            "|    time_elapsed         | 933          |\n",
            "|    total_timesteps      | 921600       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027853332 |\n",
            "|    clip_fraction        | 0.0257       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.242       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.57e+06     |\n",
            "|    n_updates            | 890          |\n",
            "|    policy_gradient_loss | -0.00283     |\n",
            "|    value_loss           | 2.59e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.75e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 987          |\n",
            "|    iterations           | 91           |\n",
            "|    time_elapsed         | 943          |\n",
            "|    total_timesteps      | 931840       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017433654 |\n",
            "|    clip_fraction        | 0.0153       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.32        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.74e+06     |\n",
            "|    n_updates            | 900          |\n",
            "|    policy_gradient_loss | -0.0028      |\n",
            "|    value_loss           | 7.54e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.75e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 988          |\n",
            "|    iterations           | 92           |\n",
            "|    time_elapsed         | 953          |\n",
            "|    total_timesteps      | 942080       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025445581 |\n",
            "|    clip_fraction        | 0.0177       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.269       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.44e+06     |\n",
            "|    n_updates            | 910          |\n",
            "|    policy_gradient_loss | -0.0027      |\n",
            "|    value_loss           | 5.87e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.75e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 987          |\n",
            "|    iterations           | 93           |\n",
            "|    time_elapsed         | 964          |\n",
            "|    total_timesteps      | 952320       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016695594 |\n",
            "|    clip_fraction        | 0.0142       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.24        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.96e+05     |\n",
            "|    n_updates            | 920          |\n",
            "|    policy_gradient_loss | -0.00263     |\n",
            "|    value_loss           | 2.63e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.73e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 987          |\n",
            "|    iterations           | 94           |\n",
            "|    time_elapsed         | 974          |\n",
            "|    total_timesteps      | 962560       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024128873 |\n",
            "|    clip_fraction        | 0.02         |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.32        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.38e+06     |\n",
            "|    n_updates            | 930          |\n",
            "|    policy_gradient_loss | -0.00364     |\n",
            "|    value_loss           | 7.75e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.73e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 987          |\n",
            "|    iterations           | 95           |\n",
            "|    time_elapsed         | 985          |\n",
            "|    total_timesteps      | 972800       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015288083 |\n",
            "|    clip_fraction        | 0.0124       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.257       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.22e+06     |\n",
            "|    n_updates            | 940          |\n",
            "|    policy_gradient_loss | -0.0019      |\n",
            "|    value_loss           | 5.7e+06      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.73e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 985          |\n",
            "|    iterations           | 96           |\n",
            "|    time_elapsed         | 997          |\n",
            "|    total_timesteps      | 983040       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032380417 |\n",
            "|    clip_fraction        | 0.028        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.254       |\n",
            "|    explained_variance   | 5.96e-08     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.14e+06     |\n",
            "|    n_updates            | 950          |\n",
            "|    policy_gradient_loss | -0.00374     |\n",
            "|    value_loss           | 2.74e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.72e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 984          |\n",
            "|    iterations           | 97           |\n",
            "|    time_elapsed         | 1009         |\n",
            "|    total_timesteps      | 993280       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020742516 |\n",
            "|    clip_fraction        | 0.0115       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.324       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.03e+06     |\n",
            "|    n_updates            | 960          |\n",
            "|    policy_gradient_loss | -0.00287     |\n",
            "|    value_loss           | 7.84e+06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 6e+03       |\n",
            "|    ep_rew_mean          | -7.72e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 984         |\n",
            "|    iterations           | 98          |\n",
            "|    time_elapsed         | 1019        |\n",
            "|    total_timesteps      | 1003520     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002508998 |\n",
            "|    clip_fraction        | 0.0232      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.265      |\n",
            "|    explained_variance   | -1.19e-07   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.42e+06    |\n",
            "|    n_updates            | 970         |\n",
            "|    policy_gradient_loss | -0.00324    |\n",
            "|    value_loss           | 5.64e+06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.72e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 983          |\n",
            "|    iterations           | 99           |\n",
            "|    time_elapsed         | 1030         |\n",
            "|    total_timesteps      | 1013760      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027353477 |\n",
            "|    clip_fraction        | 0.0251       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.257       |\n",
            "|    explained_variance   | 1.79e-07     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.52e+06     |\n",
            "|    n_updates            | 980          |\n",
            "|    policy_gradient_loss | -0.00356     |\n",
            "|    value_loss           | 2.68e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.72e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 983          |\n",
            "|    iterations           | 100          |\n",
            "|    time_elapsed         | 1041         |\n",
            "|    total_timesteps      | 1024000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018813182 |\n",
            "|    clip_fraction        | 0.0136       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.339       |\n",
            "|    explained_variance   | 5.96e-08     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.75e+06     |\n",
            "|    n_updates            | 990          |\n",
            "|    policy_gradient_loss | -0.00309     |\n",
            "|    value_loss           | 8.12e+06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 6e+03       |\n",
            "|    ep_rew_mean          | -7.72e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 983         |\n",
            "|    iterations           | 101         |\n",
            "|    time_elapsed         | 1051        |\n",
            "|    total_timesteps      | 1034240     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002035445 |\n",
            "|    clip_fraction        | 0.0163      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.278      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.3e+06     |\n",
            "|    n_updates            | 1000        |\n",
            "|    policy_gradient_loss | -0.00311    |\n",
            "|    value_loss           | 5.9e+06     |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.72e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 983          |\n",
            "|    iterations           | 102          |\n",
            "|    time_elapsed         | 1061         |\n",
            "|    total_timesteps      | 1044480      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027205627 |\n",
            "|    clip_fraction        | 0.0282       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.256       |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.42e+06     |\n",
            "|    n_updates            | 1010         |\n",
            "|    policy_gradient_loss | -0.00396     |\n",
            "|    value_loss           | 2.78e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.71e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 983          |\n",
            "|    iterations           | 103          |\n",
            "|    time_elapsed         | 1072         |\n",
            "|    total_timesteps      | 1054720      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028508208 |\n",
            "|    clip_fraction        | 0.0244       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.324       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.88e+06     |\n",
            "|    n_updates            | 1020         |\n",
            "|    policy_gradient_loss | -0.00327     |\n",
            "|    value_loss           | 7.43e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.71e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 983          |\n",
            "|    iterations           | 104          |\n",
            "|    time_elapsed         | 1082         |\n",
            "|    total_timesteps      | 1064960      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025479798 |\n",
            "|    clip_fraction        | 0.0224       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.26        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.25e+06     |\n",
            "|    n_updates            | 1030         |\n",
            "|    policy_gradient_loss | -0.00321     |\n",
            "|    value_loss           | 4.97e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.71e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 984          |\n",
            "|    iterations           | 105          |\n",
            "|    time_elapsed         | 1092         |\n",
            "|    total_timesteps      | 1075200      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022764667 |\n",
            "|    clip_fraction        | 0.0202       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.269       |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.49e+06     |\n",
            "|    n_updates            | 1040         |\n",
            "|    policy_gradient_loss | -0.00413     |\n",
            "|    value_loss           | 3.11e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.7e+05     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 984          |\n",
            "|    iterations           | 106          |\n",
            "|    time_elapsed         | 1103         |\n",
            "|    total_timesteps      | 1085440      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021146198 |\n",
            "|    clip_fraction        | 0.0104       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.32        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.3e+06      |\n",
            "|    n_updates            | 1050         |\n",
            "|    policy_gradient_loss | -0.00272     |\n",
            "|    value_loss           | 7.97e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.7e+05     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 984          |\n",
            "|    iterations           | 107          |\n",
            "|    time_elapsed         | 1112         |\n",
            "|    total_timesteps      | 1095680      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022390166 |\n",
            "|    clip_fraction        | 0.0181       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.231       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.56e+06     |\n",
            "|    n_updates            | 1060         |\n",
            "|    policy_gradient_loss | -0.00349     |\n",
            "|    value_loss           | 4.31e+06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 6e+03       |\n",
            "|    ep_rew_mean          | -7.7e+05    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 984         |\n",
            "|    iterations           | 108         |\n",
            "|    time_elapsed         | 1122        |\n",
            "|    total_timesteps      | 1105920     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003012187 |\n",
            "|    clip_fraction        | 0.0242      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.28       |\n",
            "|    explained_variance   | 5.96e-08    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.77e+06    |\n",
            "|    n_updates            | 1070        |\n",
            "|    policy_gradient_loss | -0.00386    |\n",
            "|    value_loss           | 3.8e+06     |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.69e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 984          |\n",
            "|    iterations           | 109          |\n",
            "|    time_elapsed         | 1133         |\n",
            "|    total_timesteps      | 1116160      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023830903 |\n",
            "|    clip_fraction        | 0.0167       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.306       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.38e+06     |\n",
            "|    n_updates            | 1080         |\n",
            "|    policy_gradient_loss | -0.00323     |\n",
            "|    value_loss           | 7.51e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.69e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 984          |\n",
            "|    iterations           | 110          |\n",
            "|    time_elapsed         | 1143         |\n",
            "|    total_timesteps      | 1126400      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023272105 |\n",
            "|    clip_fraction        | 0.0243       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.238       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.75e+06     |\n",
            "|    n_updates            | 1090         |\n",
            "|    policy_gradient_loss | -0.00271     |\n",
            "|    value_loss           | 3.83e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.69e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 985          |\n",
            "|    iterations           | 111          |\n",
            "|    time_elapsed         | 1153         |\n",
            "|    total_timesteps      | 1136640      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031247605 |\n",
            "|    clip_fraction        | 0.019        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.308       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.15e+06     |\n",
            "|    n_updates            | 1100         |\n",
            "|    policy_gradient_loss | -0.00352     |\n",
            "|    value_loss           | 4.41e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.69e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 984          |\n",
            "|    iterations           | 112          |\n",
            "|    time_elapsed         | 1164         |\n",
            "|    total_timesteps      | 1146880      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020775567 |\n",
            "|    clip_fraction        | 0.0188       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.318       |\n",
            "|    explained_variance   | 1.79e-07     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.12e+06     |\n",
            "|    n_updates            | 1110         |\n",
            "|    policy_gradient_loss | -0.00303     |\n",
            "|    value_loss           | 8.22e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.69e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 985          |\n",
            "|    iterations           | 113          |\n",
            "|    time_elapsed         | 1174         |\n",
            "|    total_timesteps      | 1157120      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028499027 |\n",
            "|    clip_fraction        | 0.0293       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.226       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.16e+06     |\n",
            "|    n_updates            | 1120         |\n",
            "|    policy_gradient_loss | -0.00372     |\n",
            "|    value_loss           | 2.98e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.69e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 985          |\n",
            "|    iterations           | 114          |\n",
            "|    time_elapsed         | 1184         |\n",
            "|    total_timesteps      | 1167360      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025292009 |\n",
            "|    clip_fraction        | 0.0156       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.304       |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.39e+06     |\n",
            "|    n_updates            | 1130         |\n",
            "|    policy_gradient_loss | -0.00255     |\n",
            "|    value_loss           | 4.52e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.68e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 985          |\n",
            "|    iterations           | 115          |\n",
            "|    time_elapsed         | 1195         |\n",
            "|    total_timesteps      | 1177600      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033758753 |\n",
            "|    clip_fraction        | 0.0251       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.313       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.91e+06     |\n",
            "|    n_updates            | 1140         |\n",
            "|    policy_gradient_loss | -0.00361     |\n",
            "|    value_loss           | 7.34e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.68e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 985          |\n",
            "|    iterations           | 116          |\n",
            "|    time_elapsed         | 1204         |\n",
            "|    total_timesteps      | 1187840      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026984941 |\n",
            "|    clip_fraction        | 0.0269       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.237       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.29e+06     |\n",
            "|    n_updates            | 1150         |\n",
            "|    policy_gradient_loss | -0.00343     |\n",
            "|    value_loss           | 3.03e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.68e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 986          |\n",
            "|    iterations           | 117          |\n",
            "|    time_elapsed         | 1214         |\n",
            "|    total_timesteps      | 1198080      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022901564 |\n",
            "|    clip_fraction        | 0.0217       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.297       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.41e+06     |\n",
            "|    n_updates            | 1160         |\n",
            "|    policy_gradient_loss | -0.00268     |\n",
            "|    value_loss           | 4.45e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.67e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 985          |\n",
            "|    iterations           | 118          |\n",
            "|    time_elapsed         | 1225         |\n",
            "|    total_timesteps      | 1208320      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036024642 |\n",
            "|    clip_fraction        | 0.0328       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.322       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.74e+06     |\n",
            "|    n_updates            | 1170         |\n",
            "|    policy_gradient_loss | -0.00393     |\n",
            "|    value_loss           | 7.71e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.67e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 986          |\n",
            "|    iterations           | 119          |\n",
            "|    time_elapsed         | 1234         |\n",
            "|    total_timesteps      | 1218560      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030914985 |\n",
            "|    clip_fraction        | 0.0309       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.222       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.07e+06     |\n",
            "|    n_updates            | 1180         |\n",
            "|    policy_gradient_loss | -0.00341     |\n",
            "|    value_loss           | 1.98e+06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 6e+03       |\n",
            "|    ep_rew_mean          | -7.67e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 986         |\n",
            "|    iterations           | 120         |\n",
            "|    time_elapsed         | 1245        |\n",
            "|    total_timesteps      | 1228800     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002405214 |\n",
            "|    clip_fraction        | 0.0195      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.3        |\n",
            "|    explained_variance   | 2.38e-07    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.61e+06    |\n",
            "|    n_updates            | 1190        |\n",
            "|    policy_gradient_loss | -0.00351    |\n",
            "|    value_loss           | 5.07e+06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.67e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 986          |\n",
            "|    iterations           | 121          |\n",
            "|    time_elapsed         | 1256         |\n",
            "|    total_timesteps      | 1239040      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015974597 |\n",
            "|    clip_fraction        | 0.0126       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.32        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.81e+06     |\n",
            "|    n_updates            | 1200         |\n",
            "|    policy_gradient_loss | -0.00181     |\n",
            "|    value_loss           | 7.8e+06      |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 6e+03       |\n",
            "|    ep_rew_mean          | -7.67e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 987         |\n",
            "|    iterations           | 122         |\n",
            "|    time_elapsed         | 1265        |\n",
            "|    total_timesteps      | 1249280     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002697862 |\n",
            "|    clip_fraction        | 0.0297      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.213      |\n",
            "|    explained_variance   | -1.19e-07   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 8.59e+05    |\n",
            "|    n_updates            | 1210        |\n",
            "|    policy_gradient_loss | -0.00331    |\n",
            "|    value_loss           | 1.81e+06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.66e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 987          |\n",
            "|    iterations           | 123          |\n",
            "|    time_elapsed         | 1275         |\n",
            "|    total_timesteps      | 1259520      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017189186 |\n",
            "|    clip_fraction        | 0.0169       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.304       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.23e+06     |\n",
            "|    n_updates            | 1220         |\n",
            "|    policy_gradient_loss | -0.00215     |\n",
            "|    value_loss           | 5.02e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.66e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 986          |\n",
            "|    iterations           | 124          |\n",
            "|    time_elapsed         | 1286         |\n",
            "|    total_timesteps      | 1269760      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029046657 |\n",
            "|    clip_fraction        | 0.0159       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.295       |\n",
            "|    explained_variance   | 1.19e-07     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.75e+06     |\n",
            "|    n_updates            | 1230         |\n",
            "|    policy_gradient_loss | -0.00296     |\n",
            "|    value_loss           | 7.49e+06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 6e+03       |\n",
            "|    ep_rew_mean          | -7.66e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 988         |\n",
            "|    iterations           | 125         |\n",
            "|    time_elapsed         | 1295        |\n",
            "|    total_timesteps      | 1280000     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004093333 |\n",
            "|    clip_fraction        | 0.0417      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.223      |\n",
            "|    explained_variance   | -2.38e-07   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 7.87e+05    |\n",
            "|    n_updates            | 1240        |\n",
            "|    policy_gradient_loss | -0.00362    |\n",
            "|    value_loss           | 1.76e+06    |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 6e+03      |\n",
            "|    ep_rew_mean          | -7.65e+05  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 987        |\n",
            "|    iterations           | 126        |\n",
            "|    time_elapsed         | 1306       |\n",
            "|    total_timesteps      | 1290240    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00203177 |\n",
            "|    clip_fraction        | 0.0156     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.317     |\n",
            "|    explained_variance   | -1.19e-07  |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 2.74e+06   |\n",
            "|    n_updates            | 1250       |\n",
            "|    policy_gradient_loss | -0.00294   |\n",
            "|    value_loss           | 6.08e+06   |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.65e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 987          |\n",
            "|    iterations           | 127          |\n",
            "|    time_elapsed         | 1317         |\n",
            "|    total_timesteps      | 1300480      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022508898 |\n",
            "|    clip_fraction        | 0.0205       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.282       |\n",
            "|    explained_variance   | 5.96e-08     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.96e+06     |\n",
            "|    n_updates            | 1260         |\n",
            "|    policy_gradient_loss | -0.0031      |\n",
            "|    value_loss           | 6.54e+06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 6e+03       |\n",
            "|    ep_rew_mean          | -7.65e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 988         |\n",
            "|    iterations           | 128         |\n",
            "|    time_elapsed         | 1326        |\n",
            "|    total_timesteps      | 1310720     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005208553 |\n",
            "|    clip_fraction        | 0.0448      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.235      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.04e+06    |\n",
            "|    n_updates            | 1270        |\n",
            "|    policy_gradient_loss | -0.00384    |\n",
            "|    value_loss           | 2.06e+06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.65e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 988          |\n",
            "|    iterations           | 129          |\n",
            "|    time_elapsed         | 1336         |\n",
            "|    total_timesteps      | 1320960      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023705605 |\n",
            "|    clip_fraction        | 0.0182       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.324       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.13e+06     |\n",
            "|    n_updates            | 1280         |\n",
            "|    policy_gradient_loss | -0.00413     |\n",
            "|    value_loss           | 6.13e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.65e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 987          |\n",
            "|    iterations           | 130          |\n",
            "|    time_elapsed         | 1348         |\n",
            "|    total_timesteps      | 1331200      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024822424 |\n",
            "|    clip_fraction        | 0.0207       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.278       |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.58e+06     |\n",
            "|    n_updates            | 1290         |\n",
            "|    policy_gradient_loss | -0.00297     |\n",
            "|    value_loss           | 6.02e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.65e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 987          |\n",
            "|    iterations           | 131          |\n",
            "|    time_elapsed         | 1358         |\n",
            "|    total_timesteps      | 1341440      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022870146 |\n",
            "|    clip_fraction        | 0.0267       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.244       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.71e+05     |\n",
            "|    n_updates            | 1300         |\n",
            "|    policy_gradient_loss | -0.00317     |\n",
            "|    value_loss           | 2.15e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.65e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 986          |\n",
            "|    iterations           | 132          |\n",
            "|    time_elapsed         | 1369         |\n",
            "|    total_timesteps      | 1351680      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031544059 |\n",
            "|    clip_fraction        | 0.0176       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.324       |\n",
            "|    explained_variance   | 1.79e-07     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.34e+06     |\n",
            "|    n_updates            | 1310         |\n",
            "|    policy_gradient_loss | -0.00243     |\n",
            "|    value_loss           | 6.83e+06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 6e+03       |\n",
            "|    ep_rew_mean          | -7.65e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 986         |\n",
            "|    iterations           | 133         |\n",
            "|    time_elapsed         | 1380        |\n",
            "|    total_timesteps      | 1361920     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002050298 |\n",
            "|    clip_fraction        | 0.0164      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.274      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.13e+06    |\n",
            "|    n_updates            | 1320        |\n",
            "|    policy_gradient_loss | -0.00256    |\n",
            "|    value_loss           | 5.79e+06    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 6e+03       |\n",
            "|    ep_rew_mean          | -7.65e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 986         |\n",
            "|    iterations           | 134         |\n",
            "|    time_elapsed         | 1390        |\n",
            "|    total_timesteps      | 1372160     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003957161 |\n",
            "|    clip_fraction        | 0.0436      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.245      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.37e+06    |\n",
            "|    n_updates            | 1330        |\n",
            "|    policy_gradient_loss | -0.00414    |\n",
            "|    value_loss           | 2.18e+06    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 6e+03       |\n",
            "|    ep_rew_mean          | -7.65e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 986         |\n",
            "|    iterations           | 135         |\n",
            "|    time_elapsed         | 1400        |\n",
            "|    total_timesteps      | 1382400     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001792975 |\n",
            "|    clip_fraction        | 0.0145      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.324      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.54e+06    |\n",
            "|    n_updates            | 1340        |\n",
            "|    policy_gradient_loss | -0.0035     |\n",
            "|    value_loss           | 7.31e+06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.65e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 986          |\n",
            "|    iterations           | 136          |\n",
            "|    time_elapsed         | 1411         |\n",
            "|    total_timesteps      | 1392640      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027870438 |\n",
            "|    clip_fraction        | 0.0336       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.264       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.39e+06     |\n",
            "|    n_updates            | 1350         |\n",
            "|    policy_gradient_loss | -0.00395     |\n",
            "|    value_loss           | 6e+06        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.65e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 986          |\n",
            "|    iterations           | 137          |\n",
            "|    time_elapsed         | 1421         |\n",
            "|    total_timesteps      | 1402880      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026887145 |\n",
            "|    clip_fraction        | 0.0204       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.255       |\n",
            "|    explained_variance   | 5.96e-08     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.95e+06     |\n",
            "|    n_updates            | 1360         |\n",
            "|    policy_gradient_loss | -0.00292     |\n",
            "|    value_loss           | 2.41e+06     |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 6e+03      |\n",
            "|    ep_rew_mean          | -7.66e+05  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 987        |\n",
            "|    iterations           | 138        |\n",
            "|    time_elapsed         | 1431       |\n",
            "|    total_timesteps      | 1413120    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00278111 |\n",
            "|    clip_fraction        | 0.0164     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.325     |\n",
            "|    explained_variance   | 0          |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 3.49e+06   |\n",
            "|    n_updates            | 1370       |\n",
            "|    policy_gradient_loss | -0.00392   |\n",
            "|    value_loss           | 7.22e+06   |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.66e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 986          |\n",
            "|    iterations           | 139          |\n",
            "|    time_elapsed         | 1442         |\n",
            "|    total_timesteps      | 1423360      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031984062 |\n",
            "|    clip_fraction        | 0.0262       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.252       |\n",
            "|    explained_variance   | 1.19e-07     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.31e+06     |\n",
            "|    n_updates            | 1380         |\n",
            "|    policy_gradient_loss | -0.0032      |\n",
            "|    value_loss           | 5.2e+06      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.66e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 987          |\n",
            "|    iterations           | 140          |\n",
            "|    time_elapsed         | 1452         |\n",
            "|    total_timesteps      | 1433600      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042152004 |\n",
            "|    clip_fraction        | 0.0419       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.238       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.35e+06     |\n",
            "|    n_updates            | 1390         |\n",
            "|    policy_gradient_loss | -0.00475     |\n",
            "|    value_loss           | 2.28e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.66e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 987          |\n",
            "|    iterations           | 141          |\n",
            "|    time_elapsed         | 1462         |\n",
            "|    total_timesteps      | 1443840      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042000306 |\n",
            "|    clip_fraction        | 0.024        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.32        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.59e+06     |\n",
            "|    n_updates            | 1400         |\n",
            "|    policy_gradient_loss | -0.0043      |\n",
            "|    value_loss           | 7.87e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.66e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 986          |\n",
            "|    iterations           | 142          |\n",
            "|    time_elapsed         | 1473         |\n",
            "|    total_timesteps      | 1454080      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028068614 |\n",
            "|    clip_fraction        | 0.0274       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.258       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.29e+06     |\n",
            "|    n_updates            | 1410         |\n",
            "|    policy_gradient_loss | -0.00391     |\n",
            "|    value_loss           | 5.17e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.66e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 987          |\n",
            "|    iterations           | 143          |\n",
            "|    time_elapsed         | 1482         |\n",
            "|    total_timesteps      | 1464320      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026045486 |\n",
            "|    clip_fraction        | 0.0232       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.249       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.14e+06     |\n",
            "|    n_updates            | 1420         |\n",
            "|    policy_gradient_loss | -0.00405     |\n",
            "|    value_loss           | 2.52e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.66e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 987          |\n",
            "|    iterations           | 144          |\n",
            "|    time_elapsed         | 1492         |\n",
            "|    total_timesteps      | 1474560      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027064432 |\n",
            "|    clip_fraction        | 0.0134       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.314       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4e+06        |\n",
            "|    n_updates            | 1430         |\n",
            "|    policy_gradient_loss | -0.00274     |\n",
            "|    value_loss           | 7.15e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.66e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 986          |\n",
            "|    iterations           | 145          |\n",
            "|    time_elapsed         | 1505         |\n",
            "|    total_timesteps      | 1484800      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035595451 |\n",
            "|    clip_fraction        | 0.0326       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.246       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.38e+06     |\n",
            "|    n_updates            | 1440         |\n",
            "|    policy_gradient_loss | -0.00327     |\n",
            "|    value_loss           | 4.48e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.66e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 985          |\n",
            "|    iterations           | 146          |\n",
            "|    time_elapsed         | 1516         |\n",
            "|    total_timesteps      | 1495040      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038166991 |\n",
            "|    clip_fraction        | 0.043        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.268       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.14e+06     |\n",
            "|    n_updates            | 1450         |\n",
            "|    policy_gradient_loss | -0.00355     |\n",
            "|    value_loss           | 2.97e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 6e+03        |\n",
            "|    ep_rew_mean          | -7.66e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 986          |\n",
            "|    iterations           | 147          |\n",
            "|    time_elapsed         | 1525         |\n",
            "|    total_timesteps      | 1505280      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021790224 |\n",
            "|    clip_fraction        | 0.0187       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.312       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.97e+06     |\n",
            "|    n_updates            | 1460         |\n",
            "|    policy_gradient_loss | -0.00291     |\n",
            "|    value_loss           | 6.61e+06     |\n",
            "------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.527 MB of 0.527 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "13ee1e7fdfea406eb2bef29a679aa9d9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Excess Generation</td><td></td></tr><tr><td>Inverter total power flow</td><td></td></tr><tr><td>Num Off-Peak Purchases</td><td></td></tr><tr><td>Num Peak Purchases</td><td></td></tr><tr><td>Num Purchase Actions</td><td></td></tr><tr><td>Num Standard Purchases</td><td></td></tr><tr><td>Num Standby Actions</td><td></td></tr><tr><td>Off-Peak Purchases</td><td></td></tr><tr><td>Peak Purchases</td><td></td></tr><tr><td>Rectifier total power flow</td><td></td></tr><tr><td>Standard Purchases</td><td></td></tr><tr><td>Total Reward</td><td></td></tr><tr><td>Unmet Load</td><td></td></tr><tr><td>global_step</td><td></td></tr><tr><td>rollout/ep_len_mean</td><td></td></tr><tr><td>rollout/ep_rew_mean</td><td></td></tr><tr><td>time/fps</td><td></td></tr><tr><td>train/approx_kl</td><td></td></tr><tr><td>train/clip_fraction</td><td></td></tr><tr><td>train/clip_range</td><td></td></tr><tr><td>train/entropy_loss</td><td></td></tr><tr><td>train/explained_variance</td><td></td></tr><tr><td>train/learning_rate</td><td></td></tr><tr><td>train/loss</td><td></td></tr><tr><td>train/policy_gradient_loss</td><td></td></tr><tr><td>train/value_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Excess Generation</td><td>535896.82426</td></tr><tr><td>Inverter total power flow</td><td>252916.56777</td></tr><tr><td>Num Off-Peak Purchases</td><td>960</td></tr><tr><td>Num Peak Purchases</td><td>301</td></tr><tr><td>Num Purchase Actions</td><td>1169</td></tr><tr><td>Num Standard Purchases</td><td>477</td></tr><tr><td>Num Standby Actions</td><td>4877</td></tr><tr><td>Off-Peak Purchases</td><td>247576.43775</td></tr><tr><td>Peak Purchases</td><td>74931.04992</td></tr><tr><td>Rectifier total power flow</td><td>400021.41993</td></tr><tr><td>Standard Purchases</td><td>118533.90234</td></tr><tr><td>Total Reward</td><td>-763235.23358</td></tr><tr><td>Unmet Load</td><td>5379.78414</td></tr><tr><td>global_step</td><td>1505280</td></tr><tr><td>rollout/ep_len_mean</td><td>5995.0</td></tr><tr><td>rollout/ep_rew_mean</td><td>-765839.625</td></tr><tr><td>time/fps</td><td>986.0</td></tr><tr><td>train/approx_kl</td><td>0.00218</td></tr><tr><td>train/clip_fraction</td><td>0.01866</td></tr><tr><td>train/clip_range</td><td>0.2</td></tr><tr><td>train/entropy_loss</td><td>-0.31227</td></tr><tr><td>train/explained_variance</td><td>0.0</td></tr><tr><td>train/learning_rate</td><td>0.0003</td></tr><tr><td>train/loss</td><td>3968828.5</td></tr><tr><td>train/policy_gradient_loss</td><td>-0.00291</td></tr><tr><td>train/value_loss</td><td>6610200.5</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">ethereal-paper-75</strong> at: <a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/wg4wgius' target=\"_blank\">https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/wg4wgius</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 3 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20231009_124517-wg4wgius/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "config = {\n",
        "    \"policy_type\": \"MultiInputPolicy\",\n",
        "    \"total_timesteps\": 1_500_000,\n",
        "}\n",
        "\n",
        "run = wandb.init(\n",
        "    project=\"4022_intelligent_ems\",\n",
        "    config=config,\n",
        "    sync_tensorboard=True,  # auto-upload sb3's tensorboard metrics\n",
        "    monitor_gym=True,  # auto-upload the videos of agents playing the game\n",
        "    save_code=True,  # optional\n",
        ")\n",
        "\n",
        "train_args = {\n",
        "                \"episode_len\"   : 6000,\n",
        "                \"actual_load\"   : actual_load,\n",
        "                \"actual_gen\"    : actual_gen,\n",
        "                \"bat_threshold\" : 100,\n",
        "                \"bat_cap\"       : 500,\n",
        "                \"purchase_price\": purchase_price,\n",
        "                \"num_preds\"     : 3,\n",
        "                \"load_shedding\" : load_shedding[2760:],\n",
        "                \"render_mode\"   : \"rgb_array\",\n",
        "                \"wandb_log\"     : True,\n",
        "                \"train_log\"     : True,\n",
        "\n",
        "                }\n",
        "\n",
        "eval_args = {\n",
        "                \"episode_len\"   :2760,\n",
        "                \"actual_load\"   :actual_load[6001:],\n",
        "                \"actual_gen\"    :actual_gen[6001:],\n",
        "                \"bat_threshold\" :100,\n",
        "                \"bat_cap\"       :500,\n",
        "                \"purchase_price\":purchase_price[6001:],\n",
        "                \"num_preds\"     :3,\n",
        "                \"load_shedding\" :load_shedding[6001:],\n",
        "                \"wandb_log\"     : True,\n",
        "                \"train_log\"     : False\n",
        "}\n",
        "\n",
        "#define 5 environments   for training and eval\n",
        "n_envs = 5\n",
        "n_eval_episodes =1\n",
        "train_env = make_vec_env(EMS, n_envs = n_envs,env_kwargs = train_args )\n",
        "\n",
        "\n",
        "eval_env = make_vec_env(EMS, n_envs = n_envs,env_kwargs = eval_args )\n",
        "\n",
        "\n",
        "wand_eval = f\"{version}_{model_type}_eval\"+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "wand_train = f\"{version}_{model_type}_train\"+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "wandb_callback = WandbCallback(\n",
        "                gradient_save_freq=100,\n",
        "                model_save_path=f\"models/{run.id}.{datetime.datetime.now()}\",\n",
        "                model_save_freq= 30000,\n",
        "                verbose=2,\n",
        "                log = \"all\",\n",
        "               )\n",
        "eval_callback = EvalCallback(eval_env,\n",
        "                             best_model_save_path = f\"{model_dir}{version}_{model_type}\"+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"),\n",
        "                             log_path = wand_eval,\n",
        "                             eval_freq=300,\n",
        "                             n_eval_episodes = n_eval_episodes,\n",
        "                             deterministic = True,\n",
        "                             render = False,\n",
        "                             callback_after_eval = wandb_callback)\n",
        "\n",
        "\n",
        "model = PPO(\"MultiInputPolicy\",train_env, verbose = 1, tensorboard_log = f\"runs/{run.id}\") #log_dir\n",
        "\n",
        "model.learn(total_timesteps= config[\"total_timesteps\"],\n",
        "            tb_log_name = wand_train,\n",
        "            reset_num_timesteps=False,\n",
        "            callback = wandb_callback\n",
        "            )\n",
        "\n",
        "model.save(f\"{model_dir}{version}_{model_type}\"+datetime.datetime.now().strftime(\"%m%d-%H%M%S\"))\n",
        "run.finish()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run.finish()\n"
      ],
      "metadata": {
        "id": "o3qJfzD9pLT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define a new test environment and load up the best performing model to test it.**"
      ],
      "metadata": {
        "id": "C9AGcLlsv4N7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inDHszZaxBUS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "9007e440-fadf-4bd1-f5f5-4dfb3dad9dd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbnkjul001_work\u001b[0m (\u001b[33m4022_intelligent_ems\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.12"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/EEE4022S_BNKJUL001_Thesis/wandb/run-20231009_131110-n4qcg7xn</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/n4qcg7xn' target=\"_blank\">bumbling-snowflake-76</a></strong> to <a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems' target=\"_blank\">https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/n4qcg7xn' target=\"_blank\">https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/n4qcg7xn</a>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "config = {\n",
        "    \"policy_type\": \"MultiInputPolicy\",\n",
        "    \"total_timesteps\": 2760,\n",
        "}\n",
        "run = wandb.init(\n",
        "    project=\"4022_intelligent_ems\",\n",
        "    config=config,\n",
        "    sync_tensorboard=True,  # auto-upload sb3's tensorboard metrics\n",
        "    monitor_gym=True,  # auto-upload the videos of agents playing the game\n",
        "    save_code=True,  # optional\n",
        ")\n",
        "#Load model, fetch the latest (or whichever one you want from the model_dir)\n",
        "#Best A2C model:/content/drive/MyDrive/Colab Notebooks/EMSv0_3/models/PPO/EMSv0_3_PPO20231005-102532.zip\n",
        "#best_PPO_model = \"EMSv0_3_PPO20231006-204045\"\n",
        "\n",
        "#model_load = f\"{model_dir}/{best_PPO_model}\"\n",
        "#model  = PPO.load(model_load, env = eval_env)\n",
        "\n",
        "#first run it with only standby (default)\n",
        "obs   = eval_env.reset()\n",
        "#ensure that the exit condition is reset\n",
        "done = [False]*n_envs\n",
        "#define the action to take\n",
        "action_standby = [0]*n_envs\n",
        "#reset score\n",
        "standby_score = [0]*n_envs\n",
        "standby_score = np.array(standby_score).astype(np.float32)\n",
        "while not all(done):\n",
        "    #step the model with the action\n",
        "    obs,reward,done,info = eval_env.step(action_standby)\n",
        "    #accumulate the score\n",
        "    standby_score += reward\n",
        "\n",
        "avg_standby_score = standby_score.mean()\n",
        "\n",
        "run.finish()\n",
        "\n",
        "run = wandb.init(\n",
        "    project=\"4022_intelligent_ems\",\n",
        "    config=config,\n",
        "    sync_tensorboard=True,  # auto-upload sb3's tensorboard metrics\n",
        "    monitor_gym=True,  # auto-upload the videos of agents playing the game\n",
        "    save_code=True,  # optional\n",
        ")\n",
        "obs   = eval_env.reset()\n",
        "EMS_reward,EMS_std_reward = evaluate_policy(model,eval_env,n_eval_episodes = 1,deterministic=True)# callback = wandb_callback\n",
        "run.finish()\n",
        "\n",
        "print(f\"Note: The term does not refer to the cost in rands but rather to the reward as defined by the reward function!\")\n",
        "print(f\"Done the Standby Test! Total cost accumulated is: {avg_standby_score}\")\n",
        "print(f\"Done applying the trained model! Total cost accumulated is: {EMS_reward} +- {EMS_std_reward}\")\n",
        "\n",
        "savings = EMS_reward - avg_standby_score\n",
        "print(f\"The amount that was saved by applying the EMS agent: {savings}\")\n",
        "print(f\"This was saved over a period of {2760/24} days\")\n",
        "print(f\"The savings represents {(savings/(-avg_standby_score))*100} % of the cost if no EMS is installed\")\n",
        "print(f\"And it represents {(savings/(-EMS_reward))*100} % of the cost if the EMS is installed\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "13ee1e7fdfea406eb2bef29a679aa9d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a3e822a171144b94acc21a9217a1804c",
              "IPY_MODEL_fef6ad16fb4e42b0b6d992106853863e"
            ],
            "layout": "IPY_MODEL_da3130908c104280b16bcdf7d1d8a7df"
          }
        },
        "a3e822a171144b94acc21a9217a1804c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be47693c8cf34aa18bf39a10bb4aa989",
            "placeholder": "",
            "style": "IPY_MODEL_02eb22397a9246e39dd9d083726854b0",
            "value": "0.527 MB of 0.527 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "fef6ad16fb4e42b0b6d992106853863e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b6fbe18e7234b3a84507fa53ce4fcfa",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_27139dcab1a34dd39acfdc5baa7e3395",
            "value": 1
          }
        },
        "da3130908c104280b16bcdf7d1d8a7df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be47693c8cf34aa18bf39a10bb4aa989": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02eb22397a9246e39dd9d083726854b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b6fbe18e7234b3a84507fa53ce4fcfa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27139dcab1a34dd39acfdc5baa7e3395": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}