{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Julian-Banks/EEE4022S_BNKJUL001_Thesis/blob/main/PythonWorkspace/EMSv2_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "V6yT1Kii6fZb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Version Notes**\n",
        "#**v2.6**\n",
        "*clean up of code\n",
        "\n",
        "#**v2.5**\n",
        "* getting rid of the shorter episodes and going back to the normal approach\n",
        "* reworked normalisation so that the power bal and the battery level are scaled using the same transform. The idea being that the units should be the same and thus the scales?\n",
        "* changed action space to be centered on -1,1\n",
        "*removed demand charge to try and get it to learn how to manage a continuous space first.\n",
        "\n",
        "\n",
        "# **v2.4**\n",
        "* going to have shorter episodes (one month long)\n",
        "* hope the agent can learn to expect the demand charge every 30 days.\n",
        "* fixed a bug with the purchase_price\n",
        "\n",
        "# **v2.3**\n",
        "* Flattening observation space\n",
        "* increasing learning rates\n",
        "* decreasing vf_coef\n",
        "\n",
        "# **v2.2**\n",
        " **Added:**\n",
        " * normalising values. it is time to do this.....\n",
        "\n",
        "# **v2.1**\n",
        "\n",
        "**Added:**\n",
        " * changed reward structure to give a penalty every time the agent reaches a new max demand.\n",
        " * changed obs to include max_demand\n",
        "\n",
        "# **v2.0**\n",
        "*\n",
        "Adding a continous action space! Yolo\n",
        "\n",
        "# **v1.2**\n",
        "**Added:**\n",
        "* Diesel Generator action to mitigate unmet-load\n",
        "* reward based off real prices + demand charge - Demand charge has fucked the agent cause it buys in bulk! - might be time for the continous action space so it can decide how much to buy......\n",
        "\n",
        "**To Do:**\n",
        "* impliment a priority load - not gonna do this, just gonna have unmet load\n",
        "\n",
        "* Add in actual predictions, eish\n",
        "\n",
        "* figure out how to have more episodes!! I think it will have big performance boosts on the training :)\n",
        "\n",
        "* thinking that maybe I should change obs space back to what it was cause I dont actully need to know individual loads and gens!!!!\n",
        "\n",
        "# **v1.1**\n",
        "\n",
        "**Added:**\n",
        "* rect and inverter power tracking\n",
        "* reward logging in my own logging func\n",
        "* changed logging vars to arrays\n",
        "*\n",
        "\n",
        "**To Do**\n",
        "\n",
        "* battery charging rates - I think my assumption is fine.\n",
        "\n",
        "* tweak visualisation to show bar graphs at the end of training/testing. Maybe just print graphs at the end? I have added plt.show() - remember to play if it doesnt work!\n",
        "\n",
        "* impliment a generator!!!!!\n",
        "* impliment a priority load\n",
        "\n",
        "* NB figure out how to have more episodes!! I think it will have big performance boosts on the training :)\n",
        "\n",
        "* thinking that maybe I should change obs space back to what it was cause I dont actully need to know individual loads and gens!!!!\n",
        "\n",
        "# **v1.0**\n",
        "\n",
        "**Added:**\n",
        "* AC and DC load\n",
        "* Wind Gen\n",
        "* changed obs space to hold new loads\n",
        "* re wrote standby and purchase functions\n",
        "\n",
        "**To DO**\n",
        "* thinking that maybe I should change obs space back to what it was cause I dont actully need to know individual loads and gens!!!!\n",
        "* Add in rectifier & inverter power tracking\n",
        "* battery charging rates\n",
        "\n",
        "\n",
        "# **v0.3**\n",
        "**Added:**\n",
        "* loadshedding\n",
        "* New reward structure\n",
        "* added Vec_env\n",
        "* added eval callbacks to validate training\n",
        "* added in logging\n",
        "\n",
        "**Parameters:**\n",
        "* Added in loadshedding forecast\n",
        "\n",
        "**To do:**\n",
        "* find out about battery charging rates  & impliment\n",
        "* Find out if I need to normalise\n",
        "* Try dqn\n",
        "* Find out how the bounds for the obs_space box effect things\n",
        "* Try play with DummyVec wrapper (didnt work in last version)\n",
        "\n",
        "# **v0.2_1**\n",
        "**Added:**\n",
        "*  Monitor wrapper\n",
        "*  DummyVec wrapper\n",
        "*  Wand (weights and bais) enabled\n",
        "\n",
        "**Parameters:**\n",
        "* lowered to 3 predictions  \n",
        "\n",
        "**To do:**\n",
        "* Try to use hyperparameter Optimisation - decided Im only going to do on the final version\n",
        "* Try normalise\n",
        "* Try differnet models\n",
        "* Find out how the bounds for the obs_space box effect things\n",
        "\n",
        "# **v0.2**\n",
        "**Added:**\n",
        "*  simplified load_forecast and gen_forecast to be power_bal_forecasts.\n",
        "*  combined current_load and current_gen to also show current_power_balance\n",
        "*  added proper evaluate call\n",
        "\n",
        "**Parameters:**\n",
        "* No changes  \n",
        "\n",
        "**Results:**\n",
        "* 5% savings on PPO deterministic = true\n",
        "* 4.3% savings on PPO determnistic = false\n",
        "\n",
        "**To do:**\n",
        "* Try to use hyperparameter Optimisation\n",
        "* Try normalise\n",
        "* Try differnet models\n",
        "* Try see if discount rate can be tweaked - at good level.\n",
        "* Find out how the bounds for the obs_space box effect things\n",
        "\n",
        "# **v0.1**\n",
        "**Added:**\n",
        "* added real loads, gen, tou_id's\n",
        "\n",
        "**Parameters:**\n",
        "* training episode = 6000 timesteps\n",
        "* testing episode  = 2760 timesteps\n",
        "* bat_threshold = 100\n",
        "* bat_cap = 500\n",
        "* battery_level at reset = bat_cap/2\n",
        "* num_preds = 24\n",
        "* Trained PPO for 1.65mil timesteps\n",
        "* Trained A2C for 1.2 mil timesteps\n",
        "\n",
        "**Results:**\n",
        "* PP0 - 3.7% improvement from standby mode Deterministic = False\n",
        "* PPO - 6.1% Deterministic =  True\n",
        "* A2C  - -0.3% improvement. And the models after this got worse as training progressed!\n",
        "**To do:**\n",
        "* Try lower num_preds\n",
        "* Try to use hyperparameter Optimisation\n",
        "* Try normalise\n",
        "* Try differnet models\n",
        "* Try see if discount rate can be tweaked\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5DZFnZnzStt1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "nI52iVVCCPaf"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "#install dependancies\n",
        "!pip install gymnasium\n",
        "!pip install stable_baselines3[extra]\n",
        "!pip install wandb\n",
        "!pip install sklearn\n",
        "%load_ext tensorboard\n",
        "\n",
        "#clone repository\n",
        "! git clone https://github.com/Julian-Banks/EEE4022S_BNKJUL001_Thesis\n",
        "\n",
        "#to update the rep\n",
        "%cd /content/EEE4022S_BNKJUL001_Thesis\n",
        "! git pull\n",
        "#import needed libarys\n",
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "from gymnasium import spaces\n",
        "import datetime\n",
        "from stable_baselines3 import PPO, A2C, DQN,DDPG\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from stable_baselines3.common.callbacks import EvalCallback\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.vec_env import VecVideoRecorder\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.animation import FuncAnimation\n",
        "from gym.wrappers import FlattenObservation\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "import wandb\n",
        "from wandb.integration.sb3 import WandbCallback\n",
        "from gymnasium.envs.registration import register\n",
        "\n",
        "\n",
        "\n",
        "#mount the drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#define paths to logs and model saves\n",
        "model_type = \"PPO\"\n",
        "version    = \"EMSv2_6\"\n",
        "model_dir = f\"/content/drive/MyDrive/Colab Notebooks/{version}/models/{model_type}/\"\n",
        "log_dir   = f\"/content/drive/MyDrive/Colab Notebooks/{version}/models/{model_type}logs/\"\n",
        "\n",
        "#make the appropriate directory if it does not exist\n",
        "if not os.path.exists(model_dir):\n",
        "    os.makedirs(model_dir)\n",
        "if not os.path.exists(log_dir):\n",
        "    os.makedirs(log_dir)\n"
      ],
      "metadata": {
        "id": "SIpnNCVVRTV8"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define our environment class!!**"
      ],
      "metadata": {
        "id": "Q99_jLMvwuZZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "s2iW-k26FIbm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4731d355-9549-4bff-e631-578892ea7d9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gymnasium/envs/registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment EMSv2_6 already in registry.\u001b[0m\n",
            "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n"
          ]
        }
      ],
      "source": [
        "class EMSv2_6(gym.Env):\n",
        "    \"\"\"Custom Environment that follows gym interface.\"\"\"\n",
        "\n",
        "    metadata = {\"render_modes\": [\"human\",\"rgb_array\"], \"render_fps\": 30}\n",
        "\n",
        "    def __init__(self,bat_threshold = 0.1, bat_cap = 1, actual_load = \"none\", actual_gen = \"none\", purchase_price = [1,1,1,1,1,1,1,1,2,2,2,2] , episode_len = 8760,num_preds = 24,render_mode = \"rgb_array\", load_shedding = \"none\", wandb_log = False,train_log = True, gen_size = 100,demand_charge = 252.92):\n",
        "\n",
        "        super(EMSv2_6, self).__init__()\n",
        "        #define render_mode\n",
        "        self.render_mode = render_mode\n",
        "        #define wandb\n",
        "        self.wandb_log = wandb_log\n",
        "        self.train_log = train_log\n",
        "        #define time frame\n",
        "        self.current_step = 0\n",
        "        self.final_step = int(episode_len)-num_preds-1\n",
        "        self.episode_len = int(episode_len)\n",
        "        #define num preds\n",
        "        self.num_preds = int(num_preds)\n",
        "        #define the battery max capacity\n",
        "        self.bat_cap =  np.float32(bat_cap)\n",
        "        #define the battery low threshold\n",
        "        self.bat_threshold = np.float32(bat_threshold)\n",
        "        #define demand charge\n",
        "        self.demand_charge = demand_charge\n",
        "        #define the size of the diesel_gen\n",
        "        self.gen_size = gen_size\n",
        "\n",
        "        #fill all of the actual loads\n",
        "        self.fill_load(actual_load)\n",
        "\n",
        "        #fill all of the actual generation steps.\n",
        "        self.fill_gen(actual_gen)\n",
        "\n",
        "        #fill the total power balance\n",
        "        self.fill_power_bal()\n",
        "\n",
        "        #Fill the loadShedding indicator\n",
        "        self.fill_shedding(load_shedding)\n",
        "\n",
        "        #define the purchase price for every step of the year\n",
        "        self.fill_price(purchase_price)\n",
        "\n",
        "        #action space is recomended to be -1 to 1. by stablebaslines due to the sampling distributions\n",
        "        self.action_scaler = MinMaxScaler(feature_range = (-1,1))\n",
        "        #set the lower bound of the action to 0, (requesting to buy 0 kw) and the upper to the max_avail capacity and the max load required.\n",
        "        self.action_scaler.fit_transform(np.array([0, self.bat_cap -  self.bat_threshold + np.max(self.actual_load)]).reshape(-1,1))\n",
        "        #define the size of the action space\n",
        "        self.action_space = gym.spaces.Box(low= -1 , high =1)\n",
        "\n",
        "        # Dict space to store all the different things\n",
        "        self.observation_space = spaces.Dict({\n",
        "                \"power_bal_forecast\" : gym.spaces.Box(low=-1, high=1, shape=(1,num_preds), dtype=np.float32),\n",
        "                \"price_forecast\"     : gym.spaces.Box(low=0, high=1, shape=(1,num_preds+1), dtype=np.float32),\n",
        "                \"island_forecast\"    : gym.spaces.Box(low=0, high=1, shape=(1,num_preds+1), dtype=np.float32),\n",
        "                \"bat_level\"          : gym.spaces.Box(low=-1, high=1, shape=(1,), dtype=np.float32),\n",
        "                \"current_power_bal\"  : gym.spaces.Box(low=-1, high=1, shape=(1,), dtype=np.float32)\n",
        "                })\n",
        "        #flatten the observation space to a 1D vector so that it can be interperted more easily by the agent.\n",
        "        self.observation_space = spaces.flatten_space(self.observation_space)\n",
        "\n",
        "    def step(self, action):\n",
        "        #update the current state with the action (needs to be done before current_step is inc since we want to apply the action to the previous step to get the current state)\n",
        "        self.update_state(action)\n",
        "\n",
        "        #Calculate reward from the action\n",
        "        self.reward[self.current_step] = self.calc_reward()\n",
        "        reward = self.reward[self.current_step]\n",
        "\n",
        "        #Wand log, if its set to true(so that it only gets run when wandb is initialised)\n",
        "        # if train_log is false then every step is logged by the eval logger. (only the final step is logged by the train logger)\n",
        "        if self.train_log != True and self.wandb_log ==True:\n",
        "            self.wandb_logger()\n",
        "\n",
        "        #inc time step into Future\n",
        "        self.current_step += 1\n",
        "        #get the next observation for the agent (for next time step)\n",
        "        observation = self.get_obs()\n",
        "\n",
        "        #Set terminated to False since there are no failure states\n",
        "        self.terminated = False\n",
        "        #Check if timelimit reached\n",
        "        self.truncated = False if self.current_step<self.final_step else True\n",
        "        #if the episode is truncated, log the final step(both Training and Eval modes)\n",
        "        if self.truncated and self.wandb_log:\n",
        "            self.wandb_logger()\n",
        "\n",
        "        #requirement but I am not using it so it is empty\n",
        "        info = {}\n",
        "        return observation, reward, self.terminated, self.truncated, info\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        super().reset(seed = seed, options=options)\n",
        "        #reset the state\n",
        "        self.current_step = 0\n",
        "        self.terminated = False\n",
        "        self.truncated = False\n",
        "\n",
        "        #Reset values to run Grid\n",
        "        self.battery_level      = np.zeros(self.final_step+1)\n",
        "        self.battery_level[0]   = self.power_scaler.transform(np.array(self.bat_cap/2).reshape(-1,1))#set the intial battery level to half its capacity\n",
        "        self.reward             = np.zeros(self.final_step+1)\n",
        "        self.step_purchased     = np.zeros(self.final_step+1)\n",
        "\n",
        "        #Reset all of the other variables used to log\n",
        "        self.excess_gen         = np.zeros(self.final_step+1)\n",
        "        self.step_unmet_load    = np.zeros(self.final_step+1)\n",
        "        self.off_peak_purchases = np.zeros(self.final_step+1)\n",
        "        self.peak_purchases     = np.zeros(self.final_step+1)\n",
        "        self.standard_purchases = np.zeros(self.final_step+1)\n",
        "        self.off_peak_cost      = np.zeros(self.final_step+1)\n",
        "        self.standard_cost      = np.zeros(self.final_step+1)\n",
        "        self.peak_cost          = np.zeros(self.final_step+1)\n",
        "        self.step_invt          = np.zeros(self.final_step+1)\n",
        "        self.step_rect          = np.zeros(self.final_step+1)\n",
        "        self.diesel_gen         = np.zeros(self.final_step+1)\n",
        "        self.action_purchase    = np.zeros(self.final_step+1)\n",
        "        self.money_spent        = np.zeros(self.final_step+1)\n",
        "\n",
        "        #get the first observation\n",
        "        observation = self.get_obs()\n",
        "        #Still don't know what to do with info\n",
        "        info = {}\n",
        "        return observation, info\n",
        "\n",
        "    def render(self, mode='rgb_array', save_path=None):\n",
        "        pass\n",
        "\n",
        "    def close(self):\n",
        "        #don't think i need this for my application\n",
        "        pass\n",
        "\n",
        "\n",
        "\n",
        "    #MAIN HELPER FUNCTIONS\n",
        "    #######################################################################################################################################################################\n",
        "\n",
        "    def update_state(self, action):\n",
        "        #impliment the action into the environment\n",
        "        self.run_grid(purchase_amount = action)\n",
        "        #log the agents action (in kw)\n",
        "        self.action_purchase[self.current_step] = self.action_scaler.inverse_transform(np.array([action]).reshape(-1,1))\n",
        "        #calculate and log the purchases per Time of Use rate\n",
        "        self.tou_purchase_inc()\n",
        "        #Calculate the flow of power\n",
        "        #fetch info from grids\n",
        "        self.calc_power_flow()\n",
        "\n",
        "    def run_grid(self,purchase_amount):\n",
        "        #self.power_scaler.inverse_transform(self.actual_power_bal[self.current_step].reshap(-1,1))\n",
        "        #fetch info from grids\n",
        "        ac_power_bal, avail_grid = self.AC_bus()\n",
        "        dc_power_bal, avail_bat, avail_stor = self.DC_bus()\n",
        "        #fecth the current_battery level for this step.\n",
        "        current_battery_level =  self.power_scaler.inverse_transform(self.battery_level[self.current_step].reshape(-1,1))\n",
        "        #un-normalise the agents purchase request (its action)\n",
        "        purchase_amount_unnorm = self.action_scaler.inverse_transform(np.array([purchase_amount]).reshape(-1,1))\n",
        "\n",
        "        if avail_grid: # if there is no loadshedding purchase the amount requested by the agent.\n",
        "            self.step_purchased[self.current_step] = purchase_amount_unnorm\n",
        "        else:          # if there is loadshedding then it the step purchased must be 0\n",
        "            self.step_purchased[self.current_step] = 0\n",
        "\n",
        "        #calculate the immediate power_bal, this is the AC power, DC power and the Amount that the agent has purchased\n",
        "        grid_power_bal = ac_power_bal + dc_power_bal + self.step_purchased[self.current_step]\n",
        "\n",
        "        #determine the flow of power:\n",
        "        if grid_power_bal > 0 : #if the power balance is positive, the battery is charged and any remaing power is recorded in excess gen\n",
        "            #Set the battery_level for the next step to the current battery plus the exces. Using minimium between avail_stor and grid_power_bal ensures that the battery is only charged to its max capacity.\n",
        "            self.battery_level[self.current_step+1] =  self.power_scaler.transform(current_battery_level+ min(avail_stor, grid_power_bal))\n",
        "            #increments excess gen by the max. If grid_power_bal - avail_stor is negative, there was no excess and it will add 0, else it will add the excess that couln't be stored.\n",
        "            self.excess_gen[self.current_step] = max((grid_power_bal - avail_stor), 0)\n",
        "        else:\n",
        "            #there is a shortage of power since the balance is negative, see if we can take it from the battery.\n",
        "            #set the battery level for the next step. If the battery has the avail capacity to meet the demand, then the demand is subtracted. If the battery does not then the avail_battery is subtracted. This prevents over discharge.\n",
        "            self.battery_level[self.current_step+1] = self.power_scaler.transform(current_battery_level + max(-avail_bat, grid_power_bal))\n",
        "\n",
        "            #check if there is still a shortage of power after the battery has been discharged.\n",
        "            grid_power_bal_discharged = grid_power_bal + min(avail_bat,-grid_power_bal)\n",
        "            #if there is still a shortage, Check if it can be purchased from the grid or if it will be added to unmet_load\n",
        "            if grid_power_bal_discharged  < 0 :\n",
        "            #check if we are islanded and buy elec if we arent\n",
        "                if avail_grid:\n",
        "                    #set the purchased amount for the step to be the amount purchased already, and the remaining amount needed to balance the power.\n",
        "                    self.step_purchased[self.current_step] = purchase_amount_unnorm + -grid_power_bal_discharged\n",
        "                else:\n",
        "                    #if the grid is not available, run the generator\n",
        "                    #the amount of generation provided by the generator is limited by its size\n",
        "                    self.diesel_gen[self.current_step] = min(-grid_power_bal_discharged,self.gen_size)\n",
        "                    #calulate grid_power_bal after the diesel generator has been used\n",
        "                    grid_power_bal_with_diesel = grid_power_bal_discharged + min(-grid_power_bal_discharged,self.gen_size)\n",
        "                    if grid_power_bal_with_diesel < 0:\n",
        "                        self.step_unmet_load[self.current_step] = -grid_power_bal_with_diesel\n",
        "\n",
        "    def calc_reward(self):\n",
        "        #Calculate reward based on the state\n",
        "        #cost of running generator in that step\n",
        "        petrol_per_kw  = 0.4*23 #0.4l per kwh produced multipled by a cost of 23 rand per litre. Very rough values\n",
        "        diesel_cost     = petrol_per_kw*self.diesel_gen[self.current_step]\n",
        "        #cost of purchasing electricity in that step\n",
        "        elec_purchase   = self.step_purchased[self.current_step]*self.price_scaler.inverse_transform(self.purchase_price[self.current_step].reshape(-1,1)).flatten()\n",
        "        #Penality for unmet_load\n",
        "        unmet_load_pen  = self.step_unmet_load[self.current_step]*10\n",
        "        #Calculate the reward (monetary cost and the added penality for unmet_load!)\n",
        "        reward = -elec_purchase - unmet_load_pen - diesel_cost\n",
        "        #record the money spent in this step\n",
        "        self.money_spent[self.current_step] =  elec_purchase +  diesel_cost\n",
        "        return reward\n",
        "\n",
        "    def get_obs(self):\n",
        "        #Fill the observation space with the next observation\n",
        "\n",
        "        #calculate the power forecast\n",
        "        power_bal_forecast = self.actual_power_bal[self.current_step+1: self.current_step + self.num_preds+1]\n",
        "\n",
        "        #get the prices for the current frame and the next 24 hours. Maybe will cut this down since that seems like a lot of info\n",
        "        price_forecast = np.array( [self.purchase_price[self.current_step:self.current_step+self.num_preds+1]] , dtype = np.float32).reshape(1,self.num_preds+1)\n",
        "        #Just for readibility of the dict object\n",
        "        bat_level      = np.array([self.battery_level[self.current_step]] , dtype= np.float32)\n",
        "\n",
        "        #island forecasst, same as tou forecast\n",
        "        island_forecast =np.array( [self.load_shed[self.current_step:self.current_step+self.num_preds+1]] , dtype = np.float32)\n",
        "\n",
        "        #calculate the current power balance\n",
        "        current_power_bal = self.actual_power_bal[self.current_step]\n",
        "\n",
        "        obs = dict({\n",
        "                \"bat_level\":      bat_level,\n",
        "                \"current_power_bal\" :   current_power_bal,\n",
        "                \"island_forecast\": island_forecast,\n",
        "                \"power_bal_forecast\":  power_bal_forecast,\n",
        "                \"price_forecast\": price_forecast,\n",
        "\n",
        "        })\n",
        "        #flatten the obs to make it the correct shape. 1D array\n",
        "        obs = np.concatenate([obs[key].flatten() for key in obs.keys()])\n",
        "        return obs\n",
        "\n",
        "    def wandb_logger(self):\n",
        "\n",
        "        train_log_dict={\n",
        "                    \"Excess Generation\"         :np.sum(self.excess_gen),\n",
        "                    \"Unmet Load\"                :np.sum(self.step_unmet_load),\n",
        "                    \"Off-Peak Purchases\"        :np.sum(self.off_peak_purchases),\n",
        "                    \"Standard Purchases\"        :np.sum(self.standard_purchases),\n",
        "                    \"Peak Purchases\"            :np.sum(self.peak_purchases),\n",
        "                    \"Num Off-Peak Purchases\"    :np.count_nonzero(self.off_peak_purchases),\n",
        "                    \"Num Standard Purchases\"    :np.count_nonzero(self.standard_purchases),\n",
        "                    \"Num Peak Purchases\"        :np.count_nonzero(self.peak_purchases),\n",
        "                    \"Total Elec Purchase\"       :np.sum(self.step_purchased),\n",
        "                    \"Total Purchase Requested\"  :np.sum(self.action_purchase),\n",
        "                    \"Num Diesel Gen Actions\"    :np.count_nonzero(self.diesel_gen),\n",
        "                    \"Total Reward\"              :np.sum(self.reward),\n",
        "                    \"Total Money spent\"         :np.sum(self.money_spent),\n",
        "                    \"Rectifier total power flow\":np.sum(self.step_rect),\n",
        "                    \"Inverter total power flow\" :np.sum(self.step_invt),\n",
        "                    \"Diesel Generator\"          :np.sum(self.diesel_gen),\n",
        "                    \"Max Demand\"                :np.max(self.step_purchased),\n",
        "                    \"total Purchased Elec\"      :np.sum(self.step_purchased)\n",
        "                    }\n",
        "\n",
        "        eval_log_dict={\n",
        "                    \"battery_level\"             :self.power_scaler.inverse_transform(self.battery_level[self.current_step].reshape(-1,1)).flatten(),\n",
        "                    \"AC load\"                   :self.actual_load[self.current_step,0],\n",
        "                    \"DC load\"                   :self.actual_load[self.current_step,1],\n",
        "                    \"Wind generation\"           :self.actual_gen[self.current_step,0],\n",
        "                    \"PV generation\"             :self.actual_gen[self.current_step,1],\n",
        "                    \"Excess Generation\"         :self.excess_gen[self.current_step],\n",
        "                    \"Unmet Load\"                :self.step_unmet_load[self.current_step],\n",
        "                    \"LoadShedding\"              :self.load_shed[self.current_step],\n",
        "                    \"Off-Peak Purchases\"        :self.off_peak_purchases[self.current_step],\n",
        "                    \"Standard Purchases\"        :self.standard_purchases[self.current_step],\n",
        "                    \"Peak Purchases\"            :self.peak_purchases[self.current_step],\n",
        "                    \"Num Off-Peak Purchases\"    :np.count_nonzero(self.off_peak_purchases),\n",
        "                    \"Num Standard Purchases\"    :np.count_nonzero(self.standard_purchases),\n",
        "                    \"Num Peak Purchases\"        :np.count_nonzero(self.peak_purchases),\n",
        "                    \"Step Purchased\"            :self.step_purchased[self.current_step],\n",
        "                    \"Purchase Requested\"        :self.action_purchase[self.current_step],\n",
        "                    \"Num Diesel Gen Actions\"    :np.count_nonzero(self.diesel_gen),\n",
        "                    \"Total Reward\"              :self.reward[self.current_step],\n",
        "                    \"Money Spent\"               :self.money_spent[self.current_step],\n",
        "                    \"Rectifier total power flow\":self.step_rect[self.current_step],\n",
        "                    \"Inverter total power flow\" :self.step_invt[self.current_step],\n",
        "                    \"Diesel Generator\"          :self.diesel_gen[self.current_step],\n",
        "\n",
        "                    }\n",
        "\n",
        "        if self.train_log:\n",
        "            wandb.log(train_log_dict)\n",
        "        else:\n",
        "            wandb.log(eval_log_dict)\n",
        "\n",
        "        if self.train_log == False and self.current_step == self.final_step:\n",
        "\n",
        "            values = [[np.sum(self.off_peak_purchases),'Off Peak'], [np.sum(self.standard_purchases),'Standard'], [np.sum(self.peak_purchases),'Peak']]\n",
        "            table = wandb.Table(columns = [\"values\",\"labels\"],data=values)\n",
        "            Tou_purchases = wandb.plot.bar(table,\"labels\",\"values\", title=\"kWh per TOU tariff\")\n",
        "\n",
        "            values = [[np.sum(self.off_peak_cost),'Off Peak'], [np.sum(self.standard_cost),'Standard'], [np.sum(self.peak_cost),'Peak']]\n",
        "            table = wandb.Table(columns = [\"values\",\"labels\"],data=values)\n",
        "            Tou_purchase_cost = wandb.plot.bar(table,\"labels\",\"values\", title=\"Rands per TOU tariff\")\n",
        "\n",
        "            values = [[np.max(self.step_purchased),'Max demand'], [np.max(self.diesel_gen),'Max diesel gen'], [np.max(self.step_rect),'Max rectifier power'], [np.max(self.step_invt),'Max inverter power']]\n",
        "            table = wandb.Table(columns = [\"values\",\"labels\"],data=values)\n",
        "            max_metrics = wandb.plot.bar(table,\"labels\",\"values\", title=\"Sizing Metrics\")\n",
        "\n",
        "            values = [[np.sum(self.step_purchased),'Total Purchased'], [np.sum(self.action_purchase),'Total requested purchases'],[np.sum(self.excess_gen),'Total excess generation']]\n",
        "            table = wandb.Table(columns = [\"values\",\"labels\"],data=values)\n",
        "            total_metrics = wandb.plot.bar(table,\"labels\",\"values\", title=\"Total Metrics\")\n",
        "\n",
        "            values = [[np.sum(self.diesel_gen),'Total diesel generation'], [np.sum(self.step_unmet_load),'Total unmet load']]\n",
        "            table = wandb.Table(columns = [\"values\",\"labels\"],data=values)\n",
        "            total_diesel_unmet = wandb.plot.bar(table,\"labels\",\"values\", title=\"Total diesel and unmet load\")\n",
        "\n",
        "            values = [[np.sum(self.reward),'Total reward accumulated']]\n",
        "            table = wandb.Table(columns = [\"values\",\"labels\"],data=values)\n",
        "            total_reward = wandb.plot.bar(table,\"labels\",\"values\", title=\"Total reward\")\n",
        "\n",
        "            values = [[np.sum(self.money_spent),'Total money spent']]\n",
        "            table = wandb.Table(columns = [\"values\",\"labels\"],data=values)\n",
        "            total_spent = wandb.plot.bar(table,\"labels\",\"values\", title=\"Total money spent\")\n",
        "\n",
        "            wandb.log({ \"kWh purchased per TOU tariff\"  : Tou_purchases,\n",
        "                        \"Rands per TOU tariff\"          : Tou_purchase_cost,\n",
        "                        \"Max sizing metrics\"            : max_metrics,\n",
        "                        \"Total metrics\"                 : total_metrics,\n",
        "                        \"Total diesel and unmet load\"   : total_diesel_unmet,\n",
        "                        \"Total reward and money spent\"  :total_reward,\n",
        "                        \"Total money spent\"             :total_spent\n",
        "                        })\n",
        "\n",
        "\n",
        "\n",
        "    #AUXILIARY HELPER FUNCTIONS\n",
        "    #######################################################################################################################################################################\n",
        "    def calc_power_flow(self):\n",
        "        #fetch info from grids\n",
        "        ac_power_bal, _ = self.AC_bus()\n",
        "        dc_power_bal, _ , avail_stor = self.DC_bus()\n",
        "        #Calculate the flow of power (this is max absorb, the min need is just dc_power_bal)\n",
        "        dc_power_absorb = max(-dc_power_bal+avail_stor,0)\n",
        "        #calculate the Dc_power_avail, could go to battery or AC_grid\n",
        "        dc_power_avail = max(dc_power_bal,0) #lol just defined a new var for readability.\n",
        "        #ac power excess will be the power balance added to the purchase amount\n",
        "        ac_power_excess = max(ac_power_bal+self.step_purchased[self.current_step]+self.diesel_gen[self.current_step],0)\n",
        "         # calculate how much power the ac grid needs.\n",
        "        ac_power_need   = max(-ac_power_bal-self.step_purchased[self.current_step]-self.diesel_gen[self.current_step], 0)\n",
        "        #calculate how much power would be in excess if there was to be excess.\n",
        "        dc_power_excess = max(dc_power_avail - ac_power_need - avail_stor,0)\n",
        "\n",
        "        #the power that will flow through the rectifier is the minimum between the amount the DC grid can absorb and the excess the ac_grid has\n",
        "        #This definition implies that the AC subgrid will supply its own loads first and only then send excess to dc Grid?\n",
        "        rect_power = min(dc_power_absorb,ac_power_excess)\n",
        "\n",
        "        #inverter power is equal to the minimum val between the avail dc power and the needed power. Then since all excess power needs to go to the grid, if there is any extra energy after the ac_need has been met and the battery is fully charged, it is also sent through the inverter\n",
        "        #DC subgrid will meet the AC load before charging the battery. Will send excess across if the DC load is met and the battery is fully charged.\n",
        "        invt_power = min(ac_power_need, dc_power_avail) + dc_power_excess\n",
        "        #set the attributes.\n",
        "        self.step_invt[self.current_step] = invt_power\n",
        "        self.step_rect[self.current_step] = rect_power\n",
        "\n",
        "    def tou_purchase_inc(self):\n",
        "        #Summer Months: 5.92, 2.09, 1.33\n",
        "        #Winter Months: 2.22, 1.66, 1.21\n",
        "        #un normalise the price for that step.\n",
        "        step_price = self.price_scaler.inverse_transform(self.purchase_price[self.current_step].reshape(-1,1))\n",
        "        #the conditions are a bit janky due to the different prices in Summer and Winter.\n",
        "        if step_price < 1.5:\n",
        "            self.off_peak_purchases[self.current_step] = self.step_purchased[self.current_step]\n",
        "            self.off_peak_cost[self.current_step]      = self.step_purchased[self.current_step]*step_price\n",
        "        elif step_price < 2.1:\n",
        "            self.standard_purchases[self.current_step] = self.step_purchased[self.current_step]\n",
        "            self.standard_cost[self.current_step]      = self.step_purchased[self.current_step]*step_price\n",
        "        else:\n",
        "            self.peak_purchases[self.current_step] = self.step_purchased[self.current_step]\n",
        "            self.peak_cost[self.current_step]      = self.step_purchased[self.current_step]*step_price\n",
        "\n",
        "    def AC_bus(self):\n",
        "        #fill out info on the ac\n",
        "        ac_gen = self.actual_gen[self.current_step, 0]\n",
        "        ac_load = self.actual_load[self.current_step,0]\n",
        "        ac_power_bal = ac_gen - ac_load\n",
        "        #check if there is load shedding or not\n",
        "        avail_grid = not self.load_shed[self.current_step]\n",
        "        #return relevant values\n",
        "        return ac_power_bal,avail_grid\n",
        "\n",
        "    def DC_bus(self):\n",
        "        #fill in info for DC_bus\n",
        "        dc_gen       = self.actual_gen[self.current_step,1]\n",
        "        dc_load      = self.actual_load[self.current_step,1]\n",
        "        dc_power_bal = dc_gen - dc_load\n",
        "        #fetch and transform information about the battery cap and availability\n",
        "        avail_bat  = self.power_scaler.inverse_transform(self.battery_level[self.current_step].reshape(-1,1)) - self.bat_threshold\n",
        "        avail_stor = self.bat_cap   - self.power_scaler.inverse_transform(self.battery_level[self.current_step].reshape(-1,1))\n",
        "        return dc_power_bal, avail_bat, avail_stor\n",
        "\n",
        "\n",
        "    def fill_load(self,actual_load):\n",
        "        if isinstance(actual_load,str) :#if actual_load is a string then fill with random numbers\n",
        "            self.actual_load = np.random.rand(self.final_step+self.num_preds+1,2).astype(np.float32)\n",
        "        else:                           #else fill the load with the correct number of entries from the input\n",
        "            self.actual_load  = actual_load[:self.episode_len,:]\n",
        "\n",
        "    def fill_gen(self,actual_gen):\n",
        "        if isinstance(actual_gen,str):#if actual_gen is a string then fill with random numbers\n",
        "            self.actual_gen  = np.random.rand(self.final_step+self.num_preds+1,2).astype(np.float32)\n",
        "        else:                           #else fill the gen with the correct number of entries from the input\n",
        "            self.actual_gen  = actual_gen[:self.episode_len,:]\n",
        "\n",
        "    def fill_power_bal(self):\n",
        "        actual_power_bal = self.actual_gen-self.actual_load\n",
        "        if len(actual_power_bal.shape) >= 2:\n",
        "            actual_power_bal = actual_power_bal.sum(axis=1)\n",
        "        self.power_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "        #in order for the agent to see the kw in the battery in proportion to the kw in power_bal observations. I have included the bat_cap in the transform, and the battery level will be transformed using the same scaler.\n",
        "        self.power_scaler.fit_transform(np.array(actual_power_bal,self.bat_cap).reshape(-1,1))\n",
        "        self.actual_power_bal = self.power_scaler.transform(actual_power_bal.reshape(-1,1))\n",
        "\n",
        "    def fill_price(self,purchase_price):\n",
        "        purchase_price = np.array(purchase_price).astype(np.float32)\n",
        "        if len(purchase_price)<self.episode_len: #if the proved set of purchase prices is less than the episode length, wrap it so it fills the episode.\n",
        "            repetitions    = (self.final_step+self.num_preds+1) // len(purchase_price)\n",
        "            remainder      = (self.final_step+self.num_preds+1) % len(purchase_price)\n",
        "            self.purchase_price =np.concatenate([purchase_price]*repetitions+[purchase_price[:remainder]])#need to read in from somewhere\n",
        "        else:                                    #else extract the correct number of prices.\n",
        "            self.purchase_price = purchase_price[:self.episode_len]\n",
        "\n",
        "        price_scaler = MinMaxScaler(feature_range=(0,1)) #scale purchase prices to 0,1\n",
        "        self.purchase_price = price_scaler.fit_transform(self.purchase_price.reshape(-1, 1))\n",
        "        self.price_scaler = price_scaler\n",
        "\n",
        "    def fill_shedding(self,load_shedding):\n",
        "        if isinstance(load_shedding,str): #if no loadshedding schedule has been provided then create a array with between 2-5% instances of loadshedding\n",
        "            num_shedding   = np.random.randint(int(0.02*self.episode_len), int(0.05*self.episode_len))\n",
        "            load_shed      = np.array([1]*num_shedding + [0]*(self.episode_len - num_shedding))\n",
        "            np.random.shuffle(load_shed)\n",
        "            self.load_shed = load_shed\n",
        "        else:                            #else if load shedding schedule is provided collect the correct number of instances\n",
        "            self.load_shed = load_shedding[:self.episode_len]\n",
        "\n",
        "\n",
        "#define a pointer (kinda, don't actually know what its called) a\n",
        "EMS = EMSv2_6\n",
        "\n",
        "# Register environment so I can use make_vec_env\n",
        "register(\n",
        "# unique identifier for the env `name-version`\n",
        "id=f\"{version}\",\n",
        "# path to the class for creating the env\n",
        "# Note: entry_point also accept a class as input (and not only a string)\n",
        "entry_point= EMS(),\n",
        "\n",
        ")\n",
        "\n",
        "#Check the environment with stable_baselines3 check_env.\n",
        "from stable_baselines3.common.env_checker import check_env\n",
        "env = EMS()\n",
        "check_env(env,warn = True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DG4gB2cM7tDY"
      },
      "source": [
        "**Load in the data for our specific microgrid.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "0X9RBdXC_2PD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23ea14c8-5b7b-459d-ca53-26d8ab259a7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The reset observation space looks like: [ 0.07764236 -0.49452567  0.          0.          0.          0.\n",
            " -0.53609806 -0.528026   -0.45572138  0.          0.          0.\n",
            "  0.        ]\n",
            "After action 0: \n",
            "Battery level is: 0.07764235883951187kWh\n",
            "Current  Power Balance -0.494525671005249\n",
            "Forecasted  power bal 1 hour ahead: -0.536098062992096.\n",
            "Forecasted  power bal 2 hour ahead: -0.5280259847640991. \n",
            "Forecasted  power bal 3 hour ahead: -0.455721378326416. \n",
            "current Purchase Prcie: 0.0.\n",
            "Forecasted  price 1 hour ahead: 0.0. \n",
            "Forecasted  price 2 hour ahead: 0.0. \n",
            "Forecasted  price 3 hour ahead: 0.0. \n",
            "_________________________________________________________________________________________________________________\n",
            "\n",
            "After action 0: \n",
            "Battery level is: -0.07079396396875381kWh\n",
            "Current  Power Balance -0.536098062992096\n",
            "Forecasted  power bal 1 hour ahead: -0.5280259847640991.\n",
            "Forecasted  power bal 2 hour ahead: -0.455721378326416. \n",
            "Forecasted  power bal 3 hour ahead: -0.31690627336502075. \n",
            "current Purchase Prcie: 0.0.\n",
            "Forecasted  price 1 hour ahead: 0.0. \n",
            "Forecasted  price 2 hour ahead: 0.0. \n",
            "Forecasted  price 3 hour ahead: 0.0. \n",
            "_________________________________________________________________________________________________________________\n",
            "\n",
            "After action 0: \n",
            "Battery level is: -0.17659667134284973kWh\n",
            "Current  Power Balance -0.5280259847640991\n",
            "Forecasted  power bal 1 hour ahead: -0.455721378326416.\n",
            "Forecasted  power bal 2 hour ahead: -0.31690627336502075. \n",
            "Forecasted  power bal 3 hour ahead: -0.1943129003047943. \n",
            "current Purchase Prcie: 0.0.\n",
            "Forecasted  price 1 hour ahead: 0.0. \n",
            "Forecasted  price 2 hour ahead: 0.0. \n",
            "Forecasted  price 3 hour ahead: 0.0. \n",
            "_________________________________________________________________________________________________________________\n",
            "\n",
            "After action 0: \n",
            "Battery level is: -0.17659667134284973kWh\n",
            "Current  Power Balance -0.455721378326416\n",
            "Forecasted  power bal 1 hour ahead: -0.31690627336502075.\n",
            "Forecasted  power bal 2 hour ahead: -0.1943129003047943. \n",
            "Forecasted  power bal 3 hour ahead: 0.09753653407096863. \n",
            "current Purchase Prcie: 0.0.\n",
            "Forecasted  price 1 hour ahead: 0.0. \n",
            "Forecasted  price 2 hour ahead: 0.0. \n",
            "Forecasted  price 3 hour ahead: 0.09576204419136047. \n",
            "_________________________________________________________________________________________________________________\n",
            "\n",
            "After action 1: \n",
            "Battery level is: 0.5013740658760071kWh\n",
            "Current  Power Balance -0.31690627336502075\n",
            "Forecasted  power bal 1 hour ahead: -0.1943129003047943.\n",
            "Forecasted  power bal 2 hour ahead: 0.09753653407096863. \n",
            "Forecasted  power bal 3 hour ahead: 0.27222663164138794. \n",
            "current Purchase Prcie: 0.0.\n",
            "Forecasted  price 1 hour ahead: 0.0. \n",
            "Forecasted  price 2 hour ahead: 0.09576204419136047. \n",
            "Forecasted  price 3 hour ahead: 0.21427208185195923. \n",
            "_________________________________________________________________________________________________________________\n",
            "\n",
            "Done iteration! Total reward accumulated is: -941670.4241791293\n"
          ]
        }
      ],
      "source": [
        "#need to import data from Github\n",
        "path_data = \"/content/EEE4022S_BNKJUL001_Thesis/PythonWorkspace/dataClean.csv\"\n",
        "data = pd.read_csv(path_data)\n",
        "\n",
        "path_pv_gen = \"/content/EEE4022S_BNKJUL001_Thesis/Generation/BNKJUL001_Thesis_solarGen500kWHomer.csv\"\n",
        "data_pv_gen = pd.read_csv(path_pv_gen)\n",
        "\n",
        "path_wind_gen = \"/content/EEE4022S_BNKJUL001_Thesis/Generation/BNKJUL001_Thesis_Wind500kGenHomer.csv\"\n",
        "data_wind_gen = pd.read_csv(path_wind_gen)\n",
        "\n",
        "#Not actually using this rn but will be soon :)\n",
        "path_shedding = \"/content/EEE4022S_BNKJUL001_Thesis/MatlabWorkSpace/loadShedding2022.csv\"\n",
        "data_shedding = pd.read_csv(path_shedding)\n",
        "load_shedding = data_shedding['LoadShedding'].values.astype(np.float32)\n",
        "\n",
        "wind_gen = data_wind_gen['Wind_Out'].values.astype(np.float32)\n",
        "PV_gen = data_pv_gen['PV_Out'].values.astype(np.float32)\n",
        "actual_gen = np.column_stack((wind_gen, PV_gen))\n",
        "#read in ac and DC load\n",
        "AC_load = data['AC'].values.astype(np.float32)\n",
        "DC_load = data['DC'].values.astype(np.float32)\n",
        "#stack em together for the input :)\n",
        "actual_load = np.column_stack((AC_load, DC_load))\n",
        "\n",
        "path_purchase_price = \"/content/EEE4022S_BNKJUL001_Thesis/PythonWorkspace/purchasePrice.csv\"\n",
        "data_purchase_price = pd.read_csv(path_purchase_price)\n",
        "purchase_price = data_purchase_price['Grid Power Price'].values.astype(np.float32)\n",
        "\n",
        "#define the base environment\n",
        "base_env = EMS(episode_len = 6000, actual_load = actual_load, actual_gen = actual_gen, bat_threshold = 100, bat_cap = 500, purchase_price = purchase_price,num_preds = 3)\n",
        "#going to print out a bunch of things to test the different spaces.\n",
        "obs,_    = base_env.reset()\n",
        "\n",
        "def print_obs(action_standby=0):\n",
        "    print(f\"After action {action_standby}: \" )\n",
        "    battery_level = obs[0]\n",
        "    print(f\"Battery level is: {battery_level}kWh\")\n",
        "    current_power_bal = obs[1]\n",
        "    print(f\"Current  Power Balance {current_power_bal}\")\n",
        "    power_forecast = obs[6:9]\n",
        "    print(f\"Forecasted  power bal 1 hour ahead: {power_forecast[0]}.\")\n",
        "    print(f\"Forecasted  power bal 2 hour ahead: {power_forecast[1]}. \")\n",
        "    print(f\"Forecasted  power bal 3 hour ahead: {power_forecast[2]}. \")\n",
        "    price = obs[9:]\n",
        "    print(f\"current Purchase Prcie: {price[0]}.\")\n",
        "    print(f\"Forecasted  price 1 hour ahead: {price[1]}. \")\n",
        "    print(f\"Forecasted  price 2 hour ahead: {price[2]}. \")\n",
        "    print(f\"Forecasted  price 3 hour ahead: {price[3]}. \")\n",
        "    print(f\"_________________________________________________________________________________________________________________\")\n",
        "    print(f\"\")\n",
        "\n",
        "print(f\"The reset observation space looks like: {obs}\")\n",
        "\n",
        "print_obs()\n",
        "\n",
        "action_standby = -1\n",
        "obs,reward,terminated,truncated,info = base_env.step(action_standby)\n",
        "\n",
        "print_obs()\n",
        "\n",
        "obs,reward,terminated,truncated,info = base_env.step(action_standby)\n",
        "\n",
        "print_obs()\n",
        "\n",
        "\n",
        "obs,reward,terminated,truncated,info = base_env.step(action_standby)\n",
        "print_obs()\n",
        "\n",
        "action_standby = 1\n",
        "obs,reward,terminated,truncated,info = base_env.step(action_standby)\n",
        "print_obs(action_standby)\n",
        "\n",
        "#Evaluate the base model (no EMS, just using standby mode)\n",
        "#reset score\n",
        "score = 0\n",
        "obs,_    = base_env.reset()\n",
        "#ensure that the exit condition is reset\n",
        "truncated = False\n",
        "#define the action to take. -1 represents requesting to buy 0kw every step.\n",
        "action_standby = -1\n",
        "\n",
        "while not truncated:\n",
        "    obs,reward,terminated,truncated,info = base_env.step(action_standby)\n",
        "    score += reward\n",
        "\n",
        "print(f\"Done iteration! Total reward accumulated is: {score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pAj6-n04zyt"
      },
      "source": [
        "**LOAD OR MAKE MODEL HERE!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQDhUNGWeum4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d469e160-175c-43b7-c9b6-16cc50815fda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.12"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/EEE4022S_BNKJUL001_Thesis/wandb/run-20231018_161701-vllcyeqw</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/vllcyeqw' target=\"_blank\">gallant-surf-238</a></strong> to <a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems' target=\"_blank\">https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/vllcyeqw' target=\"_blank\">https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/vllcyeqw</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "Logging to runs/vllcyeqw/EMSv2_6_PPO_train20231018-161704_0\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 601   |\n",
            "|    iterations      | 1     |\n",
            "|    time_elapsed    | 17    |\n",
            "|    total_timesteps | 10240 |\n",
            "------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 513         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 39          |\n",
            "|    total_timesteps      | 20480       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018410217 |\n",
            "|    clip_fraction        | 0.264       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.39       |\n",
            "|    explained_variance   | 4.23e-05    |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 1.27e+07    |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0284     |\n",
            "|    std                  | 0.977       |\n",
            "|    value_loss           | 7.4e+07     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -3.2e+06    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 520         |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 59          |\n",
            "|    total_timesteps      | 30720       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019409468 |\n",
            "|    clip_fraction        | 0.212       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.34       |\n",
            "|    explained_variance   | -1.19e-07   |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 1.04e+07    |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0196     |\n",
            "|    std                  | 0.917       |\n",
            "|    value_loss           | 6.22e+07    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -3.2e+06    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 529         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 77          |\n",
            "|    total_timesteps      | 40960       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010216737 |\n",
            "|    clip_fraction        | 0.124       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.3        |\n",
            "|    explained_variance   | 1.19e-07    |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 1.52e+07    |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0127     |\n",
            "|    std                  | 0.879       |\n",
            "|    value_loss           | 7.91e+07    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -3.2e+06    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 536         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 95          |\n",
            "|    total_timesteps      | 51200       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.023777325 |\n",
            "|    clip_fraction        | 0.273       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.23       |\n",
            "|    explained_variance   | 1.79e-07    |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 5.23e+06    |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0299     |\n",
            "|    std                  | 0.819       |\n",
            "|    value_loss           | 2.87e+07    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -2.77e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 535         |\n",
            "|    iterations           | 6           |\n",
            "|    time_elapsed         | 114         |\n",
            "|    total_timesteps      | 61440       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016526226 |\n",
            "|    clip_fraction        | 0.182       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.17       |\n",
            "|    explained_variance   | 5.96e-08    |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 3.83e+06    |\n",
            "|    n_updates            | 50          |\n",
            "|    policy_gradient_loss | -0.0151     |\n",
            "|    std                  | 0.776       |\n",
            "|    value_loss           | 2.91e+07    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.98e+03     |\n",
            "|    ep_rew_mean          | -2.77e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 535          |\n",
            "|    iterations           | 7            |\n",
            "|    time_elapsed         | 133          |\n",
            "|    total_timesteps      | 71680        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0125680985 |\n",
            "|    clip_fraction        | 0.14         |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.13        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 5.73e+06     |\n",
            "|    n_updates            | 60           |\n",
            "|    policy_gradient_loss | -0.0112      |\n",
            "|    std                  | 0.749        |\n",
            "|    value_loss           | 3.29e+07     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -2.77e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 539         |\n",
            "|    iterations           | 8           |\n",
            "|    time_elapsed         | 151         |\n",
            "|    total_timesteps      | 81920       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.025350824 |\n",
            "|    clip_fraction        | 0.254       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.05       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 1.1e+06     |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -0.0213     |\n",
            "|    std                  | 0.686       |\n",
            "|    value_loss           | 7.33e+06    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -2.42e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 542         |\n",
            "|    iterations           | 9           |\n",
            "|    time_elapsed         | 169         |\n",
            "|    total_timesteps      | 92160       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013159275 |\n",
            "|    clip_fraction        | 0.148       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.996      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 2.21e+06    |\n",
            "|    n_updates            | 80          |\n",
            "|    policy_gradient_loss | -0.00696    |\n",
            "|    std                  | 0.65        |\n",
            "|    value_loss           | 1.61e+07    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -2.42e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 544         |\n",
            "|    iterations           | 10          |\n",
            "|    time_elapsed         | 188         |\n",
            "|    total_timesteps      | 102400      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016777147 |\n",
            "|    clip_fraction        | 0.167       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.944      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 1.5e+06     |\n",
            "|    n_updates            | 90          |\n",
            "|    policy_gradient_loss | -0.00373    |\n",
            "|    std                  | 0.631       |\n",
            "|    value_loss           | 1.19e+07    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -2.42e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 542         |\n",
            "|    iterations           | 11          |\n",
            "|    time_elapsed         | 207         |\n",
            "|    total_timesteps      | 112640      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.060338784 |\n",
            "|    clip_fraction        | 0.254       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.879      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 1.86e+05    |\n",
            "|    n_updates            | 100         |\n",
            "|    policy_gradient_loss | -0.00181    |\n",
            "|    std                  | 0.541       |\n",
            "|    value_loss           | 1.74e+06    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -2.22e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 544         |\n",
            "|    iterations           | 12          |\n",
            "|    time_elapsed         | 225         |\n",
            "|    total_timesteps      | 122880      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019671999 |\n",
            "|    clip_fraction        | 0.254       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.793      |\n",
            "|    explained_variance   | 1.19e-07    |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 2.54e+06    |\n",
            "|    n_updates            | 110         |\n",
            "|    policy_gradient_loss | 0.012       |\n",
            "|    std                  | 0.526       |\n",
            "|    value_loss           | 1.67e+07    |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 5.98e+03   |\n",
            "|    ep_rew_mean          | -2.22e+06  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 546        |\n",
            "|    iterations           | 13         |\n",
            "|    time_elapsed         | 243        |\n",
            "|    total_timesteps      | 133120     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01336878 |\n",
            "|    clip_fraction        | 0.162      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.769     |\n",
            "|    explained_variance   | 0          |\n",
            "|    learning_rate        | 0.01       |\n",
            "|    loss                 | 1.93e+06   |\n",
            "|    n_updates            | 120        |\n",
            "|    policy_gradient_loss | -0.00214   |\n",
            "|    std                  | 0.524      |\n",
            "|    value_loss           | 1.2e+07    |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -2.22e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 547         |\n",
            "|    iterations           | 14          |\n",
            "|    time_elapsed         | 261         |\n",
            "|    total_timesteps      | 143360      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016272105 |\n",
            "|    clip_fraction        | 0.175       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.726      |\n",
            "|    explained_variance   | 0.192       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 6.85e+05    |\n",
            "|    n_updates            | 130         |\n",
            "|    policy_gradient_loss | -0.00508    |\n",
            "|    std                  | 0.497       |\n",
            "|    value_loss           | 3.58e+06    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -2.07e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 546         |\n",
            "|    iterations           | 15          |\n",
            "|    time_elapsed         | 280         |\n",
            "|    total_timesteps      | 153600      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017920036 |\n",
            "|    clip_fraction        | 0.203       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.683      |\n",
            "|    explained_variance   | 0.0154      |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 1.46e+06    |\n",
            "|    n_updates            | 140         |\n",
            "|    policy_gradient_loss | -0.00225    |\n",
            "|    std                  | 0.472       |\n",
            "|    value_loss           | 7.24e+06    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -2.07e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 547         |\n",
            "|    iterations           | 16          |\n",
            "|    time_elapsed         | 299         |\n",
            "|    total_timesteps      | 163840      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013534961 |\n",
            "|    clip_fraction        | 0.135       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.653      |\n",
            "|    explained_variance   | 0.266       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 8.77e+05    |\n",
            "|    n_updates            | 150         |\n",
            "|    policy_gradient_loss | -0.000484   |\n",
            "|    std                  | 0.481       |\n",
            "|    value_loss           | 5.05e+06    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -2.07e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 547         |\n",
            "|    iterations           | 17          |\n",
            "|    time_elapsed         | 317         |\n",
            "|    total_timesteps      | 174080      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011495268 |\n",
            "|    clip_fraction        | 0.11        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.637      |\n",
            "|    explained_variance   | 0.588       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 1.03e+05    |\n",
            "|    n_updates            | 160         |\n",
            "|    policy_gradient_loss | -0.00638    |\n",
            "|    std                  | 0.451       |\n",
            "|    value_loss           | 7.93e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -1.92e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 548         |\n",
            "|    iterations           | 18          |\n",
            "|    time_elapsed         | 336         |\n",
            "|    total_timesteps      | 184320      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012265267 |\n",
            "|    clip_fraction        | 0.162       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.582      |\n",
            "|    explained_variance   | 0.185       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 6.88e+05    |\n",
            "|    n_updates            | 170         |\n",
            "|    policy_gradient_loss | 8.52e-05    |\n",
            "|    std                  | 0.432       |\n",
            "|    value_loss           | 3.34e+06    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -1.92e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 547         |\n",
            "|    iterations           | 19          |\n",
            "|    time_elapsed         | 355         |\n",
            "|    total_timesteps      | 194560      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010169582 |\n",
            "|    clip_fraction        | 0.0913      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.557      |\n",
            "|    explained_variance   | 0.516       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 4.32e+05    |\n",
            "|    n_updates            | 180         |\n",
            "|    policy_gradient_loss | -0.0034     |\n",
            "|    std                  | 0.422       |\n",
            "|    value_loss           | 3.03e+06    |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 5.98e+03   |\n",
            "|    ep_rew_mean          | -1.92e+06  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 548        |\n",
            "|    iterations           | 20         |\n",
            "|    time_elapsed         | 373        |\n",
            "|    total_timesteps      | 204800     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00755165 |\n",
            "|    clip_fraction        | 0.0811     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.527     |\n",
            "|    explained_variance   | 0.709      |\n",
            "|    learning_rate        | 0.01       |\n",
            "|    loss                 | 5.81e+04   |\n",
            "|    n_updates            | 190        |\n",
            "|    policy_gradient_loss | -0.00486   |\n",
            "|    std                  | 0.405      |\n",
            "|    value_loss           | 4.42e+05   |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -1.79e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 548         |\n",
            "|    iterations           | 21          |\n",
            "|    time_elapsed         | 391         |\n",
            "|    total_timesteps      | 215040      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012314314 |\n",
            "|    clip_fraction        | 0.129       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.486      |\n",
            "|    explained_variance   | 0.433       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 1.91e+05    |\n",
            "|    n_updates            | 200         |\n",
            "|    policy_gradient_loss | -0.00245    |\n",
            "|    std                  | 0.391       |\n",
            "|    value_loss           | 1.76e+06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.98e+03     |\n",
            "|    ep_rew_mean          | -1.79e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 549          |\n",
            "|    iterations           | 22           |\n",
            "|    time_elapsed         | 409          |\n",
            "|    total_timesteps      | 225280       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0083738705 |\n",
            "|    clip_fraction        | 0.0842       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.458       |\n",
            "|    explained_variance   | 0.718        |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 3.03e+05     |\n",
            "|    n_updates            | 210          |\n",
            "|    policy_gradient_loss | -0.00291     |\n",
            "|    std                  | 0.383        |\n",
            "|    value_loss           | 1.39e+06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -1.79e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 548         |\n",
            "|    iterations           | 23          |\n",
            "|    time_elapsed         | 429         |\n",
            "|    total_timesteps      | 235520      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006351862 |\n",
            "|    clip_fraction        | 0.0576      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.426      |\n",
            "|    explained_variance   | 0.748       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 4.51e+04    |\n",
            "|    n_updates            | 220         |\n",
            "|    policy_gradient_loss | -0.00272    |\n",
            "|    std                  | 0.369       |\n",
            "|    value_loss           | 3.84e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -1.67e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 549         |\n",
            "|    iterations           | 24          |\n",
            "|    time_elapsed         | 447         |\n",
            "|    total_timesteps      | 245760      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008961101 |\n",
            "|    clip_fraction        | 0.0908      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.395      |\n",
            "|    explained_variance   | 0.57        |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 1.82e+05    |\n",
            "|    n_updates            | 230         |\n",
            "|    policy_gradient_loss | -0.00251    |\n",
            "|    std                  | 0.356       |\n",
            "|    value_loss           | 1.21e+06    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -1.67e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 549         |\n",
            "|    iterations           | 25          |\n",
            "|    time_elapsed         | 465         |\n",
            "|    total_timesteps      | 256000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007863134 |\n",
            "|    clip_fraction        | 0.0625      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.388      |\n",
            "|    explained_variance   | 0.779       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 1.23e+05    |\n",
            "|    n_updates            | 240         |\n",
            "|    policy_gradient_loss | -0.00226    |\n",
            "|    std                  | 0.358       |\n",
            "|    value_loss           | 1.04e+06    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -1.67e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 550         |\n",
            "|    iterations           | 26          |\n",
            "|    time_elapsed         | 483         |\n",
            "|    total_timesteps      | 266240      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006619364 |\n",
            "|    clip_fraction        | 0.0585      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.364      |\n",
            "|    explained_variance   | 0.714       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 6.17e+04    |\n",
            "|    n_updates            | 250         |\n",
            "|    policy_gradient_loss | -0.00368    |\n",
            "|    std                  | 0.346       |\n",
            "|    value_loss           | 4.18e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -1.58e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 549         |\n",
            "|    iterations           | 27          |\n",
            "|    time_elapsed         | 502         |\n",
            "|    total_timesteps      | 276480      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007297606 |\n",
            "|    clip_fraction        | 0.0652      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.341      |\n",
            "|    explained_variance   | 0.636       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 2.55e+05    |\n",
            "|    n_updates            | 260         |\n",
            "|    policy_gradient_loss | -0.00278    |\n",
            "|    std                  | 0.338       |\n",
            "|    value_loss           | 1.24e+06    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -1.58e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 550         |\n",
            "|    iterations           | 28          |\n",
            "|    time_elapsed         | 521         |\n",
            "|    total_timesteps      | 286720      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008126152 |\n",
            "|    clip_fraction        | 0.0778      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.317      |\n",
            "|    explained_variance   | 0.82        |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 6.51e+04    |\n",
            "|    n_updates            | 270         |\n",
            "|    policy_gradient_loss | -0.000881   |\n",
            "|    std                  | 0.335       |\n",
            "|    value_loss           | 6.59e+05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.98e+03     |\n",
            "|    ep_rew_mean          | -1.58e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 550          |\n",
            "|    iterations           | 29           |\n",
            "|    time_elapsed         | 539          |\n",
            "|    total_timesteps      | 296960       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0063261697 |\n",
            "|    clip_fraction        | 0.0581       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.313       |\n",
            "|    explained_variance   | 0.694        |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 3.59e+04     |\n",
            "|    n_updates            | 280          |\n",
            "|    policy_gradient_loss | -0.00188     |\n",
            "|    std                  | 0.331        |\n",
            "|    value_loss           | 3.78e+05     |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 5.98e+03   |\n",
            "|    ep_rew_mean          | -1.51e+06  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 551        |\n",
            "|    iterations           | 30         |\n",
            "|    time_elapsed         | 557        |\n",
            "|    total_timesteps      | 307200     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00632313 |\n",
            "|    clip_fraction        | 0.0544     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.3       |\n",
            "|    explained_variance   | 0.667      |\n",
            "|    learning_rate        | 0.01       |\n",
            "|    loss                 | 9.55e+04   |\n",
            "|    n_updates            | 290        |\n",
            "|    policy_gradient_loss | -0.00237   |\n",
            "|    std                  | 0.327      |\n",
            "|    value_loss           | 1.07e+06   |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.98e+03     |\n",
            "|    ep_rew_mean          | -1.51e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 550          |\n",
            "|    iterations           | 31           |\n",
            "|    time_elapsed         | 576          |\n",
            "|    total_timesteps      | 317440       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0071503185 |\n",
            "|    clip_fraction        | 0.0722       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.294       |\n",
            "|    explained_variance   | 0.829        |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 2.95e+04     |\n",
            "|    n_updates            | 300          |\n",
            "|    policy_gradient_loss | -0.00175     |\n",
            "|    std                  | 0.327        |\n",
            "|    value_loss           | 5.06e+05     |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 5.98e+03   |\n",
            "|    ep_rew_mean          | -1.51e+06  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 550        |\n",
            "|    iterations           | 32         |\n",
            "|    time_elapsed         | 595        |\n",
            "|    total_timesteps      | 327680     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00651664 |\n",
            "|    clip_fraction        | 0.0609     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.284     |\n",
            "|    explained_variance   | 0.692      |\n",
            "|    learning_rate        | 0.01       |\n",
            "|    loss                 | 5.97e+04   |\n",
            "|    n_updates            | 310        |\n",
            "|    policy_gradient_loss | -0.00198   |\n",
            "|    std                  | 0.321      |\n",
            "|    value_loss           | 4.25e+05   |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -1.44e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 550         |\n",
            "|    iterations           | 33          |\n",
            "|    time_elapsed         | 613         |\n",
            "|    total_timesteps      | 337920      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008022139 |\n",
            "|    clip_fraction        | 0.0688      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.264      |\n",
            "|    explained_variance   | 0.691       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 8.9e+04     |\n",
            "|    n_updates            | 320         |\n",
            "|    policy_gradient_loss | -0.0034     |\n",
            "|    std                  | 0.311       |\n",
            "|    value_loss           | 9.47e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -1.44e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 551         |\n",
            "|    iterations           | 34          |\n",
            "|    time_elapsed         | 631         |\n",
            "|    total_timesteps      | 348160      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009872699 |\n",
            "|    clip_fraction        | 0.0787      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.236      |\n",
            "|    explained_variance   | 0.814       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 3.15e+04    |\n",
            "|    n_updates            | 330         |\n",
            "|    policy_gradient_loss | 0.000317    |\n",
            "|    std                  | 0.304       |\n",
            "|    value_loss           | 3.91e+05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.98e+03     |\n",
            "|    ep_rew_mean          | -1.44e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 551          |\n",
            "|    iterations           | 35           |\n",
            "|    time_elapsed         | 650          |\n",
            "|    total_timesteps      | 358400       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0070923693 |\n",
            "|    clip_fraction        | 0.0608       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.217       |\n",
            "|    explained_variance   | 0.775        |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 1.04e+05     |\n",
            "|    n_updates            | 340          |\n",
            "|    policy_gradient_loss | -0.00172     |\n",
            "|    std                  | 0.3          |\n",
            "|    value_loss           | 5.93e+05     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -1.39e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 551         |\n",
            "|    iterations           | 36          |\n",
            "|    time_elapsed         | 668         |\n",
            "|    total_timesteps      | 368640      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006892071 |\n",
            "|    clip_fraction        | 0.0668      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.208      |\n",
            "|    explained_variance   | 0.722       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 9.91e+04    |\n",
            "|    n_updates            | 350         |\n",
            "|    policy_gradient_loss | -0.00238    |\n",
            "|    std                  | 0.296       |\n",
            "|    value_loss           | 8.75e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -1.39e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 551         |\n",
            "|    iterations           | 37          |\n",
            "|    time_elapsed         | 687         |\n",
            "|    total_timesteps      | 378880      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008911626 |\n",
            "|    clip_fraction        | 0.0827      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.199      |\n",
            "|    explained_variance   | 0.788       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 2.68e+04    |\n",
            "|    n_updates            | 360         |\n",
            "|    policy_gradient_loss | 2.56e-05    |\n",
            "|    std                  | 0.296       |\n",
            "|    value_loss           | 2.4e+05     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -1.34e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 551         |\n",
            "|    iterations           | 38          |\n",
            "|    time_elapsed         | 705         |\n",
            "|    total_timesteps      | 389120      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009532766 |\n",
            "|    clip_fraction        | 0.0696      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.195      |\n",
            "|    explained_variance   | 0.767       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 6.46e+04    |\n",
            "|    n_updates            | 370         |\n",
            "|    policy_gradient_loss | -0.00185    |\n",
            "|    std                  | 0.292       |\n",
            "|    value_loss           | 5.19e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -1.34e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 551         |\n",
            "|    iterations           | 39          |\n",
            "|    time_elapsed         | 724         |\n",
            "|    total_timesteps      | 399360      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007971878 |\n",
            "|    clip_fraction        | 0.0732      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.173      |\n",
            "|    explained_variance   | 0.821       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 4.31e+04    |\n",
            "|    n_updates            | 380         |\n",
            "|    policy_gradient_loss | -0.00286    |\n",
            "|    std                  | 0.286       |\n",
            "|    value_loss           | 6.78e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -1.34e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 551         |\n",
            "|    iterations           | 40          |\n",
            "|    time_elapsed         | 743         |\n",
            "|    total_timesteps      | 409600      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008902257 |\n",
            "|    clip_fraction        | 0.0742      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.149      |\n",
            "|    explained_variance   | 0.767       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 3.64e+04    |\n",
            "|    n_updates            | 390         |\n",
            "|    policy_gradient_loss | 0.000298    |\n",
            "|    std                  | 0.28        |\n",
            "|    value_loss           | 3.31e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -1.3e+06    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 551         |\n",
            "|    iterations           | 41          |\n",
            "|    time_elapsed         | 761         |\n",
            "|    total_timesteps      | 419840      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007415969 |\n",
            "|    clip_fraction        | 0.0709      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.144      |\n",
            "|    explained_variance   | 0.781       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 4.53e+04    |\n",
            "|    n_updates            | 400         |\n",
            "|    policy_gradient_loss | -0.00236    |\n",
            "|    std                  | 0.281       |\n",
            "|    value_loss           | 5.27e+05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.98e+03     |\n",
            "|    ep_rew_mean          | -1.3e+06     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 551          |\n",
            "|    iterations           | 42           |\n",
            "|    time_elapsed         | 779          |\n",
            "|    total_timesteps      | 430080       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0090904515 |\n",
            "|    clip_fraction        | 0.0694       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.146       |\n",
            "|    explained_variance   | 0.846        |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 2.37e+04     |\n",
            "|    n_updates            | 410          |\n",
            "|    policy_gradient_loss | -0.0014      |\n",
            "|    std                  | 0.28         |\n",
            "|    value_loss           | 5.9e+05      |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -1.3e+06    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 551         |\n",
            "|    iterations           | 43          |\n",
            "|    time_elapsed         | 798         |\n",
            "|    total_timesteps      | 440320      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008937139 |\n",
            "|    clip_fraction        | 0.0803      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.134      |\n",
            "|    explained_variance   | 0.791       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 2.61e+04    |\n",
            "|    n_updates            | 420         |\n",
            "|    policy_gradient_loss | -0.000517   |\n",
            "|    std                  | 0.276       |\n",
            "|    value_loss           | 3.28e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -1.27e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 551         |\n",
            "|    iterations           | 44          |\n",
            "|    time_elapsed         | 817         |\n",
            "|    total_timesteps      | 450560      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007606197 |\n",
            "|    clip_fraction        | 0.0702      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.115      |\n",
            "|    explained_variance   | 0.77        |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 4.04e+04    |\n",
            "|    n_updates            | 430         |\n",
            "|    policy_gradient_loss | -0.00139    |\n",
            "|    std                  | 0.27        |\n",
            "|    value_loss           | 4.92e+05    |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 5.98e+03   |\n",
            "|    ep_rew_mean          | -1.27e+06  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 551        |\n",
            "|    iterations           | 45         |\n",
            "|    time_elapsed         | 835        |\n",
            "|    total_timesteps      | 460800     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00814206 |\n",
            "|    clip_fraction        | 0.0745     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.107     |\n",
            "|    explained_variance   | 0.875      |\n",
            "|    learning_rate        | 0.01       |\n",
            "|    loss                 | 5.53e+04   |\n",
            "|    n_updates            | 440        |\n",
            "|    policy_gradient_loss | -0.000941  |\n",
            "|    std                  | 0.269      |\n",
            "|    value_loss           | 5.35e+05   |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -1.27e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 551         |\n",
            "|    iterations           | 46          |\n",
            "|    time_elapsed         | 854         |\n",
            "|    total_timesteps      | 471040      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009624645 |\n",
            "|    clip_fraction        | 0.0831      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.0925     |\n",
            "|    explained_variance   | 0.793       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 2.9e+04     |\n",
            "|    n_updates            | 450         |\n",
            "|    policy_gradient_loss | -0.00064    |\n",
            "|    std                  | 0.262       |\n",
            "|    value_loss           | 3.11e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -1.24e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 550         |\n",
            "|    iterations           | 47          |\n",
            "|    time_elapsed         | 874         |\n",
            "|    total_timesteps      | 481280      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008986271 |\n",
            "|    clip_fraction        | 0.0866      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.068      |\n",
            "|    explained_variance   | 0.795       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 7.66e+04    |\n",
            "|    n_updates            | 460         |\n",
            "|    policy_gradient_loss | -0.00167    |\n",
            "|    std                  | 0.259       |\n",
            "|    value_loss           | 4.45e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -1.24e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 549         |\n",
            "|    iterations           | 48          |\n",
            "|    time_elapsed         | 894         |\n",
            "|    total_timesteps      | 491520      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011281453 |\n",
            "|    clip_fraction        | 0.0889      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.0536     |\n",
            "|    explained_variance   | 0.889       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 2.91e+04    |\n",
            "|    n_updates            | 470         |\n",
            "|    policy_gradient_loss | -0.000608   |\n",
            "|    std                  | 0.255       |\n",
            "|    value_loss           | 4.76e+05    |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 5.98e+03   |\n",
            "|    ep_rew_mean          | -1.24e+06  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 549        |\n",
            "|    iterations           | 49         |\n",
            "|    time_elapsed         | 912        |\n",
            "|    total_timesteps      | 501760     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00705872 |\n",
            "|    clip_fraction        | 0.0702     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.0583    |\n",
            "|    explained_variance   | 0.782      |\n",
            "|    learning_rate        | 0.01       |\n",
            "|    loss                 | 3e+04      |\n",
            "|    n_updates            | 480        |\n",
            "|    policy_gradient_loss | 0.000347   |\n",
            "|    std                  | 0.256      |\n",
            "|    value_loss           | 3.1e+05    |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -1.21e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 549         |\n",
            "|    iterations           | 50          |\n",
            "|    time_elapsed         | 932         |\n",
            "|    total_timesteps      | 512000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008628952 |\n",
            "|    clip_fraction        | 0.0754      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.0533     |\n",
            "|    explained_variance   | 0.779       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 3.63e+04    |\n",
            "|    n_updates            | 490         |\n",
            "|    policy_gradient_loss | -0.000922   |\n",
            "|    std                  | 0.253       |\n",
            "|    value_loss           | 4.29e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -1.21e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 548         |\n",
            "|    iterations           | 51          |\n",
            "|    time_elapsed         | 951         |\n",
            "|    total_timesteps      | 522240      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009150191 |\n",
            "|    clip_fraction        | 0.0857      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.0539     |\n",
            "|    explained_variance   | 0.897       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 5.3e+04     |\n",
            "|    n_updates            | 500         |\n",
            "|    policy_gradient_loss | -0.0016     |\n",
            "|    std                  | 0.254       |\n",
            "|    value_loss           | 4.24e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -1.21e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 548         |\n",
            "|    iterations           | 52          |\n",
            "|    time_elapsed         | 970         |\n",
            "|    total_timesteps      | 532480      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007675362 |\n",
            "|    clip_fraction        | 0.0878      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.0416     |\n",
            "|    explained_variance   | 0.789       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 3.6e+04     |\n",
            "|    n_updates            | 510         |\n",
            "|    policy_gradient_loss | -0.00161    |\n",
            "|    std                  | 0.254       |\n",
            "|    value_loss           | 2.8e+05     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -1.19e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 548         |\n",
            "|    iterations           | 53          |\n",
            "|    time_elapsed         | 989         |\n",
            "|    total_timesteps      | 542720      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009734218 |\n",
            "|    clip_fraction        | 0.0839      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.0294     |\n",
            "|    explained_variance   | 0.779       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 3.67e+04    |\n",
            "|    n_updates            | 520         |\n",
            "|    policy_gradient_loss | -0.00169    |\n",
            "|    std                  | 0.247       |\n",
            "|    value_loss           | 4.05e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -1.19e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 548         |\n",
            "|    iterations           | 54          |\n",
            "|    time_elapsed         | 1008        |\n",
            "|    total_timesteps      | 552960      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011658058 |\n",
            "|    clip_fraction        | 0.0895      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.0183     |\n",
            "|    explained_variance   | 0.906       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 3.19e+04    |\n",
            "|    n_updates            | 530         |\n",
            "|    policy_gradient_loss | 0.000164    |\n",
            "|    std                  | 0.245       |\n",
            "|    value_loss           | 3.99e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -1.19e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 546         |\n",
            "|    iterations           | 55          |\n",
            "|    time_elapsed         | 1029        |\n",
            "|    total_timesteps      | 563200      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011244585 |\n",
            "|    clip_fraction        | 0.0984      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.0158      |\n",
            "|    explained_variance   | 0.82        |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 2.54e+04    |\n",
            "|    n_updates            | 540         |\n",
            "|    policy_gradient_loss | -0.00117    |\n",
            "|    std                  | 0.236       |\n",
            "|    value_loss           | 3.02e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -1.16e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 547         |\n",
            "|    iterations           | 56          |\n",
            "|    time_elapsed         | 1048        |\n",
            "|    total_timesteps      | 573440      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009438524 |\n",
            "|    clip_fraction        | 0.0937      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.0266      |\n",
            "|    explained_variance   | 0.758       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 4.9e+04     |\n",
            "|    n_updates            | 550         |\n",
            "|    policy_gradient_loss | -0.000577   |\n",
            "|    std                  | 0.235       |\n",
            "|    value_loss           | 4.13e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -1.16e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 546         |\n",
            "|    iterations           | 57          |\n",
            "|    time_elapsed         | 1067        |\n",
            "|    total_timesteps      | 583680      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011583069 |\n",
            "|    clip_fraction        | 0.11        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.0357      |\n",
            "|    explained_variance   | 0.903       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 3.35e+04    |\n",
            "|    n_updates            | 560         |\n",
            "|    policy_gradient_loss | -0.000213   |\n",
            "|    std                  | 0.233       |\n",
            "|    value_loss           | 3.82e+05    |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 5.98e+03   |\n",
            "|    ep_rew_mean          | -1.16e+06  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 546        |\n",
            "|    iterations           | 58         |\n",
            "|    time_elapsed         | 1086       |\n",
            "|    total_timesteps      | 593920     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01137781 |\n",
            "|    clip_fraction        | 0.0979     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | 0.0572     |\n",
            "|    explained_variance   | 0.816      |\n",
            "|    learning_rate        | 0.01       |\n",
            "|    loss                 | 3.53e+04   |\n",
            "|    n_updates            | 570        |\n",
            "|    policy_gradient_loss | -0.000133  |\n",
            "|    std                  | 0.228      |\n",
            "|    value_loss           | 3.19e+05   |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -1.14e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 546         |\n",
            "|    iterations           | 59          |\n",
            "|    time_elapsed         | 1105        |\n",
            "|    total_timesteps      | 604160      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011421229 |\n",
            "|    clip_fraction        | 0.105       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.0697      |\n",
            "|    explained_variance   | 0.769       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 4.34e+04    |\n",
            "|    n_updates            | 580         |\n",
            "|    policy_gradient_loss | -0.00157    |\n",
            "|    std                  | 0.226       |\n",
            "|    value_loss           | 3.94e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -1.14e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 546         |\n",
            "|    iterations           | 60          |\n",
            "|    time_elapsed         | 1123        |\n",
            "|    total_timesteps      | 614400      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014530313 |\n",
            "|    clip_fraction        | 0.108       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.0642      |\n",
            "|    explained_variance   | 0.905       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 3.36e+04    |\n",
            "|    n_updates            | 590         |\n",
            "|    policy_gradient_loss | 0.000386    |\n",
            "|    std                  | 0.229       |\n",
            "|    value_loss           | 3.46e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -1.14e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 546         |\n",
            "|    iterations           | 61          |\n",
            "|    time_elapsed         | 1143        |\n",
            "|    total_timesteps      | 624640      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009082039 |\n",
            "|    clip_fraction        | 0.0866      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.0609      |\n",
            "|    explained_variance   | 0.771       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 3.27e+04    |\n",
            "|    n_updates            | 600         |\n",
            "|    policy_gradient_loss | 6.6e-05     |\n",
            "|    std                  | 0.227       |\n",
            "|    value_loss           | 3.28e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -1.02e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 546         |\n",
            "|    iterations           | 62          |\n",
            "|    time_elapsed         | 1162        |\n",
            "|    total_timesteps      | 634880      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010912743 |\n",
            "|    clip_fraction        | 0.0921      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.0747      |\n",
            "|    explained_variance   | 0.788       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 3.9e+04     |\n",
            "|    n_updates            | 610         |\n",
            "|    policy_gradient_loss | -0.00163    |\n",
            "|    std                  | 0.225       |\n",
            "|    value_loss           | 4.69e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -1.02e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 546         |\n",
            "|    iterations           | 63          |\n",
            "|    time_elapsed         | 1181        |\n",
            "|    total_timesteps      | 645120      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016680824 |\n",
            "|    clip_fraction        | 0.12        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.0895      |\n",
            "|    explained_variance   | 0.909       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 3.32e+04    |\n",
            "|    n_updates            | 620         |\n",
            "|    policy_gradient_loss | 0.00103     |\n",
            "|    std                  | 0.221       |\n",
            "|    value_loss           | 3.12e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -1.02e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 546         |\n",
            "|    iterations           | 64          |\n",
            "|    time_elapsed         | 1199        |\n",
            "|    total_timesteps      | 655360      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008013441 |\n",
            "|    clip_fraction        | 0.101       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.096       |\n",
            "|    explained_variance   | 0.76        |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 2.75e+04    |\n",
            "|    n_updates            | 630         |\n",
            "|    policy_gradient_loss | 0.00172     |\n",
            "|    std                  | 0.218       |\n",
            "|    value_loss           | 2.9e+05     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -9.39e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 545         |\n",
            "|    iterations           | 65          |\n",
            "|    time_elapsed         | 1219        |\n",
            "|    total_timesteps      | 665600      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010413013 |\n",
            "|    clip_fraction        | 0.0957      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.114       |\n",
            "|    explained_variance   | 0.771       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 4.35e+04    |\n",
            "|    n_updates            | 640         |\n",
            "|    policy_gradient_loss | -0.000532   |\n",
            "|    std                  | 0.214       |\n",
            "|    value_loss           | 4.64e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -9.39e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 545         |\n",
            "|    iterations           | 66          |\n",
            "|    time_elapsed         | 1238        |\n",
            "|    total_timesteps      | 675840      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018912535 |\n",
            "|    clip_fraction        | 0.125       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.136       |\n",
            "|    explained_variance   | 0.894       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 2.27e+04    |\n",
            "|    n_updates            | 650         |\n",
            "|    policy_gradient_loss | 0.00162     |\n",
            "|    std                  | 0.21        |\n",
            "|    value_loss           | 2.85e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -9.39e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 545         |\n",
            "|    iterations           | 67          |\n",
            "|    time_elapsed         | 1257        |\n",
            "|    total_timesteps      | 686080      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011807096 |\n",
            "|    clip_fraction        | 0.108       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.155       |\n",
            "|    explained_variance   | 0.753       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 2.29e+04    |\n",
            "|    n_updates            | 660         |\n",
            "|    policy_gradient_loss | 0.000529    |\n",
            "|    std                  | 0.207       |\n",
            "|    value_loss           | 2.82e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -8.91e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 545         |\n",
            "|    iterations           | 68          |\n",
            "|    time_elapsed         | 1277        |\n",
            "|    total_timesteps      | 696320      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010894911 |\n",
            "|    clip_fraction        | 0.102       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.173       |\n",
            "|    explained_variance   | 0.789       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 3.05e+04    |\n",
            "|    n_updates            | 670         |\n",
            "|    policy_gradient_loss | -0.000201   |\n",
            "|    std                  | 0.204       |\n",
            "|    value_loss           | 4.34e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -8.91e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 544         |\n",
            "|    iterations           | 69          |\n",
            "|    time_elapsed         | 1297        |\n",
            "|    total_timesteps      | 706560      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012307608 |\n",
            "|    clip_fraction        | 0.133       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.177       |\n",
            "|    explained_variance   | 0.883       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 1.91e+04    |\n",
            "|    n_updates            | 680         |\n",
            "|    policy_gradient_loss | 0.00298     |\n",
            "|    std                  | 0.204       |\n",
            "|    value_loss           | 2.58e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -8.91e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 544         |\n",
            "|    iterations           | 70          |\n",
            "|    time_elapsed         | 1316        |\n",
            "|    total_timesteps      | 716800      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011679815 |\n",
            "|    clip_fraction        | 0.12        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.181       |\n",
            "|    explained_variance   | 0.845       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 2.69e+04    |\n",
            "|    n_updates            | 690         |\n",
            "|    policy_gradient_loss | 0.00041     |\n",
            "|    std                  | 0.202       |\n",
            "|    value_loss           | 3.33e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -8.47e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 544         |\n",
            "|    iterations           | 71          |\n",
            "|    time_elapsed         | 1334        |\n",
            "|    total_timesteps      | 727040      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011135355 |\n",
            "|    clip_fraction        | 0.105       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.196       |\n",
            "|    explained_variance   | 0.826       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 6.05e+04    |\n",
            "|    n_updates            | 700         |\n",
            "|    policy_gradient_loss | 0.00099     |\n",
            "|    std                  | 0.197       |\n",
            "|    value_loss           | 4.69e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -8.47e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 544         |\n",
            "|    iterations           | 72          |\n",
            "|    time_elapsed         | 1354        |\n",
            "|    total_timesteps      | 737280      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013384307 |\n",
            "|    clip_fraction        | 0.121       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.2         |\n",
            "|    explained_variance   | 0.834       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 4.09e+04    |\n",
            "|    n_updates            | 710         |\n",
            "|    policy_gradient_loss | 0.00258     |\n",
            "|    std                  | 0.198       |\n",
            "|    value_loss           | 2.42e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -8.1e+05    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 544         |\n",
            "|    iterations           | 73          |\n",
            "|    time_elapsed         | 1373        |\n",
            "|    total_timesteps      | 747520      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012219851 |\n",
            "|    clip_fraction        | 0.125       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.209       |\n",
            "|    explained_variance   | 0.823       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 5.38e+04    |\n",
            "|    n_updates            | 720         |\n",
            "|    policy_gradient_loss | 0.00121     |\n",
            "|    std                  | 0.194       |\n",
            "|    value_loss           | 3.46e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -8.1e+05    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 544         |\n",
            "|    iterations           | 74          |\n",
            "|    time_elapsed         | 1392        |\n",
            "|    total_timesteps      | 757760      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011098659 |\n",
            "|    clip_fraction        | 0.111       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.22        |\n",
            "|    explained_variance   | 0.882       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 3.3e+04     |\n",
            "|    n_updates            | 730         |\n",
            "|    policy_gradient_loss | 0.00106     |\n",
            "|    std                  | 0.195       |\n",
            "|    value_loss           | 4.19e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -8.1e+05    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 544         |\n",
            "|    iterations           | 75          |\n",
            "|    time_elapsed         | 1411        |\n",
            "|    total_timesteps      | 768000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015163985 |\n",
            "|    clip_fraction        | 0.13        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.228       |\n",
            "|    explained_variance   | 0.844       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 3.1e+04     |\n",
            "|    n_updates            | 740         |\n",
            "|    policy_gradient_loss | 0.00326     |\n",
            "|    std                  | 0.194       |\n",
            "|    value_loss           | 2.55e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -7.9e+05    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 543         |\n",
            "|    iterations           | 76          |\n",
            "|    time_elapsed         | 1431        |\n",
            "|    total_timesteps      | 778240      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010782881 |\n",
            "|    clip_fraction        | 0.111       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.221       |\n",
            "|    explained_variance   | 0.845       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 4.94e+04    |\n",
            "|    n_updates            | 750         |\n",
            "|    policy_gradient_loss | 0.00149     |\n",
            "|    std                  | 0.195       |\n",
            "|    value_loss           | 3.31e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -7.9e+05    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 543         |\n",
            "|    iterations           | 77          |\n",
            "|    time_elapsed         | 1450        |\n",
            "|    total_timesteps      | 788480      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015262445 |\n",
            "|    clip_fraction        | 0.121       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.227       |\n",
            "|    explained_variance   | 0.904       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 2.93e+04    |\n",
            "|    n_updates            | 760         |\n",
            "|    policy_gradient_loss | 0.00091     |\n",
            "|    std                  | 0.192       |\n",
            "|    value_loss           | 3.68e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -7.9e+05    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 543         |\n",
            "|    iterations           | 78          |\n",
            "|    time_elapsed         | 1468        |\n",
            "|    total_timesteps      | 798720      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011526581 |\n",
            "|    clip_fraction        | 0.117       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.223       |\n",
            "|    explained_variance   | 0.852       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 2.36e+04    |\n",
            "|    n_updates            | 770         |\n",
            "|    policy_gradient_loss | 0.000362    |\n",
            "|    std                  | 0.193       |\n",
            "|    value_loss           | 2.61e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -7.78e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 543         |\n",
            "|    iterations           | 79          |\n",
            "|    time_elapsed         | 1487        |\n",
            "|    total_timesteps      | 808960      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012572018 |\n",
            "|    clip_fraction        | 0.124       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.24        |\n",
            "|    explained_variance   | 0.845       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 4.08e+04    |\n",
            "|    n_updates            | 780         |\n",
            "|    policy_gradient_loss | 0.00112     |\n",
            "|    std                  | 0.189       |\n",
            "|    value_loss           | 3.5e+05     |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.98e+03     |\n",
            "|    ep_rew_mean          | -7.78e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 543          |\n",
            "|    iterations           | 80           |\n",
            "|    time_elapsed         | 1507         |\n",
            "|    total_timesteps      | 819200       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0152478535 |\n",
            "|    clip_fraction        | 0.119        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.24         |\n",
            "|    explained_variance   | 0.917        |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 4.21e+04     |\n",
            "|    n_updates            | 790          |\n",
            "|    policy_gradient_loss | 0.00266      |\n",
            "|    std                  | 0.19         |\n",
            "|    value_loss           | 3.5e+05      |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 5.98e+03   |\n",
            "|    ep_rew_mean          | -7.78e+05  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 543        |\n",
            "|    iterations           | 81         |\n",
            "|    time_elapsed         | 1526       |\n",
            "|    total_timesteps      | 829440     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01609226 |\n",
            "|    clip_fraction        | 0.138      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | 0.251      |\n",
            "|    explained_variance   | 0.86       |\n",
            "|    learning_rate        | 0.01       |\n",
            "|    loss                 | 2.17e+04   |\n",
            "|    n_updates            | 800        |\n",
            "|    policy_gradient_loss | 0.0033     |\n",
            "|    std                  | 0.187      |\n",
            "|    value_loss           | 2.51e+05   |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -7.72e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 543         |\n",
            "|    iterations           | 82          |\n",
            "|    time_elapsed         | 1544        |\n",
            "|    total_timesteps      | 839680      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011829429 |\n",
            "|    clip_fraction        | 0.124       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.269       |\n",
            "|    explained_variance   | 0.842       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 4.27e+04    |\n",
            "|    n_updates            | 810         |\n",
            "|    policy_gradient_loss | 0.000148    |\n",
            "|    std                  | 0.184       |\n",
            "|    value_loss           | 3.27e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -7.72e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 543         |\n",
            "|    iterations           | 83          |\n",
            "|    time_elapsed         | 1563        |\n",
            "|    total_timesteps      | 849920      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016457802 |\n",
            "|    clip_fraction        | 0.132       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.273       |\n",
            "|    explained_variance   | 0.926       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 2.92e+04    |\n",
            "|    n_updates            | 820         |\n",
            "|    policy_gradient_loss | 0.0034      |\n",
            "|    std                  | 0.184       |\n",
            "|    value_loss           | 3.2e+05     |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.98e+03     |\n",
            "|    ep_rew_mean          | -7.72e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 543          |\n",
            "|    iterations           | 84           |\n",
            "|    time_elapsed         | 1583         |\n",
            "|    total_timesteps      | 860160       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0155643225 |\n",
            "|    clip_fraction        | 0.136        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.27         |\n",
            "|    explained_variance   | 0.857        |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 2.53e+04     |\n",
            "|    n_updates            | 830          |\n",
            "|    policy_gradient_loss | 0.00353      |\n",
            "|    std                  | 0.184        |\n",
            "|    value_loss           | 2.42e+05     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -7.66e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 543         |\n",
            "|    iterations           | 85          |\n",
            "|    time_elapsed         | 1601        |\n",
            "|    total_timesteps      | 870400      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012393415 |\n",
            "|    clip_fraction        | 0.114       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.263       |\n",
            "|    explained_variance   | 0.833       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 3.51e+04    |\n",
            "|    n_updates            | 840         |\n",
            "|    policy_gradient_loss | 0.000966    |\n",
            "|    std                  | 0.187       |\n",
            "|    value_loss           | 3.18e+05    |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 5.98e+03   |\n",
            "|    ep_rew_mean          | -7.66e+05  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 543        |\n",
            "|    iterations           | 86         |\n",
            "|    time_elapsed         | 1619       |\n",
            "|    total_timesteps      | 880640     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01532914 |\n",
            "|    clip_fraction        | 0.14       |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | 0.26       |\n",
            "|    explained_variance   | 0.924      |\n",
            "|    learning_rate        | 0.01       |\n",
            "|    loss                 | 3.7e+04    |\n",
            "|    n_updates            | 850        |\n",
            "|    policy_gradient_loss | 0.00152    |\n",
            "|    std                  | 0.187      |\n",
            "|    value_loss           | 3.01e+05   |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -7.66e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 543         |\n",
            "|    iterations           | 87          |\n",
            "|    time_elapsed         | 1639        |\n",
            "|    total_timesteps      | 890880      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014624843 |\n",
            "|    clip_fraction        | 0.134       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.259       |\n",
            "|    explained_variance   | 0.855       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 3.27e+04    |\n",
            "|    n_updates            | 860         |\n",
            "|    policy_gradient_loss | 0.00204     |\n",
            "|    std                  | 0.186       |\n",
            "|    value_loss           | 2.34e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -7.61e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 543         |\n",
            "|    iterations           | 88          |\n",
            "|    time_elapsed         | 1658        |\n",
            "|    total_timesteps      | 901120      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017478872 |\n",
            "|    clip_fraction        | 0.125       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.255       |\n",
            "|    explained_variance   | 0.819       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 2.25e+04    |\n",
            "|    n_updates            | 870         |\n",
            "|    policy_gradient_loss | 0.00232     |\n",
            "|    std                  | 0.187       |\n",
            "|    value_loss           | 3.22e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -7.61e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 543         |\n",
            "|    iterations           | 89          |\n",
            "|    time_elapsed         | 1677        |\n",
            "|    total_timesteps      | 911360      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017362464 |\n",
            "|    clip_fraction        | 0.144       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.249       |\n",
            "|    explained_variance   | 0.922       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 2.82e+04    |\n",
            "|    n_updates            | 880         |\n",
            "|    policy_gradient_loss | 0.0024      |\n",
            "|    std                  | 0.189       |\n",
            "|    value_loss           | 2.77e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -7.61e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 543         |\n",
            "|    iterations           | 90          |\n",
            "|    time_elapsed         | 1695        |\n",
            "|    total_timesteps      | 921600      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014361644 |\n",
            "|    clip_fraction        | 0.124       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.267       |\n",
            "|    explained_variance   | 0.864       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 2.45e+04    |\n",
            "|    n_updates            | 890         |\n",
            "|    policy_gradient_loss | 0.00224     |\n",
            "|    std                  | 0.184       |\n",
            "|    value_loss           | 2.38e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -7.57e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 543         |\n",
            "|    iterations           | 91          |\n",
            "|    time_elapsed         | 1714        |\n",
            "|    total_timesteps      | 931840      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013230473 |\n",
            "|    clip_fraction        | 0.126       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.275       |\n",
            "|    explained_variance   | 0.826       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 4.55e+04    |\n",
            "|    n_updates            | 900         |\n",
            "|    policy_gradient_loss | 0.000445    |\n",
            "|    std                  | 0.184       |\n",
            "|    value_loss           | 3.29e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -7.57e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 543         |\n",
            "|    iterations           | 92          |\n",
            "|    time_elapsed         | 1733        |\n",
            "|    total_timesteps      | 942080      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016198631 |\n",
            "|    clip_fraction        | 0.139       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.268       |\n",
            "|    explained_variance   | 0.928       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 4.51e+04    |\n",
            "|    n_updates            | 910         |\n",
            "|    policy_gradient_loss | 0.00221     |\n",
            "|    std                  | 0.185       |\n",
            "|    value_loss           | 2.8e+05     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -7.57e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 543         |\n",
            "|    iterations           | 93          |\n",
            "|    time_elapsed         | 1751        |\n",
            "|    total_timesteps      | 952320      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011988794 |\n",
            "|    clip_fraction        | 0.116       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.276       |\n",
            "|    explained_variance   | 0.847       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 4.18e+04    |\n",
            "|    n_updates            | 920         |\n",
            "|    policy_gradient_loss | 0.00114     |\n",
            "|    std                  | 0.182       |\n",
            "|    value_loss           | 2.67e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -7.54e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 543         |\n",
            "|    iterations           | 94          |\n",
            "|    time_elapsed         | 1770        |\n",
            "|    total_timesteps      | 962560      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013303751 |\n",
            "|    clip_fraction        | 0.131       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.296       |\n",
            "|    explained_variance   | 0.828       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 3.6e+04     |\n",
            "|    n_updates            | 930         |\n",
            "|    policy_gradient_loss | 0.00157     |\n",
            "|    std                  | 0.179       |\n",
            "|    value_loss           | 3.66e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -7.54e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 543         |\n",
            "|    iterations           | 95          |\n",
            "|    time_elapsed         | 1789        |\n",
            "|    total_timesteps      | 972800      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016411405 |\n",
            "|    clip_fraction        | 0.145       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.299       |\n",
            "|    explained_variance   | 0.93        |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 4.46e+04    |\n",
            "|    n_updates            | 940         |\n",
            "|    policy_gradient_loss | 0.00386     |\n",
            "|    std                  | 0.18        |\n",
            "|    value_loss           | 2.81e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -7.54e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 543         |\n",
            "|    iterations           | 96          |\n",
            "|    time_elapsed         | 1808        |\n",
            "|    total_timesteps      | 983040      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014452659 |\n",
            "|    clip_fraction        | 0.121       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.303       |\n",
            "|    explained_variance   | 0.803       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 1.72e+04    |\n",
            "|    n_updates            | 950         |\n",
            "|    policy_gradient_loss | 0.00293     |\n",
            "|    std                  | 0.18        |\n",
            "|    value_loss           | 2.73e+05    |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 5.98e+03   |\n",
            "|    ep_rew_mean          | -7.51e+05  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 543        |\n",
            "|    iterations           | 97         |\n",
            "|    time_elapsed         | 1826       |\n",
            "|    total_timesteps      | 993280     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01554136 |\n",
            "|    clip_fraction        | 0.131      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | 0.289      |\n",
            "|    explained_variance   | 0.827      |\n",
            "|    learning_rate        | 0.01       |\n",
            "|    loss                 | 3.52e+04   |\n",
            "|    n_updates            | 960        |\n",
            "|    policy_gradient_loss | 0.00106    |\n",
            "|    std                  | 0.183      |\n",
            "|    value_loss           | 3.45e+05   |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -7.51e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 544         |\n",
            "|    iterations           | 98          |\n",
            "|    time_elapsed         | 1844        |\n",
            "|    total_timesteps      | 1003520     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018412096 |\n",
            "|    clip_fraction        | 0.138       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.28        |\n",
            "|    explained_variance   | 0.935       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 3.16e+04    |\n",
            "|    n_updates            | 970         |\n",
            "|    policy_gradient_loss | 0.00231     |\n",
            "|    std                  | 0.184       |\n",
            "|    value_loss           | 2.44e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -7.51e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 543         |\n",
            "|    iterations           | 99          |\n",
            "|    time_elapsed         | 1864        |\n",
            "|    total_timesteps      | 1013760     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013279999 |\n",
            "|    clip_fraction        | 0.124       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.285       |\n",
            "|    explained_variance   | 0.779       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 4.63e+04    |\n",
            "|    n_updates            | 980         |\n",
            "|    policy_gradient_loss | 0.00215     |\n",
            "|    std                  | 0.181       |\n",
            "|    value_loss           | 2.57e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -7.49e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 543         |\n",
            "|    iterations           | 100         |\n",
            "|    time_elapsed         | 1883        |\n",
            "|    total_timesteps      | 1024000     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013351676 |\n",
            "|    clip_fraction        | 0.126       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.29        |\n",
            "|    explained_variance   | 0.833       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 6.02e+04    |\n",
            "|    n_updates            | 990         |\n",
            "|    policy_gradient_loss | 0.000468    |\n",
            "|    std                  | 0.182       |\n",
            "|    value_loss           | 3.54e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -7.49e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 543         |\n",
            "|    iterations           | 101         |\n",
            "|    time_elapsed         | 1902        |\n",
            "|    total_timesteps      | 1034240     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018648231 |\n",
            "|    clip_fraction        | 0.159       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.289       |\n",
            "|    explained_variance   | 0.925       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 2.53e+04    |\n",
            "|    n_updates            | 1000        |\n",
            "|    policy_gradient_loss | 0.00503     |\n",
            "|    std                  | 0.182       |\n",
            "|    value_loss           | 2.28e+05    |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 5.98e+03   |\n",
            "|    ep_rew_mean          | -7.49e+05  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 543        |\n",
            "|    iterations           | 102        |\n",
            "|    time_elapsed         | 1922       |\n",
            "|    total_timesteps      | 1044480    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01482957 |\n",
            "|    clip_fraction        | 0.133      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | 0.292      |\n",
            "|    explained_variance   | 0.803      |\n",
            "|    learning_rate        | 0.01       |\n",
            "|    loss                 | 3.66e+04   |\n",
            "|    n_updates            | 1010       |\n",
            "|    policy_gradient_loss | 0.00346    |\n",
            "|    std                  | 0.181      |\n",
            "|    value_loss           | 2.52e+05   |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 5.98e+03   |\n",
            "|    ep_rew_mean          | -7.47e+05  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 543        |\n",
            "|    iterations           | 103        |\n",
            "|    time_elapsed         | 1942       |\n",
            "|    total_timesteps      | 1054720    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01707395 |\n",
            "|    clip_fraction        | 0.134      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | 0.308      |\n",
            "|    explained_variance   | 0.841      |\n",
            "|    learning_rate        | 0.01       |\n",
            "|    loss                 | 3.4e+04    |\n",
            "|    n_updates            | 1020       |\n",
            "|    policy_gradient_loss | 0.000703   |\n",
            "|    std                  | 0.176      |\n",
            "|    value_loss           | 3.56e+05   |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 5.98e+03   |\n",
            "|    ep_rew_mean          | -7.47e+05  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 543        |\n",
            "|    iterations           | 104        |\n",
            "|    time_elapsed         | 1960       |\n",
            "|    total_timesteps      | 1064960    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01752555 |\n",
            "|    clip_fraction        | 0.155      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | 0.323      |\n",
            "|    explained_variance   | 0.915      |\n",
            "|    learning_rate        | 0.01       |\n",
            "|    loss                 | 1.96e+04   |\n",
            "|    n_updates            | 1030       |\n",
            "|    policy_gradient_loss | 0.00384    |\n",
            "|    std                  | 0.173      |\n",
            "|    value_loss           | 2.12e+05   |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -7.47e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 543         |\n",
            "|    iterations           | 105         |\n",
            "|    time_elapsed         | 1978        |\n",
            "|    total_timesteps      | 1075200     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018265506 |\n",
            "|    clip_fraction        | 0.145       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.346       |\n",
            "|    explained_variance   | 0.873       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 5.34e+04    |\n",
            "|    n_updates            | 1040        |\n",
            "|    policy_gradient_loss | 0.00248     |\n",
            "|    std                  | 0.172       |\n",
            "|    value_loss           | 3.08e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -7.46e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 543         |\n",
            "|    iterations           | 106         |\n",
            "|    time_elapsed         | 1998        |\n",
            "|    total_timesteps      | 1085440     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014002192 |\n",
            "|    clip_fraction        | 0.125       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.353       |\n",
            "|    explained_variance   | 0.863       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 4.12e+04    |\n",
            "|    n_updates            | 1050        |\n",
            "|    policy_gradient_loss | 0.00123     |\n",
            "|    std                  | 0.17        |\n",
            "|    value_loss           | 4.18e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -7.46e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 543         |\n",
            "|    iterations           | 107         |\n",
            "|    time_elapsed         | 2016        |\n",
            "|    total_timesteps      | 1095680     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018033108 |\n",
            "|    clip_fraction        | 0.163       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.367       |\n",
            "|    explained_variance   | 0.869       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 1.63e+04    |\n",
            "|    n_updates            | 1060        |\n",
            "|    policy_gradient_loss | 0.003       |\n",
            "|    std                  | 0.168       |\n",
            "|    value_loss           | 1.96e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -7.44e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 543         |\n",
            "|    iterations           | 108         |\n",
            "|    time_elapsed         | 2035        |\n",
            "|    total_timesteps      | 1105920     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015070838 |\n",
            "|    clip_fraction        | 0.141       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.373       |\n",
            "|    explained_variance   | 0.87        |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 2.68e+04    |\n",
            "|    n_updates            | 1070        |\n",
            "|    policy_gradient_loss | 0.00251     |\n",
            "|    std                  | 0.167       |\n",
            "|    value_loss           | 3.08e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -7.44e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 543         |\n",
            "|    iterations           | 109         |\n",
            "|    time_elapsed         | 2053        |\n",
            "|    total_timesteps      | 1116160     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016762445 |\n",
            "|    clip_fraction        | 0.139       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.387       |\n",
            "|    explained_variance   | 0.889       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 5.89e+04    |\n",
            "|    n_updates            | 1080        |\n",
            "|    policy_gradient_loss | 0.00231     |\n",
            "|    std                  | 0.165       |\n",
            "|    value_loss           | 3.97e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -7.44e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 543         |\n",
            "|    iterations           | 110         |\n",
            "|    time_elapsed         | 2073        |\n",
            "|    total_timesteps      | 1126400     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019154906 |\n",
            "|    clip_fraction        | 0.16        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.382       |\n",
            "|    explained_variance   | 0.867       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 3.7e+04     |\n",
            "|    n_updates            | 1090        |\n",
            "|    policy_gradient_loss | 0.00552     |\n",
            "|    std                  | 0.165       |\n",
            "|    value_loss           | 2.19e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -7.43e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 543         |\n",
            "|    iterations           | 111         |\n",
            "|    time_elapsed         | 2091        |\n",
            "|    total_timesteps      | 1136640     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017004574 |\n",
            "|    clip_fraction        | 0.143       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.399       |\n",
            "|    explained_variance   | 0.868       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 3.39e+04    |\n",
            "|    n_updates            | 1100        |\n",
            "|    policy_gradient_loss | 0.0038      |\n",
            "|    std                  | 0.162       |\n",
            "|    value_loss           | 3.16e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -7.43e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 543         |\n",
            "|    iterations           | 112         |\n",
            "|    time_elapsed         | 2110        |\n",
            "|    total_timesteps      | 1146880     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019253045 |\n",
            "|    clip_fraction        | 0.165       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.423       |\n",
            "|    explained_variance   | 0.922       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 1.95e+04    |\n",
            "|    n_updates            | 1110        |\n",
            "|    policy_gradient_loss | 0.00431     |\n",
            "|    std                  | 0.158       |\n",
            "|    value_loss           | 3.25e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -7.43e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 543         |\n",
            "|    iterations           | 113         |\n",
            "|    time_elapsed         | 2128        |\n",
            "|    total_timesteps      | 1157120     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.020556571 |\n",
            "|    clip_fraction        | 0.163       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.436       |\n",
            "|    explained_variance   | 0.87        |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 2.8e+04     |\n",
            "|    n_updates            | 1120        |\n",
            "|    policy_gradient_loss | 0.00529     |\n",
            "|    std                  | 0.156       |\n",
            "|    value_loss           | 2.31e+05    |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 5.98e+03   |\n",
            "|    ep_rew_mean          | -7.41e+05  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 543        |\n",
            "|    iterations           | 114        |\n",
            "|    time_elapsed         | 2148       |\n",
            "|    total_timesteps      | 1167360    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01806686 |\n",
            "|    clip_fraction        | 0.15       |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | 0.432      |\n",
            "|    explained_variance   | 0.877      |\n",
            "|    learning_rate        | 0.01       |\n",
            "|    loss                 | 3.31e+04   |\n",
            "|    n_updates            | 1130       |\n",
            "|    policy_gradient_loss | 0.00432    |\n",
            "|    std                  | 0.157      |\n",
            "|    value_loss           | 3.24e+05   |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -7.41e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 542         |\n",
            "|    iterations           | 115         |\n",
            "|    time_elapsed         | 2168        |\n",
            "|    total_timesteps      | 1177600     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019318726 |\n",
            "|    clip_fraction        | 0.151       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.43        |\n",
            "|    explained_variance   | 0.928       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 5.36e+04    |\n",
            "|    n_updates            | 1140        |\n",
            "|    policy_gradient_loss | 0.00428     |\n",
            "|    std                  | 0.158       |\n",
            "|    value_loss           | 3.32e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -7.41e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 543         |\n",
            "|    iterations           | 116         |\n",
            "|    time_elapsed         | 2187        |\n",
            "|    total_timesteps      | 1187840     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018104544 |\n",
            "|    clip_fraction        | 0.159       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.43        |\n",
            "|    explained_variance   | 0.882       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 2.62e+04    |\n",
            "|    n_updates            | 1150        |\n",
            "|    policy_gradient_loss | 0.00327     |\n",
            "|    std                  | 0.157       |\n",
            "|    value_loss           | 2.29e+05    |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 5.98e+03   |\n",
            "|    ep_rew_mean          | -7.4e+05   |\n",
            "| time/                   |            |\n",
            "|    fps                  | 543        |\n",
            "|    iterations           | 117        |\n",
            "|    time_elapsed         | 2205       |\n",
            "|    total_timesteps      | 1198080    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.04106474 |\n",
            "|    clip_fraction        | 0.165      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | 0.436      |\n",
            "|    explained_variance   | 0.86       |\n",
            "|    learning_rate        | 0.01       |\n",
            "|    loss                 | 2.7e+04    |\n",
            "|    n_updates            | 1160       |\n",
            "|    policy_gradient_loss | 0.0063     |\n",
            "|    std                  | 0.157      |\n",
            "|    value_loss           | 3.1e+05    |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -7.4e+05    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 543         |\n",
            "|    iterations           | 118         |\n",
            "|    time_elapsed         | 2225        |\n",
            "|    total_timesteps      | 1208320     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.023817262 |\n",
            "|    clip_fraction        | 0.172       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.433       |\n",
            "|    explained_variance   | 0.929       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 3.22e+04    |\n",
            "|    n_updates            | 1170        |\n",
            "|    policy_gradient_loss | 0.00614     |\n",
            "|    std                  | 0.157       |\n",
            "|    value_loss           | 3.03e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -7.4e+05    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 543         |\n",
            "|    iterations           | 119         |\n",
            "|    time_elapsed         | 2243        |\n",
            "|    total_timesteps      | 1218560     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018216118 |\n",
            "|    clip_fraction        | 0.158       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.428       |\n",
            "|    explained_variance   | 0.882       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 2.37e+04    |\n",
            "|    n_updates            | 1180        |\n",
            "|    policy_gradient_loss | 0.00467     |\n",
            "|    std                  | 0.156       |\n",
            "|    value_loss           | 2.2e+05     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -7.4e+05    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 543         |\n",
            "|    iterations           | 120         |\n",
            "|    time_elapsed         | 2262        |\n",
            "|    total_timesteps      | 1228800     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.020736393 |\n",
            "|    clip_fraction        | 0.15        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.46        |\n",
            "|    explained_variance   | 0.854       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 3.38e+04    |\n",
            "|    n_updates            | 1190        |\n",
            "|    policy_gradient_loss | 0.00197     |\n",
            "|    std                  | 0.152       |\n",
            "|    value_loss           | 3.34e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -7.4e+05    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 543         |\n",
            "|    iterations           | 121         |\n",
            "|    time_elapsed         | 2281        |\n",
            "|    total_timesteps      | 1239040     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019796804 |\n",
            "|    clip_fraction        | 0.172       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.457       |\n",
            "|    explained_variance   | 0.938       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 3.79e+04    |\n",
            "|    n_updates            | 1200        |\n",
            "|    policy_gradient_loss | 0.00397     |\n",
            "|    std                  | 0.154       |\n",
            "|    value_loss           | 3.19e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -7.4e+05    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 542         |\n",
            "|    iterations           | 122         |\n",
            "|    time_elapsed         | 2300        |\n",
            "|    total_timesteps      | 1249280     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014850162 |\n",
            "|    clip_fraction        | 0.156       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.463       |\n",
            "|    explained_variance   | 0.855       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 1.76e+04    |\n",
            "|    n_updates            | 1210        |\n",
            "|    policy_gradient_loss | 0.00427     |\n",
            "|    std                  | 0.151       |\n",
            "|    value_loss           | 2.24e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -7.4e+05    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 543         |\n",
            "|    iterations           | 123         |\n",
            "|    time_elapsed         | 2319        |\n",
            "|    total_timesteps      | 1259520     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017879045 |\n",
            "|    clip_fraction        | 0.145       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.481       |\n",
            "|    explained_variance   | 0.843       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 5.11e+04    |\n",
            "|    n_updates            | 1220        |\n",
            "|    policy_gradient_loss | 0.00314     |\n",
            "|    std                  | 0.151       |\n",
            "|    value_loss           | 3.12e+05    |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 5.98e+03   |\n",
            "|    ep_rew_mean          | -7.4e+05   |\n",
            "| time/                   |            |\n",
            "|    fps                  | 543        |\n",
            "|    iterations           | 124        |\n",
            "|    time_elapsed         | 2337       |\n",
            "|    total_timesteps      | 1269760    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.02978902 |\n",
            "|    clip_fraction        | 0.189      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | 0.473      |\n",
            "|    explained_variance   | 0.939      |\n",
            "|    learning_rate        | 0.01       |\n",
            "|    loss                 | 1.74e+04   |\n",
            "|    n_updates            | 1230       |\n",
            "|    policy_gradient_loss | 0.00883    |\n",
            "|    std                  | 0.153      |\n",
            "|    value_loss           | 2.69e+05   |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -7.4e+05    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 543         |\n",
            "|    iterations           | 125         |\n",
            "|    time_elapsed         | 2356        |\n",
            "|    total_timesteps      | 1280000     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017308587 |\n",
            "|    clip_fraction        | 0.157       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.453       |\n",
            "|    explained_variance   | 0.875       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 2.48e+04    |\n",
            "|    n_updates            | 1240        |\n",
            "|    policy_gradient_loss | 0.00725     |\n",
            "|    std                  | 0.155       |\n",
            "|    value_loss           | 2.23e+05    |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 5.98e+03   |\n",
            "|    ep_rew_mean          | -7.39e+05  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 543        |\n",
            "|    iterations           | 126        |\n",
            "|    time_elapsed         | 2375       |\n",
            "|    total_timesteps      | 1290240    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01656411 |\n",
            "|    clip_fraction        | 0.148      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | 0.46       |\n",
            "|    explained_variance   | 0.864      |\n",
            "|    learning_rate        | 0.01       |\n",
            "|    loss                 | 8.85e+04   |\n",
            "|    n_updates            | 1250       |\n",
            "|    policy_gradient_loss | 0.00269    |\n",
            "|    std                  | 0.153      |\n",
            "|    value_loss           | 3.52e+05   |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -7.39e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 543         |\n",
            "|    iterations           | 127         |\n",
            "|    time_elapsed         | 2394        |\n",
            "|    total_timesteps      | 1300480     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.020690564 |\n",
            "|    clip_fraction        | 0.176       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.45        |\n",
            "|    explained_variance   | 0.946       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 3.12e+04    |\n",
            "|    n_updates            | 1260        |\n",
            "|    policy_gradient_loss | 0.0064      |\n",
            "|    std                  | 0.155       |\n",
            "|    value_loss           | 2.61e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -7.39e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 543         |\n",
            "|    iterations           | 128         |\n",
            "|    time_elapsed         | 2412        |\n",
            "|    total_timesteps      | 1310720     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.020151515 |\n",
            "|    clip_fraction        | 0.137       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.446       |\n",
            "|    explained_variance   | 0.856       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 3.25e+04    |\n",
            "|    n_updates            | 1270        |\n",
            "|    policy_gradient_loss | 0.00345     |\n",
            "|    std                  | 0.155       |\n",
            "|    value_loss           | 2.55e+05    |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 5.98e+03  |\n",
            "|    ep_rew_mean          | -7.39e+05 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 543       |\n",
            "|    iterations           | 129       |\n",
            "|    time_elapsed         | 2432      |\n",
            "|    total_timesteps      | 1320960   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0185507 |\n",
            "|    clip_fraction        | 0.144     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | 0.446     |\n",
            "|    explained_variance   | 0.85      |\n",
            "|    learning_rate        | 0.01      |\n",
            "|    loss                 | 3.14e+04  |\n",
            "|    n_updates            | 1280      |\n",
            "|    policy_gradient_loss | 0.0021    |\n",
            "|    std                  | 0.155     |\n",
            "|    value_loss           | 3.2e+05   |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -7.39e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 543         |\n",
            "|    iterations           | 130         |\n",
            "|    time_elapsed         | 2451        |\n",
            "|    total_timesteps      | 1331200     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.023607232 |\n",
            "|    clip_fraction        | 0.177       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.432       |\n",
            "|    explained_variance   | 0.945       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 3.75e+04    |\n",
            "|    n_updates            | 1290        |\n",
            "|    policy_gradient_loss | 0.00585     |\n",
            "|    std                  | 0.161       |\n",
            "|    value_loss           | 2.6e+05     |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 5.98e+03   |\n",
            "|    ep_rew_mean          | -7.39e+05  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 542        |\n",
            "|    iterations           | 131        |\n",
            "|    time_elapsed         | 2472       |\n",
            "|    total_timesteps      | 1341440    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01178086 |\n",
            "|    clip_fraction        | 0.11       |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | 0.399      |\n",
            "|    explained_variance   | 0.816      |\n",
            "|    learning_rate        | 0.01       |\n",
            "|    loss                 | 2.64e+04   |\n",
            "|    n_updates            | 1300       |\n",
            "|    policy_gradient_loss | 0.00152    |\n",
            "|    std                  | 0.164      |\n",
            "|    value_loss           | 2.47e+05   |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -7.39e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 542         |\n",
            "|    iterations           | 132         |\n",
            "|    time_elapsed         | 2490        |\n",
            "|    total_timesteps      | 1351680     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015699726 |\n",
            "|    clip_fraction        | 0.132       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.401       |\n",
            "|    explained_variance   | 0.866       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 3.39e+04    |\n",
            "|    n_updates            | 1310        |\n",
            "|    policy_gradient_loss | 0.00145     |\n",
            "|    std                  | 0.161       |\n",
            "|    value_loss           | 3.55e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -7.39e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 542         |\n",
            "|    iterations           | 133         |\n",
            "|    time_elapsed         | 2510        |\n",
            "|    total_timesteps      | 1361920     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.023525063 |\n",
            "|    clip_fraction        | 0.17        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.408       |\n",
            "|    explained_variance   | 0.947       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 3.63e+04    |\n",
            "|    n_updates            | 1320        |\n",
            "|    policy_gradient_loss | 0.00413     |\n",
            "|    std                  | 0.162       |\n",
            "|    value_loss           | 2.45e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -7.39e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 542         |\n",
            "|    iterations           | 134         |\n",
            "|    time_elapsed         | 2529        |\n",
            "|    total_timesteps      | 1372160     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012802537 |\n",
            "|    clip_fraction        | 0.123       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.401       |\n",
            "|    explained_variance   | 0.793       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 2.43e+04    |\n",
            "|    n_updates            | 1330        |\n",
            "|    policy_gradient_loss | 0.00281     |\n",
            "|    std                  | 0.162       |\n",
            "|    value_loss           | 2.49e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -7.38e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 542         |\n",
            "|    iterations           | 135         |\n",
            "|    time_elapsed         | 2548        |\n",
            "|    total_timesteps      | 1382400     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011816073 |\n",
            "|    clip_fraction        | 0.129       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.397       |\n",
            "|    explained_variance   | 0.872       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 3.71e+04    |\n",
            "|    n_updates            | 1340        |\n",
            "|    policy_gradient_loss | 0.000805    |\n",
            "|    std                  | 0.164       |\n",
            "|    value_loss           | 3.66e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -7.38e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 542         |\n",
            "|    iterations           | 136         |\n",
            "|    time_elapsed         | 2566        |\n",
            "|    total_timesteps      | 1392640     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016329367 |\n",
            "|    clip_fraction        | 0.151       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.379       |\n",
            "|    explained_variance   | 0.942       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 3.02e+04    |\n",
            "|    n_updates            | 1350        |\n",
            "|    policy_gradient_loss | 0.00577     |\n",
            "|    std                  | 0.167       |\n",
            "|    value_loss           | 2.28e+05    |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 5.98e+03  |\n",
            "|    ep_rew_mean          | -7.38e+05 |\n",
            "| time/                   |           |\n",
            "|    fps                  | 542       |\n",
            "|    iterations           | 137       |\n",
            "|    time_elapsed         | 2585      |\n",
            "|    total_timesteps      | 1402880   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0156326 |\n",
            "|    clip_fraction        | 0.137     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | 0.376     |\n",
            "|    explained_variance   | 0.818     |\n",
            "|    learning_rate        | 0.01      |\n",
            "|    loss                 | 2.26e+04  |\n",
            "|    n_updates            | 1360      |\n",
            "|    policy_gradient_loss | 0.0028    |\n",
            "|    std                  | 0.166     |\n",
            "|    value_loss           | 2.44e+05  |\n",
            "---------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.98e+03     |\n",
            "|    ep_rew_mean          | -7.38e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 542          |\n",
            "|    iterations           | 138          |\n",
            "|    time_elapsed         | 2605         |\n",
            "|    total_timesteps      | 1413120      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0148246335 |\n",
            "|    clip_fraction        | 0.127        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.379        |\n",
            "|    explained_variance   | 0.864        |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 5.96e+04     |\n",
            "|    n_updates            | 1370         |\n",
            "|    policy_gradient_loss | 0.00247      |\n",
            "|    std                  | 0.165        |\n",
            "|    value_loss           | 3.5e+05      |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -7.38e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 542         |\n",
            "|    iterations           | 139         |\n",
            "|    time_elapsed         | 2623        |\n",
            "|    total_timesteps      | 1423360     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019311512 |\n",
            "|    clip_fraction        | 0.161       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.385       |\n",
            "|    explained_variance   | 0.936       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 4.3e+04     |\n",
            "|    n_updates            | 1380        |\n",
            "|    policy_gradient_loss | 0.0045      |\n",
            "|    std                  | 0.164       |\n",
            "|    value_loss           | 2.04e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -7.38e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 542         |\n",
            "|    iterations           | 140         |\n",
            "|    time_elapsed         | 2642        |\n",
            "|    total_timesteps      | 1433600     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019188853 |\n",
            "|    clip_fraction        | 0.142       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.41        |\n",
            "|    explained_variance   | 0.893       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 2.31e+04    |\n",
            "|    n_updates            | 1390        |\n",
            "|    policy_gradient_loss | 0.00314     |\n",
            "|    std                  | 0.16        |\n",
            "|    value_loss           | 2.55e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -7.38e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 542         |\n",
            "|    iterations           | 141         |\n",
            "|    time_elapsed         | 2662        |\n",
            "|    total_timesteps      | 1443840     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015808862 |\n",
            "|    clip_fraction        | 0.135       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.419       |\n",
            "|    explained_variance   | 0.876       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 3.47e+04    |\n",
            "|    n_updates            | 1400        |\n",
            "|    policy_gradient_loss | 0.00184     |\n",
            "|    std                  | 0.16        |\n",
            "|    value_loss           | 3.8e+05     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -7.38e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 542         |\n",
            "|    iterations           | 142         |\n",
            "|    time_elapsed         | 2681        |\n",
            "|    total_timesteps      | 1454080     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018683258 |\n",
            "|    clip_fraction        | 0.155       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.43        |\n",
            "|    explained_variance   | 0.889       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 3.17e+04    |\n",
            "|    n_updates            | 1410        |\n",
            "|    policy_gradient_loss | 0.00553     |\n",
            "|    std                  | 0.157       |\n",
            "|    value_loss           | 1.92e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -7.38e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 542         |\n",
            "|    iterations           | 143         |\n",
            "|    time_elapsed         | 2700        |\n",
            "|    total_timesteps      | 1464320     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015504627 |\n",
            "|    clip_fraction        | 0.144       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.43        |\n",
            "|    explained_variance   | 0.878       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 4.92e+04    |\n",
            "|    n_updates            | 1420        |\n",
            "|    policy_gradient_loss | 0.00234     |\n",
            "|    std                  | 0.158       |\n",
            "|    value_loss           | 2.84e+05    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.98e+03    |\n",
            "|    ep_rew_mean          | -7.38e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 542         |\n",
            "|    iterations           | 144         |\n",
            "|    time_elapsed         | 2719        |\n",
            "|    total_timesteps      | 1474560     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014872794 |\n",
            "|    clip_fraction        | 0.143       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.433       |\n",
            "|    explained_variance   | 0.91        |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 2.38e+04    |\n",
            "|    n_updates            | 1430        |\n",
            "|    policy_gradient_loss | 0.00269     |\n",
            "|    std                  | 0.156       |\n",
            "|    value_loss           | 3.31e+05    |\n",
            "-----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "config = {\n",
        "    \"policy_type\": \"MlpPolicy\",\n",
        "    \"total_timesteps\": 1_500_000,\n",
        "}\n",
        "\n",
        "run = wandb.init(\n",
        "    project=\"4022_intelligent_ems\",\n",
        "    config=config,\n",
        "    sync_tensorboard=True,  # auto-upload sb3's tensorboard metrics\n",
        "    monitor_gym=True,  # auto-upload the videos of agents playing the game\n",
        "    save_code=True,  # optional\n",
        ")\n",
        "\n",
        "#define 5 environments   for training and eval\n",
        "n_envs = 5\n",
        "#define num predictions\n",
        "n_preds = 24\n",
        "\n",
        "train_args = {\n",
        "                \"episode_len\"   : 6000,\n",
        "                \"actual_load\"   : actual_load,\n",
        "                \"actual_gen\"    : actual_gen,\n",
        "                \"bat_threshold\" : 100,\n",
        "                \"bat_cap\"       : 500,\n",
        "                \"purchase_price\": purchase_price,\n",
        "                \"num_preds\"     : n_preds,\n",
        "                \"load_shedding\" : load_shedding[2760:],\n",
        "                \"render_mode\"   : \"rgb_array\",\n",
        "                \"wandb_log\"     : True,\n",
        "                \"train_log\"     : True,\n",
        "\n",
        "                }\n",
        "\n",
        "eval_args = {\n",
        "                \"episode_len\"   :2760,\n",
        "                \"actual_load\"   :actual_load[6001:],\n",
        "                \"actual_gen\"    :actual_gen[6001:],\n",
        "                \"bat_threshold\" :100,\n",
        "                \"bat_cap\"       :500,\n",
        "                \"purchase_price\":purchase_price[6001:],\n",
        "                \"num_preds\"     :n_preds,\n",
        "                \"load_shedding\" :load_shedding[6001:],\n",
        "                \"wandb_log\"     : True,\n",
        "                \"train_log\"     : False\n",
        "}\n",
        "\n",
        "\n",
        "train_env = make_vec_env(EMS, n_envs = n_envs,env_kwargs = train_args )\n",
        "\n",
        "\n",
        "eval_env = make_vec_env(EMS, n_envs = n_envs,env_kwargs = eval_args )\n",
        "\n",
        "\n",
        "wand_eval = f\"{version}_{model_type}_eval\"+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "wand_train = f\"{version}_{model_type}_train\"+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "wandb_callback = WandbCallback(\n",
        "                gradient_save_freq=100,\n",
        "                model_save_path=f\"models/{run.id}.{datetime.datetime.now()}\",\n",
        "                model_save_freq= 30000,\n",
        "                verbose=2,\n",
        "                log = \"all\",\n",
        "               )\n",
        "eval_callback = EvalCallback(eval_env,\n",
        "                             best_model_save_path = f\"{model_dir}{version}_{model_type}\"+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"),\n",
        "                             log_path = wand_eval,\n",
        "                             eval_freq=300,\n",
        "                             n_eval_episodes = 1,\n",
        "                             deterministic = True,\n",
        "                             render = False,\n",
        "                             callback_after_eval = wandb_callback)\n",
        "\n",
        "\n",
        "model = PPO(\"MlpPolicy\",train_env, verbose = 1, learning_rate = 0.01, vf_coef = 0.2,tensorboard_log = f\"runs/{run.id}\")#learning_rate = 0.01, vf_coef = 0.2\n",
        "\n",
        "model.learn(total_timesteps= config[\"total_timesteps\"],\n",
        "            tb_log_name = wand_train,\n",
        "            reset_num_timesteps=False,\n",
        "            callback = wandb_callback\n",
        "            )\n",
        "\n",
        "model.save(f\"{model_dir}{version}_{model_type}\"+datetime.datetime.now().strftime(\"%m%d-%H%M%S\"))\n",
        "\n",
        "#c163c28885695cb2b0493ac455e296dcc8bc462a"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define a new test environment and load up the best performing model to test it.**"
      ],
      "metadata": {
        "id": "C9AGcLlsv4N7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run.finish()"
      ],
      "metadata": {
        "id": "FBI9vEwCd76a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inDHszZaxBUS"
      },
      "outputs": [],
      "source": [
        "config = {\n",
        "    \"policy_type\": \"MlpPolicy\",\n",
        "    \"total_timesteps\": 2760,\n",
        "}\n",
        "\n",
        "run = wandb.init(\n",
        "    project=\"4022_intelligent_ems\",\n",
        "    config=config,\n",
        "    sync_tensorboard=True,  # auto-upload sb3's tensorboard metrics\n",
        "    monitor_gym=True,  # auto-upload the videos of agents playing the game\n",
        "    save_code=True,  # optional\n",
        ")\n",
        "\n",
        "\n",
        "eval_args = {\n",
        "                \"episode_len\"   :2760,\n",
        "                \"actual_load\"   :actual_load[6001:],\n",
        "                \"actual_gen\"    :actual_gen[6001:],\n",
        "                \"bat_threshold\" :100,\n",
        "                \"bat_cap\"       :500,\n",
        "                \"purchase_price\":purchase_price[6001:],\n",
        "                \"num_preds\"     :n_preds,\n",
        "                \"load_shedding\" :load_shedding[6001:],\n",
        "                \"wandb_log\"     : True,\n",
        "                \"train_log\"     : False\n",
        "}\n",
        "\n",
        "#define 5 environments   for training and eval\n",
        "\n",
        "eval_env = make_vec_env(EMS, n_envs = n_envs,env_kwargs = eval_args )\n",
        "\n",
        "\n",
        "#first run it with only standby (default)\n",
        "obs   = eval_env.reset()\n",
        "#ensure that the exit condition is reset\n",
        "done = [False]*n_envs\n",
        "#define the action to take\n",
        "action_standby = [-1]*n_envs\n",
        "#reset score\n",
        "standby_score = [0]*n_envs\n",
        "standby_score = np.array(standby_score).astype(np.float32)\n",
        "while not all(done):\n",
        "    #step the model with the action\n",
        "    obs,reward,done,info = eval_env.step(action_standby)\n",
        "    #accumulate the score\n",
        "    standby_score += reward\n",
        "\n",
        "\n",
        "avg_standby_score = standby_score.mean()\n",
        "\n",
        "run.finish()\n",
        "\n",
        "eval_args = {\n",
        "                \"episode_len\"   :2760,\n",
        "                \"actual_load\"   :actual_load[6001:],\n",
        "                \"actual_gen\"    :actual_gen[6001:],\n",
        "                \"bat_threshold\" :100,\n",
        "                \"bat_cap\"       :500,\n",
        "                \"purchase_price\":purchase_price[6001:],\n",
        "                \"num_preds\"     :n_preds,\n",
        "                \"load_shedding\" :load_shedding[6001:],\n",
        "                \"wandb_log\"     : True,\n",
        "                \"train_log\"     : False\n",
        "}\n",
        "\n",
        "#define 5 environments   for training and eval\n",
        "\n",
        "eval_env = make_vec_env(EMS, n_envs = n_envs,env_kwargs = eval_args )\n",
        "\n",
        "#Load model, fetch the latest (or whichever one you want from the model_dir)\n",
        "#Best A2C model:/content/drive/MyDrive/Colab Notebooks/EMSv1_1/models/A2C/EMSv1_1_A2C1010-081818.zip\n",
        "best_model =\"/content/drive/MyDrive/Colab Notebooks/EMSv2_1/models/PPO/EMSv2_1_PPO1017-110702.zip\"\n",
        "#best_model =\n",
        "#best_PPO_model\n",
        "#model_load = f\"{best_model}\"\n",
        "\n",
        "#model  = PPO.load(model_load, env = eval_env)\n",
        "\n",
        "run = wandb.init(\n",
        "    project=\"4022_intelligent_ems\",\n",
        "    config=config,\n",
        "    sync_tensorboard=True,  # auto-upload sb3's tensorboard metrics\n",
        "    monitor_gym=True,  # auto-upload the videos of agents playing the game\n",
        "    save_code=True,  # optional\n",
        ")\n",
        "obs   = eval_env.reset()\n",
        "EMS_reward,EMS_std_reward = evaluate_policy(model,eval_env,n_eval_episodes = 1,deterministic=True)# callback = wandb_callback\n",
        "run.finish()\n",
        "\n",
        "print(f\"Note: The term does not refer to the cost in rands but rather to the reward as defined by the reward function!\")\n",
        "print(f\"Done the Standby Test! Total cost accumulated is: {avg_standby_score}\")\n",
        "print(f\"Done applying the trained model! Total cost accumulated is: {EMS_reward} +- {EMS_std_reward}\")\n",
        "\n",
        "savings = EMS_reward - avg_standby_score\n",
        "print(f\"The amount that was saved by applying the EMS agent: {savings}\")\n",
        "print(f\"This was saved over a period of {2760/24} days\")\n",
        "print(f\"The savings represents {(savings/(-avg_standby_score))*100} % of the cost if no EMS is installed\")\n",
        "print(f\"And it represents {(savings/(-EMS_reward))*100} % of the cost if the EMS is installed\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}