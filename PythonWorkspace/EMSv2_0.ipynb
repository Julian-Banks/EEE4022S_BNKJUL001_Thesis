{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Julian-Banks/EEE4022S_BNKJUL001_Thesis/blob/main/PythonWorkspace/EMSv2_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "V6yT1Kii6fZb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Version Notes**\n",
        "\n",
        "# **v2.0**\n",
        "*\n",
        "Adding a continous action space! Yolo\n",
        "\n",
        "# **v1.2**\n",
        "**Added:**\n",
        "* Diesel Generator action to mitigate unmet-load\n",
        "* reward based off real prices + demand charge - Demand charge has fucked the agent cause it buys in bulk! - might be time for the continous action space so it can decide how much to buy......\n",
        "\n",
        "**To Do:**\n",
        "* impliment a priority load - not gonna do this, just gonna have unmet load\n",
        "\n",
        "* Add in actual predictions, eish\n",
        "\n",
        "* figure out how to have more episodes!! I think it will have big performance boosts on the training :)\n",
        "\n",
        "* thinking that maybe I should change obs space back to what it was cause I dont actully need to know individual loads and gens!!!!\n",
        "\n",
        "# **v1.1**\n",
        "\n",
        "**Added:**\n",
        "* rect and inverter power tracking\n",
        "* reward logging in my own logging func\n",
        "* changed logging vars to arrays\n",
        "*\n",
        "\n",
        "**To Do**\n",
        "\n",
        "* battery charging rates - I think my assumption is fine.\n",
        "\n",
        "* tweak visualisation to show bar graphs at the end of training/testing. Maybe just print graphs at the end? I have added plt.show() - remember to play if it doesnt work!\n",
        "\n",
        "* impliment a generator!!!!!\n",
        "* impliment a priority load\n",
        "\n",
        "* NB figure out how to have more episodes!! I think it will have big performance boosts on the training :)\n",
        "\n",
        "* thinking that maybe I should change obs space back to what it was cause I dont actully need to know individual loads and gens!!!!\n",
        "\n",
        "# **v1.0**\n",
        "\n",
        "**Added:**\n",
        "* AC and DC load\n",
        "* Wind Gen\n",
        "* changed obs space to hold new loads\n",
        "* re wrote standby and purchase functions\n",
        "\n",
        "**To DO**\n",
        "* thinking that maybe I should change obs space back to what it was cause I dont actully need to know individual loads and gens!!!!\n",
        "* Add in rectifier & inverter power tracking\n",
        "* battery charging rates\n",
        "\n",
        "\n",
        "# **v0.3**\n",
        "**Added:**\n",
        "* loadshedding\n",
        "* New reward structure\n",
        "* added Vec_env\n",
        "* added eval callbacks to validate training\n",
        "* added in logging\n",
        "\n",
        "**Parameters:**\n",
        "* Added in loadshedding forecast\n",
        "\n",
        "**To do:**\n",
        "* find out about battery charging rates  & impliment\n",
        "* Find out if I need to normalise\n",
        "* Try dqn\n",
        "* Find out how the bounds for the obs_space box effect things\n",
        "* Try play with DummyVec wrapper (didnt work in last version)\n",
        "\n",
        "# **v0.2_1**\n",
        "**Added:**\n",
        "*  Monitor wrapper\n",
        "*  DummyVec wrapper\n",
        "*  Wand (weights and bais) enabled\n",
        "\n",
        "**Parameters:**\n",
        "* lowered to 3 predictions  \n",
        "\n",
        "**To do:**\n",
        "* Try to use hyperparameter Optimisation - decided Im only going to do on the final version\n",
        "* Try normalise\n",
        "* Try differnet models\n",
        "* Find out how the bounds for the obs_space box effect things\n",
        "\n",
        "# **v0.2**\n",
        "**Added:**\n",
        "*  simplified load_forecast and gen_forecast to be power_bal_forecasts.\n",
        "*  combined current_load and current_gen to also show current_power_balance\n",
        "*  added proper evaluate call\n",
        "\n",
        "**Parameters:**\n",
        "* No changes  \n",
        "\n",
        "**Results:**\n",
        "* 5% savings on PPO deterministic = true\n",
        "* 4.3% savings on PPO determnistic = false\n",
        "\n",
        "**To do:**\n",
        "* Try to use hyperparameter Optimisation\n",
        "* Try normalise\n",
        "* Try differnet models\n",
        "* Try see if discount rate can be tweaked - at good level.\n",
        "* Find out how the bounds for the obs_space box effect things\n",
        "\n",
        "# **v0.1**\n",
        "**Added:**\n",
        "* added real loads, gen, tou_id's\n",
        "\n",
        "**Parameters:**\n",
        "* training episode = 6000 timesteps\n",
        "* testing episode  = 2760 timesteps\n",
        "* bat_threshold = 100\n",
        "* bat_cap = 500\n",
        "* battery_level at reset = bat_cap/2\n",
        "* num_preds = 24\n",
        "* Trained PPO for 1.65mil timesteps\n",
        "* Trained A2C for 1.2 mil timesteps\n",
        "\n",
        "**Results:**\n",
        "* PP0 - 3.7% improvement from standby mode Deterministic = False\n",
        "* PPO - 6.1% Deterministic =  True\n",
        "* A2C  - -0.3% improvement. And the models after this got worse as training progressed!\n",
        "**To do:**\n",
        "* Try lower num_preds\n",
        "* Try to use hyperparameter Optimisation\n",
        "* Try normalise\n",
        "* Try differnet models\n",
        "* Try see if discount rate can be tweaked\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5DZFnZnzStt1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nI52iVVCCPaf"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "#install dependancies\n",
        "!pip install gymnasium\n",
        "!pip install stable_baselines3[extra]\n",
        "!pip install wandb\n",
        "%load_ext tensorboard\n",
        "\n",
        "#clone repository\n",
        "! git clone https://github.com/Julian-Banks/EEE4022S_BNKJUL001_Thesis\n",
        "\n",
        "#to update the rep\n",
        "%cd /content/EEE4022S_BNKJUL001_Thesis\n",
        "! git pull\n",
        "#import needed libarys\n",
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from gymnasium import spaces\n",
        "import datetime\n",
        "from stable_baselines3 import PPO, A2C, DQN,DDPG\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from stable_baselines3.common.callbacks import EvalCallback\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.vec_env import VecVideoRecorder\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.animation import FuncAnimation\n",
        "from gym.wrappers import FlattenObservation\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "import wandb\n",
        "from wandb.integration.sb3 import WandbCallback\n",
        "from gymnasium.envs.registration import register\n",
        "\n",
        "\n",
        "\n",
        "#mount the drive\n",
        "drive.mount('/content/drive')\n",
        "#define paths to logs and model saves\n",
        "model_type = \"PPO\"\n",
        "version    = \"EMSv2_0\"\n",
        "model_dir = f\"/content/drive/MyDrive/Colab Notebooks/{version}/models/{model_type}/\"\n",
        "log_dir   = f\"/content/drive/MyDrive/Colab Notebooks/{version}/models/{model_type}logs/\"\n",
        "animation_dir = f\"/content/drive/MyDrive/Colab Notebooks/{version}/models/{model_type}/animation/\"\n",
        "\n",
        "#make the appropriate directory if it does not exist\n",
        "if not os.path.exists(model_dir):\n",
        "    os.makedirs(model_dir)\n",
        "if not os.path.exists(log_dir):\n",
        "    os.makedirs(log_dir)\n",
        "if not os.path.exists(animation_dir):\n",
        "    os.makedirs(animation_dir)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define our environment class!!**"
      ],
      "metadata": {
        "id": "Q99_jLMvwuZZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "s2iW-k26FIbm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da01481e-b907-4e33-d98c-43b640c8c21b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gymnasium/envs/registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment EMSv2_0 already in registry.\u001b[0m\n",
            "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n",
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/env_checker.py:244: UserWarning: Your observation island_forecast has an unconventional shape (neither an image, nor a 1D vector). We recommend you to flatten the observation to have only a 1D vector or use a custom policy to properly process the data.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/env_checker.py:244: UserWarning: Your observation power_bal_forecast has an unconventional shape (neither an image, nor a 1D vector). We recommend you to flatten the observation to have only a 1D vector or use a custom policy to properly process the data.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/env_checker.py:244: UserWarning: Your observation price_forecast has an unconventional shape (neither an image, nor a 1D vector). We recommend you to flatten the observation to have only a 1D vector or use a custom policy to properly process the data.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/env_checker.py:428: UserWarning: We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) cf. https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "class EMSv2_0(gym.Env):\n",
        "    \"\"\"Custom Environment that follows gym interface.\"\"\"\n",
        "\n",
        "    metadata = {\"render_modes\": [\"human\",\"rgb_array\"], \"render_fps\": 30}\n",
        "\n",
        "    def __init__(self,bat_threshold = 0.1, bat_cap = 1, actual_load = \"none\", actual_gen = \"none\", purchase_price = [1,1,1,1,1,1,1,1,2,2,2,2] , episode_len = 8760,num_preds = 24,render_mode = \"rgb_array\", load_shedding = \"none\", wandb_log = False,train_log = True, gen_size = 100,demand_charge = 252.92):\n",
        "\n",
        "        super(EMSv2_0, self).__init__()\n",
        "        #define render_mode\n",
        "        self.render_mode = render_mode\n",
        "        #define wandb\n",
        "        self.wandb_log = wandb_log\n",
        "        self.train_log = train_log\n",
        "        #define time frame\n",
        "        self.current_step = 0\n",
        "        self.final_step = int(episode_len)-num_preds-2 #one years worth of steps\n",
        "\n",
        "        #Might make a function for these\n",
        "        #fill all of the actual loads NB!!! is just random for now NB!!! is normalised 0-1\n",
        "        if isinstance(actual_load,str) :\n",
        "            self.actual_load = np.random.rand(self.final_step+num_preds+1,2).astype(np.float32) #will load from a file or something\n",
        "        else:\n",
        "           self.actual_load  = actual_load[:episode_len,:]\n",
        "\n",
        "        #fill all of the actual generation steps.\n",
        "        if isinstance(actual_gen,str):\n",
        "            self.actual_gen  = np.random.rand(self.final_step+num_preds+1,2).astype(np.float32) #will load from file or something\n",
        "        else:\n",
        "            self.actual_gen  = actual_gen[:episode_len,:]\n",
        "\n",
        "        #Fill the loadShedding indicator\n",
        "        if isinstance(load_shedding,str):\n",
        "            num_shedding   = np.random.randint(int(0.02*episode_len), int(0.05*episode_len))\n",
        "            load_shed      = np.array([1]*num_shedding + [0]*(episode_len - num_shedding))\n",
        "            np.random.shuffle(load_shed)\n",
        "            self.load_shed = load_shed\n",
        "        else:\n",
        "            self.load_shed = load_shedding[:episode_len]\n",
        "\n",
        "        #define vars for render\n",
        "        self.off_peak_purchases = np.zeros(self.final_step)\n",
        "        self.standard_purchases = np.zeros(self.final_step)\n",
        "        self.peak_purchases     = np.zeros(self.final_step)\n",
        "\n",
        "        self.off_peak_num       = 0\n",
        "        self.peak_num           = 0\n",
        "        self.standard           = 0\n",
        "\n",
        "        self.unmet_load_total   = 0\n",
        "        self.frames = []\n",
        "\n",
        "        #Define a var for unmet load no that there is loadshedding\n",
        "        self.step_unmet_load = np.zeros(self.final_step)\n",
        "\n",
        "        #define the purchase price for every step of the year\n",
        "        purchase_price = np.array(purchase_price).astype(np.float32)\n",
        "        repetitions    = (self.final_step+num_preds+1) // len(purchase_price)\n",
        "        remainder      = (self.final_step+num_preds+1) % len(purchase_price)\n",
        "        self.purchase_price =np.concatenate([purchase_price]*repetitions+[purchase_price[:remainder]])#need to read in from somewhere\n",
        "\n",
        "        #define demand charge\n",
        "        self.demand_charge = demand_charge\n",
        "        #define var for storing the excess gen\n",
        "        self.excess_gen = np.zeros(self.final_step)\n",
        "        #define the size of the diesel_gen\n",
        "        self.gen_size = gen_size\n",
        "        #define a var for determine amount purchased per step (dont want to make it total as this will incure growing penalties for the Agent if used in reward structure)\n",
        "        self.step_purchased = np.zeros(self.final_step)\n",
        "        self.purchased_total = 0\n",
        "        #define the battery max capacity\n",
        "        self.bat_cap = bat_cap\n",
        "        #define the battery low threshold\n",
        "        self.bat_threshold = np.float32(bat_threshold)\n",
        "        self.battery_level = np.zeros(self.final_step+1)\n",
        "        #define default action\n",
        "        self.default_action = 0\n",
        "        #define actions and observations space\n",
        "        n_actions = 2 # keeping it simple\n",
        "\n",
        "        self.num_preds = num_preds # day ahead predictions\n",
        "        #define how many different loads and generators there are\n",
        "        self.num_loads = self.actual_load.shape[1]\n",
        "        #define the size of the action space\n",
        "        self.action_space = gym.spaces.Box(low= 0 , high = self.bat_cap - self.bat_threshold)\n",
        "        # Dict space to store all the different things\n",
        "        '''\n",
        "        self.observation_space = spaces.Dict({\n",
        "                \"power_bal_forecast\": gym.spaces.Box(low=-np.inf, high=np.inf, shape=(1,num_preds,self.num_loads), dtype=np.float32),\n",
        "                \"price_forecast\": gym.spaces.Box(low=0, high=np.inf, shape=(1,num_preds+1), dtype=np.float32),\n",
        "                \"island_forecast\": gym.spaces.Box(low=0, high=1, shape=(1,num_preds+1), dtype=np.float32),\n",
        "                \"bat_level\": gym.spaces.Box(low=0, high=np.inf, shape=(1,), dtype=np.float32),\n",
        "                \"current_power_bal\": gym.spaces.Box(low=-np.inf, high=np.inf, shape=(1,self.num_loads), dtype=np.float32),\n",
        "                })\n",
        "        '''\n",
        "        self.observation_space = spaces.Dict({\n",
        "                \"power_bal_forecast\": gym.spaces.Box(low=-np.inf, high=np.inf, shape=(1,num_preds), dtype=np.float32),\n",
        "                \"price_forecast\": gym.spaces.Box(low=0, high=np.inf, shape=(1,num_preds+1), dtype=np.float32),\n",
        "                \"island_forecast\": gym.spaces.Box(low=0, high=1, shape=(1,num_preds+1), dtype=np.float32),\n",
        "                \"bat_level\": gym.spaces.Box(low=0, high=np.inf, shape=(1,), dtype=np.float32),\n",
        "                \"current_power_bal\": gym.spaces.Box(low=-np.inf, high=np.inf, shape=(1,), dtype=np.float32),\n",
        "                })\n",
        "\n",
        "    def step(self, action):\n",
        "\n",
        "        #update the current state with the action (needs to be done before current_step is inc since we want to apply the action to the previous step to get the current state)\n",
        "        self.update_state(action)\n",
        "        #Calculate reward from the action\n",
        "        self.reward[self.current_step] = self.calc_reward()\n",
        "        #print(f\"calc_reward: {self.calc_reward()}\")\n",
        "        #print(f\"self.reward[current_step]: {self.reward[self.current_step]}\")\n",
        "        reward = self.reward[self.current_step]\n",
        "        #inc time step into Future\n",
        "        self.current_step += 1\n",
        "        #get next observation (for next time step)\n",
        "        observation = self.get_obs()\n",
        "        #Set terminated to False since there are no failure states\n",
        "        self.terminated = False\n",
        "        #Check if timelimit reached\n",
        "        self.truncated = False if self.current_step<self.final_step else True\n",
        "        #Wand log, if its set to true(so that it only gets run when wandb is initialised)\n",
        "        if self.wandb_log == True:\n",
        "            #doing this for training logging\n",
        "            if self.train_log == True:\n",
        "                if self.current_step == self.final_step:\n",
        "                    self.wandb_logger()\n",
        "            else:\n",
        "                self.wandb_logger()\n",
        "        #dont know what to put into info for now\n",
        "        info = {}\n",
        "        return observation, reward, self.terminated, self.truncated, info\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        super().reset(seed = seed, options=options)\n",
        "\n",
        "        self.current_step = 0\n",
        "        self.terminated = False\n",
        "        self.truncated = False\n",
        "        #reset the state\n",
        "        self.battery_level[0]   = self.bat_cap/2\n",
        "        self.excess_gen         = np.zeros(self.final_step)\n",
        "        self.step_purchased     = np.zeros(self.final_step+1)\n",
        "        self.step_unmet_load    = np.zeros(self.final_step)\n",
        "        self.off_peak_purchases = np.zeros(self.final_step)\n",
        "        self.peak_purchases     = np.zeros(self.final_step)\n",
        "        self.standard_purchases = np.zeros(self.final_step)\n",
        "        self.diesel_count       = np.zeros(self.final_step)\n",
        "        self.reward             = np.zeros(self.final_step+1)\n",
        "        self.step_invt          = np.zeros(self.final_step)\n",
        "        self.step_rect          = np.zeros(self.final_step)\n",
        "        self.diesel_gen         = np.zeros(self.final_step)\n",
        "        self.action_purchase    = np.zeros(self.final_step+1)\n",
        "        self.money_spent        = np.zeros(self.final_step)\n",
        "\n",
        "        #get the first observation\n",
        "        observation = self.get_obs()\n",
        "        #Still don't know what to do with info\n",
        "        info = {}\n",
        "        return observation, info\n",
        "\n",
        "\n",
        "\n",
        "    def render(self, mode='rgb_array', save_path=None):\n",
        "\n",
        "        plt.clf()\n",
        "        values = [self.off_peak_purchases, self.standard_purchases, self.purchase_price[self.peak_purchases]]\n",
        "        colors = ['green', 'orange','red']\n",
        "        labels = ['Off Peak', 'Standard', 'Peak']\n",
        "        plt.xlim(0,1.6)\n",
        "        plt.ylim(0,100)\n",
        "        plt.bar(list(range(3)),values, color=colors, tick_label=labels)\n",
        "        self.frames.append(plt.gcf().canvas.tostring_rgb())\n",
        "        plt.pause(0.000001)\n",
        "\n",
        "    def wandb_logger(self):\n",
        "        train_log_dict={\n",
        "                    \"Excess Generation\"         :np.sum(self.excess_gen),\n",
        "                    \"Unmet Load\"                :np.sum(self.step_unmet_load),\n",
        "                    \"Off-Peak Purchases\"        :np.sum(self.off_peak_purchases),\n",
        "                    \"Standard Purchases\"        :np.sum(self.standard_purchases),\n",
        "                    \"Peak Purchases\"            :np.sum(self.peak_purchases),\n",
        "                    \"Num Off-Peak Purchases\"    :np.count_nonzero(self.off_peak_purchases),\n",
        "                    \"Num Standard Purchases\"    :np.count_nonzero(self.standard_purchases),\n",
        "                    \"Num Peak Purchases\"        :np.count_nonzero(self.peak_purchases),\n",
        "                    \"Total Elec Purchase\"       :np.sum(self.step_purchased),\n",
        "                    \"Total Purchase Requested\"  :np.sum(self.action_purchase),\n",
        "                    \"Num Diesel Gen Actions\"    :np.count_nonzero(self.diesel_count),\n",
        "                    \"Total Reward\"              :np.sum(self.reward),\n",
        "                    \"Total Money spent\"         :np.sum(self.money_spent),\n",
        "                    \"Rectifier total power flow\":np.sum(self.step_rect),\n",
        "                    \"Inverter total power flow\" :np.sum(self.step_invt),\n",
        "                    \"Diesel Generator\"          :np.sum(self.diesel_gen),\n",
        "                    \"Max Demand\"                :np.max(self.step_purchased),\n",
        "                    \"total Purchased Elec\"      :np.sum(self.step_purchased)\n",
        "\n",
        "\n",
        "                  }\n",
        "        eval_log_dict={\n",
        "                    \"battery_level\"             :self.battery_level[self.current_step],\n",
        "                    \"AC load\"                   :self.actual_load[self.current_step,0],\n",
        "                    \"DC load\"                   :self.actual_load[self.current_step,1],\n",
        "                    \"PV generation\"             :self.actual_gen[self.current_step,0],\n",
        "                    \"Wind generation\"           :self.actual_gen[self.current_step,1],\n",
        "                    \"Excess Generation\"         :np.sum(self.excess_gen),\n",
        "                    \"Unmet Load\"                :np.sum(self.step_unmet_load),\n",
        "                    \"LoadShedding\"              :self.load_shed[self.current_step],\n",
        "                    \"Off-Peak Purchases\"        :np.sum(self.off_peak_purchases),\n",
        "                    \"Standard Purchases\"        :np.sum(self.standard_purchases),\n",
        "                    \"Peak Purchases\"            :np.sum(self.peak_purchases),\n",
        "                    \"Num Off-Peak Purchases\"    :np.count_nonzero(self.off_peak_purchases),\n",
        "                    \"Num Standard Purchases\"    :np.count_nonzero(self.standard_purchases),\n",
        "                    \"Num Peak Purchases\"        :np.count_nonzero(self.peak_purchases),\n",
        "                    \"Step Purchased\"            :self.step_purchased[self.current_step],\n",
        "                    \"Purchase Requested\"        :self.action_purchase[self.current_step],\n",
        "                    \"Num Diesel Gen Actions\"    :np.count_nonzero(self.diesel_count),\n",
        "                    \"Total Reward\"              :np.sum(self.reward),\n",
        "                    \"Money Spent\"               :np.sum(self.money_spent),\n",
        "                    \"Rectifier total power flow\":np.sum(self.step_rect),\n",
        "                    \"Inverter total power flow\" :np.sum(self.step_invt),\n",
        "                    \"Diesel Generator\"          :np.sum(self.diesel_gen),\n",
        "\n",
        "                  }\n",
        "\n",
        "        if self.train_log:\n",
        "            wandb.log(train_log_dict)\n",
        "        else:\n",
        "            wandb.log(eval_log_dict)\n",
        "\n",
        "        if self.train_log == False and self.current_step == self.final_step:\n",
        "\n",
        "\n",
        "            values = [[np.sum(self.off_peak_purchases),'Off Peak'], [np.sum(self.standard_purchases),'Standard'], [np.sum(self.peak_purchases),'Peak']]\n",
        "            table = wandb.Table(columns = [\"values\",\"labels\"],data=values)\n",
        "            Tou_purchases = wandb.plot.bar(table,\"labels\",\"values\", title=\"kWh purchased per TOU tariff\")\n",
        "\n",
        "            values = [[np.max(self.step_purchased),'Max demand'], [np.max(self.diesel_gen),'Max diesel gen'], [np.max(self.step_rect),'Max rectifier power'], [np.max(self.step_invt),'Max inverter power']]\n",
        "            table = wandb.Table(columns = [\"values\",\"labels\"],data=values)\n",
        "            max_metrics = wandb.plot.bar(table,\"labels\",\"values\", title=\"Sizing Metrics\")\n",
        "\n",
        "            values = [[np.sum(self.step_purchased),'Total Purchased'], [np.sum(self.action_purchase),'Total requested purchases'],[np.sum(self.excess_gen),'Total excess generation']]\n",
        "            table = wandb.Table(columns = [\"values\",\"labels\"],data=values)\n",
        "            total_metrics = wandb.plot.bar(table,\"labels\",\"values\", title=\"Total Metrics\")\n",
        "\n",
        "            values = [[np.sum(self.diesel_gen),'Total diesel generation'], [np.sum(self.step_unmet_load),'Total unmet load']]\n",
        "            table = wandb.Table(columns = [\"values\",\"labels\"],data=values)\n",
        "            total_diesel_unmet = wandb.plot.bar(table,\"labels\",\"values\", title=\"Total diesel and unmet load\")\n",
        "\n",
        "            values = [[np.sum(self.reward),'Total reward accumulated'], [np.sum(self.money_spent),'Total money spent']]\n",
        "            table = wandb.Table(columns = [\"values\",\"labels\"],data=values)\n",
        "            total_reward = wandb.plot.bar(table,\"labels\",\"values\", title=\"Total reward and money spent\")\n",
        "\n",
        "\n",
        "            wandb.log({ \"kWh purchased per TOU tariff\"  : Tou_purchases,\n",
        "                        \"Max sizing metrics\"            : max_metrics,\n",
        "                        \"Total metrics\"                 : total_metrics,\n",
        "                        \"Total diesel and unmet load\"   : total_diesel_unmet,\n",
        "                        \"Total reward and money spent\"  :total_reward\n",
        "                        })\n",
        "\n",
        "\n",
        "\n",
        "            plt.clf()\n",
        "            values = [np.sum(self.off_peak_purchases), np.sum(self.standard_purchases), np.sum(self.peak_purchases)]\n",
        "            colors = ['green', 'orange','red']\n",
        "            plt.xlim(0,2)\n",
        "            plt.ylim(0,120000)\n",
        "            plt.bar(list(range(3)),values, color=colors, tick_label=labels)\n",
        "            plt.xlabel('Tariff Rate')\n",
        "            plt.ylabel('Electricity Purchased (units)')\n",
        "            plt.title('Electricity Purchased per Tariff Rate')\n",
        "\n",
        "            save_name = animation_dir + \"TOU_purchases_\"+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")+\".png\"\n",
        "            plt.savefig(save_name)\n",
        "            wandb.log({\"Electricity purchased per Tariff rate\": wandb.Image(save_name)})\n",
        "\n",
        "    def close(self):\n",
        "        #don't think i need this for my application\n",
        "        pass\n",
        "\n",
        "    def update_state(self, action):\n",
        "\n",
        "        self.standby(purchase_amount = action)\n",
        "        self.action_purchase[self.current_step] = action\n",
        "\n",
        "        self.tou_purchase_inc()\n",
        "        #Calculate the flow of power (this is max absorb, the min need is just dc_power_bal)\n",
        "        #fetch info from grids\n",
        "        ac_power_bal, avail_grid = self.AC_bus()\n",
        "        dc_power_bal, avail_bat, avail_stor = self.DC_bus()\n",
        "        self.calc_power_flow(dc_power_bal,ac_power_bal,avail_stor)\n",
        "\n",
        "    def calc_reward(self):\n",
        "        #Calculate reward based on the state\n",
        "        #Summer Months: 5.92, 2.09, 1.33\n",
        "        #Winter Months: 2.22, 1.66, 1.21\n",
        "        #Demand Charge: 252.92\n",
        "        diesel_cost = 0.4*23 #0.4l per kwh produced multipled by a cost of 23 rand per litre. Very rough values\n",
        "        reward = -self.step_purchased[self.current_step]*self.purchase_price[self.current_step] - self.step_unmet_load[self.current_step]*20 - self.diesel_gen[self.current_step]*diesel_cost\n",
        "        self.money_spent[self.current_step] =  +self.step_purchased[self.current_step]*self.purchase_price[self.current_step] + self.diesel_gen[self.current_step]*diesel_cost\n",
        "        #if a month has past, then impliment the demand charge\n",
        "        if self.current_step % (24*30) == 0 and self.current_step != 0:\n",
        "            max_grid_demand = np.max(self.step_purchased[self.current_step-(24*30):self.current_step])\n",
        "            reward = reward - max_grid_demand * self.demand_charge\n",
        "            self.money_spent[self.current_step] =  self.money_spent[self.current_step] + max_grid_demand*self.demand_charge\n",
        "\n",
        "        return reward\n",
        "\n",
        "    def get_obs(self):\n",
        "        #Fill the observation space with the next observation\n",
        "\n",
        "        #Get Forecasts Will probaly write a function for this? idk maybe a schlep to return all the info\n",
        "        load_forecast  = np.array( [self.actual_load[self.current_step+1: self.current_step + self.num_preds+1,:]] , dtype = np.float32) #will load from a file or something\n",
        "        gen_forecast   = np.array( [self.actual_gen[self.current_step+1: self.current_step + self.num_preds+1,:]] , dtype = np.float32) #will load from a file or something\n",
        "        #calculate the power forecast\n",
        "        power_bal_forecast = gen_forecast-load_forecast\n",
        "        power_bal_forecast = power_bal_forecast.sum(axis=2)\n",
        "        #get the prices for the current frame and the next 24 hours. Maybe will cut this down since that seems like a lot of info\n",
        "        price_forecast = np.array( [self.purchase_price[self.current_step:self.current_step+self.num_preds+1]] , dtype = np.float32)\n",
        "        #Just for readibility of the dict object\n",
        "        bat_level      = np.array([self.battery_level[self.current_step]] , dtype= np.float32)\n",
        "        #island forecasst, same as tou forecast\n",
        "        island_forecast =np.array( [self.load_shed[self.current_step:self.current_step+self.num_preds+1]] , dtype = np.float32)\n",
        "\n",
        "        #calculate the current power balance\n",
        "        current_load   = np.array([self.actual_load[self.current_step,:]], dtype = np.float32)\n",
        "        current_gen    = np.array([self.actual_gen[self.current_step,:]], dtype  = np.float32)\n",
        "        current_power_bal = current_gen - current_load\n",
        "        current_power_bal = current_power_bal.sum(axis=1)\n",
        "\n",
        "\n",
        "\n",
        "        obs = dict({\n",
        "                \"bat_level\":      bat_level,\n",
        "                \"current_power_bal\" :   current_power_bal,\n",
        "                \"island_forecast\": island_forecast,\n",
        "                \"power_bal_forecast\":  power_bal_forecast,\n",
        "                \"price_forecast\": price_forecast,\n",
        "        })\n",
        "        return obs\n",
        "\n",
        "    def AC_bus(self):\n",
        "        #fill out info on the ac\n",
        "        ac_gen = self.actual_gen[self.current_step, 0]\n",
        "        ac_load = self.actual_load[self.current_step,0]\n",
        "        ac_power_bal = ac_gen - ac_load\n",
        "        #check if there is load shedding or not\n",
        "        avail_grid = not self.load_shed[self.current_step]\n",
        "        #ac_diesel = Don't know what yet but I do want to use it for something.\n",
        "        #return relevant values\n",
        "        return ac_power_bal,avail_grid\n",
        "\n",
        "    def DC_bus(self):\n",
        "        #fill in info for DC_bus\n",
        "        dc_gen       = self.actual_gen[self.current_step,1]\n",
        "        dc_load      = self.actual_load[self.current_step,1]\n",
        "        dc_power_bal = dc_gen - dc_load\n",
        "        #Haven't imposed limits here but I don't think I need to. Must check.\n",
        "        avail_bat  = self.battery_level[self.current_step] - self.bat_threshold\n",
        "        avail_stor = self.bat_cap       - self.battery_level[self.current_step]\n",
        "        return dc_power_bal, avail_bat, avail_stor\n",
        "\n",
        "    def standby(self,purchase_amount):\n",
        "        #fetch info from grids\n",
        "        ac_power_bal, avail_grid = self.AC_bus()\n",
        "        dc_power_bal, avail_bat, avail_stor = self.DC_bus()\n",
        "\n",
        "        if avail_grid: # if there is no loadshedding purchase the amount requested by the agent.\n",
        "            self.step_purchased[self.current_step] = purchase_amount\n",
        "        else:\n",
        "            self.step_purchased[self.current_step] = 0\n",
        "        #calculate the immediate power_bal\n",
        "        grid_power_bal = ac_power_bal + dc_power_bal + self.step_purchased[self.current_step]\n",
        "        #determine the flow of power:\n",
        "        if grid_power_bal > 0 :\n",
        "            #increments the battery level by the minimium between avail_stor and grid_power_bal ( always keeps it in range)\n",
        "            self.battery_level[self.current_step+1] = self.battery_level[self.current_step] + min(avail_stor, grid_power_bal)\n",
        "            #increments excess gen by the max ( if grid_power_bal - avail_stor is negative, there was no excess and it will add 0, else it will add the excess that wasn't stored)\n",
        "            self.excess_gen[self.current_step] = max((grid_power_bal - avail_stor), 0)\n",
        "        else:\n",
        "            #there is a shortage of power, see if we can take it from the battery.\n",
        "            # flipping the sign of the avail bat, cause that will subtracted from current balance.\n",
        "            self.battery_level[self.current_step+1] = self.battery_level[self.current_step] + max(-avail_bat, grid_power_bal)\n",
        "            #check if we are islanded and buy elec if we arent\n",
        "            if avail_grid:\n",
        "                #if the grid is available\n",
        "                #the min power needed is 0 if the grid power bal is positive with the available batter. Otherwise it is the shortage (grid_power_bal is negative, avail_bat is positive)\n",
        "                min_power_need = - min(grid_power_bal + avail_bat, 0)\n",
        "                self.step_purchased[self.current_step] = purchase_amount + min_power_need\n",
        "               # if purchase_amount > min_power_need :\n",
        "                #   self.battery_level[self.current_step+1] = self.batter_level[self.current_step] + (purchase_amount-min_power_need)\n",
        "            else:\n",
        "                #if not available add to the step un_met_load.\n",
        "                unmet_load = -min(grid_power_bal + avail_bat, 0)\n",
        "                self.diesel_gen[self.current_step] = min(unmet_load,self.gen_size)\n",
        "                if self.diesel_gen[self.current_step] > 0:\n",
        "                    self.diesel_count[self.current_step] =1\n",
        "                self.step_unmet_load[self.current_step] = max(unmet_load - self.gen_size, 0)\n",
        "\n",
        "\n",
        "    def calc_power_flow(self,dc_power_bal,ac_power_bal,avail_stor):\n",
        "\n",
        "        #Calculate the flow of power (this is max absorb, the min need is just dc_power_bal)\n",
        "        dc_power_absorb = max(-dc_power_bal+avail_stor,0)\n",
        "        #ac power excess will be the power balance added to the purchase amount\n",
        "        ac_power_excess = max(ac_power_bal+self.step_purchased[self.current_step]+self.diesel_gen[self.current_step],0)\n",
        "        #the power that will flow through the rectifier is the minimum between the amount the DC grid can absorb and the excess the ac_grid has\n",
        "        rect_power = min(dc_power_absorb,ac_power_excess)\n",
        "\n",
        "        dc_power_avail = max(dc_power_bal,0) #lol just defined a new var for readability.\n",
        "        ac_power_need   = max(-ac_power_bal-self.step_purchased[self.current_step]-self.diesel_gen[self.current_step], 0) # calculate how much power the ac grid needs.\n",
        "        dc_power_excess = max(dc_power_avail - ac_power_need - avail_stor,0) #calculate how much power would be in excess if there was to be excess.\n",
        "        #inverter power is equal to the minimum val between the avail dc power and the needed power. Then since all excess power needs to go to the grid, if there is any extra energy after the ac_need has been met and the battery is fully charged, it is also sent through the inverter\n",
        "        invt_power = min(ac_power_need, dc_power_avail) + dc_power_excess\n",
        "        #set the attributes.\n",
        "        self.step_invt[self.current_step] = invt_power\n",
        "        self.step_rect[self.current_step] = rect_power\n",
        "\n",
        "    def purchase(self):\n",
        "        self.purchase_count[self.current_step] =1\n",
        "        #fetch info from grids\n",
        "        ac_power_bal, avail_grid = self.AC_bus()\n",
        "        dc_power_bal, avail_bat, avail_stor = self.DC_bus()\n",
        "\n",
        "        if avail_grid:\n",
        "            grid_power_bal = ac_power_bal+dc_power_bal\n",
        "            #if we are grid connected purchase the max between the amount needed elec and 0\n",
        "            min_grid_power_needed = max(-grid_power_bal -avail_bat,0)\n",
        "            self.step_purchased[self.current_step] = max(min_grid_power_needed,purchase_amount)\n",
        "            #set Battery to full\n",
        "            self.battery_level[self.current_step+1] = min(self.battery_level[self.current_step]  - avail_bat + max(purchase_amount-min_grid_power_needed,0) , self.bat_cap)\n",
        "            #calculate and add the excess electricity generated.\n",
        "            self.excess_gen[self.current_step]= max((grid_power_bal - avail_stor), 0,)\n",
        "        else:\n",
        "            #if the grid is not available then we can't purchase and standby can handle power flow ect\n",
        "            self.standby()\n",
        "\n",
        "\n",
        "    def tou_purchase_inc(self):\n",
        "        #Summer Months: 5.92, 2.09, 1.33\n",
        "        #Winter Months: 2.22, 1.66, 1.21\n",
        "        if self.step_purchased[self.current_step] != 0:\n",
        "            if self.purchase_price[self.current_step] < 1.5:\n",
        "                self.off_peak_purchases[self.current_step] = self.step_purchased[self.current_step]\n",
        "            elif self.purchase_price[self.current_step] < 2.1:\n",
        "                self.standard_purchases[self.current_step] = self.step_purchased[self.current_step]\n",
        "            else:\n",
        "                self.peak_purchases[self.current_step] = self.step_purchased[self.current_step]\n",
        "\n",
        "\n",
        "#define a pointer (kinda, don't actually know what its called) a\n",
        "EMS = EMSv2_0\n",
        "\n",
        "# Register environment so I can use make_vec_env\n",
        "register(\n",
        "# unique identifier for the env `name-version`\n",
        "id=f\"{version}\",\n",
        "# path to the class for creating the env\n",
        "# Note: entry_point also accept a class as input (and not only a string)\n",
        "entry_point= EMS(),\n",
        "\n",
        ")\n",
        "\n",
        "#Check the environment with stable_baselines3 check_env.\n",
        "from stable_baselines3.common.env_checker import check_env\n",
        "env = EMS()\n",
        "check_env(env,warn = True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DG4gB2cM7tDY"
      },
      "source": [
        "**Load in the data for our specific microgrid.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0X9RBdXC_2PD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1202bf6-928a-4a25-ecd0-8a4e91cc2acc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done iteration! Total reward accumulated is: -1668229.1474328206\n"
          ]
        }
      ],
      "source": [
        "#need to import data from Github\n",
        "path_data = \"/content/EEE4022S_BNKJUL001_Thesis/PythonWorkspace/dataClean.csv\"\n",
        "data = pd.read_csv(path_data)\n",
        "\n",
        "path_pv_gen = \"/content/EEE4022S_BNKJUL001_Thesis/Generation/BNKJUL001_Thesis_solarGen500kWHomer.csv\"\n",
        "data_pv_gen = pd.read_csv(path_pv_gen)\n",
        "\n",
        "path_wind_gen = \"/content/EEE4022S_BNKJUL001_Thesis/Generation/BNKJUL001_Thesis_Wind500kGenHomer.csv\"\n",
        "data_wind_gen = pd.read_csv(path_wind_gen)\n",
        "\n",
        "#Not actually using this rn but will be soon :)\n",
        "path_shedding = \"/content/EEE4022S_BNKJUL001_Thesis/MatlabWorkSpace/loadShedding2022.csv\"\n",
        "data_shedding = pd.read_csv(path_shedding)\n",
        "load_shedding = data_shedding['LoadShedding'].values.astype(np.float32)\n",
        "\n",
        "wind_gen = data_wind_gen['Wind_Out'].values.astype(np.float32)\n",
        "PV_gen = data_pv_gen['PV_Out'].values.astype(np.float32)\n",
        "actual_gen = np.column_stack((wind_gen, PV_gen))\n",
        "#read in ac and DC load\n",
        "AC_load = data['AC'].values.astype(np.float32)\n",
        "DC_load = data['DC'].values.astype(np.float32)\n",
        "#stack em together for the input :)\n",
        "actual_load = np.column_stack((AC_load, DC_load))\n",
        "\n",
        "path_purchase_price = \"/content/EEE4022S_BNKJUL001_Thesis/PythonWorkspace/purchasePrice.csv\"\n",
        "data_purchase_price = pd.read_csv(path_purchase_price)\n",
        "purchase_price = data_purchase_price['Grid Power Price'].values.astype(np.float32)\n",
        "\n",
        "\n",
        "#define the base environment\n",
        "base_env = EMS(episode_len = 6000, actual_load = actual_load, actual_gen = actual_gen, bat_threshold = 100, bat_cap = 500, purchase_price = purchase_price,num_preds = 3)\n",
        "#going to print out a bunch of things to test the different spaces.\n",
        "obs,_    = base_env.reset()\n",
        "'''\n",
        "print(f\"The reset observation space looks like: {obs}\")\n",
        "battery_level = obs['bat_level']\n",
        "print(f\"Battery level is: {battery_level[0]}kWh\")\n",
        "current_power_bal = obs['current_power_bal']\n",
        "print(f\"Current AC Power Balance {current_power_bal[0,0]}, Current DC Power Balance{current_power_bal[0,1]}\")\n",
        "power_forecast = obs['power_bal_forecast']\n",
        "print(f\"Forecasted AC power 1 hour ahead: {power_forecast[0,0,0]}. Forecasted DC power 1 hour ahead: {power_forecast[0,0,1]}\")\n",
        "print(f\"Forecasted AC power 2 hour ahead: {power_forecast[0,1,0]}. Forecasted DC power 2 hour ahead: {power_forecast[0,1,1]}\")\n",
        "print(f\"Forecasted AC power 3 hour ahead: {power_forecast[0,2,0]}. Forecasted DC power 3 hour ahead: {power_forecast[0,2,1]}\")\n",
        "\n",
        "print(f\"_________________________________________________________________________________________________________________\")\n",
        "print(f\"\")\n",
        "\n",
        "\n",
        "action_standby = 0\n",
        "obs,reward,terminated,truncated,info = base_env.step(action_standby)\n",
        "print(f\"After action {action_standby}: \" )\n",
        "battery_level = obs['bat_level']\n",
        "print(f\"Battery level is: {battery_level[0]}kWh\")\n",
        "current_power_bal = obs['current_power_bal']\n",
        "print(f\"Current AC Power Balance {current_power_bal[0,0]}, Current DC Power Balance{current_power_bal[0,1]}\")\n",
        "power_forecast = obs['power_bal_forecast']\n",
        "print(f\"Forecasted AC power 1 hour ahead: {power_forecast[0,0,0]}. Forecasted DC power 1 hour ahead: {power_forecast[0,0,1]}\")\n",
        "print(f\"Forecasted AC power 2 hour ahead: {power_forecast[0,1,0]}. Forecasted DC power 2 hour ahead: {power_forecast[0,1,1]}\")\n",
        "print(f\"Forecasted AC power 3 hour ahead: {power_forecast[0,2,0]}. Forecasted DC power 3 hour ahead: {power_forecast[0,2,1]}\")\n",
        "print(f\"The reward we recieved was {reward}\")\n",
        "print(f\"_________________________________________________________________________________________________________________\")\n",
        "print(f\"\")\n",
        "action_standby = 0\n",
        "obs,reward,terminated,truncated,info = base_env.step(action_standby)\n",
        "print(f\"After action {action_standby}: \" )\n",
        "battery_level = obs['bat_level']\n",
        "print(f\"Battery level is: {battery_level[0]}kWh\")\n",
        "current_power_bal = obs['current_power_bal']\n",
        "print(f\"Current AC Power Balance {current_power_bal[0,0]}, Current DC Power Balance{current_power_bal[0,1]}\")\n",
        "power_forecast = obs['power_bal_forecast']\n",
        "print(f\"Forecasted AC power 1 hour ahead: {power_forecast[0,0,0]}. Forecasted DC power 1 hour ahead: {power_forecast[0,0,1]}\")\n",
        "print(f\"Forecasted AC power 2 hour ahead: {power_forecast[0,1,0]}. Forecasted DC power 2 hour ahead: {power_forecast[0,1,1]}\")\n",
        "print(f\"Forecasted AC power 3 hour ahead: {power_forecast[0,2,0]}. Forecasted DC power 3 hour ahead: {power_forecast[0,2,1]}\")\n",
        "print(f\"The reward we recieved was {reward}\")\n",
        "print(f\"_________________________________________________________________________________________________________________\")\n",
        "print(f\"\")\n",
        "obs,reward,terminated,truncated,info = base_env.step(1)\n",
        "print(f\"After action {1} : \" )\n",
        "battery_level = obs['bat_level']\n",
        "print(f\"Battery level is: {battery_level[0]}kWh\")\n",
        "current_power_bal = obs['current_power_bal']\n",
        "print(f\"Current AC Power Balance {current_power_bal[0,0]}, Current DC Power Balance{current_power_bal[0,1]}\")\n",
        "power_forecast = obs['power_bal_forecast']\n",
        "print(f\"Forecasted AC power 1 hour ahead: {power_forecast[0,0,0]}. Forecasted DC power 1 hour ahead: {power_forecast[0,0,1]}\")\n",
        "print(f\"Forecasted AC power 2 hour ahead: {power_forecast[0,1,0]}. Forecasted DC power 2 hour ahead: {power_forecast[0,1,1]}\")\n",
        "print(f\"Forecasted AC power 3 hour ahead: {power_forecast[0,2,0]}. Forecasted DC power 3 hour ahead: {power_forecast[0,2,1]}\")\n",
        "print(f\"The reward we recieved was {reward}\")\n",
        "print(f\"_________________________________________________________________________________________________________________\")\n",
        "print(f\"\")\n",
        "obs,reward,terminated,truncated,info = base_env.step(0)\n",
        "print(f\"After action {0} : \" )\n",
        "battery_level = obs['bat_level']\n",
        "print(f\"Battery level is: {battery_level[0]}kWh\")\n",
        "current_power_bal = obs['current_power_bal']\n",
        "print(f\"Current AC Power Balance {current_power_bal[0,0]}, Current DC Power Balance{current_power_bal[0,1]}\")\n",
        "power_forecast = obs['power_bal_forecast']\n",
        "print(f\"Forecasted AC power 1 hour ahead: {power_forecast[0,0,0]}. Forecasted DC power 1 hour ahead: {power_forecast[0,0,1]}\")\n",
        "print(f\"Forecasted AC power 2 hour ahead: {power_forecast[0,1,0]}. Forecasted DC power 2 hour ahead: {power_forecast[0,1,1]}\")\n",
        "print(f\"Forecasted AC power 3 hour ahead: {power_forecast[0,2,0]}. Forecasted DC power 3 hour ahead: {power_forecast[0,2,1]}\")\n",
        "print(f\"The reward we recieved was {reward}\")\n",
        "print(f\"_________________________________________________________________________________________________________________\")\n",
        "print(f\"\")\n",
        "'''\n",
        "#Evaluate the base model (no EMS, just using standby mode)\n",
        "#A loop to get an average reward for the base model only perfoming the standby option\n",
        "#reset the environment and save the obs\n",
        "#going to run it 100 times to get a benchmark\n",
        "#reset score\n",
        "score = 0\n",
        "\n",
        "obs,_    = base_env.reset()\n",
        "#ensure that the exit condition is reset\n",
        "truncated = False\n",
        "#define the action to take\n",
        "action_standby = 0\n",
        "\n",
        "while not truncated:\n",
        "    obs,reward,terminated,truncated,info = base_env.step(action_standby)\n",
        "    score += reward\n",
        "\n",
        "print(f\"Done iteration! Total reward accumulated is: {score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pAj6-n04zyt"
      },
      "source": [
        "**LOAD OR MAKE MODEL HERE!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQDhUNGWeum4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4d8a62de-f2b1-4692-d01e-b0f429a1a859"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:5t0trbt1) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Diesel Generator</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Excess Generation</td><td>▁████████████</td></tr><tr><td>Inverter total power flow</td><td>▁████████████</td></tr><tr><td>Max Demand</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Num Diesel Gen Actions</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Num Off-Peak Purchases</td><td>▁████████████</td></tr><tr><td>Num Peak Purchases</td><td>▁████████████</td></tr><tr><td>Num Standard Purchases</td><td>▁████████████</td></tr><tr><td>Off-Peak Purchases</td><td>▁████████████</td></tr><tr><td>Peak Purchases</td><td>▁████████████</td></tr><tr><td>Rectifier total power flow</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Standard Purchases</td><td>▁████████████</td></tr><tr><td>Total Elec Purchase</td><td>▁████████████</td></tr><tr><td>Total Money spent</td><td>▁████████████</td></tr><tr><td>Total Purchase Requested</td><td>▁████████████</td></tr><tr><td>Total Reward</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Unmet Load</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>global_step</td><td>▁▄█</td></tr><tr><td>rollout/ep_len_mean</td><td>▁▁▁</td></tr><tr><td>rollout/ep_rew_mean</td><td>█▃▁</td></tr><tr><td>time/fps</td><td>█▂▁</td></tr><tr><td>total Purchased Elec</td><td>▁████████████</td></tr><tr><td>train/actor_loss</td><td>▁▆█</td></tr><tr><td>train/critic_loss</td><td>█▃▁</td></tr><tr><td>train/learning_rate</td><td>▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Diesel Generator</td><td>50.88339</td></tr><tr><td>Excess Generation</td><td>2397686.80272</td></tr><tr><td>Inverter total power flow</td><td>291144.37543</td></tr><tr><td>Max Demand</td><td>400.0</td></tr><tr><td>Num Diesel Gen Actions</td><td>2</td></tr><tr><td>Num Off-Peak Purchases</td><td>2836</td></tr><tr><td>Num Peak Purchases</td><td>866</td></tr><tr><td>Num Standard Purchases</td><td>2074</td></tr><tr><td>Off-Peak Purchases</td><td>1134400.0</td></tr><tr><td>Peak Purchases</td><td>346400.0</td></tr><tr><td>Rectifier total power flow</td><td>294746.63234</td></tr><tr><td>Standard Purchases</td><td>829600.0</td></tr><tr><td>Total Elec Purchase</td><td>2310400.0</td></tr><tr><td>Total Money spent</td><td>4925639.5381</td></tr><tr><td>Total Purchase Requested</td><td>2389600.0</td></tr><tr><td>Total Reward</td><td>-4925639.5381</td></tr><tr><td>Unmet Load</td><td>0.0</td></tr><tr><td>global_step</td><td>71688</td></tr><tr><td>rollout/ep_len_mean</td><td>5974.0</td></tr><tr><td>rollout/ep_rew_mean</td><td>-4732045.5</td></tr><tr><td>time/fps</td><td>127.0</td></tr><tr><td>total Purchased Elec</td><td>2310400.0</td></tr><tr><td>train/actor_loss</td><td>76338.95312</td></tr><tr><td>train/critic_loss</td><td>5528533.0</td></tr><tr><td>train/learning_rate</td><td>0.001</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">vivid-jazz-119</strong> at: <a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/5t0trbt1' target=\"_blank\">https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/5t0trbt1</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20231016_122914-5t0trbt1/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:5t0trbt1). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.12"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/EEE4022S_BNKJUL001_Thesis/wandb/run-20231016_124045-596q1ldr</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/596q1ldr' target=\"_blank\">ethereal-dew-120</a></strong> to <a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems' target=\"_blank\">https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/596q1ldr' target=\"_blank\">https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/596q1ldr</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "Logging to runs/596q1ldr/EMSv2_0_PPO_train20231016-124058_0\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 2723  |\n",
            "|    iterations      | 1     |\n",
            "|    time_elapsed    | 3     |\n",
            "|    total_timesteps | 10240 |\n",
            "------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 1264         |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 16           |\n",
            "|    total_timesteps      | 20480        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017133111 |\n",
            "|    clip_fraction        | 0.00145      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.41        |\n",
            "|    explained_variance   | 2.98e-07     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.45e+06     |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -0.000735    |\n",
            "|    std                  | 0.991        |\n",
            "|    value_loss           | 4.43e+07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1041         |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 29           |\n",
            "|    total_timesteps      | 30720        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0006133458 |\n",
            "|    clip_fraction        | 0.000166     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.41        |\n",
            "|    explained_variance   | 2.65e-05     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.62e+07     |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -0.000589    |\n",
            "|    std                  | 0.996        |\n",
            "|    value_loss           | 1.25e+08     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 5.97e+03      |\n",
            "|    ep_rew_mean          | -1.72e+06     |\n",
            "| time/                   |               |\n",
            "|    fps                  | 972           |\n",
            "|    iterations           | 4             |\n",
            "|    time_elapsed         | 42            |\n",
            "|    total_timesteps      | 40960         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00016910126 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.41         |\n",
            "|    explained_variance   | 6.38e-06      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 4.01e+07      |\n",
            "|    n_updates            | 30            |\n",
            "|    policy_gradient_loss | -0.000398     |\n",
            "|    std                  | 0.993         |\n",
            "|    value_loss           | 1.66e+08      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 942          |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 54           |\n",
            "|    total_timesteps      | 51200        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0009905829 |\n",
            "|    clip_fraction        | 0.000703     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.41        |\n",
            "|    explained_variance   | 4.44e-05     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.71e+07     |\n",
            "|    n_updates            | 40           |\n",
            "|    policy_gradient_loss | -0.000951    |\n",
            "|    std                  | 0.988        |\n",
            "|    value_loss           | 7.69e+07     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 5.97e+03      |\n",
            "|    ep_rew_mean          | -1.72e+06     |\n",
            "| time/                   |               |\n",
            "|    fps                  | 930           |\n",
            "|    iterations           | 6             |\n",
            "|    time_elapsed         | 66            |\n",
            "|    total_timesteps      | 61440         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00032315528 |\n",
            "|    clip_fraction        | 1.95e-05      |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.41         |\n",
            "|    explained_variance   | 1.22e-05      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 2.08e+08      |\n",
            "|    n_updates            | 50            |\n",
            "|    policy_gradient_loss | -0.000593     |\n",
            "|    std                  | 0.992         |\n",
            "|    value_loss           | 9.51e+07      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 913          |\n",
            "|    iterations           | 7            |\n",
            "|    time_elapsed         | 78           |\n",
            "|    total_timesteps      | 71680        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0006550692 |\n",
            "|    clip_fraction        | 0.000137     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.41        |\n",
            "|    explained_variance   | 7.75e-07     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.55e+07     |\n",
            "|    n_updates            | 60           |\n",
            "|    policy_gradient_loss | -0.000804    |\n",
            "|    std                  | 0.983        |\n",
            "|    value_loss           | 1.64e+08     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 900          |\n",
            "|    iterations           | 8            |\n",
            "|    time_elapsed         | 90           |\n",
            "|    total_timesteps      | 81920        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012225942 |\n",
            "|    clip_fraction        | 0.00143      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.4         |\n",
            "|    explained_variance   | 6.5e-06      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.66e+07     |\n",
            "|    n_updates            | 70           |\n",
            "|    policy_gradient_loss | -0.00114     |\n",
            "|    std                  | 0.987        |\n",
            "|    value_loss           | 7.72e+07     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 5.97e+03      |\n",
            "|    ep_rew_mean          | -1.72e+06     |\n",
            "| time/                   |               |\n",
            "|    fps                  | 889           |\n",
            "|    iterations           | 9             |\n",
            "|    time_elapsed         | 103           |\n",
            "|    total_timesteps      | 92160         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00023020509 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.41         |\n",
            "|    explained_variance   | 8.94e-07      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 2.83e+07      |\n",
            "|    n_updates            | 80            |\n",
            "|    policy_gradient_loss | -0.000489     |\n",
            "|    std                  | 0.991         |\n",
            "|    value_loss           | 1.42e+08      |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -1.72e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 880         |\n",
            "|    iterations           | 10          |\n",
            "|    time_elapsed         | 116         |\n",
            "|    total_timesteps      | 102400      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002151136 |\n",
            "|    clip_fraction        | 0.00679     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.41       |\n",
            "|    explained_variance   | 5.96e-08    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.82e+07    |\n",
            "|    n_updates            | 90          |\n",
            "|    policy_gradient_loss | -0.00208    |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 1.16e+08    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 879          |\n",
            "|    iterations           | 11           |\n",
            "|    time_elapsed         | 128          |\n",
            "|    total_timesteps      | 112640       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019932797 |\n",
            "|    clip_fraction        | 0.00313      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.42        |\n",
            "|    explained_variance   | 4.17e-07     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.48e+07     |\n",
            "|    n_updates            | 100          |\n",
            "|    policy_gradient_loss | -0.00176     |\n",
            "|    std                  | 0.997        |\n",
            "|    value_loss           | 7.73e+07     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 5.97e+03      |\n",
            "|    ep_rew_mean          | -1.72e+06     |\n",
            "| time/                   |               |\n",
            "|    fps                  | 878           |\n",
            "|    iterations           | 12            |\n",
            "|    time_elapsed         | 139           |\n",
            "|    total_timesteps      | 122880        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00034108842 |\n",
            "|    clip_fraction        | 6.84e-05      |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.41         |\n",
            "|    explained_variance   | 1.19e-07      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 1.2e+08       |\n",
            "|    n_updates            | 110           |\n",
            "|    policy_gradient_loss | -0.000802     |\n",
            "|    std                  | 0.996         |\n",
            "|    value_loss           | 1.43e+08      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 872          |\n",
            "|    iterations           | 13           |\n",
            "|    time_elapsed         | 152          |\n",
            "|    total_timesteps      | 133120       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016544797 |\n",
            "|    clip_fraction        | 0.00245      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.42        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.02e+08     |\n",
            "|    n_updates            | 120          |\n",
            "|    policy_gradient_loss | -0.00123     |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.14e+08     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 868          |\n",
            "|    iterations           | 14           |\n",
            "|    time_elapsed         | 165          |\n",
            "|    total_timesteps      | 143360       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0007740855 |\n",
            "|    clip_fraction        | 0.000361     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.42        |\n",
            "|    explained_variance   | 1.79e-07     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.26e+07     |\n",
            "|    n_updates            | 130          |\n",
            "|    policy_gradient_loss | -0.000996    |\n",
            "|    std                  | 0.997        |\n",
            "|    value_loss           | 7.75e+07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 864          |\n",
            "|    iterations           | 15           |\n",
            "|    time_elapsed         | 177          |\n",
            "|    total_timesteps      | 153600       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0003506147 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.42        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.1e+07      |\n",
            "|    n_updates            | 140          |\n",
            "|    policy_gradient_loss | -0.000754    |\n",
            "|    std                  | 0.997        |\n",
            "|    value_loss           | 1.44e+08     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 5.97e+03      |\n",
            "|    ep_rew_mean          | -1.72e+06     |\n",
            "| time/                   |               |\n",
            "|    fps                  | 862           |\n",
            "|    iterations           | 16            |\n",
            "|    time_elapsed         | 189           |\n",
            "|    total_timesteps      | 163840        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00084931793 |\n",
            "|    clip_fraction        | 0.000322      |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.42         |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 5.02e+07      |\n",
            "|    n_updates            | 150           |\n",
            "|    policy_gradient_loss | -0.00064      |\n",
            "|    std                  | 0.999         |\n",
            "|    value_loss           | 1.27e+08      |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -1.72e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 864         |\n",
            "|    iterations           | 17          |\n",
            "|    time_elapsed         | 201         |\n",
            "|    total_timesteps      | 174080      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001586459 |\n",
            "|    clip_fraction        | 0.00266     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.42       |\n",
            "|    explained_variance   | 1.79e-07    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.76e+07    |\n",
            "|    n_updates            | 160         |\n",
            "|    policy_gradient_loss | -0.00171    |\n",
            "|    std                  | 0.998       |\n",
            "|    value_loss           | 9.68e+07    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 861          |\n",
            "|    iterations           | 18           |\n",
            "|    time_elapsed         | 213          |\n",
            "|    total_timesteps      | 184320       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0007821995 |\n",
            "|    clip_fraction        | 0.000195     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.42        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.42e+07     |\n",
            "|    n_updates            | 170          |\n",
            "|    policy_gradient_loss | -0.00142     |\n",
            "|    std                  | 0.997        |\n",
            "|    value_loss           | 1.11e+08     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 5.97e+03      |\n",
            "|    ep_rew_mean          | -1.72e+06     |\n",
            "| time/                   |               |\n",
            "|    fps                  | 858           |\n",
            "|    iterations           | 19            |\n",
            "|    time_elapsed         | 226           |\n",
            "|    total_timesteps      | 194560        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00057152036 |\n",
            "|    clip_fraction        | 0.000107      |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.42         |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 8.15e+07      |\n",
            "|    n_updates            | 180           |\n",
            "|    policy_gradient_loss | -0.000857     |\n",
            "|    std                  | 1             |\n",
            "|    value_loss           | 1.27e+08      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 856          |\n",
            "|    iterations           | 20           |\n",
            "|    time_elapsed         | 238          |\n",
            "|    total_timesteps      | 204800       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015781388 |\n",
            "|    clip_fraction        | 0.00396      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.43        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.83e+07     |\n",
            "|    n_updates            | 190          |\n",
            "|    policy_gradient_loss | -0.00145     |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 9.72e+07     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 5.97e+03      |\n",
            "|    ep_rew_mean          | -1.72e+06     |\n",
            "| time/                   |               |\n",
            "|    fps                  | 854           |\n",
            "|    iterations           | 21            |\n",
            "|    time_elapsed         | 251           |\n",
            "|    total_timesteps      | 215040        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00036859766 |\n",
            "|    clip_fraction        | 4.88e-05      |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.43         |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 9.51e+07      |\n",
            "|    n_updates            | 200           |\n",
            "|    policy_gradient_loss | -0.000629     |\n",
            "|    std                  | 1.02          |\n",
            "|    value_loss           | 1.56e+08      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 855          |\n",
            "|    iterations           | 22           |\n",
            "|    time_elapsed         | 263          |\n",
            "|    total_timesteps      | 225280       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011069754 |\n",
            "|    clip_fraction        | 0.00119      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.44        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.01e+07     |\n",
            "|    n_updates            | 210          |\n",
            "|    policy_gradient_loss | -0.00155     |\n",
            "|    std                  | 1.02         |\n",
            "|    value_loss           | 7.95e+07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 855          |\n",
            "|    iterations           | 23           |\n",
            "|    time_elapsed         | 275          |\n",
            "|    total_timesteps      | 235520       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0006126116 |\n",
            "|    clip_fraction        | 0.000215     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.44        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.13e+07     |\n",
            "|    n_updates            | 220          |\n",
            "|    policy_gradient_loss | -0.000923    |\n",
            "|    std                  | 1.02         |\n",
            "|    value_loss           | 9.75e+07     |\n",
            "------------------------------------------\n",
            "--------------------------------------------\n",
            "| rollout/                |                |\n",
            "|    ep_len_mean          | 5.97e+03       |\n",
            "|    ep_rew_mean          | -1.72e+06      |\n",
            "| time/                   |                |\n",
            "|    fps                  | 853            |\n",
            "|    iterations           | 24             |\n",
            "|    time_elapsed         | 287            |\n",
            "|    total_timesteps      | 245760         |\n",
            "| train/                  |                |\n",
            "|    approx_kl            | 0.000100076126 |\n",
            "|    clip_fraction        | 0              |\n",
            "|    clip_range           | 0.2            |\n",
            "|    entropy_loss         | -1.44          |\n",
            "|    explained_variance   | 0              |\n",
            "|    learning_rate        | 0.0003         |\n",
            "|    loss                 | 6.68e+07       |\n",
            "|    n_updates            | 230            |\n",
            "|    policy_gradient_loss | -0.000554      |\n",
            "|    std                  | 1.02           |\n",
            "|    value_loss           | 1.57e+08       |\n",
            "--------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 852          |\n",
            "|    iterations           | 25           |\n",
            "|    time_elapsed         | 300          |\n",
            "|    total_timesteps      | 256000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011869749 |\n",
            "|    clip_fraction        | 0.00124      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.44        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.92e+07     |\n",
            "|    n_updates            | 240          |\n",
            "|    policy_gradient_loss | -0.00108     |\n",
            "|    std                  | 1.02         |\n",
            "|    value_loss           | 7.83e+07     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 5.97e+03      |\n",
            "|    ep_rew_mean          | -1.72e+06     |\n",
            "| time/                   |               |\n",
            "|    fps                  | 850           |\n",
            "|    iterations           | 26            |\n",
            "|    time_elapsed         | 313           |\n",
            "|    total_timesteps      | 266240        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00081268756 |\n",
            "|    clip_fraction        | 0.000576      |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.44         |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 1.94e+07      |\n",
            "|    n_updates            | 250           |\n",
            "|    policy_gradient_loss | -0.0013       |\n",
            "|    std                  | 1.02          |\n",
            "|    value_loss           | 9.9e+07       |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 5.97e+03      |\n",
            "|    ep_rew_mean          | -1.72e+06     |\n",
            "| time/                   |               |\n",
            "|    fps                  | 849           |\n",
            "|    iterations           | 27            |\n",
            "|    time_elapsed         | 325           |\n",
            "|    total_timesteps      | 276480        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00025104536 |\n",
            "|    clip_fraction        | 7.81e-05      |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.44         |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 3.68e+07      |\n",
            "|    n_updates            | 260           |\n",
            "|    policy_gradient_loss | -0.000806     |\n",
            "|    std                  | 1.02          |\n",
            "|    value_loss           | 1.59e+08      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 850          |\n",
            "|    iterations           | 28           |\n",
            "|    time_elapsed         | 336          |\n",
            "|    total_timesteps      | 286720       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018098652 |\n",
            "|    clip_fraction        | 0.00362      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.44        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.07e+07     |\n",
            "|    n_updates            | 270          |\n",
            "|    policy_gradient_loss | -0.0015      |\n",
            "|    std                  | 1.03         |\n",
            "|    value_loss           | 1.01e+08     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 849          |\n",
            "|    iterations           | 29           |\n",
            "|    time_elapsed         | 349          |\n",
            "|    total_timesteps      | 296960       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031031596 |\n",
            "|    clip_fraction        | 0.0108       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.44        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.2e+07      |\n",
            "|    n_updates            | 280          |\n",
            "|    policy_gradient_loss | -0.00211     |\n",
            "|    std                  | 1.02         |\n",
            "|    value_loss           | 7.36e+07     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 5.97e+03      |\n",
            "|    ep_rew_mean          | -1.72e+06     |\n",
            "| time/                   |               |\n",
            "|    fps                  | 848           |\n",
            "|    iterations           | 30            |\n",
            "|    time_elapsed         | 362           |\n",
            "|    total_timesteps      | 307200        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00012751206 |\n",
            "|    clip_fraction        | 0.000107      |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.44         |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 8.27e+07      |\n",
            "|    n_updates            | 290           |\n",
            "|    policy_gradient_loss | -0.000567     |\n",
            "|    std                  | 1.02          |\n",
            "|    value_loss           | 1.59e+08      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 847          |\n",
            "|    iterations           | 31           |\n",
            "|    time_elapsed         | 374          |\n",
            "|    total_timesteps      | 317440       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0009046821 |\n",
            "|    clip_fraction        | 0.000908     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.44        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.14e+08     |\n",
            "|    n_updates            | 300          |\n",
            "|    policy_gradient_loss | -0.00095     |\n",
            "|    std                  | 1.03         |\n",
            "|    value_loss           | 9.76e+07     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 5.97e+03      |\n",
            "|    ep_rew_mean          | -1.72e+06     |\n",
            "| time/                   |               |\n",
            "|    fps                  | 846           |\n",
            "|    iterations           | 32            |\n",
            "|    time_elapsed         | 386           |\n",
            "|    total_timesteps      | 327680        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00063386874 |\n",
            "|    clip_fraction        | 0.0004        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.45         |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 9.18e+06      |\n",
            "|    n_updates            | 310           |\n",
            "|    policy_gradient_loss | -0.000882     |\n",
            "|    std                  | 1.03          |\n",
            "|    value_loss           | 1.19e+08      |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 5.97e+03      |\n",
            "|    ep_rew_mean          | -1.72e+06     |\n",
            "| time/                   |               |\n",
            "|    fps                  | 847           |\n",
            "|    iterations           | 33            |\n",
            "|    time_elapsed         | 398           |\n",
            "|    total_timesteps      | 337920        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00034651504 |\n",
            "|    clip_fraction        | 5.86e-05      |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.44         |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 5.06e+07      |\n",
            "|    n_updates            | 320           |\n",
            "|    policy_gradient_loss | -0.000533     |\n",
            "|    std                  | 1.02          |\n",
            "|    value_loss           | 1.65e+08      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 847          |\n",
            "|    iterations           | 34           |\n",
            "|    time_elapsed         | 410          |\n",
            "|    total_timesteps      | 348160       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011442198 |\n",
            "|    clip_fraction        | 0.00237      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.43        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.98e+06     |\n",
            "|    n_updates            | 330          |\n",
            "|    policy_gradient_loss | -0.00182     |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 4.53e+07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 847          |\n",
            "|    iterations           | 35           |\n",
            "|    time_elapsed         | 423          |\n",
            "|    total_timesteps      | 358400       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0009408239 |\n",
            "|    clip_fraction        | 0.000811     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.43        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.07e+07     |\n",
            "|    n_updates            | 340          |\n",
            "|    policy_gradient_loss | -0.00119     |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 1.23e+08     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 5.97e+03      |\n",
            "|    ep_rew_mean          | -1.72e+06     |\n",
            "| time/                   |               |\n",
            "|    fps                  | 846           |\n",
            "|    iterations           | 36            |\n",
            "|    time_elapsed         | 435           |\n",
            "|    total_timesteps      | 368640        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00017044225 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.43         |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 5.07e+07      |\n",
            "|    n_updates            | 350           |\n",
            "|    policy_gradient_loss | -0.000511     |\n",
            "|    std                  | 1.02          |\n",
            "|    value_loss           | 1.66e+08      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 845          |\n",
            "|    iterations           | 37           |\n",
            "|    time_elapsed         | 447          |\n",
            "|    total_timesteps      | 378880       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0010769436 |\n",
            "|    clip_fraction        | 0.00108      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.43        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.66e+07     |\n",
            "|    n_updates            | 360          |\n",
            "|    policy_gradient_loss | -0.00125     |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 4.35e+07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 846          |\n",
            "|    iterations           | 38           |\n",
            "|    time_elapsed         | 459          |\n",
            "|    total_timesteps      | 389120       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0002602266 |\n",
            "|    clip_fraction        | 0.000107     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.42        |\n",
            "|    explained_variance   | 1.79e-07     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.34e+07     |\n",
            "|    n_updates            | 370          |\n",
            "|    policy_gradient_loss | -0.000758    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.23e+08     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 5.97e+03      |\n",
            "|    ep_rew_mean          | -1.72e+06     |\n",
            "| time/                   |               |\n",
            "|    fps                  | 847           |\n",
            "|    iterations           | 39            |\n",
            "|    time_elapsed         | 471           |\n",
            "|    total_timesteps      | 399360        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00043185815 |\n",
            "|    clip_fraction        | 6.84e-05      |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.42         |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 8.62e+07      |\n",
            "|    n_updates            | 380           |\n",
            "|    policy_gradient_loss | -0.00101      |\n",
            "|    std                  | 1             |\n",
            "|    value_loss           | 1.64e+08      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 846          |\n",
            "|    iterations           | 40           |\n",
            "|    time_elapsed         | 483          |\n",
            "|    total_timesteps      | 409600       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018808914 |\n",
            "|    clip_fraction        | 0.00348      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.43        |\n",
            "|    explained_variance   | 1.19e-06     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.28e+07     |\n",
            "|    n_updates            | 390          |\n",
            "|    policy_gradient_loss | -0.0015      |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 7.58e+07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 846          |\n",
            "|    iterations           | 41           |\n",
            "|    time_elapsed         | 496          |\n",
            "|    total_timesteps      | 419840       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0006408434 |\n",
            "|    clip_fraction        | 0.000352     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.42        |\n",
            "|    explained_variance   | 2.09e-06     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.92e+07     |\n",
            "|    n_updates            | 400          |\n",
            "|    policy_gradient_loss | -0.000912    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 9.34e+07     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -1.72e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 845         |\n",
            "|    iterations           | 42          |\n",
            "|    time_elapsed         | 508         |\n",
            "|    total_timesteps      | 430080      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.000409758 |\n",
            "|    clip_fraction        | 0.000107    |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.42       |\n",
            "|    explained_variance   | 2.98e-07    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 7.89e+07    |\n",
            "|    n_updates            | 410         |\n",
            "|    policy_gradient_loss | -0.000832   |\n",
            "|    std                  | 0.995       |\n",
            "|    value_loss           | 1.62e+08    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 845          |\n",
            "|    iterations           | 43           |\n",
            "|    time_elapsed         | 521          |\n",
            "|    total_timesteps      | 440320       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013166129 |\n",
            "|    clip_fraction        | 0.00223      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.41        |\n",
            "|    explained_variance   | 9.12e-06     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.88e+07     |\n",
            "|    n_updates            | 420          |\n",
            "|    policy_gradient_loss | -0.00183     |\n",
            "|    std                  | 0.982        |\n",
            "|    value_loss           | 7.61e+07     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 5.97e+03      |\n",
            "|    ep_rew_mean          | -1.72e+06     |\n",
            "| time/                   |               |\n",
            "|    fps                  | 845           |\n",
            "|    iterations           | 44            |\n",
            "|    time_elapsed         | 532           |\n",
            "|    total_timesteps      | 450560        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00036505883 |\n",
            "|    clip_fraction        | 0.000313      |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.4          |\n",
            "|    explained_variance   | 2.26e-06      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 2.01e+08      |\n",
            "|    n_updates            | 430           |\n",
            "|    policy_gradient_loss | -0.00105      |\n",
            "|    std                  | 0.973         |\n",
            "|    value_loss           | 1.4e+08       |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 5.97e+03      |\n",
            "|    ep_rew_mean          | -1.72e+06     |\n",
            "| time/                   |               |\n",
            "|    fps                  | 845           |\n",
            "|    iterations           | 45            |\n",
            "|    time_elapsed         | 544           |\n",
            "|    total_timesteps      | 460800        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00071219786 |\n",
            "|    clip_fraction        | 0.000996      |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.39         |\n",
            "|    explained_variance   | 1.79e-06      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 1.04e+08      |\n",
            "|    n_updates            | 440           |\n",
            "|    policy_gradient_loss | -0.00152      |\n",
            "|    std                  | 0.971         |\n",
            "|    value_loss           | 1.14e+08      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 845          |\n",
            "|    iterations           | 46           |\n",
            "|    time_elapsed         | 557          |\n",
            "|    total_timesteps      | 471040       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012832294 |\n",
            "|    clip_fraction        | 0.00241      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.39        |\n",
            "|    explained_variance   | 3.1e-05      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.68e+07     |\n",
            "|    n_updates            | 450          |\n",
            "|    policy_gradient_loss | -0.00157     |\n",
            "|    std                  | 0.976        |\n",
            "|    value_loss           | 7.62e+07     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 5.97e+03      |\n",
            "|    ep_rew_mean          | -1.72e+06     |\n",
            "| time/                   |               |\n",
            "|    fps                  | 844           |\n",
            "|    iterations           | 47            |\n",
            "|    time_elapsed         | 569           |\n",
            "|    total_timesteps      | 481280        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00091802573 |\n",
            "|    clip_fraction        | 0.000518      |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.4          |\n",
            "|    explained_variance   | 8.46e-06      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 1.28e+07      |\n",
            "|    n_updates            | 460           |\n",
            "|    policy_gradient_loss | -0.0012       |\n",
            "|    std                  | 0.977         |\n",
            "|    value_loss           | 1.41e+08      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 843          |\n",
            "|    iterations           | 48           |\n",
            "|    time_elapsed         | 582          |\n",
            "|    total_timesteps      | 491520       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0007192497 |\n",
            "|    clip_fraction        | 0.000645     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.39        |\n",
            "|    explained_variance   | 3.52e-06     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.82e+07     |\n",
            "|    n_updates            | 470          |\n",
            "|    policy_gradient_loss | -0.00152     |\n",
            "|    std                  | 0.974        |\n",
            "|    value_loss           | 1.13e+08     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 844          |\n",
            "|    iterations           | 49           |\n",
            "|    time_elapsed         | 594          |\n",
            "|    total_timesteps      | 501760       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021285326 |\n",
            "|    clip_fraction        | 0.00589      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.39        |\n",
            "|    explained_variance   | 3.7e-05      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.59e+06     |\n",
            "|    n_updates            | 480          |\n",
            "|    policy_gradient_loss | -0.00266     |\n",
            "|    std                  | 0.964        |\n",
            "|    value_loss           | 7.64e+07     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 5.97e+03      |\n",
            "|    ep_rew_mean          | -1.72e+06     |\n",
            "| time/                   |               |\n",
            "|    fps                  | 844           |\n",
            "|    iterations           | 50            |\n",
            "|    time_elapsed         | 606           |\n",
            "|    total_timesteps      | 512000        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00047080085 |\n",
            "|    clip_fraction        | 0.000352      |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.38         |\n",
            "|    explained_variance   | 1.79e-06      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 1.73e+07      |\n",
            "|    n_updates            | 490           |\n",
            "|    policy_gradient_loss | -0.00108      |\n",
            "|    std                  | 0.959         |\n",
            "|    value_loss           | 1.42e+08      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 844          |\n",
            "|    iterations           | 51           |\n",
            "|    time_elapsed         | 618          |\n",
            "|    total_timesteps      | 522240       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0005652566 |\n",
            "|    clip_fraction        | 0.000508     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.38        |\n",
            "|    explained_variance   | 8.05e-06     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.76e+07     |\n",
            "|    n_updates            | 500          |\n",
            "|    policy_gradient_loss | -0.00133     |\n",
            "|    std                  | 0.958        |\n",
            "|    value_loss           | 1.25e+08     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 843          |\n",
            "|    iterations           | 52           |\n",
            "|    time_elapsed         | 631          |\n",
            "|    total_timesteps      | 532480       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0010216873 |\n",
            "|    clip_fraction        | 0.0016       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.37        |\n",
            "|    explained_variance   | 5.77e-05     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.42e+07     |\n",
            "|    n_updates            | 510          |\n",
            "|    policy_gradient_loss | -0.00129     |\n",
            "|    std                  | 0.952        |\n",
            "|    value_loss           | 9.57e+07     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 5.97e+03      |\n",
            "|    ep_rew_mean          | -1.72e+06     |\n",
            "| time/                   |               |\n",
            "|    fps                  | 843           |\n",
            "|    iterations           | 53            |\n",
            "|    time_elapsed         | 643           |\n",
            "|    total_timesteps      | 542720        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00040582538 |\n",
            "|    clip_fraction        | 0.000557      |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.37         |\n",
            "|    explained_variance   | 1.1e-05       |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 7.3e+07       |\n",
            "|    n_updates            | 520           |\n",
            "|    policy_gradient_loss | -0.00117      |\n",
            "|    std                  | 0.959         |\n",
            "|    value_loss           | 1.09e+08      |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -1.72e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 842         |\n",
            "|    iterations           | 54          |\n",
            "|    time_elapsed         | 656         |\n",
            "|    total_timesteps      | 552960      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002015355 |\n",
            "|    clip_fraction        | 0.0058      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.38       |\n",
            "|    explained_variance   | 1e-05       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.83e+07    |\n",
            "|    n_updates            | 530         |\n",
            "|    policy_gradient_loss | -0.00173    |\n",
            "|    std                  | 0.961       |\n",
            "|    value_loss           | 1.25e+08    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 843          |\n",
            "|    iterations           | 55           |\n",
            "|    time_elapsed         | 667          |\n",
            "|    total_timesteps      | 563200       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014020981 |\n",
            "|    clip_fraction        | 0.00231      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.37        |\n",
            "|    explained_variance   | 0.000108     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.44e+07     |\n",
            "|    n_updates            | 540          |\n",
            "|    policy_gradient_loss | -0.00156     |\n",
            "|    std                  | 0.95         |\n",
            "|    value_loss           | 9.58e+07     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 5.97e+03      |\n",
            "|    ep_rew_mean          | -1.72e+06     |\n",
            "| time/                   |               |\n",
            "|    fps                  | 843           |\n",
            "|    iterations           | 56            |\n",
            "|    time_elapsed         | 679           |\n",
            "|    total_timesteps      | 573440        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00042616174 |\n",
            "|    clip_fraction        | 0.000488      |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.36         |\n",
            "|    explained_variance   | 2.98e-05      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 7.58e+07      |\n",
            "|    n_updates            | 550           |\n",
            "|    policy_gradient_loss | -0.0011       |\n",
            "|    std                  | 0.939         |\n",
            "|    value_loss           | 1.54e+08      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 842          |\n",
            "|    iterations           | 57           |\n",
            "|    time_elapsed         | 692          |\n",
            "|    total_timesteps      | 583680       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021689632 |\n",
            "|    clip_fraction        | 0.00599      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.36        |\n",
            "|    explained_variance   | 4.94e-05     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.42e+07     |\n",
            "|    n_updates            | 560          |\n",
            "|    policy_gradient_loss | -0.00273     |\n",
            "|    std                  | 0.943        |\n",
            "|    value_loss           | 7.83e+07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 842          |\n",
            "|    iterations           | 58           |\n",
            "|    time_elapsed         | 705          |\n",
            "|    total_timesteps      | 593920       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024858923 |\n",
            "|    clip_fraction        | 0.00854      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.36        |\n",
            "|    explained_variance   | 6.43e-05     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.22e+08     |\n",
            "|    n_updates            | 570          |\n",
            "|    policy_gradient_loss | -0.00207     |\n",
            "|    std                  | 0.94         |\n",
            "|    value_loss           | 9.61e+07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 841          |\n",
            "|    iterations           | 59           |\n",
            "|    time_elapsed         | 717          |\n",
            "|    total_timesteps      | 604160       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013341615 |\n",
            "|    clip_fraction        | 0.00345      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.36        |\n",
            "|    explained_variance   | 1.06e-05     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.41e+08     |\n",
            "|    n_updates            | 580          |\n",
            "|    policy_gradient_loss | -0.00199     |\n",
            "|    std                  | 0.94         |\n",
            "|    value_loss           | 1.55e+08     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 841          |\n",
            "|    iterations           | 60           |\n",
            "|    time_elapsed         | 729          |\n",
            "|    total_timesteps      | 614400       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015632327 |\n",
            "|    clip_fraction        | 0.00774      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.36        |\n",
            "|    explained_variance   | 6.35e-05     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.7e+07      |\n",
            "|    n_updates            | 590          |\n",
            "|    policy_gradient_loss | -0.00179     |\n",
            "|    std                  | 0.94         |\n",
            "|    value_loss           | 7.71e+07     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 5.97e+03      |\n",
            "|    ep_rew_mean          | -1.72e+06     |\n",
            "| time/                   |               |\n",
            "|    fps                  | 842           |\n",
            "|    iterations           | 61            |\n",
            "|    time_elapsed         | 741           |\n",
            "|    total_timesteps      | 624640        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00067615346 |\n",
            "|    clip_fraction        | 0.00216       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.36         |\n",
            "|    explained_variance   | 5.58e-05      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 1.25e+08      |\n",
            "|    n_updates            | 600           |\n",
            "|    policy_gradient_loss | -0.00125      |\n",
            "|    std                  | 0.946         |\n",
            "|    value_loss           | 9.76e+07      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 841          |\n",
            "|    iterations           | 62           |\n",
            "|    time_elapsed         | 754          |\n",
            "|    total_timesteps      | 634880       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0010838842 |\n",
            "|    clip_fraction        | 0.00172      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.36        |\n",
            "|    explained_variance   | 1.81e-05     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.73e+07     |\n",
            "|    n_updates            | 610          |\n",
            "|    policy_gradient_loss | -0.00166     |\n",
            "|    std                  | 0.946        |\n",
            "|    value_loss           | 1.56e+08     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -1.72e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 841         |\n",
            "|    iterations           | 63          |\n",
            "|    time_elapsed         | 766         |\n",
            "|    total_timesteps      | 645120      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001458763 |\n",
            "|    clip_fraction        | 0.00382     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.36       |\n",
            "|    explained_variance   | 3.68e-05    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 8.32e+06    |\n",
            "|    n_updates            | 620         |\n",
            "|    policy_gradient_loss | -0.00224    |\n",
            "|    std                  | 0.947       |\n",
            "|    value_loss           | 1e+08       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -1.72e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 840         |\n",
            "|    iterations           | 64          |\n",
            "|    time_elapsed         | 779         |\n",
            "|    total_timesteps      | 655360      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002691894 |\n",
            "|    clip_fraction        | 0.00815     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.37       |\n",
            "|    explained_variance   | 8e-05       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.54e+07    |\n",
            "|    n_updates            | 630         |\n",
            "|    policy_gradient_loss | -0.00204    |\n",
            "|    std                  | 0.949       |\n",
            "|    value_loss           | 7.24e+07    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 840          |\n",
            "|    iterations           | 65           |\n",
            "|    time_elapsed         | 791          |\n",
            "|    total_timesteps      | 665600       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0006373439 |\n",
            "|    clip_fraction        | 0.00122      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.37        |\n",
            "|    explained_variance   | 2.74e-05     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 8.15e+07     |\n",
            "|    n_updates            | 640          |\n",
            "|    policy_gradient_loss | -0.00119     |\n",
            "|    std                  | 0.948        |\n",
            "|    value_loss           | 1.58e+08     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 841          |\n",
            "|    iterations           | 66           |\n",
            "|    time_elapsed         | 803          |\n",
            "|    total_timesteps      | 675840       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017694082 |\n",
            "|    clip_fraction        | 0.00673      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.37        |\n",
            "|    explained_variance   | 3.95e-05     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.04e+07     |\n",
            "|    n_updates            | 650          |\n",
            "|    policy_gradient_loss | -0.00161     |\n",
            "|    std                  | 0.949        |\n",
            "|    value_loss           | 9.64e+07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 840          |\n",
            "|    iterations           | 67           |\n",
            "|    time_elapsed         | 815          |\n",
            "|    total_timesteps      | 686080       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017091132 |\n",
            "|    clip_fraction        | 0.0038       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.37        |\n",
            "|    explained_variance   | 0.000107     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.67e+08     |\n",
            "|    n_updates            | 660          |\n",
            "|    policy_gradient_loss | -0.00193     |\n",
            "|    std                  | 0.953        |\n",
            "|    value_loss           | 1.18e+08     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 840          |\n",
            "|    iterations           | 68           |\n",
            "|    time_elapsed         | 828          |\n",
            "|    total_timesteps      | 696320       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0006906904 |\n",
            "|    clip_fraction        | 0.00163      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.38        |\n",
            "|    explained_variance   | 3.47e-05     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.88e+07     |\n",
            "|    n_updates            | 670          |\n",
            "|    policy_gradient_loss | -0.00179     |\n",
            "|    std                  | 0.961        |\n",
            "|    value_loss           | 1.61e+08     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 839          |\n",
            "|    iterations           | 69           |\n",
            "|    time_elapsed         | 841          |\n",
            "|    total_timesteps      | 706560       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024148354 |\n",
            "|    clip_fraction        | 0.0108       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.38        |\n",
            "|    explained_variance   | 9.18e-05     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.78e+06     |\n",
            "|    n_updates            | 680          |\n",
            "|    policy_gradient_loss | -0.00251     |\n",
            "|    std                  | 0.968        |\n",
            "|    value_loss           | 4.53e+07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 839          |\n",
            "|    iterations           | 70           |\n",
            "|    time_elapsed         | 853          |\n",
            "|    total_timesteps      | 716800       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0005808127 |\n",
            "|    clip_fraction        | 0.00174      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.39        |\n",
            "|    explained_variance   | 0.000113     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.12e+07     |\n",
            "|    n_updates            | 690          |\n",
            "|    policy_gradient_loss | -0.00126     |\n",
            "|    std                  | 0.966        |\n",
            "|    value_loss           | 1.21e+08     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 839          |\n",
            "|    iterations           | 71           |\n",
            "|    time_elapsed         | 865          |\n",
            "|    total_timesteps      | 727040       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017756398 |\n",
            "|    clip_fraction        | 0.00397      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.38        |\n",
            "|    explained_variance   | 1.96e-05     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.12e+08     |\n",
            "|    n_updates            | 700          |\n",
            "|    policy_gradient_loss | -0.00173     |\n",
            "|    std                  | 0.966        |\n",
            "|    value_loss           | 1.63e+08     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -1.72e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 839         |\n",
            "|    iterations           | 72          |\n",
            "|    time_elapsed         | 877         |\n",
            "|    total_timesteps      | 737280      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002006174 |\n",
            "|    clip_fraction        | 0.00795     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.39       |\n",
            "|    explained_variance   | 8.2e-05     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.95e+07    |\n",
            "|    n_updates            | 710         |\n",
            "|    policy_gradient_loss | -0.00241    |\n",
            "|    std                  | 0.979       |\n",
            "|    value_loss           | 4.27e+07    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 839          |\n",
            "|    iterations           | 73           |\n",
            "|    time_elapsed         | 890          |\n",
            "|    total_timesteps      | 747520       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011805701 |\n",
            "|    clip_fraction        | 0.00281      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.4         |\n",
            "|    explained_variance   | 0.0001       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.09e+07     |\n",
            "|    n_updates            | 720          |\n",
            "|    policy_gradient_loss | -0.002       |\n",
            "|    std                  | 0.978        |\n",
            "|    value_loss           | 1.22e+08     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 839          |\n",
            "|    iterations           | 74           |\n",
            "|    time_elapsed         | 902          |\n",
            "|    total_timesteps      | 757760       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0010564647 |\n",
            "|    clip_fraction        | 0.00147      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.4         |\n",
            "|    explained_variance   | 4.7e-05      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.29e+07     |\n",
            "|    n_updates            | 730          |\n",
            "|    policy_gradient_loss | -0.00154     |\n",
            "|    std                  | 0.98         |\n",
            "|    value_loss           | 1.62e+08     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 838          |\n",
            "|    iterations           | 75           |\n",
            "|    time_elapsed         | 915          |\n",
            "|    total_timesteps      | 768000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021703828 |\n",
            "|    clip_fraction        | 0.00711      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.4         |\n",
            "|    explained_variance   | 0.000237     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.93e+06     |\n",
            "|    n_updates            | 740          |\n",
            "|    policy_gradient_loss | -0.00223     |\n",
            "|    std                  | 0.983        |\n",
            "|    value_loss           | 7.47e+07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 838          |\n",
            "|    iterations           | 76           |\n",
            "|    time_elapsed         | 928          |\n",
            "|    total_timesteps      | 778240       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022321003 |\n",
            "|    clip_fraction        | 0.00711      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.4         |\n",
            "|    explained_variance   | 0.000144     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.51e+07     |\n",
            "|    n_updates            | 750          |\n",
            "|    policy_gradient_loss | -0.00251     |\n",
            "|    std                  | 0.987        |\n",
            "|    value_loss           | 9.13e+07     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 5.97e+03      |\n",
            "|    ep_rew_mean          | -1.72e+06     |\n",
            "| time/                   |               |\n",
            "|    fps                  | 838           |\n",
            "|    iterations           | 77            |\n",
            "|    time_elapsed         | 939           |\n",
            "|    total_timesteps      | 788480        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00082286727 |\n",
            "|    clip_fraction        | 0.00276       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.41         |\n",
            "|    explained_variance   | 1.76e-05      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 6.33e+07      |\n",
            "|    n_updates            | 760           |\n",
            "|    policy_gradient_loss | -0.00153      |\n",
            "|    std                  | 0.992         |\n",
            "|    value_loss           | 1.6e+08       |\n",
            "-------------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 5.97e+03   |\n",
            "|    ep_rew_mean          | -1.72e+06  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 838        |\n",
            "|    iterations           | 78         |\n",
            "|    time_elapsed         | 952        |\n",
            "|    total_timesteps      | 798720     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00207581 |\n",
            "|    clip_fraction        | 0.00775    |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.41      |\n",
            "|    explained_variance   | 0.000343   |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 5.92e+07   |\n",
            "|    n_updates            | 770        |\n",
            "|    policy_gradient_loss | -0.0021    |\n",
            "|    std                  | 0.99       |\n",
            "|    value_loss           | 7.5e+07    |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 838          |\n",
            "|    iterations           | 79           |\n",
            "|    time_elapsed         | 964          |\n",
            "|    total_timesteps      | 808960       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012348039 |\n",
            "|    clip_fraction        | 0.00368      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.4         |\n",
            "|    explained_variance   | 0.000109     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 8.94e+07     |\n",
            "|    n_updates            | 780          |\n",
            "|    policy_gradient_loss | -0.00234     |\n",
            "|    std                  | 0.976        |\n",
            "|    value_loss           | 1.37e+08     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 837          |\n",
            "|    iterations           | 80           |\n",
            "|    time_elapsed         | 977          |\n",
            "|    total_timesteps      | 819200       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013980111 |\n",
            "|    clip_fraction        | 0.00468      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.4         |\n",
            "|    explained_variance   | 2.57e-05     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.42e+07     |\n",
            "|    n_updates            | 790          |\n",
            "|    policy_gradient_loss | -0.00218     |\n",
            "|    std                  | 0.979        |\n",
            "|    value_loss           | 1.13e+08     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 837          |\n",
            "|    iterations           | 81           |\n",
            "|    time_elapsed         | 990          |\n",
            "|    total_timesteps      | 829440       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026469612 |\n",
            "|    clip_fraction        | 0.00802      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.4         |\n",
            "|    explained_variance   | 0.000264     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.1e+06      |\n",
            "|    n_updates            | 800          |\n",
            "|    policy_gradient_loss | -0.00201     |\n",
            "|    std                  | 0.987        |\n",
            "|    value_loss           | 7.51e+07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 837          |\n",
            "|    iterations           | 82           |\n",
            "|    time_elapsed         | 1002         |\n",
            "|    total_timesteps      | 839680       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019047171 |\n",
            "|    clip_fraction        | 0.00567      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.41        |\n",
            "|    explained_variance   | 0.000147     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.44e+07     |\n",
            "|    n_updates            | 810          |\n",
            "|    policy_gradient_loss | -0.00245     |\n",
            "|    std                  | 0.989        |\n",
            "|    value_loss           | 1.39e+08     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 837          |\n",
            "|    iterations           | 83           |\n",
            "|    time_elapsed         | 1014         |\n",
            "|    total_timesteps      | 849920       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012054213 |\n",
            "|    clip_fraction        | 0.00488      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.41        |\n",
            "|    explained_variance   | 6.38e-05     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.4e+07      |\n",
            "|    n_updates            | 820          |\n",
            "|    policy_gradient_loss | -0.00217     |\n",
            "|    std                  | 0.99         |\n",
            "|    value_loss           | 1.11e+08     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 837          |\n",
            "|    iterations           | 84           |\n",
            "|    time_elapsed         | 1027         |\n",
            "|    total_timesteps      | 860160       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015825756 |\n",
            "|    clip_fraction        | 0.00603      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.41        |\n",
            "|    explained_variance   | 0.00034      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.15e+07     |\n",
            "|    n_updates            | 830          |\n",
            "|    policy_gradient_loss | -0.00215     |\n",
            "|    std                  | 0.995        |\n",
            "|    value_loss           | 7.53e+07     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -1.72e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 837         |\n",
            "|    iterations           | 85          |\n",
            "|    time_elapsed         | 1039        |\n",
            "|    total_timesteps      | 870400      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.000933382 |\n",
            "|    clip_fraction        | 0.00401     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.41       |\n",
            "|    explained_variance   | 0.000255    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.77e+07    |\n",
            "|    n_updates            | 840         |\n",
            "|    policy_gradient_loss | -0.00218    |\n",
            "|    std                  | 0.996       |\n",
            "|    value_loss           | 1.4e+08     |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 836          |\n",
            "|    iterations           | 86           |\n",
            "|    time_elapsed         | 1052         |\n",
            "|    total_timesteps      | 880640       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011818467 |\n",
            "|    clip_fraction        | 0.00497      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.41        |\n",
            "|    explained_variance   | 8.59e-05     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.99e+06     |\n",
            "|    n_updates            | 850          |\n",
            "|    policy_gradient_loss | -0.00297     |\n",
            "|    std                  | 0.992        |\n",
            "|    value_loss           | 1.24e+08     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 836          |\n",
            "|    iterations           | 87           |\n",
            "|    time_elapsed         | 1065         |\n",
            "|    total_timesteps      | 890880       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027088295 |\n",
            "|    clip_fraction        | 0.0115       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.41        |\n",
            "|    explained_variance   | 0.000457     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.6e+07      |\n",
            "|    n_updates            | 860          |\n",
            "|    policy_gradient_loss | -0.00322     |\n",
            "|    std                  | 0.983        |\n",
            "|    value_loss           | 9.31e+07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 836          |\n",
            "|    iterations           | 88           |\n",
            "|    time_elapsed         | 1077         |\n",
            "|    total_timesteps      | 901120       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011366915 |\n",
            "|    clip_fraction        | 0.00386      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.41        |\n",
            "|    explained_variance   | 0.000375     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.92e+07     |\n",
            "|    n_updates            | 870          |\n",
            "|    policy_gradient_loss | -0.00182     |\n",
            "|    std                  | 0.99         |\n",
            "|    value_loss           | 1.07e+08     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 836          |\n",
            "|    iterations           | 89           |\n",
            "|    time_elapsed         | 1088         |\n",
            "|    total_timesteps      | 911360       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012441336 |\n",
            "|    clip_fraction        | 0.00478      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.4         |\n",
            "|    explained_variance   | 0.000133     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.91e+07     |\n",
            "|    n_updates            | 880          |\n",
            "|    policy_gradient_loss | -0.00216     |\n",
            "|    std                  | 0.981        |\n",
            "|    value_loss           | 1.23e+08     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 836          |\n",
            "|    iterations           | 90           |\n",
            "|    time_elapsed         | 1101         |\n",
            "|    total_timesteps      | 921600       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019955223 |\n",
            "|    clip_fraction        | 0.00657      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.4         |\n",
            "|    explained_variance   | 0.000361     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.22e+07     |\n",
            "|    n_updates            | 890          |\n",
            "|    policy_gradient_loss | -0.00217     |\n",
            "|    std                  | 0.979        |\n",
            "|    value_loss           | 9.45e+07     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 5.97e+03      |\n",
            "|    ep_rew_mean          | -1.72e+06     |\n",
            "| time/                   |               |\n",
            "|    fps                  | 836           |\n",
            "|    iterations           | 91            |\n",
            "|    time_elapsed         | 1113          |\n",
            "|    total_timesteps      | 931840        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00084663107 |\n",
            "|    clip_fraction        | 0.0024        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.4          |\n",
            "|    explained_variance   | 0.000237      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 1.35e+08      |\n",
            "|    n_updates            | 900           |\n",
            "|    policy_gradient_loss | -0.00133      |\n",
            "|    std                  | 0.981         |\n",
            "|    value_loss           | 1.52e+08      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 836          |\n",
            "|    iterations           | 92           |\n",
            "|    time_elapsed         | 1126         |\n",
            "|    total_timesteps      | 942080       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015279475 |\n",
            "|    clip_fraction        | 0.00769      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.4         |\n",
            "|    explained_variance   | 0.000538     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.83e+07     |\n",
            "|    n_updates            | 910          |\n",
            "|    policy_gradient_loss | -0.00224     |\n",
            "|    std                  | 0.99         |\n",
            "|    value_loss           | 7.72e+07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 836          |\n",
            "|    iterations           | 93           |\n",
            "|    time_elapsed         | 1138         |\n",
            "|    total_timesteps      | 952320       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013409661 |\n",
            "|    clip_fraction        | 0.00505      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.4         |\n",
            "|    explained_variance   | 0.000279     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.28e+07     |\n",
            "|    n_updates            | 920          |\n",
            "|    policy_gradient_loss | -0.00218     |\n",
            "|    std                  | 0.974        |\n",
            "|    value_loss           | 9.49e+07     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 5.97e+03      |\n",
            "|    ep_rew_mean          | -1.72e+06     |\n",
            "| time/                   |               |\n",
            "|    fps                  | 836           |\n",
            "|    iterations           | 94            |\n",
            "|    time_elapsed         | 1150          |\n",
            "|    total_timesteps      | 962560        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00073924643 |\n",
            "|    clip_fraction        | 0.00433       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.4          |\n",
            "|    explained_variance   | 0.000127      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 5.27e+07      |\n",
            "|    n_updates            | 930           |\n",
            "|    policy_gradient_loss | -0.00189      |\n",
            "|    std                  | 0.98          |\n",
            "|    value_loss           | 1.53e+08      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 836          |\n",
            "|    iterations           | 95           |\n",
            "|    time_elapsed         | 1162         |\n",
            "|    total_timesteps      | 972800       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015558114 |\n",
            "|    clip_fraction        | 0.00689      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.4         |\n",
            "|    explained_variance   | 0.0011       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.77e+06     |\n",
            "|    n_updates            | 940          |\n",
            "|    policy_gradient_loss | -0.00238     |\n",
            "|    std                  | 0.986        |\n",
            "|    value_loss           | 7.6e+07      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 836          |\n",
            "|    iterations           | 96           |\n",
            "|    time_elapsed         | 1175         |\n",
            "|    total_timesteps      | 983040       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013832496 |\n",
            "|    clip_fraction        | 0.00486      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.4         |\n",
            "|    explained_variance   | 0.000286     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.9e+07      |\n",
            "|    n_updates            | 950          |\n",
            "|    policy_gradient_loss | -0.00221     |\n",
            "|    std                  | 0.976        |\n",
            "|    value_loss           | 9.63e+07     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 5.97e+03      |\n",
            "|    ep_rew_mean          | -1.72e+06     |\n",
            "| time/                   |               |\n",
            "|    fps                  | 836           |\n",
            "|    iterations           | 97            |\n",
            "|    time_elapsed         | 1187          |\n",
            "|    total_timesteps      | 993280        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00061796716 |\n",
            "|    clip_fraction        | 0.00242       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.4          |\n",
            "|    explained_variance   | 6.14e-05      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 4.23e+07      |\n",
            "|    n_updates            | 960           |\n",
            "|    policy_gradient_loss | -0.00144      |\n",
            "|    std                  | 0.981         |\n",
            "|    value_loss           | 1.53e+08      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 836          |\n",
            "|    iterations           | 98           |\n",
            "|    time_elapsed         | 1200         |\n",
            "|    total_timesteps      | 1003520      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012809443 |\n",
            "|    clip_fraction        | 0.00677      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.39        |\n",
            "|    explained_variance   | 0.00028      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.92e+07     |\n",
            "|    n_updates            | 970          |\n",
            "|    policy_gradient_loss | -0.00215     |\n",
            "|    std                  | 0.966        |\n",
            "|    value_loss           | 9.91e+07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 836          |\n",
            "|    iterations           | 99           |\n",
            "|    time_elapsed         | 1212         |\n",
            "|    total_timesteps      | 1013760      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024944604 |\n",
            "|    clip_fraction        | 0.00818      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.38        |\n",
            "|    explained_variance   | 0.000349     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.43e+06     |\n",
            "|    n_updates            | 980          |\n",
            "|    policy_gradient_loss | -0.00278     |\n",
            "|    std                  | 0.953        |\n",
            "|    value_loss           | 7.11e+07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 836          |\n",
            "|    iterations           | 100          |\n",
            "|    time_elapsed         | 1223         |\n",
            "|    total_timesteps      | 1024000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0009204586 |\n",
            "|    clip_fraction        | 0.00327      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.37        |\n",
            "|    explained_variance   | 8.86e-05     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.55e+07     |\n",
            "|    n_updates            | 990          |\n",
            "|    policy_gradient_loss | -0.00192     |\n",
            "|    std                  | 0.951        |\n",
            "|    value_loss           | 1.56e+08     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -1.72e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 836         |\n",
            "|    iterations           | 101         |\n",
            "|    time_elapsed         | 1236        |\n",
            "|    total_timesteps      | 1034240     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001425692 |\n",
            "|    clip_fraction        | 0.00737     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.37       |\n",
            "|    explained_variance   | 0.000152    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.67e+07    |\n",
            "|    n_updates            | 1000        |\n",
            "|    policy_gradient_loss | -0.00239    |\n",
            "|    std                  | 0.951       |\n",
            "|    value_loss           | 9.52e+07    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 836          |\n",
            "|    iterations           | 102          |\n",
            "|    time_elapsed         | 1248         |\n",
            "|    total_timesteps      | 1044480      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012360588 |\n",
            "|    clip_fraction        | 0.00525      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.37        |\n",
            "|    explained_variance   | 0.00034      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.5e+07      |\n",
            "|    n_updates            | 1010         |\n",
            "|    policy_gradient_loss | -0.00203     |\n",
            "|    std                  | 0.951        |\n",
            "|    value_loss           | 1.16e+08     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 835          |\n",
            "|    iterations           | 103          |\n",
            "|    time_elapsed         | 1261         |\n",
            "|    total_timesteps      | 1054720      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0007712502 |\n",
            "|    clip_fraction        | 0.00339      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.37        |\n",
            "|    explained_variance   | 0.00011      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.08e+08     |\n",
            "|    n_updates            | 1020         |\n",
            "|    policy_gradient_loss | -0.00174     |\n",
            "|    std                  | 0.946        |\n",
            "|    value_loss           | 1.59e+08     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 835          |\n",
            "|    iterations           | 104          |\n",
            "|    time_elapsed         | 1274         |\n",
            "|    total_timesteps      | 1064960      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021025832 |\n",
            "|    clip_fraction        | 0.013        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.36        |\n",
            "|    explained_variance   | 0.000191     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.81e+06     |\n",
            "|    n_updates            | 1030         |\n",
            "|    policy_gradient_loss | -0.0027      |\n",
            "|    std                  | 0.939        |\n",
            "|    value_loss           | 4.5e+07      |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -1.72e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 836         |\n",
            "|    iterations           | 105         |\n",
            "|    time_elapsed         | 1285        |\n",
            "|    total_timesteps      | 1075200     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001158942 |\n",
            "|    clip_fraction        | 0.00555     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.36       |\n",
            "|    explained_variance   | 0.000495    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.22e+07    |\n",
            "|    n_updates            | 1040        |\n",
            "|    policy_gradient_loss | -0.00209    |\n",
            "|    std                  | 0.949       |\n",
            "|    value_loss           | 1.19e+08    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 836          |\n",
            "|    iterations           | 106          |\n",
            "|    time_elapsed         | 1297         |\n",
            "|    total_timesteps      | 1085440      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015521125 |\n",
            "|    clip_fraction        | 0.00739      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.37        |\n",
            "|    explained_variance   | 7.25e-05     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 8.07e+07     |\n",
            "|    n_updates            | 1050         |\n",
            "|    policy_gradient_loss | -0.00271     |\n",
            "|    std                  | 0.948        |\n",
            "|    value_loss           | 1.61e+08     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 836          |\n",
            "|    iterations           | 107          |\n",
            "|    time_elapsed         | 1310         |\n",
            "|    total_timesteps      | 1095680      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018223582 |\n",
            "|    clip_fraction        | 0.0136       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.37        |\n",
            "|    explained_variance   | 0.00012      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.03e+06     |\n",
            "|    n_updates            | 1060         |\n",
            "|    policy_gradient_loss | -0.00226     |\n",
            "|    std                  | 0.952        |\n",
            "|    value_loss           | 4.2e+07      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 835          |\n",
            "|    iterations           | 108          |\n",
            "|    time_elapsed         | 1323         |\n",
            "|    total_timesteps      | 1105920      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021877098 |\n",
            "|    clip_fraction        | 0.00827      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.37        |\n",
            "|    explained_variance   | 0.000413     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.84e+06     |\n",
            "|    n_updates            | 1070         |\n",
            "|    policy_gradient_loss | -0.00257     |\n",
            "|    std                  | 0.95         |\n",
            "|    value_loss           | 1.2e+08      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 835          |\n",
            "|    iterations           | 109          |\n",
            "|    time_elapsed         | 1335         |\n",
            "|    total_timesteps      | 1116160      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014959481 |\n",
            "|    clip_fraction        | 0.00646      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.36        |\n",
            "|    explained_variance   | 5.04e-05     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.88e+07     |\n",
            "|    n_updates            | 1080         |\n",
            "|    policy_gradient_loss | -0.00241     |\n",
            "|    std                  | 0.943        |\n",
            "|    value_loss           | 1.6e+08      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 835          |\n",
            "|    iterations           | 110          |\n",
            "|    time_elapsed         | 1347         |\n",
            "|    total_timesteps      | 1126400      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024540613 |\n",
            "|    clip_fraction        | 0.0136       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.35        |\n",
            "|    explained_variance   | 0.000781     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.92e+07     |\n",
            "|    n_updates            | 1090         |\n",
            "|    policy_gradient_loss | -0.00263     |\n",
            "|    std                  | 0.926        |\n",
            "|    value_loss           | 7.38e+07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 836          |\n",
            "|    iterations           | 111          |\n",
            "|    time_elapsed         | 1359         |\n",
            "|    total_timesteps      | 1136640      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014115497 |\n",
            "|    clip_fraction        | 0.00779      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.34        |\n",
            "|    explained_variance   | 0.000248     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.82e+07     |\n",
            "|    n_updates            | 1100         |\n",
            "|    policy_gradient_loss | -0.00206     |\n",
            "|    std                  | 0.928        |\n",
            "|    value_loss           | 8.98e+07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 835          |\n",
            "|    iterations           | 112          |\n",
            "|    time_elapsed         | 1371         |\n",
            "|    total_timesteps      | 1146880      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011934356 |\n",
            "|    clip_fraction        | 0.00776      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.34        |\n",
            "|    explained_variance   | 0.000197     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.19e+07     |\n",
            "|    n_updates            | 1110         |\n",
            "|    policy_gradient_loss | -0.00235     |\n",
            "|    std                  | 0.928        |\n",
            "|    value_loss           | 1.58e+08     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -1.72e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 835          |\n",
            "|    iterations           | 113          |\n",
            "|    time_elapsed         | 1384         |\n",
            "|    total_timesteps      | 1157120      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021648002 |\n",
            "|    clip_fraction        | 0.0104       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.34        |\n",
            "|    explained_variance   | 0.00108      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.84e+07     |\n",
            "|    n_updates            | 1120         |\n",
            "|    policy_gradient_loss | -0.00191     |\n",
            "|    std                  | 0.923        |\n",
            "|    value_loss           | 7.4e+07      |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -1.72e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 835         |\n",
            "|    iterations           | 114         |\n",
            "|    time_elapsed         | 1397        |\n",
            "|    total_timesteps      | 1167360     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001296646 |\n",
            "|    clip_fraction        | 0.00579     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.34       |\n",
            "|    explained_variance   | 0.000275    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 9.01e+07    |\n",
            "|    n_updates            | 1130        |\n",
            "|    policy_gradient_loss | -0.00185    |\n",
            "|    std                  | 0.925       |\n",
            "|    value_loss           | 1.35e+08    |\n",
            "-----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "config = {\n",
        "    \"policy_type\": \"MultiInputPolicy\",\n",
        "    \"total_timesteps\": 1_500_000,\n",
        "}\n",
        "\n",
        "run = wandb.init(\n",
        "    project=\"4022_intelligent_ems\",\n",
        "    config=config,\n",
        "    sync_tensorboard=True,  # auto-upload sb3's tensorboard metrics\n",
        "    monitor_gym=True,  # auto-upload the videos of agents playing the game\n",
        "    save_code=True,  # optional\n",
        ")\n",
        "\n",
        "train_args = {\n",
        "                \"episode_len\"   : 6000,\n",
        "                \"actual_load\"   : actual_load,\n",
        "                \"actual_gen\"    : actual_gen,\n",
        "                \"bat_threshold\" : 100,\n",
        "                \"bat_cap\"       : 500,\n",
        "                \"purchase_price\": purchase_price,\n",
        "                \"num_preds\"     : 24,\n",
        "                \"load_shedding\" : load_shedding[2760:],\n",
        "                \"render_mode\"   : \"rgb_array\",\n",
        "                \"wandb_log\"     : True,\n",
        "                \"train_log\"     : True,\n",
        "\n",
        "                }\n",
        "\n",
        "eval_args = {\n",
        "                \"episode_len\"   :2760,\n",
        "                \"actual_load\"   :actual_load[6001:],\n",
        "                \"actual_gen\"    :actual_gen[6001:],\n",
        "                \"bat_threshold\" :100,\n",
        "                \"bat_cap\"       :500,\n",
        "                \"purchase_price\":purchase_price[6001:],\n",
        "                \"num_preds\"     :24,\n",
        "                \"load_shedding\" :load_shedding[6001:],\n",
        "                \"wandb_log\"     : True,\n",
        "                \"train_log\"     : False\n",
        "}\n",
        "\n",
        "#define 5 environments   for training and eval\n",
        "n_envs = 5\n",
        "n_eval_episodes =1\n",
        "train_env = make_vec_env(EMS, n_envs = n_envs,env_kwargs = train_args )\n",
        "\n",
        "\n",
        "eval_env = make_vec_env(EMS, n_envs = n_envs,env_kwargs = eval_args )\n",
        "\n",
        "\n",
        "wand_eval = f\"{version}_{model_type}_eval\"+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "wand_train = f\"{version}_{model_type}_train\"+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "wandb_callback = WandbCallback(\n",
        "                gradient_save_freq=100,\n",
        "                model_save_path=f\"models/{run.id}.{datetime.datetime.now()}\",\n",
        "                model_save_freq= 30000,\n",
        "                verbose=2,\n",
        "                log = \"all\",\n",
        "               )\n",
        "eval_callback = EvalCallback(eval_env,\n",
        "                             best_model_save_path = f\"{model_dir}{version}_{model_type}\"+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"),\n",
        "                             log_path = wand_eval,\n",
        "                             eval_freq=300,\n",
        "                             n_eval_episodes = n_eval_episodes,\n",
        "                             deterministic = True,\n",
        "                             render = False,\n",
        "                             callback_after_eval = wandb_callback)\n",
        "\n",
        "\n",
        "model = PPO(\"MultiInputPolicy\",train_env, verbose = 1, tensorboard_log = f\"runs/{run.id}\") #log_dir\n",
        "\n",
        "model.learn(total_timesteps= config[\"total_timesteps\"],\n",
        "            tb_log_name = wand_train,\n",
        "            reset_num_timesteps=False,\n",
        "            callback = wandb_callback\n",
        "            )\n",
        "\n",
        "model.save(f\"{model_dir}{version}_{model_type}\"+datetime.datetime.now().strftime(\"%m%d-%H%M%S\"))\n",
        "run.finish()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define a new test environment and load up the best performing model to test it.**"
      ],
      "metadata": {
        "id": "C9AGcLlsv4N7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inDHszZaxBUS"
      },
      "outputs": [],
      "source": [
        "config = {\n",
        "    \"policy_type\": \"MultiInputPolicy\",\n",
        "    \"total_timesteps\": 2760,\n",
        "}\n",
        "\n",
        "run = wandb.init(\n",
        "    project=\"4022_intelligent_ems\",\n",
        "    config=config,\n",
        "    sync_tensorboard=True,  # auto-upload sb3's tensorboard metrics\n",
        "    monitor_gym=True,  # auto-upload the videos of agents playing the game\n",
        "    save_code=True,  # optional\n",
        ")\n",
        "\n",
        "\n",
        "eval_args = {\n",
        "                \"episode_len\"   :2760,\n",
        "                \"actual_load\"   :actual_load[6001:],\n",
        "                \"actual_gen\"    :actual_gen[6001:],\n",
        "                \"bat_threshold\" :100,\n",
        "                \"bat_cap\"       :500,\n",
        "                \"purchase_price\":purchase_price[6001:],\n",
        "                \"num_preds\"     :6,\n",
        "                \"load_shedding\" :load_shedding[6001:],\n",
        "                \"wandb_log\"     : True,\n",
        "                \"train_log\"     : False\n",
        "}\n",
        "\n",
        "#define 5 environments   for training and eval\n",
        "n_envs = 1\n",
        "eval_env = make_vec_env(EMS, n_envs = n_envs,env_kwargs = eval_args )\n",
        "\n",
        "\n",
        "#first run it with only standby (default)\n",
        "obs   = eval_env.reset()\n",
        "#ensure that the exit condition is reset\n",
        "done = [False]*n_envs\n",
        "#define the action to take\n",
        "action_standby = [0]*n_envs\n",
        "#reset score\n",
        "standby_score = [0]*n_envs\n",
        "standby_score = np.array(standby_score).astype(np.float32)\n",
        "while not all(done):\n",
        "    #step the model with the action\n",
        "    obs,reward,done,info = eval_env.step(action_standby)\n",
        "    #accumulate the score\n",
        "    standby_score += reward\n",
        "obs,reward,done,info = eval_env.step(action_standby)\n",
        "\n",
        "avg_standby_score = standby_score.mean()\n",
        "\n",
        "run.finish()\n",
        "\n",
        "eval_args = {\n",
        "                \"episode_len\"   :2760,\n",
        "                \"actual_load\"   :actual_load[6001:],\n",
        "                \"actual_gen\"    :actual_gen[6001:],\n",
        "                \"bat_threshold\" :100,\n",
        "                \"bat_cap\"       :500,\n",
        "                \"purchase_price\":purchase_price[6001:],\n",
        "                \"num_preds\"     :6,\n",
        "                \"load_shedding\" :load_shedding[6001:],\n",
        "                \"wandb_log\"     : True,\n",
        "                \"train_log\"     : False\n",
        "}\n",
        "\n",
        "#define 5 environments   for training and eval\n",
        "n_envs = 5\n",
        "eval_env = make_vec_env(EMS, n_envs = n_envs,env_kwargs = eval_args )\n",
        "\n",
        "#Load model, fetch the latest (or whichever one you want from the model_dir)\n",
        "#Best A2C model:/content/drive/MyDrive/Colab Notebooks/EMSv1_1/models/A2C/EMSv1_1_A2C1010-081818.zip\n",
        "best_model = \"/content/drive/MyDrive/Colab Notebooks/EMSv1_1/models/A2C/EMSv1_1_A2C1010-081818.zip\"\n",
        "#best_model =\n",
        "#best_PPO_model\n",
        "model_load = f\"{best_model}\"\n",
        "\n",
        "#model  = A2C.load(model_load, env = eval_env)\n",
        "\n",
        "run = wandb.init(\n",
        "    project=\"4022_intelligent_ems\",\n",
        "    config=config,\n",
        "    sync_tensorboard=True,  # auto-upload sb3's tensorboard metrics\n",
        "    monitor_gym=True,  # auto-upload the videos of agents playing the game\n",
        "    save_code=True,  # optional\n",
        ")\n",
        "obs   = eval_env.reset()\n",
        "EMS_reward,EMS_std_reward = evaluate_policy(model,eval_env,n_eval_episodes = 1,deterministic=True)# callback = wandb_callback\n",
        "run.finish()\n",
        "\n",
        "print(f\"Note: The term does not refer to the cost in rands but rather to the reward as defined by the reward function!\")\n",
        "print(f\"Done the Standby Test! Total cost accumulated is: {avg_standby_score}\")\n",
        "print(f\"Done applying the trained model! Total cost accumulated is: {EMS_reward} +- {EMS_std_reward}\")\n",
        "\n",
        "savings = EMS_reward - avg_standby_score\n",
        "print(f\"The amount that was saved by applying the EMS agent: {savings}\")\n",
        "print(f\"This was saved over a period of {2760/24} days\")\n",
        "print(f\"The savings represents {(savings/(-avg_standby_score))*100} % of the cost if no EMS is installed\")\n",
        "print(f\"And it represents {(savings/(-EMS_reward))*100} % of the cost if the EMS is installed\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}