{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Julian-Banks/EEE4022S_BNKJUL001_Thesis/blob/main/PythonWorkspace/EMSv2_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "V6yT1Kii6fZb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Version Notes**\n",
        "\n",
        "# **v2.7**\n",
        " **options**\n",
        " * decreased unmet demand penalty\n",
        " * include real forecasts\n",
        " * include demand charge\n",
        " * try either of these options with or without loadshedding?\n",
        "\n",
        "#**v2.6**\n",
        "*clean up of code\n",
        "\n",
        "#**v2.5**\n",
        "* getting rid of the shorter episodes and going back to the normal approach\n",
        "* reworked normalisation so that the power bal and the battery level are scaled using the same transform. The idea being that the units should be the same and thus the scales?\n",
        "* changed action space to be centered on -1,1\n",
        "*removed demand charge to try and get it to learn how to manage a continuous space first.\n",
        "\n",
        "\n",
        "# **v2.4**\n",
        "* going to have shorter episodes (one month long)\n",
        "* hope the agent can learn to expect the demand charge every 30 days.\n",
        "* fixed a bug with the purchase_price\n",
        "\n",
        "# **v2.3**\n",
        "* Flattening observation space\n",
        "* increasing learning rates\n",
        "* decreasing vf_coef\n",
        "\n",
        "# **v2.2**\n",
        " **Added:**\n",
        " * normalising values. it is time to do this.....\n",
        "\n",
        "# **v2.1**\n",
        "\n",
        "**Added:**\n",
        " * changed reward structure to give a penalty every time the agent reaches a new max demand.\n",
        " * changed obs to include max_demand\n",
        "\n",
        "# **v2.0**\n",
        "*\n",
        "Adding a continous action space! Yolo\n",
        "\n",
        "# **v1.2**\n",
        "**Added:**\n",
        "* Diesel Generator action to mitigate unmet-load\n",
        "* reward based off real prices + demand charge - Demand charge has fucked the agent cause it buys in bulk! - might be time for the continous action space so it can decide how much to buy......\n",
        "\n",
        "**To Do:**\n",
        "* impliment a priority load - not gonna do this, just gonna have unmet load\n",
        "\n",
        "* Add in actual predictions, eish\n",
        "\n",
        "* figure out how to have more episodes!! I think it will have big performance boosts on the training :)\n",
        "\n",
        "* thinking that maybe I should change obs space back to what it was cause I dont actully need to know individual loads and gens!!!!\n",
        "\n",
        "# **v1.1**\n",
        "\n",
        "**Added:**\n",
        "* rect and inverter power tracking\n",
        "* reward logging in my own logging func\n",
        "* changed logging vars to arrays\n",
        "*\n",
        "\n",
        "**To Do**\n",
        "\n",
        "* battery charging rates - I think my assumption is fine.\n",
        "\n",
        "* tweak visualisation to show bar graphs at the end of training/testing. Maybe just print graphs at the end? I have added plt.show() - remember to play if it doesnt work!\n",
        "\n",
        "* impliment a generator!!!!!\n",
        "* impliment a priority load\n",
        "\n",
        "* NB figure out how to have more episodes!! I think it will have big performance boosts on the training :)\n",
        "\n",
        "* thinking that maybe I should change obs space back to what it was cause I dont actully need to know individual loads and gens!!!!\n",
        "\n",
        "# **v1.0**\n",
        "\n",
        "**Added:**\n",
        "* AC and DC load\n",
        "* Wind Gen\n",
        "* changed obs space to hold new loads\n",
        "* re wrote standby and purchase functions\n",
        "\n",
        "**To DO**\n",
        "* thinking that maybe I should change obs space back to what it was cause I dont actully need to know individual loads and gens!!!!\n",
        "* Add in rectifier & inverter power tracking\n",
        "* battery charging rates\n",
        "\n",
        "\n",
        "# **v0.3**\n",
        "**Added:**\n",
        "* loadshedding\n",
        "* New reward structure\n",
        "* added Vec_env\n",
        "* added eval callbacks to validate training\n",
        "* added in logging\n",
        "\n",
        "**Parameters:**\n",
        "* Added in loadshedding forecast\n",
        "\n",
        "**To do:**\n",
        "* find out about battery charging rates  & impliment\n",
        "* Find out if I need to normalise\n",
        "* Try dqn\n",
        "* Find out how the bounds for the obs_space box effect things\n",
        "* Try play with DummyVec wrapper (didnt work in last version)\n",
        "\n",
        "# **v0.2_1**\n",
        "**Added:**\n",
        "*  Monitor wrapper\n",
        "*  DummyVec wrapper\n",
        "*  Wand (weights and bais) enabled\n",
        "\n",
        "**Parameters:**\n",
        "* lowered to 3 predictions  \n",
        "\n",
        "**To do:**\n",
        "* Try to use hyperparameter Optimisation - decided Im only going to do on the final version\n",
        "* Try normalise\n",
        "* Try differnet models\n",
        "* Find out how the bounds for the obs_space box effect things\n",
        "\n",
        "# **v0.2**\n",
        "**Added:**\n",
        "*  simplified load_forecast and gen_forecast to be power_bal_forecasts.\n",
        "*  combined current_load and current_gen to also show current_power_balance\n",
        "*  added proper evaluate call\n",
        "\n",
        "**Parameters:**\n",
        "* No changes  \n",
        "\n",
        "**Results:**\n",
        "* 5% savings on PPO deterministic = true\n",
        "* 4.3% savings on PPO determnistic = false\n",
        "\n",
        "**To do:**\n",
        "* Try to use hyperparameter Optimisation\n",
        "* Try normalise\n",
        "* Try differnet models\n",
        "* Try see if discount rate can be tweaked - at good level.\n",
        "* Find out how the bounds for the obs_space box effect things\n",
        "\n",
        "# **v0.1**\n",
        "**Added:**\n",
        "* added real loads, gen, tou_id's\n",
        "\n",
        "**Parameters:**\n",
        "* training episode = 6000 timesteps\n",
        "* testing episode  = 2760 timesteps\n",
        "* bat_threshold = 100\n",
        "* bat_cap = 500\n",
        "* battery_level at reset = bat_cap/2\n",
        "* num_preds = 24\n",
        "* Trained PPO for 1.65mil timesteps\n",
        "* Trained A2C for 1.2 mil timesteps\n",
        "\n",
        "**Results:**\n",
        "* PP0 - 3.7% improvement from standby mode Deterministic = False\n",
        "* PPO - 6.1% Deterministic =  True\n",
        "* A2C  - -0.3% improvement. And the models after this got worse as training progressed!\n",
        "**To do:**\n",
        "* Try lower num_preds\n",
        "* Try to use hyperparameter Optimisation\n",
        "* Try normalise\n",
        "* Try differnet models\n",
        "* Try see if discount rate can be tweaked\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5DZFnZnzStt1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nI52iVVCCPaf"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "#install dependancies\n",
        "!pip install gymnasium\n",
        "!pip install stable_baselines3[extra]\n",
        "!pip install wandb\n",
        "!pip install sklearn\n",
        "!pip install scipy\n",
        "%load_ext tensorboard\n",
        "\n",
        "#clone repository\n",
        "! git clone https://github.com/Julian-Banks/EEE4022S_BNKJUL001_Thesis\n",
        "\n",
        "#to update the rep\n",
        "%cd /content/EEE4022S_BNKJUL001_Thesis\n",
        "! git pull\n",
        "#import needed libarys\n",
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "from gymnasium import spaces\n",
        "import datetime\n",
        "from stable_baselines3 import PPO, A2C, DQN,DDPG\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from stable_baselines3.common.callbacks import EvalCallback\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.vec_env import VecVideoRecorder\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.animation import FuncAnimation\n",
        "from gym.wrappers import FlattenObservation\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from google.colab import drive\n",
        "import os\n",
        "import wandb\n",
        "from wandb.integration.sb3 import WandbCallback\n",
        "from gymnasium.envs.registration import register\n",
        "import scipy.io\n",
        "from typing import Callable\n",
        "\n",
        "\n",
        "#mount the drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#define paths to logs and model saves\n",
        "model_type = \"PPO\"\n",
        "version    = \"EMSv2_7\"\n",
        "model_dir = f\"/content/drive/MyDrive/Colab Notebooks/{version}/models/{model_type}/\"\n",
        "log_dir   = f\"/content/drive/MyDrive/Colab Notebooks/{version}/models/{model_type}logs/\"\n",
        "\n",
        "#make the appropriate directory if it does not exist\n",
        "if not os.path.exists(model_dir):\n",
        "    os.makedirs(model_dir)\n",
        "if not os.path.exists(log_dir):\n",
        "    os.makedirs(log_dir)\n"
      ],
      "metadata": {
        "id": "SIpnNCVVRTV8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6edc6878-2531-4b94-95ad-6202121bfe8b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define our environment class!!**"
      ],
      "metadata": {
        "id": "Q99_jLMvwuZZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "s2iW-k26FIbm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64723684-bf78-4368-b43d-a1ef323456b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gymnasium/envs/registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment EMSv2_7 already in registry.\u001b[0m\n",
            "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n"
          ]
        }
      ],
      "source": [
        "class EMSv2_7(gym.Env):\n",
        "    \"\"\"Custom Environment that follows gym interface.\"\"\"\n",
        "\n",
        "    metadata = {\"render_modes\": [\"human\",\"rgb_array\"], \"render_fps\": 30}\n",
        "\n",
        "    def __init__(self,bat_threshold = 0.1, bat_cap = 1, actual_load = None, actual_gen = None, load_forecast = None , gen_forecast = None, purchase_price = [1,1,1,1,1,1,1,1,2,2,2,2] , episode_len = 8760,num_preds = 24,render_mode = \"rgb_array\", load_shedding = None, wandb_log = False,train_log = True, gen_size = 100,demand_charge = 252.92, demand_flag = True):\n",
        "\n",
        "        super(EMSv2_7, self).__init__()\n",
        "        #define render_mode\n",
        "        self.render_mode = render_mode\n",
        "        #define wandb\n",
        "        self.wandb_log = wandb_log\n",
        "        self.train_log = train_log\n",
        "        #define time frame\n",
        "        self.current_step = 0\n",
        "        self.final_step = int(episode_len)-num_preds-2\n",
        "        self.episode_len = int(episode_len)\n",
        "        #define num preds\n",
        "        self.num_preds = int(num_preds)\n",
        "        #define the battery max capacity\n",
        "        self.bat_cap =  np.float32(bat_cap)\n",
        "        #define the battery low threshold\n",
        "        self.bat_threshold = np.float32(bat_threshold)\n",
        "        #define demand charge\n",
        "        self.demand_charge = demand_charge\n",
        "        self.demand_flag = demand_flag\n",
        "        #define the size of the diesel_gen\n",
        "        self.gen_size = gen_size\n",
        "\n",
        "        #fill all of the actual loads\n",
        "        self.fill_load(actual_load)\n",
        "\n",
        "        #fill all of the actual generation steps.\n",
        "        self.fill_gen(actual_gen)\n",
        "\n",
        "        #fill the total power balance\n",
        "        self.fill_power_bal()\n",
        "\n",
        "        #Fill the loadShedding indicator\n",
        "        self.fill_shedding(load_shedding)\n",
        "\n",
        "        #define the purchase price for every step of the year\n",
        "        self.fill_price(purchase_price)\n",
        "\n",
        "        #Fill the load forecasts\n",
        "        self.fill_load_forecast(load_forecast)\n",
        "\n",
        "        #fill the gen Forecast\n",
        "        self.fill_gen_forecast(gen_forecast)\n",
        "\n",
        "        #action space is recomended to be -1 to 1. by stablebaslines due to the sampling distributions\n",
        "        self.action_scaler = MinMaxScaler(feature_range = (-1,1))\n",
        "        #set the lower bound of the action to 0, (requesting to buy 0 kw) and the upper to the max_avail capacity and the max load required.\n",
        "        self.action_scaler.fit_transform(np.array([0, 300]).reshape(-1,1))\n",
        "        #define the size of the action space\n",
        "        self.action_space = gym.spaces.Box(low= -1 , high =1)\n",
        "\n",
        "        # Dict space to store all the different things\n",
        "        self.observation_space = spaces.Dict({\n",
        "                \"power_bal_forecast\" : gym.spaces.Box(low=-1, high=1, shape=(1,num_preds), dtype=np.float32),\n",
        "                \"price_forecast\"     : gym.spaces.Box(low=0, high=1, shape=(1,num_preds+1), dtype=np.float32),\n",
        "                \"island_forecast\"    : gym.spaces.Box(low=0, high=1, shape=(1,num_preds+1), dtype=np.float32),\n",
        "                \"bat_level\"          : gym.spaces.Box(low=-1, high=1, shape=(1,), dtype=np.float32),\n",
        "                \"current_power_bal\"  : gym.spaces.Box(low=-1, high=1, shape=(1,), dtype=np.float32)\n",
        "                })\n",
        "        #flatten the observation space to a 1D vector so that it can be interperted more easily by the agent.\n",
        "        self.observation_space = spaces.flatten_space(self.observation_space)\n",
        "\n",
        "    def step(self, action):\n",
        "        #update the current state with the action (needs to be done before current_step is inc since we want to apply the action to the previous step to get the current state)\n",
        "        self.update_state(action)\n",
        "\n",
        "        #Calculate reward from the action\n",
        "        self.reward[self.current_step] = self.calc_reward()\n",
        "        reward = self.reward[self.current_step]\n",
        "\n",
        "        #Wand log, if its set to true(so that it only gets run when wandb is initialised)\n",
        "        # if train_log is false then every step is logged by the eval logger. (only the final step is logged by the train logger)\n",
        "        if self.train_log != True and self.wandb_log ==True:\n",
        "            self.wandb_logger()\n",
        "\n",
        "        #inc time step into Future\n",
        "        self.current_step += 1\n",
        "        #get the next observation for the agent (for next time step)\n",
        "        observation = self.get_obs()\n",
        "\n",
        "        #Set terminated to False since there are no failure states\n",
        "        self.terminated = False\n",
        "        #Check if timelimit reached\n",
        "        self.truncated = False if self.current_step<self.final_step else True\n",
        "        #if the episode is truncated, log the final step(both Training and Eval modes)\n",
        "        if self.truncated and self.wandb_log:\n",
        "            self.wandb_logger()\n",
        "\n",
        "        #requirement but I am not using it so it is empty\n",
        "        info = {}\n",
        "        return observation, reward, self.terminated, self.truncated, info\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        super().reset(seed = seed, options=options)\n",
        "        #reset the state\n",
        "        self.current_step = 0\n",
        "        self.terminated = False\n",
        "        self.truncated = False\n",
        "\n",
        "        #Reset values to run Grid\n",
        "        self.battery_level      = np.zeros(self.final_step+1)\n",
        "        self.battery_level[0]   = self.power_scaler.transform(np.array(self.bat_cap/2).reshape(-1,1))#set the intial battery level to half its capacity\n",
        "        self.reward             = np.zeros(self.final_step+1)\n",
        "        self.step_purchased     = np.zeros(self.final_step+1)\n",
        "\n",
        "        #Reset all of the other variables used to log\n",
        "        self.excess_gen         = np.zeros(self.final_step+1)\n",
        "        self.step_unmet_load    = np.zeros(self.final_step+1)\n",
        "        self.off_peak_purchases = np.zeros(self.final_step+1)\n",
        "        self.peak_purchases     = np.zeros(self.final_step+1)\n",
        "        self.standard_purchases = np.zeros(self.final_step+1)\n",
        "        self.off_peak_cost      = np.zeros(self.final_step+1)\n",
        "        self.standard_cost      = np.zeros(self.final_step+1)\n",
        "        self.peak_cost          = np.zeros(self.final_step+1)\n",
        "        self.step_invt          = np.zeros(self.final_step+1)\n",
        "        self.step_rect          = np.zeros(self.final_step+1)\n",
        "        self.diesel_gen         = np.zeros(self.final_step+1)\n",
        "        self.action_purchase    = np.zeros(self.final_step+1)\n",
        "        self.money_spent        = np.zeros(self.final_step+1)\n",
        "\n",
        "        #get the first observation\n",
        "        observation = self.get_obs()\n",
        "        #Still don't know what to do with info\n",
        "        info = {}\n",
        "        return observation, info\n",
        "\n",
        "    def render(self, mode='rgb_array', save_path=None):\n",
        "        pass\n",
        "\n",
        "    def close(self):\n",
        "        #don't think i need this for my application\n",
        "        pass\n",
        "\n",
        "\n",
        "\n",
        "    #MAIN HELPER FUNCTIONS\n",
        "    #######################################################################################################################################################################\n",
        "\n",
        "    def update_state(self, action):\n",
        "        #impliment the action into the environment\n",
        "        self.run_grid(purchase_amount = action)\n",
        "        #log the agents action (in kw)\n",
        "        self.action_purchase[self.current_step] = self.action_scaler.inverse_transform(np.array([action]).reshape(-1,1))\n",
        "        #calculate and log the purchases per Time of Use rate\n",
        "        self.tou_purchase_inc()\n",
        "        #Calculate the flow of power\n",
        "        #fetch info from grids\n",
        "        self.calc_power_flow()\n",
        "\n",
        "    def run_grid(self,purchase_amount):\n",
        "        #self.power_scaler.inverse_transform(self.actual_power_bal[self.current_step].reshap(-1,1))\n",
        "        #fetch info from grids\n",
        "        ac_power_bal, avail_grid = self.AC_bus()\n",
        "        dc_power_bal, avail_bat, avail_stor = self.DC_bus()\n",
        "        #fecth the current_battery level for this step.\n",
        "        current_battery_level =  self.power_scaler.inverse_transform(self.battery_level[self.current_step].reshape(-1,1))\n",
        "        #un-normalise the agents purchase request (its action)\n",
        "        purchase_amount_unnorm = self.action_scaler.inverse_transform(np.array([purchase_amount]).reshape(-1,1))\n",
        "\n",
        "        if avail_grid: # if there is no loadshedding purchase the amount requested by the agent.\n",
        "            self.step_purchased[self.current_step] = purchase_amount_unnorm\n",
        "        else:          # if there is loadshedding then it the step purchased must be 0\n",
        "            self.step_purchased[self.current_step] = 0\n",
        "\n",
        "        #calculate the immediate power_bal, this is the AC power, DC power and the Amount that the agent has purchased\n",
        "        grid_power_bal = ac_power_bal + dc_power_bal + self.step_purchased[self.current_step]\n",
        "\n",
        "        #determine the flow of power:\n",
        "        if grid_power_bal > 0 : #if the power balance is positive, the battery is charged and any remaing power is recorded in excess gen\n",
        "            #Set the battery_level for the next step to the current battery plus the exces. Using minimium between avail_stor and grid_power_bal ensures that the battery is only charged to its max capacity.\n",
        "            self.battery_level[self.current_step+1] =  self.power_scaler.transform(current_battery_level+ min(avail_stor, grid_power_bal))\n",
        "            #increments excess gen by the max. If grid_power_bal - avail_stor is negative, there was no excess and it will add 0, else it will add the excess that couln't be stored.\n",
        "            self.excess_gen[self.current_step] = max((grid_power_bal - avail_stor), 0)\n",
        "        else:\n",
        "            #there is a shortage of power since the balance is negative, see if we can take it from the battery.\n",
        "            #set the battery level for the next step. If the battery has the avail capacity to meet the demand, then the demand is subtracted. If the battery does not then the avail_battery is subtracted. This prevents over discharge.\n",
        "            self.battery_level[self.current_step+1] = self.power_scaler.transform(current_battery_level + max(-avail_bat, grid_power_bal))\n",
        "\n",
        "            #check if there is still a shortage of power after the battery has been discharged.\n",
        "            grid_power_bal_discharged = grid_power_bal + min(avail_bat,-grid_power_bal)\n",
        "            #if there is still a shortage, Check if it can be purchased from the grid or if it will be added to unmet_load\n",
        "            if grid_power_bal_discharged  < 0 :\n",
        "            #check if we are islanded and buy elec if we arent\n",
        "                if avail_grid:\n",
        "                    #set the purchased amount for the step to be the amount purchased already, and the remaining amount needed to balance the power.\n",
        "                    self.step_purchased[self.current_step] = purchase_amount_unnorm + -grid_power_bal_discharged\n",
        "                else:\n",
        "                    #if the grid is not available, run the generator\n",
        "                    #the amount of generation provided by the generator is limited by its size\n",
        "                    self.diesel_gen[self.current_step] = min(-grid_power_bal_discharged,self.gen_size)\n",
        "                    #calulate grid_power_bal after the diesel generator has been used\n",
        "                    grid_power_bal_with_diesel = grid_power_bal_discharged + min(-grid_power_bal_discharged,self.gen_size)\n",
        "                    if grid_power_bal_with_diesel < 0:\n",
        "                        self.step_unmet_load[self.current_step] = -grid_power_bal_with_diesel\n",
        "\n",
        "    def calc_reward(self):\n",
        "        #Calculate reward based on the state\n",
        "        #cost of running generator in that step\n",
        "        petrol_per_kw  = 0.4*23 #0.4l per kwh produced multipled by a cost of 23 rand per litre. Very rough values\n",
        "        diesel_cost     = petrol_per_kw*self.diesel_gen[self.current_step]\n",
        "        #cost of purchasing electricity in that step\n",
        "        elec_purchase   = self.step_purchased[self.current_step]*self.price_scaler.inverse_transform(self.purchase_price[self.current_step].reshape(-1,1)).flatten()\n",
        "\n",
        "        #Penality for unmet_load\n",
        "        unmet_load_pen  = self.step_unmet_load[self.current_step]*10\n",
        "\n",
        "        demand_penalty = self.get_demand_penalty()\n",
        "        demand_charge = self.get_demand_charge()\n",
        "\n",
        "        if self.demand_flag:\n",
        "            #Calculate the reward (monetary cost and the added penality for unmet_load!)\n",
        "            reward = -elec_purchase - unmet_load_pen - diesel_cost - demand_penalty\n",
        "            #record the money spent in this step\n",
        "            self.money_spent[self.current_step] =  elec_purchase +  diesel_cost + demand_charge\n",
        "        else:\n",
        "            #Calculate the reward (monetary cost and the added penality for unmet_load!)\n",
        "            reward = -elec_purchase - unmet_load_pen - diesel_cost\n",
        "            #record the money spent in this step\n",
        "            self.money_spent[self.current_step] =  elec_purchase +  diesel_cost\n",
        "        return reward\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def get_obs(self):\n",
        "        #Fill the observation space with the next observation\n",
        "\n",
        "        #calculate the power forecast\n",
        "        power_bal_forecast = self.get_forecast() #self.actual_power_bal[self.current_step+1: self.current_step + self.num_preds+1]\n",
        "\n",
        "        #get the prices for the current frame and the next 24 hours. Maybe will cut this down since that seems like a lot of info\n",
        "        price_forecast = np.array( [self.purchase_price[self.current_step:self.current_step+self.num_preds+1]] , dtype = np.float32).reshape(1,self.num_preds+1)\n",
        "        #Just for readibility of the dict object\n",
        "        bat_level      = np.array([self.battery_level[self.current_step]] , dtype= np.float32)\n",
        "\n",
        "        #island forecasst, same as tou forecast\n",
        "        island_forecast =np.array( [self.load_shed[self.current_step:self.current_step+self.num_preds+1]] , dtype = np.float32)\n",
        "\n",
        "        #calculate the current power balance\n",
        "        current_power_bal = self.actual_power_bal[self.current_step]\n",
        "\n",
        "        obs = dict({\n",
        "                \"bat_level\":      bat_level,\n",
        "                \"current_power_bal\" :   current_power_bal,\n",
        "                \"island_forecast\": island_forecast,\n",
        "                \"power_bal_forecast\":  power_bal_forecast,\n",
        "                \"price_forecast\": price_forecast,\n",
        "\n",
        "        })\n",
        "        #flatten the obs to make it the correct shape. 1D array\n",
        "        obs = np.concatenate([obs[key].flatten() for key in obs.keys()])\n",
        "        return obs\n",
        "\n",
        "    def wandb_logger(self):\n",
        "\n",
        "        train_log_dict={\n",
        "                    \"Excess Generation\"         :np.sum(self.excess_gen),\n",
        "                    \"Unmet Load\"                :np.sum(self.step_unmet_load),\n",
        "                    \"Off-Peak Purchases\"        :np.sum(self.off_peak_purchases),\n",
        "                    \"Standard Purchases\"        :np.sum(self.standard_purchases),\n",
        "                    \"Peak Purchases\"            :np.sum(self.peak_purchases),\n",
        "                    \"Num Off-Peak Purchases\"    :np.count_nonzero(self.off_peak_purchases),\n",
        "                    \"Num Standard Purchases\"    :np.count_nonzero(self.standard_purchases),\n",
        "                    \"Num Peak Purchases\"        :np.count_nonzero(self.peak_purchases),\n",
        "                    \"Total Elec Purchase\"       :np.sum(self.step_purchased),\n",
        "                    \"Total Purchase Requested\"  :np.sum(self.action_purchase),\n",
        "                    \"Num Diesel Gen Actions\"    :np.count_nonzero(self.diesel_gen),\n",
        "                    \"Total Reward\"              :np.sum(self.reward),\n",
        "                    \"Total Money spent\"         :np.sum(self.money_spent),\n",
        "                    \"Rectifier total power flow\":np.sum(self.step_rect),\n",
        "                    \"Inverter total power flow\" :np.sum(self.step_invt),\n",
        "                    \"Diesel Generator\"          :np.sum(self.diesel_gen),\n",
        "                    \"Max Demand\"                :np.max(self.step_purchased),\n",
        "                    \"total Purchased Elec\"      :np.sum(self.step_purchased)\n",
        "                    }\n",
        "\n",
        "        eval_log_dict={\n",
        "                    \"battery_level\"             :self.power_scaler.inverse_transform(self.battery_level[self.current_step].reshape(-1,1)).flatten(),\n",
        "                    \"AC load\"                   :self.actual_load[self.current_step,0],\n",
        "                    \"DC load\"                   :self.actual_load[self.current_step,1],\n",
        "                    \"Wind generation\"           :self.actual_gen[self.current_step,0],\n",
        "                    \"PV generation\"             :self.actual_gen[self.current_step,1],\n",
        "                    \"Excess Generation\"         :self.excess_gen[self.current_step],\n",
        "                    \"Unmet Load\"                :self.step_unmet_load[self.current_step],\n",
        "                    \"LoadShedding\"              :self.load_shed[self.current_step],\n",
        "                    \"Off-Peak Purchases\"        :self.off_peak_purchases[self.current_step],\n",
        "                    \"Standard Purchases\"        :self.standard_purchases[self.current_step],\n",
        "                    \"Peak Purchases\"            :self.peak_purchases[self.current_step],\n",
        "                    \"Num Off-Peak Purchases\"    :np.count_nonzero(self.off_peak_purchases),\n",
        "                    \"Num Standard Purchases\"    :np.count_nonzero(self.standard_purchases),\n",
        "                    \"Num Peak Purchases\"        :np.count_nonzero(self.peak_purchases),\n",
        "                    \"Step Purchased\"            :self.step_purchased[self.current_step],\n",
        "                    \"Purchase Requested\"        :self.action_purchase[self.current_step],\n",
        "                    \"Num Diesel Gen Actions\"    :np.count_nonzero(self.diesel_gen),\n",
        "                    \"Total Reward\"              :self.reward[self.current_step],\n",
        "                    \"Money Spent\"               :self.money_spent[self.current_step],\n",
        "                    \"Rectifier total power flow\":self.step_rect[self.current_step],\n",
        "                    \"Inverter total power flow\" :self.step_invt[self.current_step],\n",
        "                    \"Diesel Generator\"          :self.diesel_gen[self.current_step],\n",
        "\n",
        "                    }\n",
        "\n",
        "        if self.train_log:\n",
        "            wandb.log(train_log_dict)\n",
        "        else:\n",
        "            wandb.log(eval_log_dict)\n",
        "\n",
        "        if self.train_log == False and self.current_step == self.final_step:\n",
        "\n",
        "            values = [[np.sum(self.off_peak_purchases),'Off Peak'], [np.sum(self.standard_purchases),'Standard'], [np.sum(self.peak_purchases),'Peak']]\n",
        "            table = wandb.Table(columns = [\"values\",\"labels\"],data=values)\n",
        "            Tou_purchases = wandb.plot.bar(table,\"labels\",\"values\", title=\"kWh per TOU tariff\")\n",
        "\n",
        "            values = [[np.sum(self.off_peak_cost),'Off Peak'], [np.sum(self.standard_cost),'Standard'], [np.sum(self.peak_cost),'Peak']]\n",
        "            table = wandb.Table(columns = [\"values\",\"labels\"],data=values)\n",
        "            Tou_purchase_cost = wandb.plot.bar(table,\"labels\",\"values\", title=\"Rands per TOU tariff\")\n",
        "\n",
        "            values = [[np.max(self.step_purchased),'Max demand'], [np.max(self.diesel_gen),'Max diesel gen'], [np.max(self.step_rect),'Max rectifier power'], [np.max(self.step_invt),'Max inverter power']]\n",
        "            table = wandb.Table(columns = [\"values\",\"labels\"],data=values)\n",
        "            max_metrics = wandb.plot.bar(table,\"labels\",\"values\", title=\"Sizing Metrics\")\n",
        "\n",
        "            values = [[np.sum(self.step_purchased),'Total Purchased'], [np.sum(self.action_purchase),'Total requested purchases'],[np.sum(self.excess_gen),'Total excess generation']]\n",
        "            table = wandb.Table(columns = [\"values\",\"labels\"],data=values)\n",
        "            total_metrics = wandb.plot.bar(table,\"labels\",\"values\", title=\"Total Metrics\")\n",
        "\n",
        "            values = [[np.sum(self.diesel_gen),'Total diesel generation'], [np.sum(self.step_unmet_load),'Total unmet load']]\n",
        "            table = wandb.Table(columns = [\"values\",\"labels\"],data=values)\n",
        "            total_diesel_unmet = wandb.plot.bar(table,\"labels\",\"values\", title=\"Total diesel and unmet load\")\n",
        "\n",
        "            values = [[np.sum(self.reward),'Total reward accumulated']]\n",
        "            table = wandb.Table(columns = [\"values\",\"labels\"],data=values)\n",
        "            total_reward = wandb.plot.bar(table,\"labels\",\"values\", title=\"Total reward\")\n",
        "\n",
        "            values = [[np.sum(self.money_spent),'Total money spent']]\n",
        "            table = wandb.Table(columns = [\"values\",\"labels\"],data=values)\n",
        "            total_spent = wandb.plot.bar(table,\"labels\",\"values\", title=\"Total money spent\")\n",
        "\n",
        "            wandb.log({ \"kWh purchased per TOU tariff\"  : Tou_purchases,\n",
        "                        \"Rands per TOU tariff\"          : Tou_purchase_cost,\n",
        "                        \"Max sizing metrics\"            : max_metrics,\n",
        "                        \"Total metrics\"                 : total_metrics,\n",
        "                        \"Total diesel and unmet load\"   : total_diesel_unmet,\n",
        "                        \"Total reward and money spent\"  :total_reward,\n",
        "                        \"Total money spent\"             :total_spent\n",
        "                        })\n",
        "\n",
        "\n",
        "\n",
        "    #AUXILIARY HELPER FUNCTIONS\n",
        "    #######################################################################################################################################################################\n",
        "    def calc_power_flow(self):\n",
        "        #fetch info from grids\n",
        "        ac_power_bal, _ = self.AC_bus()\n",
        "        dc_power_bal, _ , avail_stor = self.DC_bus()\n",
        "        #Calculate the flow of power (this is max absorb, the min need is just dc_power_bal)\n",
        "        dc_power_absorb = max(-dc_power_bal+avail_stor,0)\n",
        "        #calculate the Dc_power_avail, could go to battery or AC_grid\n",
        "        dc_power_avail = max(dc_power_bal,0) #lol just defined a new var for readability.\n",
        "        #ac power excess will be the power balance added to the purchase amount\n",
        "        ac_power_excess = max(ac_power_bal+self.step_purchased[self.current_step]+self.diesel_gen[self.current_step],0)\n",
        "         # calculate how much power the ac grid needs.\n",
        "        ac_power_need   = max(-ac_power_bal-self.step_purchased[self.current_step]-self.diesel_gen[self.current_step], 0)\n",
        "        #calculate how much power would be in excess if there was to be excess.\n",
        "        dc_power_excess = max(dc_power_avail - ac_power_need - avail_stor,0)\n",
        "\n",
        "        #the power that will flow through the rectifier is the minimum between the amount the DC grid can absorb and the excess the ac_grid has\n",
        "        #This definition implies that the AC subgrid will supply its own loads first and only then send excess to dc Grid?\n",
        "        rect_power = min(dc_power_absorb,ac_power_excess)\n",
        "\n",
        "        #inverter power is equal to the minimum val between the avail dc power and the needed power. Then since all excess power needs to go to the grid, if there is any extra energy after the ac_need has been met and the battery is fully charged, it is also sent through the inverter\n",
        "        #DC subgrid will meet the AC load before charging the battery. Will send excess across if the DC load is met and the battery is fully charged.\n",
        "        invt_power = min(ac_power_need, dc_power_avail) + dc_power_excess\n",
        "        #set the attributes.\n",
        "        self.step_invt[self.current_step] = invt_power\n",
        "        self.step_rect[self.current_step] = rect_power\n",
        "\n",
        "    def tou_purchase_inc(self):\n",
        "        #Summer Months: 5.92, 2.09, 1.33\n",
        "        #Winter Months: 2.22, 1.66, 1.21\n",
        "        #un normalise the price for that step.\n",
        "        step_price = self.price_scaler.inverse_transform(self.purchase_price[self.current_step].reshape(-1,1))\n",
        "        #the conditions are a bit janky due to the different prices in Summer and Winter.\n",
        "        if step_price < 1.5:\n",
        "            self.off_peak_purchases[self.current_step] = self.step_purchased[self.current_step]\n",
        "            self.off_peak_cost[self.current_step]      = self.step_purchased[self.current_step]*step_price\n",
        "        elif step_price < 2.1:\n",
        "            self.standard_purchases[self.current_step] = self.step_purchased[self.current_step]\n",
        "            self.standard_cost[self.current_step]      = self.step_purchased[self.current_step]*step_price\n",
        "        else:\n",
        "            self.peak_purchases[self.current_step] = self.step_purchased[self.current_step]\n",
        "            self.peak_cost[self.current_step]      = self.step_purchased[self.current_step]*step_price\n",
        "\n",
        "    def AC_bus(self):\n",
        "        #fill out info on the ac\n",
        "        ac_gen = self.actual_gen[self.current_step, 0]\n",
        "        ac_load = self.actual_load[self.current_step,0]\n",
        "        ac_power_bal = ac_gen - ac_load\n",
        "        #check if there is load shedding or not\n",
        "        avail_grid = not self.load_shed[self.current_step]\n",
        "        #return relevant values\n",
        "        return ac_power_bal,avail_grid\n",
        "\n",
        "    def DC_bus(self):\n",
        "        #fill in info for DC_bus\n",
        "        dc_gen       = self.actual_gen[self.current_step,1]\n",
        "        dc_load      = self.actual_load[self.current_step,1]\n",
        "        dc_power_bal = dc_gen - dc_load\n",
        "        #fetch and transform information about the battery cap and availability\n",
        "        avail_bat  = self.power_scaler.inverse_transform(self.battery_level[self.current_step].reshape(-1,1)) - self.bat_threshold\n",
        "        avail_stor = self.bat_cap   - self.power_scaler.inverse_transform(self.battery_level[self.current_step].reshape(-1,1))\n",
        "        return dc_power_bal, avail_bat, avail_stor\n",
        "\n",
        "\n",
        "    def fill_load(self,actual_load):\n",
        "        if actual_load is None :#if actual_load is a string then fill with random numbers\n",
        "            self.actual_load = np.random.rand(self.final_step+self.num_preds+1,2).astype(np.float32)\n",
        "        else:                           #else fill the load with the correct number of entries from the input\n",
        "            self.actual_load  = actual_load[:self.episode_len,:]\n",
        "\n",
        "    def fill_gen(self,actual_gen):\n",
        "        if actual_gen is None:#if actual_gen is a string then fill with random numbers\n",
        "            self.actual_gen  = np.random.rand(self.final_step+self.num_preds+1,2).astype(np.float32)\n",
        "        else:                           #else fill the gen with the correct number of entries from the input\n",
        "            self.actual_gen  = actual_gen[:self.episode_len,:]\n",
        "\n",
        "    def fill_load_forecast(self, load_forecast):\n",
        "        if load_forecast is None:\n",
        "            load_sum = self.actual_load.sum(axis = 1)\n",
        "            self.load_forecast = [load_sum[i+1:i+1+self.num_preds] for i in range(self.final_step+1)]\n",
        "            self.load_forecast = np.array(self.load_forecast).astype(np.float32)\n",
        "        else:\n",
        "            self.load_forecast = np.array(load_forecast[:self.final_step,:]).astype(np.float32)\n",
        "\n",
        "    def fill_gen_forecast(self, gen_forecast):\n",
        "        if gen_forecast is None:\n",
        "            gen_sum = self.actual_gen.sum(axis = 1)\n",
        "            self.gen_forecast = [gen_sum[i+1:i+1+self.num_preds] for i in range(self.final_step+1)]\n",
        "            self.gen_forecast = np.array(self.gen_forecast).astype(np.float32)\n",
        "        else:\n",
        "            self.gen_forecast = np.array(gen_forecast[:self.final_step,:]).astype(np.float32)\n",
        "\n",
        "    def fill_power_bal(self):\n",
        "        actual_power_bal = self.actual_gen-self.actual_load\n",
        "        if len(actual_power_bal.shape) >= 2:\n",
        "            actual_power_bal = actual_power_bal.sum(axis=1)\n",
        "        self.power_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "        #in order for the agent to see the kw in the battery in proportion to the kw in power_bal observations. I have included the bat_cap in the transform, and the battery level will be transformed using the same scaler.\n",
        "        self.power_scaler.fit_transform(np.array(actual_power_bal,self.bat_cap).reshape(-1,1))\n",
        "        self.actual_power_bal = self.power_scaler.transform(actual_power_bal.reshape(-1,1))\n",
        "\n",
        "    def fill_price(self,purchase_price):\n",
        "        purchase_price = np.array(purchase_price).astype(np.float32)\n",
        "        if len(purchase_price)<self.episode_len: #if the proved set of purchase prices is less than the episode length, wrap it so it fills the episode.\n",
        "            repetitions    = (self.final_step+self.num_preds+1) // len(purchase_price)\n",
        "            remainder      = (self.final_step+self.num_preds+1) % len(purchase_price)\n",
        "            self.purchase_price =np.concatenate([purchase_price]*repetitions+[purchase_price[:remainder]])#need to read in from somewhere\n",
        "        else:                                    #else extract the correct number of prices.\n",
        "            self.purchase_price = purchase_price[:self.episode_len]\n",
        "\n",
        "        price_scaler = MinMaxScaler(feature_range=(0,1)) #scale purchase prices to 0,1\n",
        "        self.purchase_price = price_scaler.fit_transform(self.purchase_price.reshape(-1, 1))\n",
        "        self.price_scaler = price_scaler\n",
        "\n",
        "    def fill_shedding(self,load_shedding):\n",
        "        if load_shedding is None: #if no loadshedding schedule has been provided then create a array with between 2-5% instances of loadshedding\n",
        "            num_shedding   = np.random.randint(int(0.02*self.episode_len), int(0.05*self.episode_len))\n",
        "            load_shed      = np.array([1]*num_shedding + [0]*(self.episode_len - num_shedding))\n",
        "            np.random.shuffle(load_shed)\n",
        "            self.load_shed = load_shed\n",
        "        else:                            #else if load shedding schedule is provided collect the correct number of instances\n",
        "            self.load_shed = load_shedding[:self.episode_len]\n",
        "\n",
        "    def get_forecast(self):\n",
        "        load_forecast =   (self.load_forecast[self.current_step,:self.num_preds]).reshape(-1,1)\n",
        "        gen_forecast  =   (self.gen_forecast[self.current_step,:self.num_preds]).reshape(-1,1)\n",
        "        power_bal_forecast = gen_forecast - load_forecast\n",
        "        power_bal_forecast = self.power_scaler.transform(power_bal_forecast.reshape(-1,1))\n",
        "        return power_bal_forecast\n",
        "\n",
        "    def get_demand_charge(self):\n",
        "        if self.current_step % (30*24) == 0:\n",
        "            if self.current_step > 0:\n",
        "                max_demand = max(self.step_purchased[max(0,self.current_step - 30*24) : self.current_step])\n",
        "            else:\n",
        "                max_demand = 0\n",
        "            demand_charge = max_demand * self.demand_charge\n",
        "        else:\n",
        "            demand_charge = 0\n",
        "        return demand_charge\n",
        "\n",
        "    def get_demand_penalty(self):\n",
        "        if self.current_step>0:\n",
        "            rolling_peak_demand = max(self.step_purchased[max(0, self.current_step-30*24):self.current_step])\n",
        "        else:\n",
        "            rolling_peak_demand = 0\n",
        "        rolling_peak_demand = 250\n",
        "        demand_penalty = np.exp(self.power_scaler.transform(self.step_purchased[self.current_step].reshape(-1,1)) - self.power_scaler.transform(np.array(rolling_peak_demand).reshape(-1,1)))*400\n",
        "        return demand_penalty\n",
        "#define a pointer (kinda, don't actually know what its called) a\n",
        "EMS = EMSv2_7\n",
        "\n",
        "# Register environment so I can use make_vec_env\n",
        "register(\n",
        "# unique identifier for the env `name-version`\n",
        "id=f\"{version}\",\n",
        "# path to the class for creating the env\n",
        "# Note: entry_point also accept a class as input (and not only a string)\n",
        "entry_point= EMS(),\n",
        "\n",
        ")\n",
        "\n",
        "#Check the environment with stable_baselines3 check_env.\n",
        "from stable_baselines3.common.env_checker import check_env\n",
        "env = EMS()\n",
        "check_env(env,warn = True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DG4gB2cM7tDY"
      },
      "source": [
        "**Load in the data for our specific microgrid.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "0X9RBdXC_2PD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ba248b6-bbad-4bf0-ad77-1a5811085691"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The reset observation space looks like: [ 0.07764236 -0.49452567  0.          0.          0.          0.\n",
            " -0.53609806 -0.528026   -0.45572138  0.          0.          0.\n",
            "  0.        ]\n",
            "After action 0: \n",
            "Battery level is: 0.07764235883951187kWh\n",
            "Current  Power Balance -0.494525671005249\n",
            "Forecasted  power bal 1 hour ahead: -0.536098062992096.\n",
            "Forecasted  power bal 2 hour ahead: -0.5280259847640991. \n",
            "Forecasted  power bal 3 hour ahead: -0.455721378326416. \n",
            "current Purchase Prcie: 0.0.\n",
            "Forecasted  price 1 hour ahead: 0.0. \n",
            "Forecasted  price 2 hour ahead: 0.0. \n",
            "Forecasted  price 3 hour ahead: 0.0. \n",
            "_________________________________________________________________________________________________________________\n",
            "\n",
            "After action 0: \n",
            "Battery level is: -0.07079396396875381kWh\n",
            "Current  Power Balance -0.536098062992096\n",
            "Forecasted  power bal 1 hour ahead: -0.5280259847640991.\n",
            "Forecasted  power bal 2 hour ahead: -0.455721378326416. \n",
            "Forecasted  power bal 3 hour ahead: -0.31690630316734314. \n",
            "current Purchase Prcie: 0.0.\n",
            "Forecasted  price 1 hour ahead: 0.0. \n",
            "Forecasted  price 2 hour ahead: 0.0. \n",
            "Forecasted  price 3 hour ahead: 0.0. \n",
            "_________________________________________________________________________________________________________________\n",
            "\n",
            "After action 0: \n",
            "Battery level is: -0.17659667134284973kWh\n",
            "Current  Power Balance -0.5280259847640991\n",
            "Forecasted  power bal 1 hour ahead: -0.455721378326416.\n",
            "Forecasted  power bal 2 hour ahead: -0.31690630316734314. \n",
            "Forecasted  power bal 3 hour ahead: -0.1943129003047943. \n",
            "current Purchase Prcie: 0.0.\n",
            "Forecasted  price 1 hour ahead: 0.0. \n",
            "Forecasted  price 2 hour ahead: 0.0. \n",
            "Forecasted  price 3 hour ahead: 0.0. \n",
            "_________________________________________________________________________________________________________________\n",
            "\n",
            "After action 0: \n",
            "Battery level is: -0.17659667134284973kWh\n",
            "Current  Power Balance -0.455721378326416\n",
            "Forecasted  power bal 1 hour ahead: -0.31690630316734314.\n",
            "Forecasted  power bal 2 hour ahead: -0.1943129003047943. \n",
            "Forecasted  power bal 3 hour ahead: 0.09753653407096863. \n",
            "current Purchase Prcie: 0.0.\n",
            "Forecasted  price 1 hour ahead: 0.0. \n",
            "Forecasted  price 2 hour ahead: 0.0. \n",
            "Forecasted  price 3 hour ahead: 0.09576204419136047. \n",
            "_________________________________________________________________________________________________________________\n",
            "\n",
            "After action 1: \n",
            "Battery level is: 0.2222493588924408kWh\n",
            "Current  Power Balance -0.31690627336502075\n",
            "Forecasted  power bal 1 hour ahead: -0.1943129003047943.\n",
            "Forecasted  power bal 2 hour ahead: 0.09753653407096863. \n",
            "Forecasted  power bal 3 hour ahead: 0.2722266912460327. \n",
            "current Purchase Prcie: 0.0.\n",
            "Forecasted  price 1 hour ahead: 0.0. \n",
            "Forecasted  price 2 hour ahead: 0.09576204419136047. \n",
            "Forecasted  price 3 hour ahead: 0.21427208185195923. \n",
            "_________________________________________________________________________________________________________________\n",
            "\n",
            "Done iteration! Total reward accumulated is: -2713291.054657737\n"
          ]
        }
      ],
      "source": [
        "#need to import data from Github\n",
        "path_data = \"/content/EEE4022S_BNKJUL001_Thesis/PythonWorkspace/dataClean.csv\"\n",
        "data = pd.read_csv(path_data)\n",
        "\n",
        "path_pv_gen = \"/content/EEE4022S_BNKJUL001_Thesis/Generation/BNKJUL001_Thesis_solarGen500kWHomer.csv\"\n",
        "data_pv_gen = pd.read_csv(path_pv_gen)\n",
        "\n",
        "path_wind_gen = \"/content/EEE4022S_BNKJUL001_Thesis/Generation/BNKJUL001_Thesis_Wind500kGenHomer.csv\"\n",
        "data_wind_gen = pd.read_csv(path_wind_gen)\n",
        "\n",
        "\n",
        "path_shedding = \"/content/EEE4022S_BNKJUL001_Thesis/MatlabWorkSpace/loadShedding2022.csv\"\n",
        "data_shedding = pd.read_csv(path_shedding)\n",
        "load_shedding = data_shedding['LoadShedding'].values.astype(np.float32)\n",
        "\n",
        "#load_forecasts = scipy.io.loadmat('load_forecasts.mat')\n",
        "#load_forecasts = load_forecasts['load_forecasts']\n",
        "\n",
        "#get the correct arrays from the data\n",
        "wind_gen = data_wind_gen['Wind_Out'].values.astype(np.float32)\n",
        "PV_gen = data_pv_gen['PV_Out'].values.astype(np.float32)\n",
        "actual_gen = np.column_stack((wind_gen, PV_gen))\n",
        "#read in ac and DC load\n",
        "AC_load = data['AC'].values.astype(np.float32)\n",
        "DC_load = data['DC'].values.astype(np.float32)\n",
        "#stack em together for the input :)\n",
        "actual_load = np.column_stack((AC_load, DC_load))\n",
        "\n",
        "path_purchase_price = \"/content/EEE4022S_BNKJUL001_Thesis/PythonWorkspace/purchasePrice.csv\"\n",
        "data_purchase_price = pd.read_csv(path_purchase_price)\n",
        "purchase_price = data_purchase_price['Grid Power Price'].values.astype(np.float32)\n",
        "\n",
        "#define the base environment\n",
        "base_env = EMS(episode_len = 6000, actual_load = actual_load, actual_gen = actual_gen, bat_threshold = 100, bat_cap = 500, purchase_price = purchase_price,num_preds = 3)\n",
        "#going to print out a bunch of things to test the different spaces.\n",
        "obs,_    = base_env.reset()\n",
        "\n",
        "def print_obs(action_standby=0):\n",
        "    print(f\"After action {action_standby}: \" )\n",
        "    battery_level = obs[0]\n",
        "    print(f\"Battery level is: {battery_level}kWh\")\n",
        "    current_power_bal = obs[1]\n",
        "    print(f\"Current  Power Balance {current_power_bal}\")\n",
        "    power_forecast = obs[6:9]\n",
        "    print(f\"Forecasted  power bal 1 hour ahead: {power_forecast[0]}.\")\n",
        "    print(f\"Forecasted  power bal 2 hour ahead: {power_forecast[1]}. \")\n",
        "    print(f\"Forecasted  power bal 3 hour ahead: {power_forecast[2]}. \")\n",
        "    price = obs[9:]\n",
        "    print(f\"current Purchase Prcie: {price[0]}.\")\n",
        "    print(f\"Forecasted  price 1 hour ahead: {price[1]}. \")\n",
        "    print(f\"Forecasted  price 2 hour ahead: {price[2]}. \")\n",
        "    print(f\"Forecasted  price 3 hour ahead: {price[3]}. \")\n",
        "    print(f\"_________________________________________________________________________________________________________________\")\n",
        "    print(f\"\")\n",
        "\n",
        "print(f\"The reset observation space looks like: {obs}\")\n",
        "\n",
        "print_obs()\n",
        "\n",
        "action_standby = -1\n",
        "obs,reward,terminated,truncated,info = base_env.step(action_standby)\n",
        "\n",
        "print_obs()\n",
        "\n",
        "obs,reward,terminated,truncated,info = base_env.step(action_standby)\n",
        "\n",
        "print_obs()\n",
        "\n",
        "\n",
        "obs,reward,terminated,truncated,info = base_env.step(action_standby)\n",
        "print_obs()\n",
        "\n",
        "action_standby = 1\n",
        "obs,reward,terminated,truncated,info = base_env.step(action_standby)\n",
        "print_obs(action_standby)\n",
        "\n",
        "#Evaluate the base model (no EMS, just using standby mode)\n",
        "#reset score\n",
        "score = 0\n",
        "obs,_    = base_env.reset()\n",
        "#ensure that the exit condition is reset\n",
        "truncated = False\n",
        "#define the action to take. -1 represents requesting to buy 0kw every step.\n",
        "action_standby = -1\n",
        "\n",
        "while not truncated:\n",
        "    obs,reward,terminated,truncated,info = base_env.step(action_standby)\n",
        "    score += reward\n",
        "\n",
        "print(f\"Done iteration! Total reward accumulated is: {score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pAj6-n04zyt"
      },
      "source": [
        "**LOAD OR MAKE MODEL HERE!**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def linear_schedule(initial_value: float) -> Callable[[float], float]:\n",
        "    \"\"\"\n",
        "    Linear learning rate schedule.\n",
        "\n",
        "    :param initial_value: Initial learning rate.\n",
        "    :return: schedule that computes\n",
        "      current learning rate depending on remaining progress\n",
        "    \"\"\"\n",
        "    def func(progress_remaining: float) -> float:\n",
        "        \"\"\"\n",
        "        Progress will decrease from 1 (beginning) to 0.\n",
        "\n",
        "        :param progress_remaining:\n",
        "        :return: current learning rate\n",
        "        \"\"\"\n",
        "        return progress_remaining * initial_value\n",
        "\n",
        "    return func\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnO0Jh7fcBcl",
        "outputId": "7237593a-801c-4130-ca69-b9e1daa823c8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "test environment and load up the best performing model to test it.**"
      ],
      "metadata": {
        "id": "C9AGcLlsv4N7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "inDHszZaxBUS"
      },
      "outputs": [],
      "source": [
        "def evaluate_current_model(note,loadshedding,demand_charge):\n",
        "\n",
        "    config = {\n",
        "        \"policy_type\": \"MlpPolicy\",\n",
        "        \"total_timesteps\": 2760,\n",
        "        \"notes\":f\"{note}_base\"\n",
        "    }\n",
        "\n",
        "    run = wandb.init(\n",
        "        project=\"4022_intelligent_ems\",\n",
        "        config=config,\n",
        "        sync_tensorboard=True,  # auto-upload sb3's tensorboard metrics\n",
        "        monitor_gym=True,  # auto-upload the videos of agents playing the game\n",
        "        save_code=True,  # optional\n",
        "    )\n",
        "\n",
        "\n",
        "    eval_args = {\n",
        "                    \"episode_len\"   :2760,\n",
        "                    \"actual_load\"   :actual_load[6001:],\n",
        "                    \"actual_gen\"    :actual_gen[6001:],\n",
        "                    \"bat_threshold\" :100,\n",
        "                    \"bat_cap\"       :600,\n",
        "                    \"purchase_price\":purchase_price[6001:],\n",
        "                    \"num_preds\"     :n_preds,\n",
        "                    \"load_shedding\" :loadshedding,\n",
        "                    \"wandb_log\"     : True,\n",
        "                    \"train_log\"     : False,\n",
        "                    \"demand_flag\"   : demand_charge\n",
        "    }\n",
        "    #define 5 environments   for training and eval\n",
        "    eval_env = make_vec_env(EMS, n_envs = n_envs,env_kwargs = eval_args )\n",
        "    #first run it with only standby (default)\n",
        "    obs   = eval_env.reset()\n",
        "    #ensure that the exit condition is reset\n",
        "    done = [False]*n_envs\n",
        "    #define the action to take\n",
        "    action_standby = [-1]*n_envs\n",
        "    #reset score\n",
        "    standby_score = [0]*n_envs\n",
        "    standby_score = np.array(standby_score).astype(np.float32)\n",
        "    while not all(done):\n",
        "        #step the model with the action\n",
        "        obs,reward,done,info = eval_env.step(action_standby)\n",
        "        #accumulate the score\n",
        "        standby_score += reward\n",
        "    avg_standby_score = standby_score.mean()\n",
        "    run.finish()\n",
        "\n",
        "    #define 5 environments   for training and eval\n",
        "    eval_env = make_vec_env(EMS, n_envs = n_envs,env_kwargs = eval_args )\n",
        "\n",
        "    #Load model, fetch the latest (or whichever one you want from the model_dir)\n",
        "    #Best A2C model:/content/drive/MyDrive/Colab Notebooks/EMSv1_1/models/A2C/EMSv1_1_A2C1010-081818.zip\n",
        "    best_model =\"/content/drive/MyDrive/Colab Notebooks/EMSv2_1/models/PPO/EMSv2_1_PPO1017-110702.zip\"\n",
        "    #best_model =\n",
        "    #best_PPO_model\n",
        "    #model_load = f\"{best_model}\"\n",
        "\n",
        "    #model  = PPO.load(model_load, env = eval_env)\n",
        "    config = {\n",
        "        \"policy_type\": \"MlpPolicy\",\n",
        "        \"total_timesteps\": 2760,\n",
        "        \"notes\":f\"{note}_eval\"\n",
        "    }\n",
        "\n",
        "    run = wandb.init(\n",
        "        project=\"4022_intelligent_ems\",\n",
        "        config=config,\n",
        "        sync_tensorboard=True,  # auto-upload sb3's tensorboard metrics\n",
        "        monitor_gym=True,  # auto-upload the videos of agents playing the game\n",
        "        save_code=True,  # optional\n",
        "    )\n",
        "    obs   = eval_env.reset()\n",
        "    model  = PPO.load(\"model\", env = eval_env,tensorboard_log = f\"runs/{run.id}\")\n",
        "    EMS_reward,EMS_std_reward = evaluate_policy(model,eval_env,n_eval_episodes = 1,deterministic=True)# callback = wandb_callback\n",
        "    run.finish()\n",
        "\n",
        "    print(f\"Note: The term does not refer to the cost in rands but rather to the reward as defined by the reward function!\")\n",
        "    print(f\"Done the Standby Test! Total cost accumulated is: {avg_standby_score}\")\n",
        "    print(f\"Done applying the trained model! Total cost accumulated is: {EMS_reward} +- {EMS_std_reward}\")\n",
        "\n",
        "    savings = EMS_reward - avg_standby_score\n",
        "    print(f\"The amount that was saved by applying the EMS agent: {savings}\")\n",
        "    print(f\"This was saved over a period of {2760/24} days\")\n",
        "    print(f\"The savings represents {(savings/(-avg_standby_score))*100} % of the cost if no EMS is installed\")\n",
        "    print(f\"And it represents {(savings/(-EMS_reward))*100} % of the cost if the EMS is installed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_my_model(note,loadshedding,demand_flag,lr):\n",
        "    model_note = note\n",
        "    config = {\n",
        "        \"policy_type\": \"MlpPolicy\",\n",
        "        \"total_timesteps\": 1_500_000,\n",
        "        \"notes\": f\"{model_note}_train\"\n",
        "    }\n",
        "\n",
        "    run = wandb.init(\n",
        "        project=\"4022_intelligent_ems\",\n",
        "        config=config,\n",
        "        sync_tensorboard=True,  # auto-upload sb3's tensorboard metrics\n",
        "        monitor_gym=True,  # auto-upload the videos of agents playing the game\n",
        "        save_code=True,  # optional\n",
        "    )\n",
        "\n",
        "    #define 5 environments   for training and eval\n",
        "    n_envs = 5\n",
        "    #define num predictions\n",
        "    n_preds = 24\n",
        "\n",
        "    train_args = {\n",
        "                    \"episode_len\"   : 6000,\n",
        "                    \"actual_load\"   : actual_load,\n",
        "                    \"actual_gen\"    : actual_gen,\n",
        "                    \"bat_threshold\" : 100,\n",
        "                    \"bat_cap\"       : 600,\n",
        "                    \"purchase_price\": purchase_price,\n",
        "                    \"num_preds\"     : n_preds,\n",
        "                    \"load_shedding\" : loadshedding,\n",
        "                    \"render_mode\"   : \"rgb_array\",\n",
        "                    \"wandb_log\"     : True,\n",
        "                    \"train_log\"     : True,\n",
        "                    \"demand_flag\"   : demand_flag\n",
        "\n",
        "                    }\n",
        "\n",
        "    train_env = make_vec_env(EMS, n_envs = n_envs,env_kwargs = train_args )\n",
        "\n",
        "    wand_eval = f\"{version}_{model_type}_eval\"+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "    wand_train = f\"{version}_{model_type}_train\"+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "    wandb_callback = WandbCallback(\n",
        "                    gradient_save_freq=100,\n",
        "                    model_save_path=f\"models/{run.id}.{datetime.datetime.now()}\",\n",
        "                    model_save_freq= 30000,\n",
        "                    verbose=2,\n",
        "                    log = \"all\",\n",
        "                )\n",
        "\n",
        "    #model_load = \"/content/drive/MyDrive/Colab Notebooks/EMSv2_7/models/PPO/EMSv2_7_PPO1018-225923.zip\"\n",
        "    model  = PPO.load(\"model\", env = train_env,learning_rate = linear_schedule(lr),tensorboard_log = f\"runs/{run.id}\")\n",
        "    #model = PPO(\"MlpPolicy\",train_env, verbose = 1, learning_rate = linear_schedule(0.002),tensorboard_log = f\"runs/{run.id}\")#learning_rate = 0.01, vf_coef = 0.2\n",
        "\n",
        "    model.learn(total_timesteps= config[\"total_timesteps\"],\n",
        "                tb_log_name = wand_train,\n",
        "                callback = wandb_callback\n",
        "                )\n",
        "\n",
        "    model.save(f\"{model_dir}{version}_{model_type}\"+datetime.datetime.now().strftime(\"%m%d-%H%M%S\"))\n",
        "    model.save(\"model\")\n",
        "    run.finish()"
      ],
      "metadata": {
        "id": "5cKsknGULCtO"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "gQDhUNGWeum4"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "#define 5 environments   for training and eval\n",
        "n_envs = 5\n",
        "#define num predictions\n",
        "n_preds = 24\n",
        "\n",
        "train_args = {\n",
        "              \"episode_len\"   : 6000,\n",
        "              \"actual_load\"   : actual_load,\n",
        "              \"actual_gen\"    : actual_gen,\n",
        "              \"bat_threshold\" : 100,\n",
        "              \"bat_cap\"       : 600,\n",
        "              \"purchase_price\": purchase_price,\n",
        "              \"num_preds\"     : n_preds,\n",
        "              \"load_shedding\" : load_shedding,\n",
        "              \"render_mode\"   : \"rgb_array\",\n",
        "              \"wandb_log\"     : True,\n",
        "              \"train_log\"     : True,\n",
        "              \"demand_flag\"   : False\n",
        "\n",
        "                    }\n",
        "\n",
        "train_env = make_vec_env(EMS, n_envs = n_envs,env_kwargs = train_args )\n",
        "model_load = \"/content/drive/MyDrive/Colab Notebooks/EMSv2_7/models/PPO/EMSv2_7_PPO1022-190346.zip\"\n",
        "model  = PPO.load(model_load, env = train_env)\n",
        "#model = PPO(\"MlpPolicy\", train_env,verbose = 1, learning_rate = linear_schedule(0.002))#learning_rate = 0.01, vf_coef = 0.2\n",
        "model.save(\"model\")\n",
        "#c163c28885695cb2b0493ac455e296dcc8bc462a"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "no_shedding = np.zeros(len(load_shedding)).astype(np.float32)\n",
        "train_my_model('Neither',no_shedding,False,0.01)\n",
        "evaluate_current_model('Neither',no_shedding,False)"
      ],
      "metadata": {
        "id": "DVMSShWpcK-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_my_model(\"Only Demand\",no_shedding,True,0.01)\n",
        "evaluate_current_model(\"only Demand\",no_shedding,True)"
      ],
      "metadata": {
        "id": "xWhPKRFMetZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_my_model(\"Only Load shedding\",load_shedding[2760:],False,0.005)\n",
        "evaluate_current_model(\"only load shedding\",load_shedding[6001:],False)"
      ],
      "metadata": {
        "id": "fxKc1iW1fF8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_my_model(\"both\",load_shedding[2760:],True,0.005)\n",
        "evaluate_current_model(\"both\",load_shedding[6001:],True)"
      ],
      "metadata": {
        "id": "V2hH7CCVDks_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "903ca881fc284bd9af87d33b8ba45213",
            "7cd78624dc474b30b24c3a0c77a18a64",
            "8431d6389ad04456b2d1e499622b81ed",
            "5088a52b31da4d73934eb462776e84d0",
            "6479e914b3374f12968957e6b4ad90ff",
            "3c78c6d2ea1c4f23bb8fa2e3712acce9",
            "4377e058ab7b41bf9c83a458c2e3ca44",
            "c74fea468ff64564a7e639868f1f3877"
          ]
        },
        "outputId": "963a3b47-8170-4f20-b7fe-e096c6ac3b0c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/notebook/utils.py:280: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
            "  return LooseVersion(v) >= LooseVersion(check)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.12"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/EEE4022S_BNKJUL001_Thesis/wandb/run-20231023_070503-uu4smqqg</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/uu4smqqg' target=\"_blank\">scarlet-oath-393</a></strong> to <a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems' target=\"_blank\">https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/uu4smqqg' target=\"_blank\">https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/uu4smqqg</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logging to runs/uu4smqqg/EMSv2_7_PPO_train20231023-070506_1\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 487   |\n",
            "|    iterations      | 1     |\n",
            "|    time_elapsed    | 21    |\n",
            "|    total_timesteps | 10240 |\n",
            "------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 449          |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 45           |\n",
            "|    total_timesteps      | 20480        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0051545044 |\n",
            "|    clip_fraction        | 0.0408       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.505        |\n",
            "|    explained_variance   | 0.86         |\n",
            "|    learning_rate        | 0.00497      |\n",
            "|    loss                 | 1.06e+06     |\n",
            "|    n_updates            | 4420         |\n",
            "|    policy_gradient_loss | -0.00125     |\n",
            "|    std                  | 0.146        |\n",
            "|    value_loss           | 2.44e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.57e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 433          |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 70           |\n",
            "|    total_timesteps      | 30720        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0048822393 |\n",
            "|    clip_fraction        | 0.0309       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.506        |\n",
            "|    explained_variance   | 0.708        |\n",
            "|    learning_rate        | 0.00493      |\n",
            "|    loss                 | 6.38e+05     |\n",
            "|    n_updates            | 4430         |\n",
            "|    policy_gradient_loss | -0.00222     |\n",
            "|    std                  | 0.146        |\n",
            "|    value_loss           | 3.48e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.57e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 427          |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 95           |\n",
            "|    total_timesteps      | 40960        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041242116 |\n",
            "|    clip_fraction        | 0.032        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.505        |\n",
            "|    explained_variance   | 0.753        |\n",
            "|    learning_rate        | 0.0049       |\n",
            "|    loss                 | 9.46e+05     |\n",
            "|    n_updates            | 4440         |\n",
            "|    policy_gradient_loss | -0.00189     |\n",
            "|    std                  | 0.146        |\n",
            "|    value_loss           | 4.6e+06      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.57e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 428          |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 119          |\n",
            "|    total_timesteps      | 51200        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042210156 |\n",
            "|    clip_fraction        | 0.0343       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.507        |\n",
            "|    explained_variance   | 0.39         |\n",
            "|    learning_rate        | 0.00486      |\n",
            "|    loss                 | 1.17e+06     |\n",
            "|    n_updates            | 4450         |\n",
            "|    policy_gradient_loss | -0.00206     |\n",
            "|    std                  | 0.145        |\n",
            "|    value_loss           | 3.26e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.57e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 425          |\n",
            "|    iterations           | 6            |\n",
            "|    time_elapsed         | 144          |\n",
            "|    total_timesteps      | 61440        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039542234 |\n",
            "|    clip_fraction        | 0.0306       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.513        |\n",
            "|    explained_variance   | 0.645        |\n",
            "|    learning_rate        | 0.00483      |\n",
            "|    loss                 | 1.17e+06     |\n",
            "|    n_updates            | 4460         |\n",
            "|    policy_gradient_loss | -0.0019      |\n",
            "|    std                  | 0.144        |\n",
            "|    value_loss           | 4.02e+06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -2.57e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 423         |\n",
            "|    iterations           | 7           |\n",
            "|    time_elapsed         | 169         |\n",
            "|    total_timesteps      | 71680       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005772265 |\n",
            "|    clip_fraction        | 0.0445      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.516       |\n",
            "|    explained_variance   | 0.796       |\n",
            "|    learning_rate        | 0.0048      |\n",
            "|    loss                 | 8.2e+05     |\n",
            "|    n_updates            | 4470        |\n",
            "|    policy_gradient_loss | -0.00304    |\n",
            "|    std                  | 0.144       |\n",
            "|    value_loss           | 4.37e+06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.57e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 422          |\n",
            "|    iterations           | 8            |\n",
            "|    time_elapsed         | 193          |\n",
            "|    total_timesteps      | 81920        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0046492387 |\n",
            "|    clip_fraction        | 0.0277       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.522        |\n",
            "|    explained_variance   | 0.514        |\n",
            "|    learning_rate        | 0.00476      |\n",
            "|    loss                 | 1.69e+06     |\n",
            "|    n_updates            | 4480         |\n",
            "|    policy_gradient_loss | -0.00171     |\n",
            "|    std                  | 0.143        |\n",
            "|    value_loss           | 3.16e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.57e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 421          |\n",
            "|    iterations           | 9            |\n",
            "|    time_elapsed         | 218          |\n",
            "|    total_timesteps      | 92160        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0050818613 |\n",
            "|    clip_fraction        | 0.0427       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.53         |\n",
            "|    explained_variance   | 0.688        |\n",
            "|    learning_rate        | 0.00473      |\n",
            "|    loss                 | 1.24e+06     |\n",
            "|    n_updates            | 4490         |\n",
            "|    policy_gradient_loss | -0.00274     |\n",
            "|    std                  | 0.142        |\n",
            "|    value_loss           | 3.43e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.57e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 420          |\n",
            "|    iterations           | 10           |\n",
            "|    time_elapsed         | 243          |\n",
            "|    total_timesteps      | 102400       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0052781417 |\n",
            "|    clip_fraction        | 0.0453       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.531        |\n",
            "|    explained_variance   | 0.803        |\n",
            "|    learning_rate        | 0.00469      |\n",
            "|    loss                 | 1.14e+06     |\n",
            "|    n_updates            | 4500         |\n",
            "|    policy_gradient_loss | -0.00263     |\n",
            "|    std                  | 0.143        |\n",
            "|    value_loss           | 4.08e+06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -2.57e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 420         |\n",
            "|    iterations           | 11          |\n",
            "|    time_elapsed         | 268         |\n",
            "|    total_timesteps      | 112640      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003822369 |\n",
            "|    clip_fraction        | 0.0293      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.531       |\n",
            "|    explained_variance   | 0.568       |\n",
            "|    learning_rate        | 0.00466     |\n",
            "|    loss                 | 7.95e+05    |\n",
            "|    n_updates            | 4510        |\n",
            "|    policy_gradient_loss | -0.00103    |\n",
            "|    std                  | 0.142       |\n",
            "|    value_loss           | 2.8e+06     |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.57e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 419          |\n",
            "|    iterations           | 12           |\n",
            "|    time_elapsed         | 293          |\n",
            "|    total_timesteps      | 122880       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0061141653 |\n",
            "|    clip_fraction        | 0.0472       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.535        |\n",
            "|    explained_variance   | 0.689        |\n",
            "|    learning_rate        | 0.00462      |\n",
            "|    loss                 | 1.18e+06     |\n",
            "|    n_updates            | 4520         |\n",
            "|    policy_gradient_loss | -0.00248     |\n",
            "|    std                  | 0.141        |\n",
            "|    value_loss           | 3.1e+06      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.57e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 416          |\n",
            "|    iterations           | 13           |\n",
            "|    time_elapsed         | 319          |\n",
            "|    total_timesteps      | 133120       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0064355456 |\n",
            "|    clip_fraction        | 0.0583       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.539        |\n",
            "|    explained_variance   | 0.83         |\n",
            "|    learning_rate        | 0.00459      |\n",
            "|    loss                 | 1.01e+06     |\n",
            "|    n_updates            | 4530         |\n",
            "|    policy_gradient_loss | -0.00313     |\n",
            "|    std                  | 0.141        |\n",
            "|    value_loss           | 3.49e+06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -2.57e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 14          |\n",
            "|    time_elapsed         | 344         |\n",
            "|    total_timesteps      | 143360      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004365383 |\n",
            "|    clip_fraction        | 0.0344      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.542       |\n",
            "|    explained_variance   | 0.578       |\n",
            "|    learning_rate        | 0.00456     |\n",
            "|    loss                 | 8.76e+05    |\n",
            "|    n_updates            | 4540        |\n",
            "|    policy_gradient_loss | -0.00139    |\n",
            "|    std                  | 0.14        |\n",
            "|    value_loss           | 2.37e+06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.57e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 415          |\n",
            "|    iterations           | 15           |\n",
            "|    time_elapsed         | 369          |\n",
            "|    total_timesteps      | 153600       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0054196035 |\n",
            "|    clip_fraction        | 0.0468       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.543        |\n",
            "|    explained_variance   | 0.688        |\n",
            "|    learning_rate        | 0.00452      |\n",
            "|    loss                 | 1.13e+06     |\n",
            "|    n_updates            | 4550         |\n",
            "|    policy_gradient_loss | -0.00121     |\n",
            "|    std                  | 0.141        |\n",
            "|    value_loss           | 3.22e+06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -2.57e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 416         |\n",
            "|    iterations           | 16          |\n",
            "|    time_elapsed         | 393         |\n",
            "|    total_timesteps      | 163840      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007540971 |\n",
            "|    clip_fraction        | 0.0639      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.538       |\n",
            "|    explained_variance   | 0.842       |\n",
            "|    learning_rate        | 0.00449     |\n",
            "|    loss                 | 1.28e+06    |\n",
            "|    n_updates            | 4560        |\n",
            "|    policy_gradient_loss | -0.00281    |\n",
            "|    std                  | 0.142       |\n",
            "|    value_loss           | 3.45e+06    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -2.57e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 17          |\n",
            "|    time_elapsed         | 418         |\n",
            "|    total_timesteps      | 174080      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005001437 |\n",
            "|    clip_fraction        | 0.0459      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.533       |\n",
            "|    explained_variance   | 0.618       |\n",
            "|    learning_rate        | 0.00445     |\n",
            "|    loss                 | 6.22e+05    |\n",
            "|    n_updates            | 4570        |\n",
            "|    policy_gradient_loss | -0.00211    |\n",
            "|    std                  | 0.142       |\n",
            "|    value_loss           | 1.93e+06    |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 5.97e+03   |\n",
            "|    ep_rew_mean          | -2.57e+06  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 415        |\n",
            "|    iterations           | 18         |\n",
            "|    time_elapsed         | 443        |\n",
            "|    total_timesteps      | 184320     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00599561 |\n",
            "|    clip_fraction        | 0.0609     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | 0.529      |\n",
            "|    explained_variance   | 0.691      |\n",
            "|    learning_rate        | 0.00442    |\n",
            "|    loss                 | 1.13e+06   |\n",
            "|    n_updates            | 4580       |\n",
            "|    policy_gradient_loss | -0.00239   |\n",
            "|    std                  | 0.143      |\n",
            "|    value_loss           | 2.73e+06   |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -2.57e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 19          |\n",
            "|    time_elapsed         | 467         |\n",
            "|    total_timesteps      | 194560      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006091774 |\n",
            "|    clip_fraction        | 0.058       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.527       |\n",
            "|    explained_variance   | 0.85        |\n",
            "|    learning_rate        | 0.00439     |\n",
            "|    loss                 | 2.01e+06    |\n",
            "|    n_updates            | 4590        |\n",
            "|    policy_gradient_loss | -0.00173    |\n",
            "|    std                  | 0.143       |\n",
            "|    value_loss           | 3.28e+06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.57e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 415          |\n",
            "|    iterations           | 20           |\n",
            "|    time_elapsed         | 493          |\n",
            "|    total_timesteps      | 204800       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0049869036 |\n",
            "|    clip_fraction        | 0.0392       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.528        |\n",
            "|    explained_variance   | 0.683        |\n",
            "|    learning_rate        | 0.00435      |\n",
            "|    loss                 | 7.43e+05     |\n",
            "|    n_updates            | 4600         |\n",
            "|    policy_gradient_loss | -0.00247     |\n",
            "|    std                  | 0.143        |\n",
            "|    value_loss           | 1.86e+06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -2.57e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 21          |\n",
            "|    time_elapsed         | 517         |\n",
            "|    total_timesteps      | 215040      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008593668 |\n",
            "|    clip_fraction        | 0.0776      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.536       |\n",
            "|    explained_variance   | 0.706       |\n",
            "|    learning_rate        | 0.00432     |\n",
            "|    loss                 | 9.56e+05    |\n",
            "|    n_updates            | 4610        |\n",
            "|    policy_gradient_loss | -0.00261    |\n",
            "|    std                  | 0.141       |\n",
            "|    value_loss           | 2.67e+06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.57e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 415          |\n",
            "|    iterations           | 22           |\n",
            "|    time_elapsed         | 541          |\n",
            "|    total_timesteps      | 225280       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0077875243 |\n",
            "|    clip_fraction        | 0.0594       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.54         |\n",
            "|    explained_variance   | 0.852        |\n",
            "|    learning_rate        | 0.00428      |\n",
            "|    loss                 | 7.11e+05     |\n",
            "|    n_updates            | 4620         |\n",
            "|    policy_gradient_loss | -0.00225     |\n",
            "|    std                  | 0.141        |\n",
            "|    value_loss           | 2.68e+06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -2.57e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 23          |\n",
            "|    time_elapsed         | 567         |\n",
            "|    total_timesteps      | 235520      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004090143 |\n",
            "|    clip_fraction        | 0.0453      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.537       |\n",
            "|    explained_variance   | 0.681       |\n",
            "|    learning_rate        | 0.00425     |\n",
            "|    loss                 | 4.09e+05    |\n",
            "|    n_updates            | 4630        |\n",
            "|    policy_gradient_loss | -0.0017     |\n",
            "|    std                  | 0.141       |\n",
            "|    value_loss           | 1.72e+06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.57e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 416          |\n",
            "|    iterations           | 24           |\n",
            "|    time_elapsed         | 590          |\n",
            "|    total_timesteps      | 245760       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0071235956 |\n",
            "|    clip_fraction        | 0.069        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.543        |\n",
            "|    explained_variance   | 0.715        |\n",
            "|    learning_rate        | 0.00421      |\n",
            "|    loss                 | 9.8e+05      |\n",
            "|    n_updates            | 4640         |\n",
            "|    policy_gradient_loss | -0.002       |\n",
            "|    std                  | 0.14         |\n",
            "|    value_loss           | 2.39e+06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -2.57e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 25          |\n",
            "|    time_elapsed         | 615         |\n",
            "|    total_timesteps      | 256000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008266015 |\n",
            "|    clip_fraction        | 0.0607      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.547       |\n",
            "|    explained_variance   | 0.866       |\n",
            "|    learning_rate        | 0.00418     |\n",
            "|    loss                 | 1.08e+06    |\n",
            "|    n_updates            | 4650        |\n",
            "|    policy_gradient_loss | -0.00293    |\n",
            "|    std                  | 0.14        |\n",
            "|    value_loss           | 2.36e+06    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -2.57e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 26          |\n",
            "|    time_elapsed         | 640         |\n",
            "|    total_timesteps      | 266240      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006120573 |\n",
            "|    clip_fraction        | 0.0472      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.551       |\n",
            "|    explained_variance   | 0.679       |\n",
            "|    learning_rate        | 0.00415     |\n",
            "|    loss                 | 5.77e+05    |\n",
            "|    n_updates            | 4660        |\n",
            "|    policy_gradient_loss | -0.00148    |\n",
            "|    std                  | 0.139       |\n",
            "|    value_loss           | 1.61e+06    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -2.57e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 416         |\n",
            "|    iterations           | 27          |\n",
            "|    time_elapsed         | 664         |\n",
            "|    total_timesteps      | 276480      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007492901 |\n",
            "|    clip_fraction        | 0.075       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.549       |\n",
            "|    explained_variance   | 0.723       |\n",
            "|    learning_rate        | 0.00411     |\n",
            "|    loss                 | 1.13e+06    |\n",
            "|    n_updates            | 4670        |\n",
            "|    policy_gradient_loss | -0.00128    |\n",
            "|    std                  | 0.14        |\n",
            "|    value_loss           | 2.86e+06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.57e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 415          |\n",
            "|    iterations           | 28           |\n",
            "|    time_elapsed         | 689          |\n",
            "|    total_timesteps      | 286720       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0062069697 |\n",
            "|    clip_fraction        | 0.0543       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.541        |\n",
            "|    explained_variance   | 0.862        |\n",
            "|    learning_rate        | 0.00408      |\n",
            "|    loss                 | 5.45e+05     |\n",
            "|    n_updates            | 4680         |\n",
            "|    policy_gradient_loss | -0.00216     |\n",
            "|    std                  | 0.141        |\n",
            "|    value_loss           | 1.74e+06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -2.57e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 416         |\n",
            "|    iterations           | 29          |\n",
            "|    time_elapsed         | 713         |\n",
            "|    total_timesteps      | 296960      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004580038 |\n",
            "|    clip_fraction        | 0.0399      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.534       |\n",
            "|    explained_variance   | 0.726       |\n",
            "|    learning_rate        | 0.00404     |\n",
            "|    loss                 | 5.35e+05    |\n",
            "|    n_updates            | 4690        |\n",
            "|    policy_gradient_loss | -0.00167    |\n",
            "|    std                  | 0.142       |\n",
            "|    value_loss           | 1.48e+06    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -2.57e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 30          |\n",
            "|    time_elapsed         | 738         |\n",
            "|    total_timesteps      | 307200      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009060854 |\n",
            "|    clip_fraction        | 0.074       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.531       |\n",
            "|    explained_variance   | 0.729       |\n",
            "|    learning_rate        | 0.00401     |\n",
            "|    loss                 | 7.38e+05    |\n",
            "|    n_updates            | 4700        |\n",
            "|    policy_gradient_loss | -0.00305    |\n",
            "|    std                  | 0.142       |\n",
            "|    value_loss           | 2.85e+06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.57e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 415          |\n",
            "|    iterations           | 31           |\n",
            "|    time_elapsed         | 764          |\n",
            "|    total_timesteps      | 317440       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0066804336 |\n",
            "|    clip_fraction        | 0.0508       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.534        |\n",
            "|    explained_variance   | 0.844        |\n",
            "|    learning_rate        | 0.00398      |\n",
            "|    loss                 | 3.28e+05     |\n",
            "|    n_updates            | 4710         |\n",
            "|    policy_gradient_loss | -0.00271     |\n",
            "|    std                  | 0.141        |\n",
            "|    value_loss           | 1.64e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.57e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 415          |\n",
            "|    iterations           | 32           |\n",
            "|    time_elapsed         | 787          |\n",
            "|    total_timesteps      | 327680       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0059190895 |\n",
            "|    clip_fraction        | 0.0451       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.543        |\n",
            "|    explained_variance   | 0.772        |\n",
            "|    learning_rate        | 0.00394      |\n",
            "|    loss                 | 7.06e+05     |\n",
            "|    n_updates            | 4720         |\n",
            "|    policy_gradient_loss | -0.00138     |\n",
            "|    std                  | 0.14         |\n",
            "|    value_loss           | 1.41e+06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -2.57e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 33          |\n",
            "|    time_elapsed         | 813         |\n",
            "|    total_timesteps      | 337920      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007884713 |\n",
            "|    clip_fraction        | 0.073       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.551       |\n",
            "|    explained_variance   | 0.738       |\n",
            "|    learning_rate        | 0.00391     |\n",
            "|    loss                 | 1.32e+06    |\n",
            "|    n_updates            | 4730        |\n",
            "|    policy_gradient_loss | -0.00207    |\n",
            "|    std                  | 0.139       |\n",
            "|    value_loss           | 2.81e+06    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -2.57e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 34          |\n",
            "|    time_elapsed         | 837         |\n",
            "|    total_timesteps      | 348160      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005331271 |\n",
            "|    clip_fraction        | 0.0554      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.557       |\n",
            "|    explained_variance   | 0.794       |\n",
            "|    learning_rate        | 0.00387     |\n",
            "|    loss                 | 5.23e+05    |\n",
            "|    n_updates            | 4740        |\n",
            "|    policy_gradient_loss | -0.00166    |\n",
            "|    std                  | 0.138       |\n",
            "|    value_loss           | 1.25e+06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.57e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 415          |\n",
            "|    iterations           | 35           |\n",
            "|    time_elapsed         | 862          |\n",
            "|    total_timesteps      | 358400       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0052978275 |\n",
            "|    clip_fraction        | 0.046        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.565        |\n",
            "|    explained_variance   | 0.79         |\n",
            "|    learning_rate        | 0.00384      |\n",
            "|    loss                 | 8.96e+05     |\n",
            "|    n_updates            | 4750         |\n",
            "|    policy_gradient_loss | -0.00172     |\n",
            "|    std                  | 0.137        |\n",
            "|    value_loss           | 1.81e+06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -2.57e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 36          |\n",
            "|    time_elapsed         | 887         |\n",
            "|    total_timesteps      | 368640      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007871068 |\n",
            "|    clip_fraction        | 0.0637      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.568       |\n",
            "|    explained_variance   | 0.772       |\n",
            "|    learning_rate        | 0.00381     |\n",
            "|    loss                 | 9.94e+05    |\n",
            "|    n_updates            | 4760        |\n",
            "|    policy_gradient_loss | -0.00174    |\n",
            "|    std                  | 0.137       |\n",
            "|    value_loss           | 2.63e+06    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -2.57e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 37          |\n",
            "|    time_elapsed         | 911         |\n",
            "|    total_timesteps      | 378880      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005352814 |\n",
            "|    clip_fraction        | 0.0483      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.573       |\n",
            "|    explained_variance   | 0.768       |\n",
            "|    learning_rate        | 0.00377     |\n",
            "|    loss                 | 5.82e+05    |\n",
            "|    n_updates            | 4770        |\n",
            "|    policy_gradient_loss | -0.00208    |\n",
            "|    std                  | 0.136       |\n",
            "|    value_loss           | 1.11e+06    |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 5.97e+03   |\n",
            "|    ep_rew_mean          | -2.57e+06  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 415        |\n",
            "|    iterations           | 38         |\n",
            "|    time_elapsed         | 936        |\n",
            "|    total_timesteps      | 389120     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00491639 |\n",
            "|    clip_fraction        | 0.0432     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | 0.58       |\n",
            "|    explained_variance   | 0.803      |\n",
            "|    learning_rate        | 0.00374    |\n",
            "|    loss                 | 5.3e+05    |\n",
            "|    n_updates            | 4780       |\n",
            "|    policy_gradient_loss | -0.00146   |\n",
            "|    std                  | 0.135      |\n",
            "|    value_loss           | 1.78e+06   |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.57e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 415          |\n",
            "|    iterations           | 39           |\n",
            "|    time_elapsed         | 961          |\n",
            "|    total_timesteps      | 399360       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0062051476 |\n",
            "|    clip_fraction        | 0.0648       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.576        |\n",
            "|    explained_variance   | 0.863        |\n",
            "|    learning_rate        | 0.0037       |\n",
            "|    loss                 | 5.68e+05     |\n",
            "|    n_updates            | 4790         |\n",
            "|    policy_gradient_loss | -0.00236     |\n",
            "|    std                  | 0.137        |\n",
            "|    value_loss           | 2.29e+06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -2.57e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 40          |\n",
            "|    time_elapsed         | 985         |\n",
            "|    total_timesteps      | 409600      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005411297 |\n",
            "|    clip_fraction        | 0.0432      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.573       |\n",
            "|    explained_variance   | 0.753       |\n",
            "|    learning_rate        | 0.00367     |\n",
            "|    loss                 | 3.57e+05    |\n",
            "|    n_updates            | 4800        |\n",
            "|    policy_gradient_loss | -0.00211    |\n",
            "|    std                  | 0.136       |\n",
            "|    value_loss           | 1.11e+06    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -2.57e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 41          |\n",
            "|    time_elapsed         | 1011        |\n",
            "|    total_timesteps      | 419840      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004759484 |\n",
            "|    clip_fraction        | 0.0413      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.577       |\n",
            "|    explained_variance   | 0.806       |\n",
            "|    learning_rate        | 0.00363     |\n",
            "|    loss                 | 5.25e+05    |\n",
            "|    n_updates            | 4810        |\n",
            "|    policy_gradient_loss | -0.00224    |\n",
            "|    std                  | 0.136       |\n",
            "|    value_loss           | 1.79e+06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.57e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 415          |\n",
            "|    iterations           | 42           |\n",
            "|    time_elapsed         | 1036         |\n",
            "|    total_timesteps      | 430080       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0090125445 |\n",
            "|    clip_fraction        | 0.072        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.576        |\n",
            "|    explained_variance   | 0.883        |\n",
            "|    learning_rate        | 0.0036       |\n",
            "|    loss                 | 1.17e+06     |\n",
            "|    n_updates            | 4820         |\n",
            "|    policy_gradient_loss | -0.00281     |\n",
            "|    std                  | 0.136        |\n",
            "|    value_loss           | 2.15e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.57e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 414          |\n",
            "|    iterations           | 43           |\n",
            "|    time_elapsed         | 1061         |\n",
            "|    total_timesteps      | 440320       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0048312317 |\n",
            "|    clip_fraction        | 0.043        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.577        |\n",
            "|    explained_variance   | 0.782        |\n",
            "|    learning_rate        | 0.00357      |\n",
            "|    loss                 | 4.89e+05     |\n",
            "|    n_updates            | 4830         |\n",
            "|    policy_gradient_loss | -0.00215     |\n",
            "|    std                  | 0.136        |\n",
            "|    value_loss           | 1.2e+06      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.57e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 414          |\n",
            "|    iterations           | 44           |\n",
            "|    time_elapsed         | 1086         |\n",
            "|    total_timesteps      | 450560       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0046515455 |\n",
            "|    clip_fraction        | 0.0478       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.581        |\n",
            "|    explained_variance   | 0.83         |\n",
            "|    learning_rate        | 0.00353      |\n",
            "|    loss                 | 6.73e+05     |\n",
            "|    n_updates            | 4840         |\n",
            "|    policy_gradient_loss | -0.00204     |\n",
            "|    std                  | 0.135        |\n",
            "|    value_loss           | 1.86e+06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -2.57e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 414         |\n",
            "|    iterations           | 45          |\n",
            "|    time_elapsed         | 1110        |\n",
            "|    total_timesteps      | 460800      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006704124 |\n",
            "|    clip_fraction        | 0.0655      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.585       |\n",
            "|    explained_variance   | 0.89        |\n",
            "|    learning_rate        | 0.0035      |\n",
            "|    loss                 | 6.5e+05     |\n",
            "|    n_updates            | 4850        |\n",
            "|    policy_gradient_loss | -0.00245    |\n",
            "|    std                  | 0.134       |\n",
            "|    value_loss           | 2.06e+06    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -2.57e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 414         |\n",
            "|    iterations           | 46          |\n",
            "|    time_elapsed         | 1135        |\n",
            "|    total_timesteps      | 471040      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004349482 |\n",
            "|    clip_fraction        | 0.0371      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.591       |\n",
            "|    explained_variance   | 0.811       |\n",
            "|    learning_rate        | 0.00346     |\n",
            "|    loss                 | 5.91e+05    |\n",
            "|    n_updates            | 4860        |\n",
            "|    policy_gradient_loss | -0.000814   |\n",
            "|    std                  | 0.133       |\n",
            "|    value_loss           | 1.25e+06    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -2.57e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 414         |\n",
            "|    iterations           | 47          |\n",
            "|    time_elapsed         | 1160        |\n",
            "|    total_timesteps      | 481280      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004725578 |\n",
            "|    clip_fraction        | 0.049       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.599       |\n",
            "|    explained_variance   | 0.818       |\n",
            "|    learning_rate        | 0.00343     |\n",
            "|    loss                 | 1.27e+06    |\n",
            "|    n_updates            | 4870        |\n",
            "|    policy_gradient_loss | -0.00186    |\n",
            "|    std                  | 0.132       |\n",
            "|    value_loss           | 1.77e+06    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -2.57e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 48          |\n",
            "|    time_elapsed         | 1184        |\n",
            "|    total_timesteps      | 491520      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008929156 |\n",
            "|    clip_fraction        | 0.0649      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.608       |\n",
            "|    explained_variance   | 0.903       |\n",
            "|    learning_rate        | 0.0034      |\n",
            "|    loss                 | 9.92e+05    |\n",
            "|    n_updates            | 4880        |\n",
            "|    policy_gradient_loss | -0.00233    |\n",
            "|    std                  | 0.131       |\n",
            "|    value_loss           | 1.97e+06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.57e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 414          |\n",
            "|    iterations           | 49           |\n",
            "|    time_elapsed         | 1209         |\n",
            "|    total_timesteps      | 501760       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0043555954 |\n",
            "|    clip_fraction        | 0.0453       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.616        |\n",
            "|    explained_variance   | 0.799        |\n",
            "|    learning_rate        | 0.00336      |\n",
            "|    loss                 | 2.48e+05     |\n",
            "|    n_updates            | 4890         |\n",
            "|    policy_gradient_loss | -0.00174     |\n",
            "|    std                  | 0.13         |\n",
            "|    value_loss           | 1.2e+06      |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -2.57e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 50          |\n",
            "|    time_elapsed         | 1233        |\n",
            "|    total_timesteps      | 512000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005866128 |\n",
            "|    clip_fraction        | 0.0587      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.621       |\n",
            "|    explained_variance   | 0.793       |\n",
            "|    learning_rate        | 0.00333     |\n",
            "|    loss                 | 8.69e+05    |\n",
            "|    n_updates            | 4900        |\n",
            "|    policy_gradient_loss | -0.00299    |\n",
            "|    std                  | 0.13        |\n",
            "|    value_loss           | 1.69e+06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.57e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 415          |\n",
            "|    iterations           | 51           |\n",
            "|    time_elapsed         | 1257         |\n",
            "|    total_timesteps      | 522240       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0075058313 |\n",
            "|    clip_fraction        | 0.0641       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.623        |\n",
            "|    explained_variance   | 0.908        |\n",
            "|    learning_rate        | 0.00329      |\n",
            "|    loss                 | 7.41e+05     |\n",
            "|    n_updates            | 4910         |\n",
            "|    policy_gradient_loss | -0.00183     |\n",
            "|    std                  | 0.13         |\n",
            "|    value_loss           | 1.87e+06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -2.57e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 52          |\n",
            "|    time_elapsed         | 1282        |\n",
            "|    total_timesteps      | 532480      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005571018 |\n",
            "|    clip_fraction        | 0.0445      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.626       |\n",
            "|    explained_variance   | 0.794       |\n",
            "|    learning_rate        | 0.00326     |\n",
            "|    loss                 | 4.43e+05    |\n",
            "|    n_updates            | 4920        |\n",
            "|    policy_gradient_loss | -0.00179    |\n",
            "|    std                  | 0.129       |\n",
            "|    value_loss           | 1.17e+06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.57e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 415          |\n",
            "|    iterations           | 53           |\n",
            "|    time_elapsed         | 1306         |\n",
            "|    total_timesteps      | 542720       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0071545886 |\n",
            "|    clip_fraction        | 0.0663       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.626        |\n",
            "|    explained_variance   | 0.772        |\n",
            "|    learning_rate        | 0.00323      |\n",
            "|    loss                 | 1.11e+06     |\n",
            "|    n_updates            | 4930         |\n",
            "|    policy_gradient_loss | -0.003       |\n",
            "|    std                  | 0.13         |\n",
            "|    value_loss           | 1.62e+06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -2.57e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 54          |\n",
            "|    time_elapsed         | 1331        |\n",
            "|    total_timesteps      | 552960      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006963706 |\n",
            "|    clip_fraction        | 0.0637      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.624       |\n",
            "|    explained_variance   | 0.911       |\n",
            "|    learning_rate        | 0.00319     |\n",
            "|    loss                 | 9.63e+05    |\n",
            "|    n_updates            | 4940        |\n",
            "|    policy_gradient_loss | -0.000886   |\n",
            "|    std                  | 0.13        |\n",
            "|    value_loss           | 1.81e+06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.57e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 415          |\n",
            "|    iterations           | 55           |\n",
            "|    time_elapsed         | 1356         |\n",
            "|    total_timesteps      | 563200       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0054906723 |\n",
            "|    clip_fraction        | 0.0437       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.625        |\n",
            "|    explained_variance   | 0.813        |\n",
            "|    learning_rate        | 0.00316      |\n",
            "|    loss                 | 5.03e+05     |\n",
            "|    n_updates            | 4950         |\n",
            "|    policy_gradient_loss | -0.000974    |\n",
            "|    std                  | 0.129        |\n",
            "|    value_loss           | 1.2e+06      |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -2.57e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 56          |\n",
            "|    time_elapsed         | 1380        |\n",
            "|    total_timesteps      | 573440      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007048155 |\n",
            "|    clip_fraction        | 0.0567      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.628       |\n",
            "|    explained_variance   | 0.774       |\n",
            "|    learning_rate        | 0.00312     |\n",
            "|    loss                 | 9.48e+05    |\n",
            "|    n_updates            | 4960        |\n",
            "|    policy_gradient_loss | -0.00175    |\n",
            "|    std                  | 0.129       |\n",
            "|    value_loss           | 1.69e+06    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -2.57e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 57          |\n",
            "|    time_elapsed         | 1405        |\n",
            "|    total_timesteps      | 583680      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008474058 |\n",
            "|    clip_fraction        | 0.0702      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.633       |\n",
            "|    explained_variance   | 0.91        |\n",
            "|    learning_rate        | 0.00309     |\n",
            "|    loss                 | 1.06e+06    |\n",
            "|    n_updates            | 4970        |\n",
            "|    policy_gradient_loss | -0.00278    |\n",
            "|    std                  | 0.128       |\n",
            "|    value_loss           | 1.7e+06     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -2.57e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 58          |\n",
            "|    time_elapsed         | 1430        |\n",
            "|    total_timesteps      | 593920      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004853914 |\n",
            "|    clip_fraction        | 0.0371      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.638       |\n",
            "|    explained_variance   | 0.802       |\n",
            "|    learning_rate        | 0.00305     |\n",
            "|    loss                 | 8.23e+05    |\n",
            "|    n_updates            | 4980        |\n",
            "|    policy_gradient_loss | -0.0012     |\n",
            "|    std                  | 0.127       |\n",
            "|    value_loss           | 1.19e+06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.56e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 415          |\n",
            "|    iterations           | 59           |\n",
            "|    time_elapsed         | 1455         |\n",
            "|    total_timesteps      | 604160       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0064744367 |\n",
            "|    clip_fraction        | 0.054        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.644        |\n",
            "|    explained_variance   | 0.788        |\n",
            "|    learning_rate        | 0.00302      |\n",
            "|    loss                 | 8.88e+05     |\n",
            "|    n_updates            | 4990         |\n",
            "|    policy_gradient_loss | -0.00228     |\n",
            "|    std                  | 0.127        |\n",
            "|    value_loss           | 1.67e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.56e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 415          |\n",
            "|    iterations           | 60           |\n",
            "|    time_elapsed         | 1480         |\n",
            "|    total_timesteps      | 614400       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0071660257 |\n",
            "|    clip_fraction        | 0.0584       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.647        |\n",
            "|    explained_variance   | 0.915        |\n",
            "|    learning_rate        | 0.00299      |\n",
            "|    loss                 | 1.06e+06     |\n",
            "|    n_updates            | 5000         |\n",
            "|    policy_gradient_loss | -0.00231     |\n",
            "|    std                  | 0.127        |\n",
            "|    value_loss           | 1.64e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.56e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 415          |\n",
            "|    iterations           | 61           |\n",
            "|    time_elapsed         | 1504         |\n",
            "|    total_timesteps      | 624640       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044438555 |\n",
            "|    clip_fraction        | 0.0413       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.647        |\n",
            "|    explained_variance   | 0.778        |\n",
            "|    learning_rate        | 0.00295      |\n",
            "|    loss                 | 8.8e+05      |\n",
            "|    n_updates            | 5010         |\n",
            "|    policy_gradient_loss | -0.00205     |\n",
            "|    std                  | 0.126        |\n",
            "|    value_loss           | 1.2e+06      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.56e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 415          |\n",
            "|    iterations           | 62           |\n",
            "|    time_elapsed         | 1529         |\n",
            "|    total_timesteps      | 634880       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0073223608 |\n",
            "|    clip_fraction        | 0.0714       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.651        |\n",
            "|    explained_variance   | 0.805        |\n",
            "|    learning_rate        | 0.00292      |\n",
            "|    loss                 | 7.51e+05     |\n",
            "|    n_updates            | 5020         |\n",
            "|    policy_gradient_loss | -0.00257     |\n",
            "|    std                  | 0.126        |\n",
            "|    value_loss           | 2.17e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.56e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 415          |\n",
            "|    iterations           | 63           |\n",
            "|    time_elapsed         | 1554         |\n",
            "|    total_timesteps      | 645120       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0073644845 |\n",
            "|    clip_fraction        | 0.0619       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.654        |\n",
            "|    explained_variance   | 0.917        |\n",
            "|    learning_rate        | 0.00288      |\n",
            "|    loss                 | 5.25e+05     |\n",
            "|    n_updates            | 5030         |\n",
            "|    policy_gradient_loss | -0.00259     |\n",
            "|    std                  | 0.126        |\n",
            "|    value_loss           | 1.16e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.56e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 415          |\n",
            "|    iterations           | 64           |\n",
            "|    time_elapsed         | 1578         |\n",
            "|    total_timesteps      | 655360       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041670264 |\n",
            "|    clip_fraction        | 0.0412       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.655        |\n",
            "|    explained_variance   | 0.782        |\n",
            "|    learning_rate        | 0.00285      |\n",
            "|    loss                 | 5.53e+05     |\n",
            "|    n_updates            | 5040         |\n",
            "|    policy_gradient_loss | -0.00239     |\n",
            "|    std                  | 0.125        |\n",
            "|    value_loss           | 1.2e+06      |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -2.56e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 65          |\n",
            "|    time_elapsed         | 1603        |\n",
            "|    total_timesteps      | 665600      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007786803 |\n",
            "|    clip_fraction        | 0.0731      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.657       |\n",
            "|    explained_variance   | 0.808       |\n",
            "|    learning_rate        | 0.00282     |\n",
            "|    loss                 | 1.09e+06    |\n",
            "|    n_updates            | 5050        |\n",
            "|    policy_gradient_loss | -0.0025     |\n",
            "|    std                  | 0.125       |\n",
            "|    value_loss           | 2.14e+06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.56e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 415          |\n",
            "|    iterations           | 66           |\n",
            "|    time_elapsed         | 1627         |\n",
            "|    total_timesteps      | 675840       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0052473885 |\n",
            "|    clip_fraction        | 0.0451       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.661        |\n",
            "|    explained_variance   | 0.9          |\n",
            "|    learning_rate        | 0.00278      |\n",
            "|    loss                 | 2.97e+05     |\n",
            "|    n_updates            | 5060         |\n",
            "|    policy_gradient_loss | -0.00221     |\n",
            "|    std                  | 0.125        |\n",
            "|    value_loss           | 1.11e+06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -2.56e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 67          |\n",
            "|    time_elapsed         | 1651        |\n",
            "|    total_timesteps      | 686080      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004208979 |\n",
            "|    clip_fraction        | 0.0374      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.664       |\n",
            "|    explained_variance   | 0.804       |\n",
            "|    learning_rate        | 0.00275     |\n",
            "|    loss                 | 4.76e+05    |\n",
            "|    n_updates            | 5070        |\n",
            "|    policy_gradient_loss | -0.0021     |\n",
            "|    std                  | 0.125       |\n",
            "|    value_loss           | 1.09e+06    |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 5.97e+03   |\n",
            "|    ep_rew_mean          | -2.56e+06  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 415        |\n",
            "|    iterations           | 68         |\n",
            "|    time_elapsed         | 1676       |\n",
            "|    total_timesteps      | 696320     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00840429 |\n",
            "|    clip_fraction        | 0.0751     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | 0.665      |\n",
            "|    explained_variance   | 0.813      |\n",
            "|    learning_rate        | 0.00271    |\n",
            "|    loss                 | 1.02e+06   |\n",
            "|    n_updates            | 5080       |\n",
            "|    policy_gradient_loss | -0.00198   |\n",
            "|    std                  | 0.124      |\n",
            "|    value_loss           | 2.15e+06   |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -2.56e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 69          |\n",
            "|    time_elapsed         | 1700        |\n",
            "|    total_timesteps      | 706560      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005061886 |\n",
            "|    clip_fraction        | 0.044       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.668       |\n",
            "|    explained_variance   | 0.859       |\n",
            "|    learning_rate        | 0.00268     |\n",
            "|    loss                 | 5.88e+05    |\n",
            "|    n_updates            | 5090        |\n",
            "|    policy_gradient_loss | -0.00194    |\n",
            "|    std                  | 0.124       |\n",
            "|    value_loss           | 1.01e+06    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -2.56e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 70          |\n",
            "|    time_elapsed         | 1725        |\n",
            "|    total_timesteps      | 716800      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004363917 |\n",
            "|    clip_fraction        | 0.0368      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.667       |\n",
            "|    explained_variance   | 0.834       |\n",
            "|    learning_rate        | 0.00264     |\n",
            "|    loss                 | 3.57e+05    |\n",
            "|    n_updates            | 5100        |\n",
            "|    policy_gradient_loss | -0.00171    |\n",
            "|    std                  | 0.124       |\n",
            "|    value_loss           | 1.39e+06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.56e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 415          |\n",
            "|    iterations           | 71           |\n",
            "|    time_elapsed         | 1751         |\n",
            "|    total_timesteps      | 727040       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0055686813 |\n",
            "|    clip_fraction        | 0.0528       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.665        |\n",
            "|    explained_variance   | 0.826        |\n",
            "|    learning_rate        | 0.00261      |\n",
            "|    loss                 | 3.92e+05     |\n",
            "|    n_updates            | 5110         |\n",
            "|    policy_gradient_loss | -0.00169     |\n",
            "|    std                  | 0.125        |\n",
            "|    value_loss           | 1.99e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.56e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 415          |\n",
            "|    iterations           | 72           |\n",
            "|    time_elapsed         | 1775         |\n",
            "|    total_timesteps      | 737280       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0047847196 |\n",
            "|    clip_fraction        | 0.0453       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.661        |\n",
            "|    explained_variance   | 0.852        |\n",
            "|    learning_rate        | 0.00258      |\n",
            "|    loss                 | 3.73e+05     |\n",
            "|    n_updates            | 5120         |\n",
            "|    policy_gradient_loss | -0.00198     |\n",
            "|    std                  | 0.125        |\n",
            "|    value_loss           | 8.6e+05      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.56e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 415          |\n",
            "|    iterations           | 73           |\n",
            "|    time_elapsed         | 1799         |\n",
            "|    total_timesteps      | 747520       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044967374 |\n",
            "|    clip_fraction        | 0.0433       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.661        |\n",
            "|    explained_variance   | 0.841        |\n",
            "|    learning_rate        | 0.00254      |\n",
            "|    loss                 | 5.1e+05      |\n",
            "|    n_updates            | 5130         |\n",
            "|    policy_gradient_loss | -0.00292     |\n",
            "|    std                  | 0.125        |\n",
            "|    value_loss           | 1.47e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.56e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 415          |\n",
            "|    iterations           | 74           |\n",
            "|    time_elapsed         | 1824         |\n",
            "|    total_timesteps      | 757760       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0069534807 |\n",
            "|    clip_fraction        | 0.0613       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.661        |\n",
            "|    explained_variance   | 0.898        |\n",
            "|    learning_rate        | 0.00251      |\n",
            "|    loss                 | 8.59e+05     |\n",
            "|    n_updates            | 5140         |\n",
            "|    policy_gradient_loss | -0.00272     |\n",
            "|    std                  | 0.125        |\n",
            "|    value_loss           | 1.91e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.56e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 415          |\n",
            "|    iterations           | 75           |\n",
            "|    time_elapsed         | 1848         |\n",
            "|    total_timesteps      | 768000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0049053663 |\n",
            "|    clip_fraction        | 0.0418       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.659        |\n",
            "|    explained_variance   | 0.836        |\n",
            "|    learning_rate        | 0.00247      |\n",
            "|    loss                 | 2.89e+05     |\n",
            "|    n_updates            | 5150         |\n",
            "|    policy_gradient_loss | -0.00217     |\n",
            "|    std                  | 0.125        |\n",
            "|    value_loss           | 8.62e+05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.56e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 415          |\n",
            "|    iterations           | 76           |\n",
            "|    time_elapsed         | 1873         |\n",
            "|    total_timesteps      | 778240       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0050062956 |\n",
            "|    clip_fraction        | 0.0464       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.663        |\n",
            "|    explained_variance   | 0.847        |\n",
            "|    learning_rate        | 0.00244      |\n",
            "|    loss                 | 8.06e+05     |\n",
            "|    n_updates            | 5160         |\n",
            "|    policy_gradient_loss | -0.00301     |\n",
            "|    std                  | 0.124        |\n",
            "|    value_loss           | 1.48e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.56e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 415          |\n",
            "|    iterations           | 77           |\n",
            "|    time_elapsed         | 1896         |\n",
            "|    total_timesteps      | 788480       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0070973085 |\n",
            "|    clip_fraction        | 0.0602       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.668        |\n",
            "|    explained_variance   | 0.915        |\n",
            "|    learning_rate        | 0.00241      |\n",
            "|    loss                 | 1.06e+06     |\n",
            "|    n_updates            | 5170         |\n",
            "|    policy_gradient_loss | -0.002       |\n",
            "|    std                  | 0.124        |\n",
            "|    value_loss           | 1.85e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.56e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 415          |\n",
            "|    iterations           | 78           |\n",
            "|    time_elapsed         | 1921         |\n",
            "|    total_timesteps      | 798720       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040219775 |\n",
            "|    clip_fraction        | 0.039        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.672        |\n",
            "|    explained_variance   | 0.848        |\n",
            "|    learning_rate        | 0.00237      |\n",
            "|    loss                 | 4.62e+05     |\n",
            "|    n_updates            | 5180         |\n",
            "|    policy_gradient_loss | -0.0022      |\n",
            "|    std                  | 0.123        |\n",
            "|    value_loss           | 9.28e+05     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -2.56e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 79          |\n",
            "|    time_elapsed         | 1945        |\n",
            "|    total_timesteps      | 808960      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004901954 |\n",
            "|    clip_fraction        | 0.0397      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.675       |\n",
            "|    explained_variance   | 0.859       |\n",
            "|    learning_rate        | 0.00234     |\n",
            "|    loss                 | 5.22e+05    |\n",
            "|    n_updates            | 5190        |\n",
            "|    policy_gradient_loss | -0.00238    |\n",
            "|    std                  | 0.123       |\n",
            "|    value_loss           | 1.54e+06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.56e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 415          |\n",
            "|    iterations           | 80           |\n",
            "|    time_elapsed         | 1969         |\n",
            "|    total_timesteps      | 819200       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0071579395 |\n",
            "|    clip_fraction        | 0.0599       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.679        |\n",
            "|    explained_variance   | 0.922        |\n",
            "|    learning_rate        | 0.0023       |\n",
            "|    loss                 | 1.38e+06     |\n",
            "|    n_updates            | 5200         |\n",
            "|    policy_gradient_loss | -0.00239     |\n",
            "|    std                  | 0.122        |\n",
            "|    value_loss           | 1.78e+06     |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 5.97e+03   |\n",
            "|    ep_rew_mean          | -2.56e+06  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 415        |\n",
            "|    iterations           | 81         |\n",
            "|    time_elapsed         | 1994       |\n",
            "|    total_timesteps      | 829440     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00396692 |\n",
            "|    clip_fraction        | 0.0312     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | 0.684      |\n",
            "|    explained_variance   | 0.85       |\n",
            "|    learning_rate        | 0.00227    |\n",
            "|    loss                 | 5.19e+05   |\n",
            "|    n_updates            | 5210       |\n",
            "|    policy_gradient_loss | -0.00135   |\n",
            "|    std                  | 0.122      |\n",
            "|    value_loss           | 9.54e+05   |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -2.56e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 416         |\n",
            "|    iterations           | 82          |\n",
            "|    time_elapsed         | 2018        |\n",
            "|    total_timesteps      | 839680      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004178633 |\n",
            "|    clip_fraction        | 0.0378      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.688       |\n",
            "|    explained_variance   | 0.852       |\n",
            "|    learning_rate        | 0.00224     |\n",
            "|    loss                 | 4.43e+05    |\n",
            "|    n_updates            | 5220        |\n",
            "|    policy_gradient_loss | -0.00133    |\n",
            "|    std                  | 0.121       |\n",
            "|    value_loss           | 1.53e+06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.56e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 416          |\n",
            "|    iterations           | 83           |\n",
            "|    time_elapsed         | 2042         |\n",
            "|    total_timesteps      | 849920       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0070736557 |\n",
            "|    clip_fraction        | 0.0487       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.693        |\n",
            "|    explained_variance   | 0.928        |\n",
            "|    learning_rate        | 0.0022       |\n",
            "|    loss                 | 1.14e+06     |\n",
            "|    n_updates            | 5230         |\n",
            "|    policy_gradient_loss | -0.00209     |\n",
            "|    std                  | 0.12         |\n",
            "|    value_loss           | 1.69e+06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -2.56e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 416         |\n",
            "|    iterations           | 84          |\n",
            "|    time_elapsed         | 2067        |\n",
            "|    total_timesteps      | 860160      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004480449 |\n",
            "|    clip_fraction        | 0.0414      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.699       |\n",
            "|    explained_variance   | 0.852       |\n",
            "|    learning_rate        | 0.00217     |\n",
            "|    loss                 | 4.18e+05    |\n",
            "|    n_updates            | 5240        |\n",
            "|    policy_gradient_loss | -0.00231    |\n",
            "|    std                  | 0.12        |\n",
            "|    value_loss           | 9.54e+05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.56e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 416          |\n",
            "|    iterations           | 85           |\n",
            "|    time_elapsed         | 2091         |\n",
            "|    total_timesteps      | 870400       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0049973833 |\n",
            "|    clip_fraction        | 0.0437       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.701        |\n",
            "|    explained_variance   | 0.84         |\n",
            "|    learning_rate        | 0.00213      |\n",
            "|    loss                 | 4.97e+05     |\n",
            "|    n_updates            | 5250         |\n",
            "|    policy_gradient_loss | -0.00249     |\n",
            "|    std                  | 0.12         |\n",
            "|    value_loss           | 1.5e+06      |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -2.56e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 86          |\n",
            "|    time_elapsed         | 2116        |\n",
            "|    total_timesteps      | 880640      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005915013 |\n",
            "|    clip_fraction        | 0.0579      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.703       |\n",
            "|    explained_variance   | 0.929       |\n",
            "|    learning_rate        | 0.0021      |\n",
            "|    loss                 | 1.03e+06    |\n",
            "|    n_updates            | 5260        |\n",
            "|    policy_gradient_loss | -0.00313    |\n",
            "|    std                  | 0.12        |\n",
            "|    value_loss           | 1.61e+06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.56e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 416          |\n",
            "|    iterations           | 87           |\n",
            "|    time_elapsed         | 2140         |\n",
            "|    total_timesteps      | 890880       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036809207 |\n",
            "|    clip_fraction        | 0.0325       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.701        |\n",
            "|    explained_variance   | 0.842        |\n",
            "|    learning_rate        | 0.00206      |\n",
            "|    loss                 | 2.39e+05     |\n",
            "|    n_updates            | 5270         |\n",
            "|    policy_gradient_loss | -0.00133     |\n",
            "|    std                  | 0.12         |\n",
            "|    value_loss           | 9.64e+05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.56e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 416          |\n",
            "|    iterations           | 88           |\n",
            "|    time_elapsed         | 2165         |\n",
            "|    total_timesteps      | 901120       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0055291215 |\n",
            "|    clip_fraction        | 0.0436       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.703        |\n",
            "|    explained_variance   | 0.821        |\n",
            "|    learning_rate        | 0.00203      |\n",
            "|    loss                 | 4.88e+05     |\n",
            "|    n_updates            | 5280         |\n",
            "|    policy_gradient_loss | -0.00227     |\n",
            "|    std                  | 0.12         |\n",
            "|    value_loss           | 1.48e+06     |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 5.97e+03   |\n",
            "|    ep_rew_mean          | -2.56e+06  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 415        |\n",
            "|    iterations           | 89         |\n",
            "|    time_elapsed         | 2191       |\n",
            "|    total_timesteps      | 911360     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00619309 |\n",
            "|    clip_fraction        | 0.0488     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | 0.702      |\n",
            "|    explained_variance   | 0.931      |\n",
            "|    learning_rate        | 0.002      |\n",
            "|    loss                 | 4.68e+05   |\n",
            "|    n_updates            | 5290       |\n",
            "|    policy_gradient_loss | -0.0031    |\n",
            "|    std                  | 0.12       |\n",
            "|    value_loss           | 1.58e+06   |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.56e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 415          |\n",
            "|    iterations           | 90           |\n",
            "|    time_elapsed         | 2215         |\n",
            "|    total_timesteps      | 921600       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0043172874 |\n",
            "|    clip_fraction        | 0.0387       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.699        |\n",
            "|    explained_variance   | 0.856        |\n",
            "|    learning_rate        | 0.00196      |\n",
            "|    loss                 | 3.76e+05     |\n",
            "|    n_updates            | 5300         |\n",
            "|    policy_gradient_loss | -0.00259     |\n",
            "|    std                  | 0.12         |\n",
            "|    value_loss           | 9.85e+05     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -2.55e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 91          |\n",
            "|    time_elapsed         | 2241        |\n",
            "|    total_timesteps      | 931840      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004967359 |\n",
            "|    clip_fraction        | 0.0409      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.701       |\n",
            "|    explained_variance   | 0.834       |\n",
            "|    learning_rate        | 0.00193     |\n",
            "|    loss                 | 1.23e+06    |\n",
            "|    n_updates            | 5310        |\n",
            "|    policy_gradient_loss | -0.00248    |\n",
            "|    std                  | 0.12        |\n",
            "|    value_loss           | 1.56e+06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.55e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 415          |\n",
            "|    iterations           | 92           |\n",
            "|    time_elapsed         | 2266         |\n",
            "|    total_timesteps      | 942080       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0046226704 |\n",
            "|    clip_fraction        | 0.0452       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.703        |\n",
            "|    explained_variance   | 0.93         |\n",
            "|    learning_rate        | 0.00189      |\n",
            "|    loss                 | 5.47e+05     |\n",
            "|    n_updates            | 5320         |\n",
            "|    policy_gradient_loss | -0.0021      |\n",
            "|    std                  | 0.12         |\n",
            "|    value_loss           | 1.58e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.55e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 415          |\n",
            "|    iterations           | 93           |\n",
            "|    time_elapsed         | 2291         |\n",
            "|    total_timesteps      | 952320       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035593316 |\n",
            "|    clip_fraction        | 0.0264       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.7          |\n",
            "|    explained_variance   | 0.841        |\n",
            "|    learning_rate        | 0.00186      |\n",
            "|    loss                 | 4.09e+05     |\n",
            "|    n_updates            | 5330         |\n",
            "|    policy_gradient_loss | -0.00113     |\n",
            "|    std                  | 0.12         |\n",
            "|    value_loss           | 1.01e+06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -2.55e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 94          |\n",
            "|    time_elapsed         | 2316        |\n",
            "|    total_timesteps      | 962560      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004763813 |\n",
            "|    clip_fraction        | 0.0406      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.7         |\n",
            "|    explained_variance   | 0.827       |\n",
            "|    learning_rate        | 0.00183     |\n",
            "|    loss                 | 8.37e+05    |\n",
            "|    n_updates            | 5340        |\n",
            "|    policy_gradient_loss | -0.00238    |\n",
            "|    std                  | 0.12        |\n",
            "|    value_loss           | 1.54e+06    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -2.55e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 95          |\n",
            "|    time_elapsed         | 2341        |\n",
            "|    total_timesteps      | 972800      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004502221 |\n",
            "|    clip_fraction        | 0.0371      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.703       |\n",
            "|    explained_variance   | 0.934       |\n",
            "|    learning_rate        | 0.00179     |\n",
            "|    loss                 | 5.51e+05    |\n",
            "|    n_updates            | 5350        |\n",
            "|    policy_gradient_loss | -0.00196    |\n",
            "|    std                  | 0.12        |\n",
            "|    value_loss           | 1.53e+06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.55e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 415          |\n",
            "|    iterations           | 96           |\n",
            "|    time_elapsed         | 2366         |\n",
            "|    total_timesteps      | 983040       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033098725 |\n",
            "|    clip_fraction        | 0.0276       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.706        |\n",
            "|    explained_variance   | 0.809        |\n",
            "|    learning_rate        | 0.00176      |\n",
            "|    loss                 | 5.06e+05     |\n",
            "|    n_updates            | 5360         |\n",
            "|    policy_gradient_loss | -0.00225     |\n",
            "|    std                  | 0.119        |\n",
            "|    value_loss           | 1.02e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.55e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 415          |\n",
            "|    iterations           | 97           |\n",
            "|    time_elapsed         | 2391         |\n",
            "|    total_timesteps      | 993280       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0055367164 |\n",
            "|    clip_fraction        | 0.0463       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.709        |\n",
            "|    explained_variance   | 0.836        |\n",
            "|    learning_rate        | 0.00172      |\n",
            "|    loss                 | 6.06e+05     |\n",
            "|    n_updates            | 5370         |\n",
            "|    policy_gradient_loss | -0.00277     |\n",
            "|    std                  | 0.119        |\n",
            "|    value_loss           | 1.88e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.55e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 415          |\n",
            "|    iterations           | 98           |\n",
            "|    time_elapsed         | 2416         |\n",
            "|    total_timesteps      | 1003520      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0057818205 |\n",
            "|    clip_fraction        | 0.0461       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.709        |\n",
            "|    explained_variance   | 0.936        |\n",
            "|    learning_rate        | 0.00169      |\n",
            "|    loss                 | 2.59e+05     |\n",
            "|    n_updates            | 5380         |\n",
            "|    policy_gradient_loss | -0.00267     |\n",
            "|    std                  | 0.119        |\n",
            "|    value_loss           | 1.06e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.55e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 415          |\n",
            "|    iterations           | 99           |\n",
            "|    time_elapsed         | 2441         |\n",
            "|    total_timesteps      | 1013760      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035202994 |\n",
            "|    clip_fraction        | 0.0267       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.711        |\n",
            "|    explained_variance   | 0.821        |\n",
            "|    learning_rate        | 0.00165      |\n",
            "|    loss                 | 3.62e+05     |\n",
            "|    n_updates            | 5390         |\n",
            "|    policy_gradient_loss | -0.00234     |\n",
            "|    std                  | 0.119        |\n",
            "|    value_loss           | 1.01e+06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -2.55e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 100         |\n",
            "|    time_elapsed         | 2466        |\n",
            "|    total_timesteps      | 1024000     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007525116 |\n",
            "|    clip_fraction        | 0.0481      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.713       |\n",
            "|    explained_variance   | 0.841       |\n",
            "|    learning_rate        | 0.00162     |\n",
            "|    loss                 | 1.35e+06    |\n",
            "|    n_updates            | 5400        |\n",
            "|    policy_gradient_loss | -0.00252    |\n",
            "|    std                  | 0.119       |\n",
            "|    value_loss           | 2.02e+06    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -2.55e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 101         |\n",
            "|    time_elapsed         | 2490        |\n",
            "|    total_timesteps      | 1034240     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005042803 |\n",
            "|    clip_fraction        | 0.0371      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.716       |\n",
            "|    explained_variance   | 0.925       |\n",
            "|    learning_rate        | 0.00159     |\n",
            "|    loss                 | 4.63e+05    |\n",
            "|    n_updates            | 5410        |\n",
            "|    policy_gradient_loss | -0.00205    |\n",
            "|    std                  | 0.118       |\n",
            "|    value_loss           | 1.02e+06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.55e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 415          |\n",
            "|    iterations           | 102          |\n",
            "|    time_elapsed         | 2516         |\n",
            "|    total_timesteps      | 1044480      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032239247 |\n",
            "|    clip_fraction        | 0.0256       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.719        |\n",
            "|    explained_variance   | 0.823        |\n",
            "|    learning_rate        | 0.00155      |\n",
            "|    loss                 | 7.52e+05     |\n",
            "|    n_updates            | 5420         |\n",
            "|    policy_gradient_loss | -0.00154     |\n",
            "|    std                  | 0.118        |\n",
            "|    value_loss           | 1.02e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.55e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 414          |\n",
            "|    iterations           | 103          |\n",
            "|    time_elapsed         | 2542         |\n",
            "|    total_timesteps      | 1054720      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0058528045 |\n",
            "|    clip_fraction        | 0.0429       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.72         |\n",
            "|    explained_variance   | 0.841        |\n",
            "|    learning_rate        | 0.00152      |\n",
            "|    loss                 | 7.22e+05     |\n",
            "|    n_updates            | 5430         |\n",
            "|    policy_gradient_loss | -0.00261     |\n",
            "|    std                  | 0.118        |\n",
            "|    value_loss           | 2e+06        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.55e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 414          |\n",
            "|    iterations           | 104          |\n",
            "|    time_elapsed         | 2566         |\n",
            "|    total_timesteps      | 1064960      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039068544 |\n",
            "|    clip_fraction        | 0.0326       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.72         |\n",
            "|    explained_variance   | 0.899        |\n",
            "|    learning_rate        | 0.00148      |\n",
            "|    loss                 | 4.55e+05     |\n",
            "|    n_updates            | 5440         |\n",
            "|    policy_gradient_loss | -0.00176     |\n",
            "|    std                  | 0.118        |\n",
            "|    value_loss           | 9.92e+05     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -2.55e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 414         |\n",
            "|    iterations           | 105         |\n",
            "|    time_elapsed         | 2591        |\n",
            "|    total_timesteps      | 1075200     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003992052 |\n",
            "|    clip_fraction        | 0.0273      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.72        |\n",
            "|    explained_variance   | 0.852       |\n",
            "|    learning_rate        | 0.00145     |\n",
            "|    loss                 | 3.96e+05    |\n",
            "|    n_updates            | 5450        |\n",
            "|    policy_gradient_loss | -0.00248    |\n",
            "|    std                  | 0.117       |\n",
            "|    value_loss           | 1.3e+06     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -2.55e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 414         |\n",
            "|    iterations           | 106         |\n",
            "|    time_elapsed         | 2616        |\n",
            "|    total_timesteps      | 1085440     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004333222 |\n",
            "|    clip_fraction        | 0.0392      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.723       |\n",
            "|    explained_variance   | 0.857       |\n",
            "|    learning_rate        | 0.00142     |\n",
            "|    loss                 | 7.26e+05    |\n",
            "|    n_updates            | 5460        |\n",
            "|    policy_gradient_loss | -0.00152    |\n",
            "|    std                  | 0.117       |\n",
            "|    value_loss           | 1.85e+06    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -2.55e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 414         |\n",
            "|    iterations           | 107         |\n",
            "|    time_elapsed         | 2641        |\n",
            "|    total_timesteps      | 1095680     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004369332 |\n",
            "|    clip_fraction        | 0.0374      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.723       |\n",
            "|    explained_variance   | 0.885       |\n",
            "|    learning_rate        | 0.00138     |\n",
            "|    loss                 | 4.61e+05    |\n",
            "|    n_updates            | 5470        |\n",
            "|    policy_gradient_loss | -0.00253    |\n",
            "|    std                  | 0.117       |\n",
            "|    value_loss           | 7.92e+05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.55e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 414          |\n",
            "|    iterations           | 108          |\n",
            "|    time_elapsed         | 2667         |\n",
            "|    total_timesteps      | 1105920      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038421764 |\n",
            "|    clip_fraction        | 0.0299       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.726        |\n",
            "|    explained_variance   | 0.865        |\n",
            "|    learning_rate        | 0.00135      |\n",
            "|    loss                 | 5.42e+05     |\n",
            "|    n_updates            | 5480         |\n",
            "|    policy_gradient_loss | -0.0028      |\n",
            "|    std                  | 0.117        |\n",
            "|    value_loss           | 1.36e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.55e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 414          |\n",
            "|    iterations           | 109          |\n",
            "|    time_elapsed         | 2692         |\n",
            "|    total_timesteps      | 1116160      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035296376 |\n",
            "|    clip_fraction        | 0.0352       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.728        |\n",
            "|    explained_variance   | 0.921        |\n",
            "|    learning_rate        | 0.00131      |\n",
            "|    loss                 | 2.84e+05     |\n",
            "|    n_updates            | 5490         |\n",
            "|    policy_gradient_loss | -0.00217     |\n",
            "|    std                  | 0.117        |\n",
            "|    value_loss           | 1.72e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.55e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 414          |\n",
            "|    iterations           | 110          |\n",
            "|    time_elapsed         | 2717         |\n",
            "|    total_timesteps      | 1126400      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039501926 |\n",
            "|    clip_fraction        | 0.0268       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.73         |\n",
            "|    explained_variance   | 0.874        |\n",
            "|    learning_rate        | 0.00128      |\n",
            "|    loss                 | 6.4e+05      |\n",
            "|    n_updates            | 5500         |\n",
            "|    policy_gradient_loss | -0.00179     |\n",
            "|    std                  | 0.116        |\n",
            "|    value_loss           | 8.16e+05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.55e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 414          |\n",
            "|    iterations           | 111          |\n",
            "|    time_elapsed         | 2742         |\n",
            "|    total_timesteps      | 1136640      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0047114757 |\n",
            "|    clip_fraction        | 0.0296       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.735        |\n",
            "|    explained_variance   | 0.878        |\n",
            "|    learning_rate        | 0.00125      |\n",
            "|    loss                 | 7.46e+05     |\n",
            "|    n_updates            | 5510         |\n",
            "|    policy_gradient_loss | -0.00364     |\n",
            "|    std                  | 0.116        |\n",
            "|    value_loss           | 1.38e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.55e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 414          |\n",
            "|    iterations           | 112          |\n",
            "|    time_elapsed         | 2766         |\n",
            "|    total_timesteps      | 1146880      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0055020745 |\n",
            "|    clip_fraction        | 0.0481       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.738        |\n",
            "|    explained_variance   | 0.931        |\n",
            "|    learning_rate        | 0.00121      |\n",
            "|    loss                 | 4.73e+05     |\n",
            "|    n_updates            | 5520         |\n",
            "|    policy_gradient_loss | -0.00353     |\n",
            "|    std                  | 0.116        |\n",
            "|    value_loss           | 1.67e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.55e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 414          |\n",
            "|    iterations           | 113          |\n",
            "|    time_elapsed         | 2791         |\n",
            "|    total_timesteps      | 1157120      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031099245 |\n",
            "|    clip_fraction        | 0.0214       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.74         |\n",
            "|    explained_variance   | 0.887        |\n",
            "|    learning_rate        | 0.00118      |\n",
            "|    loss                 | 3.35e+05     |\n",
            "|    n_updates            | 5530         |\n",
            "|    policy_gradient_loss | -0.00113     |\n",
            "|    std                  | 0.115        |\n",
            "|    value_loss           | 8.59e+05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.55e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 414          |\n",
            "|    iterations           | 114          |\n",
            "|    time_elapsed         | 2817         |\n",
            "|    total_timesteps      | 1167360      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035699282 |\n",
            "|    clip_fraction        | 0.024        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.74         |\n",
            "|    explained_variance   | 0.89         |\n",
            "|    learning_rate        | 0.00114      |\n",
            "|    loss                 | 5.45e+05     |\n",
            "|    n_updates            | 5540         |\n",
            "|    policy_gradient_loss | -0.00191     |\n",
            "|    std                  | 0.116        |\n",
            "|    value_loss           | 1.44e+06     |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 5.97e+03   |\n",
            "|    ep_rew_mean          | -2.55e+06  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 414        |\n",
            "|    iterations           | 115        |\n",
            "|    time_elapsed         | 2841       |\n",
            "|    total_timesteps      | 1177600    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00525043 |\n",
            "|    clip_fraction        | 0.0412     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | 0.739      |\n",
            "|    explained_variance   | 0.936      |\n",
            "|    learning_rate        | 0.00111    |\n",
            "|    loss                 | 4.17e+05   |\n",
            "|    n_updates            | 5550       |\n",
            "|    policy_gradient_loss | -0.0033    |\n",
            "|    std                  | 0.115      |\n",
            "|    value_loss           | 1.66e+06   |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.55e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 414          |\n",
            "|    iterations           | 116          |\n",
            "|    time_elapsed         | 2866         |\n",
            "|    total_timesteps      | 1187840      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026641297 |\n",
            "|    clip_fraction        | 0.0212       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.74         |\n",
            "|    explained_variance   | 0.885        |\n",
            "|    learning_rate        | 0.00107      |\n",
            "|    loss                 | 3.5e+05      |\n",
            "|    n_updates            | 5560         |\n",
            "|    policy_gradient_loss | -0.00126     |\n",
            "|    std                  | 0.115        |\n",
            "|    value_loss           | 9.19e+05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.55e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 414          |\n",
            "|    iterations           | 117          |\n",
            "|    time_elapsed         | 2891         |\n",
            "|    total_timesteps      | 1198080      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038791895 |\n",
            "|    clip_fraction        | 0.0286       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.739        |\n",
            "|    explained_variance   | 0.883        |\n",
            "|    learning_rate        | 0.00104      |\n",
            "|    loss                 | 9.79e+05     |\n",
            "|    n_updates            | 5570         |\n",
            "|    policy_gradient_loss | -0.0029      |\n",
            "|    std                  | 0.116        |\n",
            "|    value_loss           | 1.42e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.55e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 414          |\n",
            "|    iterations           | 118          |\n",
            "|    time_elapsed         | 2915         |\n",
            "|    total_timesteps      | 1208320      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0049051726 |\n",
            "|    clip_fraction        | 0.0353       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.739        |\n",
            "|    explained_variance   | 0.943        |\n",
            "|    learning_rate        | 0.00101      |\n",
            "|    loss                 | 8.21e+05     |\n",
            "|    n_updates            | 5580         |\n",
            "|    policy_gradient_loss | -0.00267     |\n",
            "|    std                  | 0.116        |\n",
            "|    value_loss           | 1.61e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.55e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 414          |\n",
            "|    iterations           | 119          |\n",
            "|    time_elapsed         | 2941         |\n",
            "|    total_timesteps      | 1218560      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025121567 |\n",
            "|    clip_fraction        | 0.0178       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.738        |\n",
            "|    explained_variance   | 0.883        |\n",
            "|    learning_rate        | 0.000972     |\n",
            "|    loss                 | 6.09e+05     |\n",
            "|    n_updates            | 5590         |\n",
            "|    policy_gradient_loss | -0.00144     |\n",
            "|    std                  | 0.116        |\n",
            "|    value_loss           | 9.28e+05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.55e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 414          |\n",
            "|    iterations           | 120          |\n",
            "|    time_elapsed         | 2964         |\n",
            "|    total_timesteps      | 1228800      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029795375 |\n",
            "|    clip_fraction        | 0.0271       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.74         |\n",
            "|    explained_variance   | 0.871        |\n",
            "|    learning_rate        | 0.000938     |\n",
            "|    loss                 | 6.1e+05      |\n",
            "|    n_updates            | 5600         |\n",
            "|    policy_gradient_loss | -0.00209     |\n",
            "|    std                  | 0.115        |\n",
            "|    value_loss           | 1.47e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.55e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 414          |\n",
            "|    iterations           | 121          |\n",
            "|    time_elapsed         | 2990         |\n",
            "|    total_timesteps      | 1239040      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0047210357 |\n",
            "|    clip_fraction        | 0.0296       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.741        |\n",
            "|    explained_variance   | 0.946        |\n",
            "|    learning_rate        | 0.000904     |\n",
            "|    loss                 | 9.38e+05     |\n",
            "|    n_updates            | 5610         |\n",
            "|    policy_gradient_loss | -0.0022      |\n",
            "|    std                  | 0.115        |\n",
            "|    value_loss           | 1.55e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.55e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 414          |\n",
            "|    iterations           | 122          |\n",
            "|    time_elapsed         | 3015         |\n",
            "|    total_timesteps      | 1249280      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022688496 |\n",
            "|    clip_fraction        | 0.0126       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.74         |\n",
            "|    explained_variance   | 0.881        |\n",
            "|    learning_rate        | 0.00087      |\n",
            "|    loss                 | 4.62e+05     |\n",
            "|    n_updates            | 5620         |\n",
            "|    policy_gradient_loss | -0.000421    |\n",
            "|    std                  | 0.115        |\n",
            "|    value_loss           | 9.48e+05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.55e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 414          |\n",
            "|    iterations           | 123          |\n",
            "|    time_elapsed         | 3039         |\n",
            "|    total_timesteps      | 1259520      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033503585 |\n",
            "|    clip_fraction        | 0.0255       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.74         |\n",
            "|    explained_variance   | 0.859        |\n",
            "|    learning_rate        | 0.000836     |\n",
            "|    loss                 | 6.1e+05      |\n",
            "|    n_updates            | 5630         |\n",
            "|    policy_gradient_loss | -0.00304     |\n",
            "|    std                  | 0.115        |\n",
            "|    value_loss           | 1.5e+06      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.55e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 414          |\n",
            "|    iterations           | 124          |\n",
            "|    time_elapsed         | 3064         |\n",
            "|    total_timesteps      | 1269760      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034403794 |\n",
            "|    clip_fraction        | 0.0235       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.742        |\n",
            "|    explained_variance   | 0.947        |\n",
            "|    learning_rate        | 0.000802     |\n",
            "|    loss                 | 6.76e+05     |\n",
            "|    n_updates            | 5640         |\n",
            "|    policy_gradient_loss | -0.00198     |\n",
            "|    std                  | 0.115        |\n",
            "|    value_loss           | 1.52e+06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -2.55e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 414         |\n",
            "|    iterations           | 125         |\n",
            "|    time_elapsed         | 3089        |\n",
            "|    total_timesteps      | 1280000     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002765386 |\n",
            "|    clip_fraction        | 0.0197      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.742       |\n",
            "|    explained_variance   | 0.89        |\n",
            "|    learning_rate        | 0.000767    |\n",
            "|    loss                 | 5.31e+05    |\n",
            "|    n_updates            | 5650        |\n",
            "|    policy_gradient_loss | -0.00163    |\n",
            "|    std                  | 0.115       |\n",
            "|    value_loss           | 9.73e+05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.55e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 414          |\n",
            "|    iterations           | 126          |\n",
            "|    time_elapsed         | 3113         |\n",
            "|    total_timesteps      | 1290240      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028093192 |\n",
            "|    clip_fraction        | 0.0193       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.743        |\n",
            "|    explained_variance   | 0.863        |\n",
            "|    learning_rate        | 0.000733     |\n",
            "|    loss                 | 2.6e+05      |\n",
            "|    n_updates            | 5660         |\n",
            "|    policy_gradient_loss | -0.00211     |\n",
            "|    std                  | 0.115        |\n",
            "|    value_loss           | 1.56e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.55e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 414          |\n",
            "|    iterations           | 127          |\n",
            "|    time_elapsed         | 3139         |\n",
            "|    total_timesteps      | 1300480      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039485125 |\n",
            "|    clip_fraction        | 0.0314       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.744        |\n",
            "|    explained_variance   | 0.946        |\n",
            "|    learning_rate        | 0.000699     |\n",
            "|    loss                 | 8.15e+05     |\n",
            "|    n_updates            | 5670         |\n",
            "|    policy_gradient_loss | -0.00293     |\n",
            "|    std                  | 0.115        |\n",
            "|    value_loss           | 1.49e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.55e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 414          |\n",
            "|    iterations           | 128          |\n",
            "|    time_elapsed         | 3163         |\n",
            "|    total_timesteps      | 1310720      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025065555 |\n",
            "|    clip_fraction        | 0.0158       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.744        |\n",
            "|    explained_variance   | 0.879        |\n",
            "|    learning_rate        | 0.000665     |\n",
            "|    loss                 | 7.22e+05     |\n",
            "|    n_updates            | 5680         |\n",
            "|    policy_gradient_loss | -0.00127     |\n",
            "|    std                  | 0.115        |\n",
            "|    value_loss           | 9.76e+05     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.55e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 414          |\n",
            "|    iterations           | 129          |\n",
            "|    time_elapsed         | 3188         |\n",
            "|    total_timesteps      | 1320960      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030809161 |\n",
            "|    clip_fraction        | 0.0206       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.746        |\n",
            "|    explained_variance   | 0.868        |\n",
            "|    learning_rate        | 0.000631     |\n",
            "|    loss                 | 7.73e+05     |\n",
            "|    n_updates            | 5690         |\n",
            "|    policy_gradient_loss | -0.00218     |\n",
            "|    std                  | 0.115        |\n",
            "|    value_loss           | 1.58e+06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -2.55e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 414         |\n",
            "|    iterations           | 130         |\n",
            "|    time_elapsed         | 3213        |\n",
            "|    total_timesteps      | 1331200     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004106162 |\n",
            "|    clip_fraction        | 0.0239      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.746       |\n",
            "|    explained_variance   | 0.949       |\n",
            "|    learning_rate        | 0.000597    |\n",
            "|    loss                 | 1.02e+06    |\n",
            "|    n_updates            | 5700        |\n",
            "|    policy_gradient_loss | -0.00307    |\n",
            "|    std                  | 0.115       |\n",
            "|    value_loss           | 1.51e+06    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -2.55e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 414         |\n",
            "|    iterations           | 131         |\n",
            "|    time_elapsed         | 3237        |\n",
            "|    total_timesteps      | 1341440     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001759487 |\n",
            "|    clip_fraction        | 0.00967     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.745       |\n",
            "|    explained_variance   | 0.853       |\n",
            "|    learning_rate        | 0.000563    |\n",
            "|    loss                 | 4.62e+05    |\n",
            "|    n_updates            | 5710        |\n",
            "|    policy_gradient_loss | -0.00117    |\n",
            "|    std                  | 0.115       |\n",
            "|    value_loss           | 9.86e+05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.55e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 414          |\n",
            "|    iterations           | 132          |\n",
            "|    time_elapsed         | 3262         |\n",
            "|    total_timesteps      | 1351680      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032990663 |\n",
            "|    clip_fraction        | 0.0242       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.746        |\n",
            "|    explained_variance   | 0.878        |\n",
            "|    learning_rate        | 0.000529     |\n",
            "|    loss                 | 7.45e+05     |\n",
            "|    n_updates            | 5720         |\n",
            "|    policy_gradient_loss | -0.00283     |\n",
            "|    std                  | 0.115        |\n",
            "|    value_loss           | 1.76e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.55e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 414          |\n",
            "|    iterations           | 133          |\n",
            "|    time_elapsed         | 3286         |\n",
            "|    total_timesteps      | 1361920      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030598436 |\n",
            "|    clip_fraction        | 0.0145       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.747        |\n",
            "|    explained_variance   | 0.952        |\n",
            "|    learning_rate        | 0.000494     |\n",
            "|    loss                 | 6.92e+05     |\n",
            "|    n_updates            | 5730         |\n",
            "|    policy_gradient_loss | -0.00189     |\n",
            "|    std                  | 0.115        |\n",
            "|    value_loss           | 1.09e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.55e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 414          |\n",
            "|    iterations           | 134          |\n",
            "|    time_elapsed         | 3311         |\n",
            "|    total_timesteps      | 1372160      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018191903 |\n",
            "|    clip_fraction        | 0.00441      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.749        |\n",
            "|    explained_variance   | 0.855        |\n",
            "|    learning_rate        | 0.00046      |\n",
            "|    loss                 | 3.82e+05     |\n",
            "|    n_updates            | 5740         |\n",
            "|    policy_gradient_loss | -0.00109     |\n",
            "|    std                  | 0.114        |\n",
            "|    value_loss           | 1e+06        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.55e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 414          |\n",
            "|    iterations           | 135          |\n",
            "|    time_elapsed         | 3336         |\n",
            "|    total_timesteps      | 1382400      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035844636 |\n",
            "|    clip_fraction        | 0.0263       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.75         |\n",
            "|    explained_variance   | 0.876        |\n",
            "|    learning_rate        | 0.000426     |\n",
            "|    loss                 | 9.79e+05     |\n",
            "|    n_updates            | 5750         |\n",
            "|    policy_gradient_loss | -0.00284     |\n",
            "|    std                  | 0.114        |\n",
            "|    value_loss           | 2.09e+06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -2.55e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 414         |\n",
            "|    iterations           | 136         |\n",
            "|    time_elapsed         | 3360        |\n",
            "|    total_timesteps      | 1392640     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003103406 |\n",
            "|    clip_fraction        | 0.0193      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.751       |\n",
            "|    explained_variance   | 0.945       |\n",
            "|    learning_rate        | 0.000392    |\n",
            "|    loss                 | 5.66e+05    |\n",
            "|    n_updates            | 5760        |\n",
            "|    policy_gradient_loss | -0.00247    |\n",
            "|    std                  | 0.114       |\n",
            "|    value_loss           | 1.03e+06    |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 5.97e+03   |\n",
            "|    ep_rew_mean          | -2.55e+06  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 414        |\n",
            "|    iterations           | 137        |\n",
            "|    time_elapsed         | 3385       |\n",
            "|    total_timesteps      | 1402880    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00240262 |\n",
            "|    clip_fraction        | 0.0137     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | 0.751      |\n",
            "|    explained_variance   | 0.855      |\n",
            "|    learning_rate        | 0.000358   |\n",
            "|    loss                 | 3.37e+05   |\n",
            "|    n_updates            | 5770       |\n",
            "|    policy_gradient_loss | -0.00154   |\n",
            "|    std                  | 0.114      |\n",
            "|    value_loss           | 1.01e+06   |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 5.97e+03   |\n",
            "|    ep_rew_mean          | -2.55e+06  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 414        |\n",
            "|    iterations           | 138        |\n",
            "|    time_elapsed         | 3410       |\n",
            "|    total_timesteps      | 1413120    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00213902 |\n",
            "|    clip_fraction        | 0.0102     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | 0.751      |\n",
            "|    explained_variance   | 0.878      |\n",
            "|    learning_rate        | 0.000324   |\n",
            "|    loss                 | 1.45e+06   |\n",
            "|    n_updates            | 5780       |\n",
            "|    policy_gradient_loss | -0.00147   |\n",
            "|    std                  | 0.114      |\n",
            "|    value_loss           | 2.09e+06   |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.55e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 414          |\n",
            "|    iterations           | 139          |\n",
            "|    time_elapsed         | 3433         |\n",
            "|    total_timesteps      | 1423360      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023693785 |\n",
            "|    clip_fraction        | 0.0153       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.752        |\n",
            "|    explained_variance   | 0.927        |\n",
            "|    learning_rate        | 0.00029      |\n",
            "|    loss                 | 5.79e+05     |\n",
            "|    n_updates            | 5790         |\n",
            "|    policy_gradient_loss | -0.00211     |\n",
            "|    std                  | 0.114        |\n",
            "|    value_loss           | 1.01e+06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -2.55e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 414         |\n",
            "|    iterations           | 140         |\n",
            "|    time_elapsed         | 3458        |\n",
            "|    total_timesteps      | 1433600     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001722157 |\n",
            "|    clip_fraction        | 0.00552     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.752       |\n",
            "|    explained_variance   | 0.886       |\n",
            "|    learning_rate        | 0.000255    |\n",
            "|    loss                 | 3.92e+05    |\n",
            "|    n_updates            | 5800        |\n",
            "|    policy_gradient_loss | -0.00141    |\n",
            "|    std                  | 0.114       |\n",
            "|    value_loss           | 1.28e+06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.54e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 414          |\n",
            "|    iterations           | 141          |\n",
            "|    time_elapsed         | 3482         |\n",
            "|    total_timesteps      | 1443840      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015126939 |\n",
            "|    clip_fraction        | 0.00561      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.752        |\n",
            "|    explained_variance   | 0.89         |\n",
            "|    learning_rate        | 0.000221     |\n",
            "|    loss                 | 9.31e+05     |\n",
            "|    n_updates            | 5810         |\n",
            "|    policy_gradient_loss | -0.00105     |\n",
            "|    std                  | 0.114        |\n",
            "|    value_loss           | 1.95e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.54e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 414          |\n",
            "|    iterations           | 142          |\n",
            "|    time_elapsed         | 3506         |\n",
            "|    total_timesteps      | 1454080      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024213358 |\n",
            "|    clip_fraction        | 0.00827      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.752        |\n",
            "|    explained_variance   | 0.917        |\n",
            "|    learning_rate        | 0.000187     |\n",
            "|    loss                 | 3.81e+05     |\n",
            "|    n_updates            | 5820         |\n",
            "|    policy_gradient_loss | -0.0012      |\n",
            "|    std                  | 0.114        |\n",
            "|    value_loss           | 8.5e+05      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.54e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 414          |\n",
            "|    iterations           | 143          |\n",
            "|    time_elapsed         | 3531         |\n",
            "|    total_timesteps      | 1464320      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0009809814 |\n",
            "|    clip_fraction        | 0.00243      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.753        |\n",
            "|    explained_variance   | 0.891        |\n",
            "|    learning_rate        | 0.000153     |\n",
            "|    loss                 | 4.05e+05     |\n",
            "|    n_updates            | 5830         |\n",
            "|    policy_gradient_loss | -0.00106     |\n",
            "|    std                  | 0.114        |\n",
            "|    value_loss           | 1.4e+06      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.54e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 414          |\n",
            "|    iterations           | 144          |\n",
            "|    time_elapsed         | 3554         |\n",
            "|    total_timesteps      | 1474560      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019328769 |\n",
            "|    clip_fraction        | 0.011        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.753        |\n",
            "|    explained_variance   | 0.94         |\n",
            "|    learning_rate        | 0.000119     |\n",
            "|    loss                 | 1.21e+06     |\n",
            "|    n_updates            | 5840         |\n",
            "|    policy_gradient_loss | -0.00177     |\n",
            "|    std                  | 0.114        |\n",
            "|    value_loss           | 1.83e+06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -2.54e+06   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 414         |\n",
            "|    iterations           | 145         |\n",
            "|    time_elapsed         | 3579        |\n",
            "|    total_timesteps      | 1484800     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002285285 |\n",
            "|    clip_fraction        | 0.00433     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | 0.753       |\n",
            "|    explained_variance   | 0.911       |\n",
            "|    learning_rate        | 8.48e-05    |\n",
            "|    loss                 | 5.94e+05    |\n",
            "|    n_updates            | 5850        |\n",
            "|    policy_gradient_loss | -0.00102    |\n",
            "|    std                  | 0.114       |\n",
            "|    value_loss           | 9.01e+05    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.54e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 414          |\n",
            "|    iterations           | 146          |\n",
            "|    time_elapsed         | 3604         |\n",
            "|    total_timesteps      | 1495040      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0005126846 |\n",
            "|    clip_fraction        | 3.91e-05     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.753        |\n",
            "|    explained_variance   | 0.901        |\n",
            "|    learning_rate        | 5.07e-05     |\n",
            "|    loss                 | 6.25e+05     |\n",
            "|    n_updates            | 5860         |\n",
            "|    policy_gradient_loss | -0.000265    |\n",
            "|    std                  | 0.114        |\n",
            "|    value_loss           | 1.53e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -2.54e+06    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 414          |\n",
            "|    iterations           | 147          |\n",
            "|    time_elapsed         | 3628         |\n",
            "|    total_timesteps      | 1505280      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 1.693422e-05 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | 0.753        |\n",
            "|    explained_variance   | 0.95         |\n",
            "|    learning_rate        | 1.65e-05     |\n",
            "|    loss                 | 7.15e+05     |\n",
            "|    n_updates            | 5870         |\n",
            "|    policy_gradient_loss | -0.000121    |\n",
            "|    std                  | 0.114        |\n",
            "|    value_loss           | 1.92e+06     |\n",
            "------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.678 MB of 0.678 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "903ca881fc284bd9af87d33b8ba45213"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Diesel Generator</td><td></td></tr><tr><td>Excess Generation</td><td></td></tr><tr><td>Inverter total power flow</td><td></td></tr><tr><td>Max Demand</td><td></td></tr><tr><td>Num Diesel Gen Actions</td><td></td></tr><tr><td>Num Off-Peak Purchases</td><td></td></tr><tr><td>Num Peak Purchases</td><td></td></tr><tr><td>Num Standard Purchases</td><td></td></tr><tr><td>Off-Peak Purchases</td><td></td></tr><tr><td>Peak Purchases</td><td></td></tr><tr><td>Rectifier total power flow</td><td></td></tr><tr><td>Standard Purchases</td><td></td></tr><tr><td>Total Elec Purchase</td><td></td></tr><tr><td>Total Money spent</td><td></td></tr><tr><td>Total Purchase Requested</td><td></td></tr><tr><td>Total Reward</td><td></td></tr><tr><td>Unmet Load</td><td></td></tr><tr><td>global_step</td><td></td></tr><tr><td>rollout/ep_len_mean</td><td></td></tr><tr><td>rollout/ep_rew_mean</td><td></td></tr><tr><td>time/fps</td><td></td></tr><tr><td>total Purchased Elec</td><td></td></tr><tr><td>train/approx_kl</td><td></td></tr><tr><td>train/clip_fraction</td><td></td></tr><tr><td>train/clip_range</td><td></td></tr><tr><td>train/entropy_loss</td><td></td></tr><tr><td>train/explained_variance</td><td></td></tr><tr><td>train/learning_rate</td><td></td></tr><tr><td>train/loss</td><td></td></tr><tr><td>train/policy_gradient_loss</td><td></td></tr><tr><td>train/std</td><td></td></tr><tr><td>train/value_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Diesel Generator</td><td>4929.22766</td></tr><tr><td>Excess Generation</td><td>518263.38707</td></tr><tr><td>Inverter total power flow</td><td>244398.32181</td></tr><tr><td>Max Demand</td><td>370.98447</td></tr><tr><td>Num Diesel Gen Actions</td><td>57</td></tr><tr><td>Num Off-Peak Purchases</td><td>1719</td></tr><tr><td>Num Peak Purchases</td><td>298</td></tr><tr><td>Num Standard Purchases</td><td>703</td></tr><tr><td>Off-Peak Purchases</td><td>285187.17558</td></tr><tr><td>Peak Purchases</td><td>39478.02449</td></tr><tr><td>Rectifier total power flow</td><td>303249.04866</td></tr><tr><td>Standard Purchases</td><td>97950.05574</td></tr><tr><td>Total Elec Purchase</td><td>422615.25582</td></tr><tr><td>Total Money spent</td><td>1365492.34558</td></tr><tr><td>Total Purchase Requested</td><td>342327.27849</td></tr><tr><td>Total Reward</td><td>-2539780.65086</td></tr><tr><td>Unmet Load</td><td>3491.31717</td></tr><tr><td>global_step</td><td>1505280</td></tr><tr><td>rollout/ep_len_mean</td><td>5974.0</td></tr><tr><td>rollout/ep_rew_mean</td><td>-2543664.5</td></tr><tr><td>time/fps</td><td>414.0</td></tr><tr><td>total Purchased Elec</td><td>422615.25582</td></tr><tr><td>train/approx_kl</td><td>2e-05</td></tr><tr><td>train/clip_fraction</td><td>0.0</td></tr><tr><td>train/clip_range</td><td>0.2</td></tr><tr><td>train/entropy_loss</td><td>0.75306</td></tr><tr><td>train/explained_variance</td><td>0.94997</td></tr><tr><td>train/learning_rate</td><td>2e-05</td></tr><tr><td>train/loss</td><td>715312.25</td></tr><tr><td>train/policy_gradient_loss</td><td>-0.00012</td></tr><tr><td>train/std</td><td>0.11395</td></tr><tr><td>train/value_loss</td><td>1920539.25</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">scarlet-oath-393</strong> at: <a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/uu4smqqg' target=\"_blank\">https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/uu4smqqg</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 3 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20231023_070503-uu4smqqg/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbnkjul001_work\u001b[0m (\u001b[33m4022_intelligent_ems\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.12"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/EEE4022S_BNKJUL001_Thesis/wandb/run-20231023_080600-j149ynqt</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/j149ynqt' target=\"_blank\">kind-bee-397</a></strong> to <a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems' target=\"_blank\">https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/j149ynqt' target=\"_blank\">https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/j149ynqt</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>AC load</td><td></td></tr><tr><td>DC load</td><td></td></tr><tr><td>Diesel Generator</td><td></td></tr><tr><td>Excess Generation</td><td></td></tr><tr><td>Inverter total power flow</td><td></td></tr><tr><td>LoadShedding</td><td></td></tr><tr><td>Money Spent</td><td></td></tr><tr><td>Num Diesel Gen Actions</td><td></td></tr><tr><td>Num Off-Peak Purchases</td><td></td></tr><tr><td>Num Peak Purchases</td><td></td></tr><tr><td>Num Standard Purchases</td><td></td></tr><tr><td>Off-Peak Purchases</td><td></td></tr><tr><td>PV generation</td><td></td></tr><tr><td>Peak Purchases</td><td></td></tr><tr><td>Purchase Requested</td><td></td></tr><tr><td>Rectifier total power flow</td><td></td></tr><tr><td>Standard Purchases</td><td></td></tr><tr><td>Step Purchased</td><td></td></tr><tr><td>Total Reward</td><td></td></tr><tr><td>Unmet Load</td><td></td></tr><tr><td>Wind generation</td><td></td></tr><tr><td>battery_level</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>AC load</td><td>113.37033</td></tr><tr><td>DC load</td><td>54.4</td></tr><tr><td>Diesel Generator</td><td>0.0</td></tr><tr><td>Excess Generation</td><td>0.0</td></tr><tr><td>Inverter total power flow</td><td>0.0</td></tr><tr><td>LoadShedding</td><td>0.0</td></tr><tr><td>Money Spent</td><td>0.0</td></tr><tr><td>Num Diesel Gen Actions</td><td>61</td></tr><tr><td>Num Off-Peak Purchases</td><td>527</td></tr><tr><td>Num Peak Purchases</td><td>91</td></tr><tr><td>Num Standard Purchases</td><td>144</td></tr><tr><td>Off-Peak Purchases</td><td>0.0</td></tr><tr><td>PV generation</td><td>0.0</td></tr><tr><td>Peak Purchases</td><td>0.0</td></tr><tr><td>Purchase Requested</td><td>0.0</td></tr><tr><td>Rectifier total power flow</td><td>0.0</td></tr><tr><td>Standard Purchases</td><td>0.0</td></tr><tr><td>Step Purchased</td><td>0.0</td></tr><tr><td>Total Reward</td><td>0.0</td></tr><tr><td>Unmet Load</td><td>0.0</td></tr><tr><td>Wind generation</td><td>84.94012</td></tr><tr><td>battery_level</td><td>100.0</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">kind-bee-397</strong> at: <a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/j149ynqt' target=\"_blank\">https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/j149ynqt</a><br/>Synced 4 W&B file(s), 35 media file(s), 9 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20231023_080600-j149ynqt/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.12"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/EEE4022S_BNKJUL001_Thesis/wandb/run-20231023_080718-2l6e0y5e</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/2l6e0y5e' target=\"_blank\">golden-firefly-398</a></strong> to <a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems' target=\"_blank\">https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/2l6e0y5e' target=\"_blank\">https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/2l6e0y5e</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>AC load</td><td></td></tr><tr><td>DC load</td><td></td></tr><tr><td>Diesel Generator</td><td></td></tr><tr><td>Excess Generation</td><td></td></tr><tr><td>Inverter total power flow</td><td></td></tr><tr><td>LoadShedding</td><td></td></tr><tr><td>Money Spent</td><td></td></tr><tr><td>Num Diesel Gen Actions</td><td></td></tr><tr><td>Num Off-Peak Purchases</td><td></td></tr><tr><td>Num Peak Purchases</td><td></td></tr><tr><td>Num Standard Purchases</td><td></td></tr><tr><td>Off-Peak Purchases</td><td></td></tr><tr><td>PV generation</td><td></td></tr><tr><td>Peak Purchases</td><td></td></tr><tr><td>Purchase Requested</td><td></td></tr><tr><td>Rectifier total power flow</td><td></td></tr><tr><td>Standard Purchases</td><td></td></tr><tr><td>Step Purchased</td><td></td></tr><tr><td>Total Reward</td><td></td></tr><tr><td>Unmet Load</td><td></td></tr><tr><td>Wind generation</td><td></td></tr><tr><td>battery_level</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>AC load</td><td>113.37033</td></tr><tr><td>DC load</td><td>54.4</td></tr><tr><td>Diesel Generator</td><td>0.0</td></tr><tr><td>Excess Generation</td><td>0.0</td></tr><tr><td>Inverter total power flow</td><td>0.0</td></tr><tr><td>LoadShedding</td><td>0.0</td></tr><tr><td>Money Spent</td><td>0.0</td></tr><tr><td>Num Diesel Gen Actions</td><td>40</td></tr><tr><td>Num Off-Peak Purchases</td><td>673</td></tr><tr><td>Num Peak Purchases</td><td>31</td></tr><tr><td>Num Standard Purchases</td><td>178</td></tr><tr><td>Off-Peak Purchases</td><td>0.0</td></tr><tr><td>PV generation</td><td>0.0</td></tr><tr><td>Peak Purchases</td><td>0.0</td></tr><tr><td>Purchase Requested</td><td>0.0</td></tr><tr><td>Rectifier total power flow</td><td>0.0</td></tr><tr><td>Standard Purchases</td><td>0.0</td></tr><tr><td>Step Purchased</td><td>0.0</td></tr><tr><td>Total Reward</td><td>0.0</td></tr><tr><td>Unmet Load</td><td>0.0</td></tr><tr><td>Wind generation</td><td>84.94012</td></tr><tr><td>battery_level</td><td>100.0</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">golden-firefly-398</strong> at: <a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/2l6e0y5e' target=\"_blank\">https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/2l6e0y5e</a><br/>Synced 4 W&B file(s), 35 media file(s), 9 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20231023_080718-2l6e0y5e/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Note: The term does not refer to the cost in rands but rather to the reward as defined by the reward function!\n",
            "Done the Standby Test! Total cost accumulated is: -984529.125\n",
            "Done applying the trained model! Total cost accumulated is: -955610.755203 +- 0.0\n",
            "The amount that was saved by applying the EMS agent: 28918.369796999963\n",
            "This was saved over a period of 115.0 days\n",
            "The savings represents 2.9372792599711017 % of the cost if no EMS is installed\n",
            "And it represents 3.0261662125032114 % of the cost if the EMS is installed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(f\"{model_dir}{version}_{model_type}\"+datetime.datetime.now().strftime(\"%m%d-%H%M%S\"))\n"
      ],
      "metadata": {
        "id": "PNPNF7_yOA5v"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "903ca881fc284bd9af87d33b8ba45213": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7cd78624dc474b30b24c3a0c77a18a64",
              "IPY_MODEL_8431d6389ad04456b2d1e499622b81ed"
            ],
            "layout": "IPY_MODEL_5088a52b31da4d73934eb462776e84d0"
          }
        },
        "7cd78624dc474b30b24c3a0c77a18a64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6479e914b3374f12968957e6b4ad90ff",
            "placeholder": "",
            "style": "IPY_MODEL_3c78c6d2ea1c4f23bb8fa2e3712acce9",
            "value": "0.678 MB of 0.678 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "8431d6389ad04456b2d1e499622b81ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4377e058ab7b41bf9c83a458c2e3ca44",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c74fea468ff64564a7e639868f1f3877",
            "value": 1
          }
        },
        "5088a52b31da4d73934eb462776e84d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6479e914b3374f12968957e6b4ad90ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c78c6d2ea1c4f23bb8fa2e3712acce9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4377e058ab7b41bf9c83a458c2e3ca44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c74fea468ff64564a7e639868f1f3877": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}