{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Julian-Banks/EEE4022S_BNKJUL001_Thesis/blob/main/PythonWorkspace/EMSv0_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Version Notes**\n",
        "\n",
        "# **v0.3**\n",
        "**Added:**\n",
        "* loadshedding\n",
        "* New reward structure\n",
        "* added Vec_env\n",
        "* added eval callbacks to validate training\n",
        "\n",
        "**Parameters:**\n",
        "* Added in loadshedding forecast\n",
        "\n",
        "**To do:**\n",
        "* find out about battery charging rates  & impliment\n",
        "* Find out if I need to normalise\n",
        "* Try dqn\n",
        "* Find out how the bounds for the obs_space box effect things\n",
        "* Try play with DummyVec wrapper (didnt work in last version)\n",
        "\n",
        "# **v0.2_1**\n",
        "**Added:**\n",
        "*  Monitor wrapper\n",
        "*  DummyVec wrapper\n",
        "*  Wand (weights and bais) enabled\n",
        "\n",
        "**Parameters:**\n",
        "* lowered to 3 predictions  \n",
        "\n",
        "**To do:**\n",
        "* Try to use hyperparameter Optimisation - decided Im only going to do on the final version\n",
        "* Try normalise\n",
        "* Try differnet models\n",
        "* Find out how the bounds for the obs_space box effect things\n",
        "\n",
        "# **v0.2**\n",
        "**Added:**\n",
        "*  simplified load_forecast and gen_forecast to be power_bal_forecasts.\n",
        "*  combined current_load and current_gen to also show current_power_balance\n",
        "*  added proper evaluate call\n",
        "\n",
        "**Parameters:**\n",
        "* No changes  \n",
        "\n",
        "**Results:**\n",
        "* 5% savings on PPO deterministic = true\n",
        "* 4.3% savings on PPO determnistic = false\n",
        "\n",
        "**To do:**\n",
        "* Try to use hyperparameter Optimisation\n",
        "* Try normalise\n",
        "* Try differnet models\n",
        "* Try see if discount rate can be tweaked - at good level.\n",
        "* Find out how the bounds for the obs_space box effect things\n",
        "\n",
        "# **v0.1**\n",
        "**Added:**\n",
        "* added real loads, gen, tou_id's\n",
        "\n",
        "**Parameters:**\n",
        "* training episode = 6000 timesteps\n",
        "* testing episode  = 2760 timesteps\n",
        "* bat_threshold = 100\n",
        "* bat_cap = 500\n",
        "* battery_level at reset = bat_cap/2\n",
        "* num_preds = 24\n",
        "* Trained PPO for 1.65mil timesteps\n",
        "* Trained A2C for 1.2 mil timesteps\n",
        "\n",
        "**Results:**\n",
        "* PP0 - 3.7% improvement from standby mode Deterministic = False\n",
        "* PPO - 6.1% Deterministic =  True\n",
        "* A2C  - -0.3% improvement. And the models after this got worse as training progressed!\n",
        "**To do:**\n",
        "* Try lower num_preds\n",
        "* Try to use hyperparameter Optimisation\n",
        "* Try normalise\n",
        "* Try differnet models\n",
        "* Try see if discount rate can be tweaked\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5DZFnZnzStt1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nI52iVVCCPaf",
        "outputId": "b05813f1-6664-4fc6-8b62-26f08f8dcfe5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "%%capture\n",
        "#install dependancies\n",
        "!pip install gymnasium\n",
        "!pip install stable_baselines3[extra]\n",
        "!pip install wandb\n",
        "%load_ext tensorboard\n",
        "\n",
        "#clone repository\n",
        "! git clone https://github.com/Julian-Banks/EEE4022S_BNKJUL001_Thesis\n",
        "\n",
        "#to update the rep\n",
        "%cd /content/EEE4022S_BNKJUL001_Thesis\n",
        "! git pull\n",
        "#import needed libarys\n",
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from gymnasium import spaces\n",
        "import datetime\n",
        "from stable_baselines3 import PPO, A2C, DQN\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from stable_baselines3.common.callbacks import EvalCallback\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.vec_env import VecVideoRecorder\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.animation import FuncAnimation\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "import wandb\n",
        "from wandb.integration.sb3 import WandbCallback\n",
        "from gymnasium.envs.registration import register\n",
        "\n",
        "\n",
        "\n",
        "#mount the drive\n",
        "drive.mount('/content/drive')\n",
        "#define paths to logs and model saves\n",
        "model_type = \"DQN\"\n",
        "version    = \"EMSv0_3\"\n",
        "model_dir = f\"/content/drive/MyDrive/Colab Notebooks/{version}/models/{model_type}/\"\n",
        "log_dir   = f\"/content/drive/MyDrive/Colab Notebooks/{version}/models/{model_type}logs/\"\n",
        "animation_dir = f\"/content/drive/MyDrive/Colab Notebooks/{version}/models/{model_type}/animation\"\n",
        "\n",
        "#make the appropriate directory if it does not exist\n",
        "if not os.path.exists(model_dir):\n",
        "    os.makedirs(model_dir)\n",
        "if not os.path.exists(log_dir):\n",
        "    os.makedirs(log_dir)\n",
        "if not os.path.exists(animation_dir):\n",
        "    os.makedirs(animation_dir)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define our environment class!!**"
      ],
      "metadata": {
        "id": "Q99_jLMvwuZZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "s2iW-k26FIbm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46a1d599-7947-4fa1-ea3b-6b513e55d494"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/gymnasium/envs/registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment EMSv0_3 already in registry.\u001b[0m\n",
            "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n",
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/env_checker.py:244: UserWarning: Your observation island_forecast has an unconventional shape (neither an image, nor a 1D vector). We recommend you to flatten the observation to have only a 1D vector or use a custom policy to properly process the data.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/env_checker.py:244: UserWarning: Your observation power_bal_forecast has an unconventional shape (neither an image, nor a 1D vector). We recommend you to flatten the observation to have only a 1D vector or use a custom policy to properly process the data.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/env_checker.py:244: UserWarning: Your observation price_forecast has an unconventional shape (neither an image, nor a 1D vector). We recommend you to flatten the observation to have only a 1D vector or use a custom policy to properly process the data.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "class EMSv0_3(gym.Env):\n",
        "    \"\"\"Custom Environment that follows gym interface.\"\"\"\n",
        "\n",
        "    metadata = {\"render_modes\": [\"human\",\"rgb_array\"], \"render_fps\": 30}\n",
        "\n",
        "    def __init__(self,bat_threshold = 0.1, bat_cap = 1, actual_load = \"none\", actual_gen = \"none\", purchase_price = [1,1,1,1,1,1,1,1,2,2,2,2] , episode_len = 8760,num_preds = 24,render_mode = \"rgb_array\", load_shedding = \"none\", wandb_log = False):\n",
        "\n",
        "        super(EMSv0_3, self).__init__()\n",
        "        #define render_mode\n",
        "        self.render_mode = render_mode\n",
        "        #define wandb\n",
        "        self.wandb_log = wandb_log\n",
        "        #define time frame\n",
        "        self.current_step = 0\n",
        "        self.final_step = int(episode_len)-num_preds-2 #one years worth of steps\n",
        "\n",
        "        #Might make a function for these\n",
        "        #fill all of the actual loads NB!!! is just random for now NB!!! is normalised 0-1\n",
        "        if isinstance(actual_load,str) :\n",
        "            self.actual_load = np.random.rand(self.final_step+num_preds+1).astype(np.float32) #will load from a file or something\n",
        "        else:\n",
        "            self.actual_load = actual_load[:episode_len]\n",
        "\n",
        "        #fill all of the actual generation steps.\n",
        "        if isinstance(actual_gen,str):\n",
        "            self.actual_gen  = np.random.rand(self.final_step+num_preds+1).astype(np.float32) #will load from file or something\n",
        "        else:\n",
        "            self.actual_gen  = actual_gen[:episode_len]\n",
        "\n",
        "        #Fill the loadShedding indicator\n",
        "        if isinstance(load_shedding,str):\n",
        "            num_shedding   = np.random.randint(int(0.02*episode_len), int(0.05*episode_len))\n",
        "            load_shed      = np.array([1]*num_shedding + [0]*(episode_len - num_shedding))\n",
        "            np.random.shuffle(load_shed)\n",
        "            self.load_shed = load_shed\n",
        "        else:\n",
        "            self.load_shed = load_shedding[:episode_len]\n",
        "\n",
        "        #define vars for render\n",
        "        self.off_peak_purchases = 0\n",
        "        self.peak_purchases     = 0\n",
        "        self.standard_purchases = 0\n",
        "        self.unmet_load_total   = 0\n",
        "        self.frames = []\n",
        "\n",
        "        #Define a var for unmet load no that there is loadshedding\n",
        "        self.unmet_load = 0\n",
        "\n",
        "        #define the purchase price for every step of the year\n",
        "        purchase_price = np.array(purchase_price).astype(np.float32)\n",
        "        repetitions    = (self.final_step+num_preds+1) // len(purchase_price)\n",
        "        remainder      = (self.final_step+num_preds+1) % len(purchase_price)\n",
        "        self.purchase_price =np.concatenate([purchase_price]*repetitions+[purchase_price[:remainder]])#need to read in from somewhere\n",
        "\n",
        "        #define var for storing the excess gen\n",
        "        self.excess_gen = 0\n",
        "        #define a var for determine amount purchased per step (dont want to make it total as this will incure growing penalties for the Agent if used in reward structure)\n",
        "        self.step_purchased = 0\n",
        "        #define the battery max capacity\n",
        "        self.bat_cap = bat_cap\n",
        "        #define the battery low threshold\n",
        "        self.bat_threshold = np.float32(bat_threshold)\n",
        "        #define default action\n",
        "        self.default_action = 0\n",
        "        #define actions and observations space\n",
        "        n_actions = 2 # keeping it simple\n",
        "\n",
        "        self.num_preds = num_preds # day ahead predictions\n",
        "        self.action_space = spaces.Discrete(n_actions)\n",
        "        # Dict space to store all the different things\n",
        "        self.observation_space = spaces.Dict({\n",
        "                \"power_bal_forecast\": gym.spaces.Box(low=-np.inf, high=np.inf, shape=(1,num_preds), dtype=np.float32),\n",
        "                \"price_forecast\": gym.spaces.Box(low=0, high=np.inf, shape=(1,num_preds+1), dtype=np.float32),\n",
        "                \"island_forecast\": gym.spaces.Box(low=0, high=1, shape=(1,num_preds+1), dtype=np.float32),\n",
        "                \"bat_level\": gym.spaces.Box(low=0, high=np.inf, shape=(1,), dtype=np.float32),\n",
        "                \"current_power_bal\": gym.spaces.Box(low=-np.inf, high=np.inf, shape=(1,), dtype=np.float32),\n",
        "                })\n",
        "\n",
        "    def step(self, action):\n",
        "\n",
        "        #update the current state with the action (needs to be done before current_step is inc since we want to apply the action to the previous step to get the current state)\n",
        "        self.update_state(action)\n",
        "        #Calculate reward from the action\n",
        "        reward = self.calc_reward()\n",
        "        #inc time step into Future\n",
        "        self.current_step += 1\n",
        "        #get next observation (for next time step)\n",
        "        observation = self.get_obs()\n",
        "        #Set terminated to False since there are no failure states\n",
        "        self.terminated = False\n",
        "        #Check if timelimit reached\n",
        "        self.truncated = False if self.current_step<self.final_step else True\n",
        "        #Wand log\n",
        "        if self.wandb_log = True:\n",
        "            self.wandb_log()\n",
        "        #dont know what to put into info for now\n",
        "        info = {}\n",
        "        return observation, reward, self.terminated, self.truncated, info\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        super().reset(seed = seed, options=options)\n",
        "\n",
        "        self.current_step = 0\n",
        "        self.terminated = False\n",
        "        self.truncated = False\n",
        "        #reset the state\n",
        "        self.battery_level = self.bat_cap/2\n",
        "        self.excess_gen = 0\n",
        "        self.step_purchased = 0\n",
        "        self.unmet_load = 0\n",
        "        self.off_peak_purchases = 0\n",
        "        self.peak_purchases     = 0\n",
        "        self.standard_purchases = 0\n",
        "        self.unmet_load_total   = 0\n",
        "        #get the first observation\n",
        "        observation = self.get_obs()\n",
        "        #Still don't know what to do with info\n",
        "        info = {}\n",
        "        return observation, info\n",
        "\n",
        "    def wandb_log(self)\n",
        "        wandb.log({\"battery_level\": self.battery_level})\n",
        "        #log shit here\n",
        "\n",
        "    def render(self, mode='rgb_array', save_path=None):\n",
        "\n",
        "        plt.clf()\n",
        "        values = [self.off_peak_purchases, self.standard_purchases, self.purchase_price[self.peak_purchases]]\n",
        "        colors = ['green', 'orange','red']\n",
        "        labels = ['Off Peak', 'Standard', 'Peak']\n",
        "        plt.xlim(0,1.6)\n",
        "        plt.ylim(0,100)\n",
        "        plt.bar(list(range(3)),values, color=colors, tick_label=labels)\n",
        "        self.frames.append(plt.gcf().canvas.tostring_rgb())\n",
        "        plt.pause(0.000001)\n",
        "\n",
        "\n",
        "    def close(self):\n",
        "        #don't think i need this for my application\n",
        "        pass\n",
        "\n",
        "    def update_state(self, action):\n",
        "        #Update current state with actions\n",
        "        if action == 0: #do nothing action\n",
        "            self.standby()\n",
        "        elif action == 1: #buy from Grid\n",
        "            self.purchase()\n",
        "        else:  #error case\n",
        "            raise ValueError(\n",
        "                f\"Received invalid action = {action} which is not part of the action space.\"\n",
        "            )\n",
        "        #case list for each action?\n",
        "\n",
        "    def calc_reward(self):\n",
        "        #Calculate reward based on the state\n",
        "        reward = -self.step_purchased*self.purchase_price[self.current_step] - self.unmet_load*10\n",
        "\n",
        "        return reward\n",
        "\n",
        "    def get_obs(self):\n",
        "        #Fill the observation space with the next observation\n",
        "\n",
        "        #Get Forecasts Will probaly write a function for this? idk maybe a schlep to return all the info\n",
        "        load_forecast  = np.array( [self.actual_load[self.current_step+1: self.current_step + self.num_preds+1]] , dtype = np.float32) #will load from a file or something\n",
        "        if load_forecast.shape != (1,self.num_preds):\n",
        "            print(f\"load_forecast shape is {load_forecast.shape} but it should be {(1, self.num_preds)}. Current step is {self.current_step}\")\n",
        "        gen_forecast   = np.array( [self.actual_gen[self.current_step+1: self.current_step + self.num_preds+1]] , dtype = np.float32) #will load from a file or something\n",
        "        if gen_forecast.shape != (1,self.num_preds):\n",
        "            print(f\"gen_forecast shape is {gen_forecast.shape} but it should be {(1, self.num_preds)}. Current step is {self.current_step}\")\n",
        "        #calculate the power forecast\n",
        "        power_bal_forecast = gen_forecast-load_forecast\n",
        "        #get the prices for the current frame and the next 24 hours. Maybe will cut this down since that seems like a lot of info\n",
        "        price_forecast = np.array( [self.purchase_price[self.current_step:self.current_step+self.num_preds+1]] , dtype = np.float32)\n",
        "        #Just for readibility of the dict object\n",
        "        bat_level      = np.array([self.battery_level] , dtype= np.float32)\n",
        "        #island forecasst, same as tou forecast\n",
        "        island_forecast =np.array( [self.load_shed[self.current_step:self.current_step+self.num_preds+1]] , dtype = np.float32)\n",
        "\n",
        "        #calculate the current power balance\n",
        "        current_load   = np.array([self.actual_load[self.current_step]], dtype = np.float32)\n",
        "        current_gen    = np.array([self.actual_gen[self.current_step]], dtype  = np.float32)\n",
        "        current_power_bal = current_gen - current_load\n",
        "\n",
        "\n",
        "\n",
        "        obs = dict({\n",
        "                \"bat_level\":      bat_level,\n",
        "                \"current_power_bal\" :   current_power_bal,\n",
        "                \"island_forecast\": island_forecast,\n",
        "                \"power_bal_forecast\":  power_bal_forecast,\n",
        "                \"price_forecast\": price_forecast,\n",
        "        })\n",
        "        return obs\n",
        "\n",
        "    def standby(self):\n",
        "        #ems stands by, load is met by generation, battery and then grid\n",
        "        #if there is excess generation it is used to charge the batteries\n",
        "\n",
        "        #define step_gen and step_load for readability\n",
        "        step_gen  =  self.actual_gen[self.current_step]\n",
        "        step_load =  self.actual_load[self.current_step]\n",
        "        battery   =  self.battery_level\n",
        "        islanded  =  self.load_shed[self.current_step]\n",
        "        #reset purchased and unmet load amount\n",
        "        self.step_purchased = 0\n",
        "        #should have had step indicated in the name.\n",
        "        self.unmet_load     = 0\n",
        "\n",
        "        #check for gen meeting load\n",
        "        if step_load <= step_gen :\n",
        "            #Purchased electricity stays at 0 since there is sufficient generation.\n",
        "            #calulate the excess elec that was generated\n",
        "            step_excess = step_gen - step_load\n",
        "            #check if battery needs to be charged\n",
        "            if battery < self.bat_cap :\n",
        "                #check if the excess amount that was generated is less than the available capacity\n",
        "                if self.bat_cap-battery-step_excess > 0:\n",
        "                    self.battery_level += step_excess\n",
        "                else:\n",
        "                    #if the excess is greater than the availability then charge till full\n",
        "                    self.battery_level = self.bat_cap\n",
        "                    #set step excess to excess minus the amount used to charge\n",
        "                    step_excess -= (self.bat_cap-battery)\n",
        "                    self.excess_gen += step_excess\n",
        "            else:\n",
        "                #if the battery is full then just inc excess_gen\n",
        "                self.excess_gen += step_excess\n",
        "        else:\n",
        "            #if the generation does not meet load\n",
        "            step_shortfall = step_load - step_gen\n",
        "            #checking if battery is above a threshold.\n",
        "            if battery > self.bat_threshold:\n",
        "                #check if battery has enough capacity to meet the load\n",
        "                if battery - step_shortfall >= self.bat_threshold:\n",
        "                    #if it does then subtract the shortfall from battery level\n",
        "                    self.battery_level -= step_shortfall\n",
        "                    #Purchased electricity stays at 0 since there is sufficient generation.\n",
        "\n",
        "                else:\n",
        "                    #set the battery to min value and purchase the rest from the grid\n",
        "                    self.battery_level = self.bat_threshold\n",
        "                    #calculate how much needs to be purchased\n",
        "                    step_shortfall -= (battery - self.bat_threshold)\n",
        "                    #check if the microgrid is grid connected\n",
        "                    if islanded:\n",
        "                        #if it is then set the unmet load to the shortfall\n",
        "                        self.unmet_load = step_shortfall\n",
        "                    else:\n",
        "                        #if it is grid connected, purchase the shortfall.\n",
        "                        self.step_purchased = step_shortfall\n",
        "            else:\n",
        "                #no battery available, therefore everything needs to be bought from the grid.\n",
        "                if islanded:\n",
        "                    #if it is then set the unmet load to the shortfall\n",
        "                    self.unmet_load = step_shortfall\n",
        "                else:\n",
        "                    #if it is grid connected, purchase the shortfall.\n",
        "                    self.step_purchased = step_shortfall\n",
        "                    if self.purchase_price[self.current_step] == 1:\n",
        "                        self.off_peak_purchases += 1\n",
        "\n",
        "                    elif self.purchase_price[self.current_step] == 2:\n",
        "                        self.standard_purchases += 1\n",
        "                    else:\n",
        "                        self.peak_purchases += 1\n",
        "\n",
        "\n",
        "    def purchase(self):\n",
        "        #purchase electricity to charge battery even if there is enough generation (I assume this will be used to buy at lower prices)\n",
        "        #get values for readability\n",
        "        step_load = self.actual_load[self.current_step]\n",
        "        step_gen  = self.actual_gen[self.current_step]\n",
        "        battery = self.battery_level\n",
        "        islanded = self.load_shed[self.current_step]\n",
        "\n",
        "        #Check if it is possible to buy electricity\n",
        "        if islanded:\n",
        "            #if its not then impliment the standby mode which handles load shedding\n",
        "            self.standby()\n",
        "        else:\n",
        "            #if there is no loadshedding then proceed with purchase as normal\n",
        "            #calculate the total power need (the load plus the amount that the battery needs to charge)\n",
        "            total_need = step_load + (self.bat_cap-battery)\n",
        "            #if the generation is less than the need then purchase the remainder\n",
        "            if step_gen<total_need:\n",
        "                #purchashing the shortfall\n",
        "                self.step_purchased = total_need - step_gen\n",
        "                #inc the purchase count\n",
        "                if self.purchase_price[self.current_step] == 1:\n",
        "                    self.off_peak_purchases += 1\n",
        "                elif self.purchase_price[self.current_step] == 2:\n",
        "                    self.standard_purchases += 1\n",
        "                else:\n",
        "                    self.peak_purchases += 1\n",
        "                #setting the battery levels to full\n",
        "                self.battery_level = self.bat_cap\n",
        "            else:\n",
        "                #if the gen is enough then set purchase to 0\n",
        "                self.step_purchased  = 0\n",
        "                #set the battery to fully charged\n",
        "                self.battery_level = self.bat_cap\n",
        "                #inc excess_gen by caluclating the excess between the step gen and the total need (includes amount needed to charge the battery)\n",
        "                self.excess_gen += (step_gen - total_need)\n",
        "\n",
        "\n",
        "#define a pointer (kinda, don't actually know what its called) a\n",
        "EMS = EMSv0_3\n",
        "# Register environment so I can use make_vec_env\n",
        "register(\n",
        "# unique identifier for the env `name-version`\n",
        "id=f\"{version}\",\n",
        "# path to the class for creating the env\n",
        "# Note: entry_point also accept a class as input (and not only a string)\n",
        "entry_point= EMS(),\n",
        "\n",
        ")\n",
        "\n",
        "#Check the environment with stable_baselines3 check_env.\n",
        "from stable_baselines3.common.env_checker import check_env\n",
        "env = EMS()\n",
        "check_env(env,warn = True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DG4gB2cM7tDY"
      },
      "source": [
        "**Load in the data for our specific microgrid.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "0X9RBdXC_2PD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c145ca75-0e07-4201-9e04-8f88b0889581"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The reset observation space looks like: {'bat_level': array([250.], dtype=float32), 'current_power_bal': array([-96.855], dtype=float32), 'island_forecast': array([[0., 0., 0., 0.]], dtype=float32), 'power_bal_forecast': array([[-97.053, -97.229, -96.859]], dtype=float32), 'price_forecast': array([[1., 1., 1., 1.]], dtype=float32)}\n",
            "After action 0 the observation space looks like {'bat_level': array([153.14499], dtype=float32), 'current_power_bal': array([-97.053], dtype=float32), 'island_forecast': array([[0., 0., 0., 0.]], dtype=float32), 'power_bal_forecast': array([[-97.229, -96.859, -98.018]], dtype=float32), 'price_forecast': array([[1., 1., 1., 1.]], dtype=float32)}\n",
            "The reward we recieved was 0.0\n",
            "Done iteration! Total reward accumulated is: -1013563.534992218\n"
          ]
        }
      ],
      "source": [
        "#need to import data from Github\n",
        "path_data = \"/content/EEE4022S_BNKJUL001_Thesis/PythonWorkspace/dataClean.csv\"\n",
        "data = pd.read_csv(path_data)\n",
        "\n",
        "path_gen = \"/content/EEE4022S_BNKJUL001_Thesis/Generation/BNKJUL001_Thesis_solarGen500kWHomer.csv\"\n",
        "data_gen = pd.read_csv(path_gen)\n",
        "\n",
        "#Not actually using this rn but will be soon :)\n",
        "path_shedding = \"/content/EEE4022S_BNKJUL001_Thesis/MatlabWorkSpace/loadShedding2022.csv\"\n",
        "data_shedding = pd.read_csv(path_shedding)\n",
        "load_shedding = data_shedding['LoadShedding'].values.astype(np.float32)\n",
        "\n",
        "actual_gen = data_gen['PV_Out'].values.astype(np.float32)\n",
        "actual_load = data['AC'].values.astype(np.float32)\n",
        "purchase_price = data['tou_id'].values.astype(np.float32)\n",
        "\n",
        "\n",
        "#define the base environment\n",
        "base_env = EMS(episode_len = 6000, actual_load = actual_load, actual_gen = actual_gen, bat_threshold = 100, bat_cap = 500, purchase_price = purchase_price,num_preds = 3)\n",
        "#going to print out a bunch of things to test the different spaces.\n",
        "obs,_    = base_env.reset()\n",
        "print(f\"The reset observation space looks like: {obs}\")\n",
        "action_standby = 0\n",
        "obs,reward,terminated,truncated,info = base_env.step(action_standby)\n",
        "print(f\"After action {action_standby} the observation space looks like {obs}\")\n",
        "print(f\"The reward we recieved was {reward}\")\n",
        "\n",
        "#Evaluate the base model (no EMS, just using standby mode)\n",
        "#A loop to get an average reward for the base model only perfoming the standby option\n",
        "#reset the environment and save the obs\n",
        "#going to run it 100 times to get a benchmark\n",
        "#reset score\n",
        "score = 0\n",
        "\n",
        "obs,_    = base_env.reset()\n",
        "#ensure that the exit condition is reset\n",
        "truncated = False\n",
        "#define the action to take\n",
        "action_standby = 0\n",
        "\n",
        "while not truncated:\n",
        "    obs,reward,terminated,truncated,info = base_env.step(action_standby)\n",
        "    score += reward\n",
        "\n",
        "print(f\"Done iteration! Total reward accumulated is: {score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pAj6-n04zyt"
      },
      "source": [
        "**LOAD OR MAKE MODEL HERE!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQDhUNGWeum4"
      },
      "outputs": [],
      "source": [
        "config = {\n",
        "    \"policy_type\": \"MultiInputPolicy\",\n",
        "    \"total_timesteps\": 1000000,\n",
        "}\n",
        "\n",
        "run = wandb.init(\n",
        "    project=\"4022_intelligent_ems\",\n",
        "    config=config,\n",
        "    sync_tensorboard=True,  # auto-upload sb3's tensorboard metrics\n",
        "    monitor_gym=True,  # auto-upload the videos of agents playing the game\n",
        "    save_code=True,  # optional\n",
        ")\n",
        "\n",
        "train_args = {\n",
        "                \"episode_len\"   : 6000,\n",
        "                \"actual_load\"   : actual_load,\n",
        "                \"actual_gen\"    : actual_gen,\n",
        "                \"bat_threshold\" : 100,\n",
        "                \"bat_cap\"       : 500,\n",
        "                \"purchase_price\": purchase_price,\n",
        "                \"num_preds\"     : 3,\n",
        "                \"load_shedding\" : load_shedding,\n",
        "                \"render_mode\"   : \"rgb_array\",\n",
        "                \"wandb_log\"     : True\n",
        "\n",
        "                }\n",
        "\n",
        "eval_args = {\n",
        "                \"episode_len\"   :2760,\n",
        "                \"actual_load\"   :actual_load[6001:],\n",
        "                \"actual_gen\"    :actual_gen[6001:],\n",
        "                \"bat_threshold\" :100,\n",
        "                \"bat_cap\"       :500,\n",
        "                \"purchase_price\":purchase_price[6001:],\n",
        "                \"num_preds\"     :3,\n",
        "                \"load_shedding\" :load_shedding[6001:],\n",
        "                \"wandb_log\"     : True\n",
        "}\n",
        "\n",
        "#define 5 environments   for training and eval\n",
        "n_envs = 10\n",
        "n_eval_episodes =1\n",
        "train_env = make_vec_env(EMS, n_envs = n_envs,env_kwargs = train_args )\n",
        "\n",
        "\n",
        "eval_env = make_vec_env(EMS, n_envs = n_envs,env_kwargs = eval_args )\n",
        "\n",
        "\n",
        "wand_eval = f\"{version}_{model_type}_eval\"+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "wand_train = f\"{version}_{model_type}_train\"+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "wandb_callback = WandbCallback(\n",
        "                gradient_save_freq=100,\n",
        "                model_save_path=f\"models/{run.id}\",\n",
        "                model_save_freq= 30000,\n",
        "                verbose=2,\n",
        "                log = \"all\",\n",
        "               )\n",
        "eval_callback = EvalCallback(eval_env,\n",
        "                             best_model_save_path = f\"{model_dir}{version}_{model_type}\"+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"),\n",
        "                             log_path = wand_eval,\n",
        "                             eval_freq=300,\n",
        "                             n_eval_episodes = n_eval_episodes,\n",
        "                             deterministic = True,\n",
        "                             render = False,\n",
        "                             callback_after_eval = wandb_callback)\n",
        "\n",
        "\n",
        "model = DQN(\"MultiInputPolicy\",train_env, verbose = 1, tensorboard_log = f\"runs/{run.id}\") #log_dir\n",
        "\n",
        "model.learn(total_timesteps= config[\"total_timesteps\"],\n",
        "            tb_log_name = wand_train,\n",
        "            reset_num_timesteps=False,\n",
        "            callback = wandb_callback\n",
        "            )\n",
        "\n",
        "model.save(f\"{model_dir}{version}_{model_type}\"+datetime.datetime.now().strftime(\"%m%d-%H%M%S\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define a new test environment and load up the best performing model to test it.**"
      ],
      "metadata": {
        "id": "C9AGcLlsv4N7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "inDHszZaxBUS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "049684ec-e6e8-4833-cca6-d352a0caffae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>▁▁▂▂▃▃▄▄▅▅▆▆▇▇██</td></tr><tr><td>rollout/ep_len_mean</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>rollout/ep_rew_mean</td><td>▁▃▄▄▄▅▅▅▆▆▆▇▇▇██</td></tr><tr><td>rollout/exploration_rate</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>time/fps</td><td>█▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/loss</td><td>▂▁▂▃▃▃▄▅▇▄▅▆▅▆██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>959200</td></tr><tr><td>rollout/ep_len_mean</td><td>5995.0</td></tr><tr><td>rollout/ep_rew_mean</td><td>-901054.375</td></tr><tr><td>rollout/exploration_rate</td><td>0.05</td></tr><tr><td>time/fps</td><td>4472.0</td></tr><tr><td>train/learning_rate</td><td>0.0001</td></tr><tr><td>train/loss</td><td>619.63318</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">magic-firebrand-32</strong> at: <a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/ml60o20x' target=\"_blank\">https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/ml60o20x</a><br/>Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 3 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20231007_170745-ml60o20x/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Note: The term does not refer to the cost in rands but rather to the reward as defined by the reward function!\n",
            "Done the Standby Test! Total cost accumulated is: -440125.59375\n",
            "Done applying the trained model! Total cost accumulated is: -465364.938667 +- 0.0\n",
            "The amount that was saved by applying the EMS agent: -25239.34491699998\n",
            "This was saved over a period of 115.0 days\n",
            "The savings represents -5.7345778740003075 % of the cost if no EMS is installed\n",
            "And it represents -5.423559623828996 % of the cost if the EMS is installed\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "#Load model, fetch the latest (or whichever one you want from the model_dir)\n",
        "#Best A2C model:/content/drive/MyDrive/Colab Notebooks/EMSv0_3/models/PPO/EMSv0_3_PPO20231005-102532.zip\n",
        "#best_PPO_model = \"EMSv0_3_PPO20231006-204045.zip\"\n",
        "\n",
        "#model_load = f\"{model_dir}/{best_PPO_model}\"\n",
        "#model  = PPO.load(model_load, env = eval_env)\n",
        "\n",
        "#first run it with only standby (default)\n",
        "obs   = eval_env.reset()\n",
        "#ensure that the exit condition is reset\n",
        "done = [False]*n_envs\n",
        "#define the action to take\n",
        "action_standby = [0]*n_envs\n",
        "#reset score\n",
        "standby_score = [0]*n_envs\n",
        "standby_score = np.array(standby_score).astype(np.float32)\n",
        "while not all(done):\n",
        "    #step the model with the action\n",
        "    obs,reward,done,info = eval_env.step(action_standby)\n",
        "    #accumulate the score\n",
        "    standby_score += reward\n",
        "\n",
        "avg_standby_score = standby_score.mean()\n",
        "\n",
        "EMS_reward,EMS_std_reward = evaluate_policy(model,eval_env,n_eval_episodes = 20,deterministic=True)# callback = wandb_callback\n",
        "\n",
        "run.finish()\n",
        "print(f\"Note: The term does not refer to the cost in rands but rather to the reward as defined by the reward function!\")\n",
        "print(f\"Done the Standby Test! Total cost accumulated is: {avg_standby_score}\")\n",
        "print(f\"Done applying the trained model! Total cost accumulated is: {EMS_reward} +- {EMS_std_reward}\")\n",
        "\n",
        "savings = EMS_reward - avg_standby_score\n",
        "print(f\"The amount that was saved by applying the EMS agent: {savings}\")\n",
        "print(f\"This was saved over a period of {2760/24} days\")\n",
        "print(f\"The savings represents {(savings/(-avg_standby_score))*100} % of the cost if no EMS is installed\")\n",
        "print(f\"And it represents {(savings/(-EMS_reward))*100} % of the cost if the EMS is installed\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP3erzBzQW86Dpbhqy4HU2r",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}