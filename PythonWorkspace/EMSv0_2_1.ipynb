{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Julian-Banks/EEE4022S_BNKJUL001_Thesis/blob/main/PythonWorkspace/EMSv0_2_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Version Notes**\n",
        "\n",
        "# **v0.2_1**\n",
        "**Added:**\n",
        "*  Monitor wrapper\n",
        "*  DummyVec wrapper\n",
        "*  Wand (weights and bais) enabled\n",
        "\n",
        "**Parameters:**\n",
        "* lowered to 3 predictions  \n",
        "\n",
        "**To do:**\n",
        "* Try to use hyperparameter Optimisation\n",
        "* Try normalise\n",
        "* Try differnet models\n",
        "* Find out how the bounds for the obs_space box effect things\n",
        "\n",
        "# **v0.2**\n",
        "**Added:**\n",
        "*  simplified load_forecast and gen_forecast to be power_bal_forecasts.\n",
        "*  combined current_load and current_gen to also show current_power_balance\n",
        "*  added proper evaluate call\n",
        "\n",
        "**Parameters:**\n",
        "* No changes  \n",
        "\n",
        "**Results:**\n",
        "* 5% savings on PPO deterministic = true\n",
        "* 4.3% savings on PPO determnistic = false\n",
        "\n",
        "**To do:**\n",
        "* Try to use hyperparameter Optimisation\n",
        "* Try normalise\n",
        "* Try differnet models\n",
        "* Try see if discount rate can be tweaked - at good level.\n",
        "* Find out how the bounds for the obs_space box effect things\n",
        "\n",
        "# **v0.1**\n",
        "**Added:**\n",
        "* added real loads, gen, tou_id's\n",
        "\n",
        "**Parameters:**\n",
        "* training episode = 6000 timesteps\n",
        "* testing episode  = 2760 timesteps\n",
        "* bat_threshold = 100\n",
        "* bat_cap = 500\n",
        "* battery_level at reset = bat_cap/2\n",
        "* num_preds = 24\n",
        "* Trained PPO for 1.65mil timesteps\n",
        "* Trained A2C for 1.2 mil timesteps\n",
        "\n",
        "**Results:**\n",
        "* PP0 - 3.7% improvement from standby mode Deterministic = False\n",
        "* PPO - 6.1% Deterministic =  True\n",
        "* A2C  - -0.3% improvement. And the models after this got worse as training progressed!\n",
        "**To do:**\n",
        "* Try lower num_preds\n",
        "* Try to use hyperparameter Optimisation\n",
        "* Try normalise\n",
        "* Try differnet models\n",
        "* Try see if discount rate can be tweaked\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5DZFnZnzStt1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "MXzZxVUQFroQ"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install gymnasium\n",
        "!pip install stable_baselines3[extra]\n",
        "!pip install wandb\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Hu74obFw8Gts",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a844c1e6-4891-4e86-c717-c0fa758b72de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'EEE4022S_BNKJUL001_Thesis' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/Julian-Banks/EEE4022S_BNKJUL001_Thesis\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#to update the rep\n",
        "%cd /content/EEE4022S_BNKJUL001_Thesis\n",
        "! git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IBm2Ge7rrfe",
        "outputId": "3d61681f-24c7-4389-969c-883e5bce08d0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/EEE4022S_BNKJUL001_Thesis\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#to save the code afterwards\n",
        "'''\n",
        "%cd /content/EEE4022S_BNKJUL001_Thesis\n",
        "\n",
        "Message = \"Changes to EMSv0_2_1\"\n",
        "\n",
        "! git add.\n",
        "! git commit -m \"{Message}\"\n",
        "! git push\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "OYtyqOTcscTG",
        "outputId": "f467348f-03c9-4de4-cc49-f62180db2413"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n%cd /content/EEE4022S_BNKJUL001_Thesis\\n\\nMessage = \"Changes to EMSv0_2_1\"\\n\\n! git add.\\n! git commit -m \"{Message}\"\\n! git push\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nI52iVVCCPaf",
        "outputId": "314817f9-cbd8-49e5-c4e7-e8f7e1b7ddf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#import needed libarys\n",
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from gymnasium import spaces\n",
        "import datetime\n",
        "from stable_baselines3 import PPO, A2C, DQN\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv, VecVideoRecorder\n",
        "from google.colab import drive\n",
        "import os\n",
        "import wandb\n",
        "from wandb.integration.sb3 import WandbCallback\n",
        "\n",
        "#mount the drive\n",
        "drive.mount('/content/drive')\n",
        "#define paths to logs and model saves\n",
        "model_type = \"A2C\"\n",
        "version    = \"EMSv0_2_1\"\n",
        "model_dir = f\"/content/drive/MyDrive/Colab Notebooks/{version}/models/{model_type}/\"\n",
        "log_dir   = f\"/content/drive/MyDrive/Colab Notebooks/{version}/models/{model_type}logs/\"\n",
        "\n",
        "#make the appropriate directory if it does not exist\n",
        "if not os.path.exists(model_dir):\n",
        "    os.makedirs(model_dir)\n",
        "if not os.path.exists(log_dir):\n",
        "    os.makedirs(log_dir)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define our environment class!!**"
      ],
      "metadata": {
        "id": "Q99_jLMvwuZZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "s2iW-k26FIbm"
      },
      "outputs": [],
      "source": [
        "class EMSv0_2_1(gym.Env):\n",
        "    \"\"\"Custom Environment that follows gym interface.\"\"\"\n",
        "\n",
        "    metadata = {\"render_modes\": [\"human\"], \"render_fps\": 30}\n",
        "\n",
        "    def __init__(self,bat_threshold = 0.1, bat_cap = 1, actual_load = \"none\", actual_gen = \"none\", purchase_price = [1,1,1,1,1,1,1,1,2,2,2,2] , episode_len = 8760,num_preds = 24,render_mode = \"none\"):\n",
        "\n",
        "        super(EMSv0_2_1, self).__init__()\n",
        "\n",
        "        #define time frame\n",
        "        self.current_step = 0\n",
        "        self.final_step = int(episode_len)-num_preds-2 #one years worth of steps\n",
        "\n",
        "        #Might make a function for these\n",
        "        #fill all of the actual loads NB!!! is just random for now NB!!! is normalised 0-1\n",
        "        if isinstance(actual_load,str) :\n",
        "            self.actual_load = np.random.rand(self.final_step+num_preds+1).astype(np.float32) #will load from a file or something\n",
        "        else:\n",
        "            self.actual_load = actual_load[:episode_len]\n",
        "\n",
        "        #fill all of the actual generation steps.\n",
        "        if isinstance(actual_gen,str):\n",
        "            self.actual_gen  = np.random.rand(self.final_step+num_preds+1).astype(np.float32) #will load from file or something\n",
        "        else:\n",
        "            self.actual_gen  = actual_gen[:episode_len]\n",
        "\n",
        "        #define the purchase price for every step of the year\n",
        "        purchase_price = np.array(purchase_price).astype(np.float32)\n",
        "        repetitions    = (self.final_step+num_preds+1) // len(purchase_price)\n",
        "        remainder      = (self.final_step+num_preds+1) % len(purchase_price)\n",
        "        self.purchase_price =np.concatenate([purchase_price]*repetitions+[purchase_price[:remainder]])#need to read in from somewhere\n",
        "\n",
        "        #define var for storing the excess gen\n",
        "        self.excess_gen = 0\n",
        "        #define a var for determine amount purchased per step (dont want to make it total as this will incure growing penalties for the Agent if used in reward structure)\n",
        "        self.step_purchased = 0\n",
        "        #define the battery max capacity\n",
        "        self.bat_cap = bat_cap\n",
        "        #define the battery low threshold\n",
        "        self.bat_threshold = np.float32(bat_threshold)\n",
        "        #define default action\n",
        "        self.default_action = 0\n",
        "        #define actions and observations space\n",
        "        n_actions = 2 # keeping it simple\n",
        "\n",
        "        self.num_preds = num_preds # day ahead predictions\n",
        "        self.action_space = spaces.Discrete(n_actions)\n",
        "        # Dict space to store all the different things\n",
        "        self.observation_space = spaces.Dict({\n",
        "                \"power_bal_forecast\": gym.spaces.Box(low=-np.inf, high=np.inf, shape=(1,num_preds), dtype=np.float32),\n",
        "                \"price_forecast\": gym.spaces.Box(low=0, high=np.inf, shape=(1,num_preds+1), dtype=np.float32),\n",
        "                \"bat_level\": gym.spaces.Box(low=0, high=np.inf, shape=(1,), dtype=np.float32),\n",
        "                \"current_power_bal\": gym.spaces.Box(low=-np.inf, high=np.inf, shape=(1,), dtype=np.float32),\n",
        "                })\n",
        "\n",
        "    def step(self, action):\n",
        "\n",
        "        #update the current state with the action (needs to be done before current_step is inc since we want to apply the action to the previous step to get the current state)\n",
        "        self.update_state(action)\n",
        "        #Calculate reward from the action\n",
        "        reward = self.calc_reward()\n",
        "\n",
        "        #inc time step into Future\n",
        "        self.current_step += 1\n",
        "        #get next observation (for next time step)\n",
        "        observation = self.get_obs()\n",
        "        #Set terminated to False since there are no failure states\n",
        "        self.terminated = False\n",
        "        #Check if timelimit reached\n",
        "        self.truncated = False if self.current_step<self.final_step else True\n",
        "        #dont know what to put into info for now\n",
        "        info = {}\n",
        "        return observation, reward, self.terminated, self.truncated, info\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        super().reset(seed = seed, options=options)\n",
        "\n",
        "        self.current_step = 0\n",
        "        self.terminated = False\n",
        "        self.truncated = False\n",
        "\n",
        "        #reset these cause I dont want the model to just memorise the random data (so it gets changed every reset)\n",
        "        #fill all of the actual loads NB!!! is just random for now NB!!! is normalised 0-1\n",
        "        #self.actual_load = np.random.rand(self.final_step+self.num_preds+1).astype(np.float32) #will load from a file or something\n",
        "        #fill all of the actual generation steps.\n",
        "        #self.actual_gen   = np.random.rand(self.final_step+self.num_preds+1).astype(np.float32) #will load from file or something\n",
        "\n",
        "\n",
        "        #reset the state\n",
        "        self.battery_level = self.bat_cap/2\n",
        "        self.current_load = self.actual_load[0]\n",
        "        self.excess_gen = 0\n",
        "        self.step_purchased = 0\n",
        "        #get the first observation\n",
        "        observation = self.get_obs()\n",
        "        #Still don't know what to do with info\n",
        "        info = {}\n",
        "        return observation, info\n",
        "\n",
        "    def render(self):\n",
        "        #Reaaaaalllyyyy want to render something, Maybe the curent load as a point, the forecasts as a plot and the bat levels as bar\n",
        "        pass\n",
        "\n",
        "    def close(self):\n",
        "        #don't think i need this for my application\n",
        "        pass\n",
        "\n",
        "    def update_state(self, action):\n",
        "        #Update current state with actions\n",
        "        if action == 0: #do nothing action\n",
        "            self.standby()\n",
        "        elif action == 1: #buy from Grid\n",
        "            self.purchase()\n",
        "        else:  #error case\n",
        "            raise ValueError(\n",
        "              f\"Received invalid action = {action} which is not part of the action space.\"\n",
        "            )\n",
        "        #case list for each action?\n",
        "\n",
        "    def calc_reward(self):\n",
        "        #Calculate reward based on the state\n",
        "        reward = -self.step_purchased*self.purchase_price[self.current_step]\n",
        "\n",
        "        return reward\n",
        "\n",
        "    def get_obs(self):\n",
        "        #Fill the observation space with the next observation\n",
        "\n",
        "        #Get Forecasts Will probaly write a function for this? idk maybe a schlep to return all the info\n",
        "        load_forecast  = np.array( [self.actual_load[self.current_step+1: self.current_step + self.num_preds+1]] , dtype = np.float32) #will load from a file or something\n",
        "        if load_forecast.shape != (1,self.num_preds):\n",
        "            print(f\"load_forecast shape is {load_forecast.shape} but it should be {(1, self.num_preds)}. Current step is {self.current_step}\")\n",
        "        gen_forecast   = np.array( [self.actual_gen[self.current_step+1: self.current_step + self.num_preds+1]] , dtype = np.float32) #will load from a file or something\n",
        "        if gen_forecast.shape != (1,self.num_preds):\n",
        "            print(f\"gen_forecast shape is {gen_forecast.shape} but it should be {(1, self.num_preds)}. Current step is {self.current_step}\")\n",
        "        #calculate the power forecast\n",
        "        power_bal_forecast = gen_forecast-load_forecast\n",
        "        #get the prices for the current frame and the next 24 hours. Maybe will cut this down since that seems like a lot of info\n",
        "        price_forecast = np.array( [self.purchase_price[self.current_step:self.current_step+self.num_preds+1]] , dtype = np.float32)\n",
        "        #Just for readibility of the dict object\n",
        "        bat_level      = np.array([self.battery_level] , dtype= np.float32)\n",
        "\n",
        "        #calculate the current power balance\n",
        "        current_load   = np.array([self.actual_load[self.current_step]], dtype = np.float32)\n",
        "        current_gen    = np.array([self.actual_gen[self.current_step]], dtype  = np.float32)\n",
        "        current_power_bal = current_gen - current_load\n",
        "\n",
        "\n",
        "\n",
        "        obs = dict({\n",
        "                \"bat_level\":      bat_level,\n",
        "                \"current_power_bal\" :   current_power_bal,\n",
        "                \"power_bal_forecast\":  power_bal_forecast,\n",
        "                \"price_forecast\": price_forecast,\n",
        "        })\n",
        "        return obs\n",
        "\n",
        "    def standby(self):\n",
        "        #ems stands by, load is met by generation, battery and then grid\n",
        "        #if there is excess generation it is used to charge the batteries\n",
        "\n",
        "        #define step_gen and step_load for readability\n",
        "        step_gen  =  self.actual_gen[self.current_step]\n",
        "        step_load =  self.actual_load[self.current_step]\n",
        "        battery   =  self.battery_level\n",
        "        #check for gen meeting load\n",
        "        if step_load <= step_gen :\n",
        "            #set the purchased elect to 0 since gen meets load\n",
        "            self.step_purchased = 0\n",
        "            #calulate the excess elec that was generated\n",
        "            step_excess = step_gen - step_load\n",
        "            #check if battery needs to be charged\n",
        "            if battery < self.bat_cap :\n",
        "                #check if the excess amount that was generated is less than the available capacity\n",
        "                if self.bat_cap-battery-step_excess > 0:\n",
        "                    self.battery_level += step_excess\n",
        "                else:\n",
        "                    #if the excess is greater than the availability then charge till full\n",
        "                    self.battery_level = self.bat_cap\n",
        "                    #set step excess to excess minus the amount used to charge\n",
        "                    step_excess -= (self.bat_cap-battery)\n",
        "                    self.excess_gen += step_excess\n",
        "            else:\n",
        "                #if the battery is full then just inc excess_gen\n",
        "                self.excess_gen += step_excess\n",
        "        else:\n",
        "            #if the generation does not meet load\n",
        "            step_shortfall = step_load - step_gen\n",
        "            #checking if battery is above a threshold.\n",
        "            if battery > self.bat_threshold:\n",
        "                #check if battery has enough capacity to meet the load\n",
        "                if battery - step_shortfall >= self.bat_threshold:\n",
        "                    #if it does then subtract the shortfall from battery level\n",
        "                    self.battery_level -= step_shortfall\n",
        "                    #set the purchased variable to 0 since nothing was purchased\n",
        "                    self.step_purchased = 0\n",
        "                else:\n",
        "                    #set the battery to min value and purchase the rest from the grid\n",
        "                    self.battery_level = self.bat_threshold\n",
        "                    #calculate how much needs to be purchased\n",
        "                    step_shortfall -= (battery - self.bat_threshold)\n",
        "                    self.step_purchased = step_shortfall\n",
        "            else:\n",
        "                #no battery available, therefore everything needs to be bought from the grid.\n",
        "                self.step_purchased = step_shortfall\n",
        "\n",
        "    def purchase(self):\n",
        "        #purchase electricity to charge battery even if there is enough generation (I assume this will be used to buy at lower prices)\n",
        "        #get values for readability\n",
        "        step_load = self.actual_load[self.current_step]\n",
        "        step_gen  = self.actual_gen[self.current_step]\n",
        "        battery = self.battery_level\n",
        "\n",
        "        #calculate the total power need (the load plus the amount that the battery needs to charge)\n",
        "        total_need = step_load + (self.bat_cap-battery)\n",
        "        #if the generation is less than the need then purchase the remainder\n",
        "        if step_gen<total_need:\n",
        "            #purchashing the shortfall\n",
        "            self.step_purchased = total_need - step_gen\n",
        "            #setting the battery levels to full\n",
        "            self.battery_level = self.bat_cap\n",
        "        else:\n",
        "            #if the gen is enough then set purchase to 0\n",
        "            self.step_purchased  = 0\n",
        "            #set the battery to fully charged\n",
        "            self.battery_level = self.bat_cap\n",
        "            #inc excess_gen by caluclating the excess between the step gen and the total need (includes amount needed to charge the battery)\n",
        "            self.excess_gen += (step_gen - total_need)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RUZKr7RrN-u"
      },
      "source": [
        "Check the environment with stable_baselines3 check_env."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "v4GSJ8LsidPq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8426b784-3cac-4c57-f895-703e9fb00465"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/env_checker.py:244: UserWarning: Your observation power_bal_forecast has an unconventional shape (neither an image, nor a 1D vector). We recommend you to flatten the observation to have only a 1D vector or use a custom policy to properly process the data.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/env_checker.py:244: UserWarning: Your observation price_forecast has an unconventional shape (neither an image, nor a 1D vector). We recommend you to flatten the observation to have only a 1D vector or use a custom policy to properly process the data.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from stable_baselines3.common.env_checker import check_env\n",
        "env = EMSv0_2_1()\n",
        "check_env(env,warn = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DG4gB2cM7tDY"
      },
      "source": [
        "**Load in the data for our specific microgrid.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "0X9RBdXC_2PD"
      },
      "outputs": [],
      "source": [
        "#need to import data from Github\n",
        "path_data = \"/content/EEE4022S_BNKJUL001_Thesis/PythonWorkspace/dataClean.csv\"\n",
        "data = pd.read_csv(path_data)\n",
        "\n",
        "path_gen = \"/content/EEE4022S_BNKJUL001_Thesis/Generation/BNKJUL001_Thesis_solarGen500kWHomer.csv\"\n",
        "data_gen = pd.read_csv(path_gen)\n",
        "\n",
        "#Not actually using this rn but will be soon :)\n",
        "path_shedding = \"/content/EEE4022S_BNKJUL001_Thesis/MatlabWorkSpace/loadShedding2022.csv\"\n",
        "data_shedding = pd.read_csv(path_shedding)\n",
        "load_shedding = data_shedding['LoadShedding'].values.astype(np.float32)\n",
        "\n",
        "actual_gen = data_gen['PV_Out'].values.astype(np.float32)\n",
        "actual_load = data['AC'].values.astype(np.float32)\n",
        "purchase_price = data['tou_id'].values.astype(np.float32)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Kvh0dymrVgV"
      },
      "source": [
        "Evaluate the base model (no EMS, just using standby mode)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vMEdXW4otUB",
        "outputId": "5883da08-4e2c-4c24-d806-0a9057b1429c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The reset observation space looks like: {'bat_level': array([250.], dtype=float32), 'current_power_bal': array([-96.855], dtype=float32), 'power_bal_forecast': array([[-97.053, -97.229, -96.859]], dtype=float32), 'price_forecast': array([[1., 1., 1., 1.]], dtype=float32)}\n",
            "After action 0 the observation space looks like {'bat_level': array([153.14499], dtype=float32), 'current_power_bal': array([-97.053], dtype=float32), 'power_bal_forecast': array([[-97.229, -96.859, -98.018]], dtype=float32), 'price_forecast': array([[1., 1., 1., 1.]], dtype=float32)}\n",
            "The reward we recieved was 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "#define the base environment\n",
        "base_env = EMSv0_2_1(episode_len = 6000, actual_load = actual_load, actual_gen = actual_gen, bat_threshold = 100, bat_cap = 500, purchase_price = purchase_price,num_preds = 3)\n",
        "#going to print out a bunch of things to test the different spaces.\n",
        "obs,_    = base_env.reset()\n",
        "print(f\"The reset observation space looks like: {obs}\")\n",
        "action_standby = 0\n",
        "obs,reward,terminated,truncated,info = base_env.step(action_standby)\n",
        "print(f\"After action {action_standby} the observation space looks like {obs}\")\n",
        "print(f\"The reward we recieved was {reward}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A loop to get an average reward for the base model only perfoming the standby option"
      ],
      "metadata": {
        "id": "-0iOsrI-0qGo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6ZzBAQFX2_DF"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#reset the environment and save the obs\n",
        "#going to run it 100 times to get a benchmark\n",
        "#reset score\n",
        "score = 0\n",
        "for step in range(1000):\n",
        "    obs,_    = base_env.reset()\n",
        "    #ensure that the exit condition is reset\n",
        "    truncated = False\n",
        "    #define the action to take\n",
        "    action_standby = 0\n",
        "\n",
        "    while not truncated:\n",
        "        obs,reward,terminated,truncated,info = base_env.step(action_standby)\n",
        "        score += reward\n",
        "\n",
        "print(f\"Done iteration! Total reward accumulated is: {score/step}\")"
      ],
      "metadata": {
        "id": "BztNxs9w0nRz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61cfc7fe-57e4-464a-e28e-4d06c3826cc5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done iteration! Total reward accumulated is: -880769.0387836567\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRy0KQKOriqk"
      },
      "source": [
        "Connect to drive, create new directories for the logs and models to be saved in.\n",
        "\n",
        "Open tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "kqy-glMavKA6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 856
        },
        "outputId": "c8f20e1a-262f-45a7-be0c-f0c00161ad4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "            const url = new URL(await google.colab.kernel.proxyPort(8008, {'cache': true}));\n",
              "            url.searchParams.set('tensorboardColab', 'true');\n",
              "            const iframe = document.createElement('iframe');\n",
              "            iframe.src = url;\n",
              "            iframe.setAttribute('width', '100%');\n",
              "            iframe.setAttribute('height', '800');\n",
              "            iframe.setAttribute('frameborder', 0);\n",
              "            document.body.appendChild(iframe);\n",
              "        })();\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir \"{log_dir}\" --load_fast=false --port 8008\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pAj6-n04zyt"
      },
      "source": [
        "**LOAD OR MAKE MODEL HERE!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "gQDhUNGWeum4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "18ef38c7-79cd-465c-b2a5-1bc5e2ee4cd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/notebook/utils.py:280: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
            "  return LooseVersion(v) >= LooseVersion(check)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.12"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/EEE4022S_BNKJUL001_Thesis/wandb/run-20231005_203422-0sgocl6l</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/0sgocl6l' target=\"_blank\">colorful-eon-3</a></strong> to <a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems' target=\"_blank\">https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/0sgocl6l' target=\"_blank\">https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/0sgocl6l</a>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "config = {\n",
        "    \"policy_type\": \"MultiInputPolicy\",\n",
        "    \"total_timesteps\": 1500000,\n",
        "}\n",
        "\n",
        "run = wandb.init(\n",
        "    project=\"4022_intelligent_ems\",\n",
        "    config=config,\n",
        "    sync_tensorboard=True,  # auto-upload sb3's tensorboard metrics\n",
        "    monitor_gym=True,  # auto-upload the videos of agents playing the game\n",
        "    save_code=True,  # optional\n",
        ")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create a new environment to train the model in.\n",
        "train_env = EMSv0_2_1(episode_len = 6000, actual_load = actual_load, actual_gen = actual_gen, bat_threshold = 100, bat_cap = 500, purchase_price = purchase_price,num_preds = 3)\n",
        "\n",
        "train_env = Monitor(train_env)\n",
        "#train_env = DummyVecEnv(train_env)\n",
        "#Create the model with the MultiInputPolicy, use the training env, verbose is off because tensorboard loging is enabled\n",
        "model = A2C(\"MultiInputPolicy\",train_env, verbose = 0, tensorboard_log = f\"runs/{run.id}\") #log_dir\n",
        "\n",
        "#Load model, fetch the latest (or whichever one you want from the model_dir)\n",
        "#PPO latest:\n",
        "#model_load = f\"{model_dir}/\"\n",
        "#model  = PPO.load(model_load, env = train_env)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZ3Hs1sYSt89",
        "outputId": "30bb28dd-0625-4958-c3ed-bd06a0e855c1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Infinite while loop to train  model.**"
      ],
      "metadata": {
        "id": "vEDG0IiVvxeH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "g5dU9TLFzhxD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440,
          "referenced_widgets": [
            "b14f70adbf59420ab69c2fd93ae2874d",
            "8255087e36da417da0a90d4f20185974",
            "eaf5460df1c4481e8dc1840472aa8d7e",
            "032920c1fd074747a1acef48edd10a25",
            "79872faff7ce452e9d0ca11cbd6fd874",
            "2089f6cc0ece43b8ad494782fb554293",
            "64571fece5cc44b5acf5aef73cb696a0",
            "ce42723d3df74846be4b53e4d92918ba"
          ]
        },
        "outputId": "b5356426-3a35-4968-d8ea-95d38d4d6bf3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='1.245 MB of 1.245 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b14f70adbf59420ab69c2fd93ae2874d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>rollout/ep_len_mean</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>rollout/ep_rew_mean</td><td>▁▂▃▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▆▆▆▆▆▇▇▇▇██</td></tr><tr><td>time/fps</td><td>███▇▇▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▁</td></tr><tr><td>train/entropy_loss</td><td>████▅▇██▅█▇███▇████▆▅▃▇▇▆▂▅▂█▂█▁▆▁▆▅▃▄▇▇</td></tr><tr><td>train/explained_variance</td><td>▇▁▇▇▇▇▇▆▇▇▇▇▇█▇█▇█▇█▇▇▇▇█▇▇▇▇▇█▇█▇█▇▇▇█▇</td></tr><tr><td>train/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/policy_loss</td><td>████▇▅██▆███████████▃▁██▇▂▇▇█▆█▅▇▇▇█▃▇██</td></tr><tr><td>train/value_loss</td><td>▃▁▁▁▄▁▁▁▂▁▁▆▁▁▂▁▁▁▁▁▃█▁▁▁▅▂▁▁▁▁▂▁▁▂▁▆▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>1500000</td></tr><tr><td>rollout/ep_len_mean</td><td>5995.0</td></tr><tr><td>rollout/ep_rew_mean</td><td>-881977.8125</td></tr><tr><td>time/fps</td><td>120.0</td></tr><tr><td>train/entropy_loss</td><td>-0.35933</td></tr><tr><td>train/explained_variance</td><td>0.00451</td></tr><tr><td>train/learning_rate</td><td>0.0007</td></tr><tr><td>train/policy_loss</td><td>-214.18924</td></tr><tr><td>train/value_loss</td><td>663746.875</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">colorful-eon-3</strong> at: <a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/0sgocl6l' target=\"_blank\">https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/0sgocl6l</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 52 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20231005_203422-0sgocl6l/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "wand_name = f\"{version}_{model_type}\"+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "for i in range(50):\n",
        "    #define the name for the specific log\n",
        "\n",
        "    #make the model learn, set the reset to false so that it keeps its old learning\n",
        "    model.learn(total_timesteps= 30000,\n",
        "                tb_log_name = wand_name,\n",
        "                reset_num_timesteps=False,\n",
        "                callback = WandbCallback(\n",
        "                        gradient_save_freq=100,\n",
        "                        model_save_path=f\"models/{run.id}\",\n",
        "                        verbose=2,\n",
        "                ))\n",
        "    log_name = f\"{version}_{model_type}\"+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "    model.save(f\"{model_dir}{log_name}\")\n",
        "    #open tensorboard\n",
        "run.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define a new test environment and load up the best performing model to test it.**"
      ],
      "metadata": {
        "id": "C9AGcLlsv4N7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "inDHszZaxBUS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b213134d-d5d5-4c4c-8fde-b8bb1dbde448"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Note: The term does not refer to the cost in rands but rather to the reward as defined by the reward function!\n",
            "Done the Standby Test! Total cost accumulated is: -309839.33152008057\n",
            "Done applying the trained model! Total cost accumulated is: -328105.00497436523 +- 0.0\n",
            "The amount that was saved by applying the EMS agent: -18265.673454284668\n",
            "This was saved over a period of 115.0 days\n",
            "The savings represents -5.89520812760367 % of the cost if no EMS is installed\n",
            "And it represents -5.567020672455686 % of the cost if the EMS is installed\n"
          ]
        }
      ],
      "source": [
        "#define a test environment\n",
        "test_env = EMSv0_2_1(episode_len = 2760, actual_load = actual_load[6001:], actual_gen = actual_gen[6001:], bat_threshold = 100, bat_cap = 500, purchase_price = purchase_price[6001:],num_preds = 3)\n",
        "#reset the environment and save the obs\n",
        "\n",
        "#Load model, fetch the latest (or whichever one you want from the model_dir)\n",
        "#Best A2C model:/content/drive/MyDrive/Colab Notebooks/EMSv0_2_1/models/PPO/EMSv0_2_1_PPO20231005-102532.zip\n",
        "#best_PPO_model = \"EMSv0_2_1_PPO20231005-102532.zip\"\n",
        "\n",
        "\n",
        "#model_load = f\"{model_dir}/{best_PPO_model}\"\n",
        "#model  = PPO.load(model_load, env = test_env)\n",
        "\n",
        "\n",
        "#first run it with only standby (default)\n",
        "obs,_    = test_env.reset()\n",
        "#ensure that the exit condition is reset\n",
        "truncated = False\n",
        "#define the action to take\n",
        "action_standby = 0\n",
        "#reset score\n",
        "standby_score = 0\n",
        "while not truncated:\n",
        "    #step the model with the action\n",
        "    obs,reward,terminated,truncated,info = test_env.step(action_standby)\n",
        "    #accumulate the score\n",
        "    standby_score += reward\n",
        "\n",
        "EMS_reward,EMS_std_reward = evaluate_policy(model,test_env,n_eval_episodes = 100,deterministic=True)\n",
        "\n",
        "\n",
        "print(f\"Note: The term does not refer to the cost in rands but rather to the reward as defined by the reward function!\")\n",
        "print(f\"Done the Standby Test! Total cost accumulated is: {standby_score}\")\n",
        "print(f\"Done applying the trained model! Total cost accumulated is: {EMS_reward} +- {EMS_std_reward}\")\n",
        "\n",
        "savings = EMS_reward - standby_score\n",
        "print(f\"The amount that was saved by applying the EMS agent: {savings}\")\n",
        "print(f\"This was saved over a period of {2760/24} days\")\n",
        "print(f\"The savings represents {(savings/(-standby_score))*100} % of the cost if no EMS is installed\")\n",
        "print(f\"And it represents {(savings/(-EMS_reward))*100} % of the cost if the EMS is installed\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP3ARUL+sQmaeGtJKc/RGcr",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b14f70adbf59420ab69c2fd93ae2874d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8255087e36da417da0a90d4f20185974",
              "IPY_MODEL_eaf5460df1c4481e8dc1840472aa8d7e"
            ],
            "layout": "IPY_MODEL_032920c1fd074747a1acef48edd10a25"
          }
        },
        "8255087e36da417da0a90d4f20185974": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79872faff7ce452e9d0ca11cbd6fd874",
            "placeholder": "​",
            "style": "IPY_MODEL_2089f6cc0ece43b8ad494782fb554293",
            "value": "1.245 MB of 1.245 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "eaf5460df1c4481e8dc1840472aa8d7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64571fece5cc44b5acf5aef73cb696a0",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ce42723d3df74846be4b53e4d92918ba",
            "value": 1
          }
        },
        "032920c1fd074747a1acef48edd10a25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79872faff7ce452e9d0ca11cbd6fd874": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2089f6cc0ece43b8ad494782fb554293": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "64571fece5cc44b5acf5aef73cb696a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce42723d3df74846be4b53e4d92918ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}