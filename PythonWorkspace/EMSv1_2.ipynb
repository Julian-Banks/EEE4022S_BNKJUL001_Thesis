{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Julian-Banks/EEE4022S_BNKJUL001_Thesis/blob/main/PythonWorkspace/EMSv1_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Version Notes**\n",
        "\n",
        "# **v1.1**\n",
        "\n",
        "**Added:**\n",
        "* rect and inverter power tracking\n",
        "* reward logging in my own logging func\n",
        "* changed logging vars to arrays\n",
        "*\n",
        "\n",
        "**To Do**\n",
        "\n",
        "* battery charging rates - I think my assumption is fine.\n",
        "\n",
        "* tweak visualisation to show bar graphs at the end of training/testing. Maybe just print graphs at the end? I have added plt.show() - remember to play if it doesnt work!\n",
        "\n",
        "* impliment a generator!!!!!\n",
        "* impliment a priority load\n",
        "\n",
        "* NB figure out how to have more episodes!! I think it will have big performance boosts on the training :)\n",
        "\n",
        "* thinking that maybe I should change obs space back to what it was cause I dont actully need to know individual loads and gens!!!!\n",
        "\n",
        "# **v1.0**\n",
        "\n",
        "**Added:**\n",
        "* AC and DC load\n",
        "* Wind Gen\n",
        "* changed obs space to hold new loads\n",
        "* re wrote standby and purchase functions\n",
        "\n",
        "**To DO**\n",
        "* thinking that maybe I should change obs space back to what it was cause I dont actully need to know individual loads and gens!!!!\n",
        "* Add in rectifier & inverter power tracking\n",
        "* battery charging rates\n",
        "\n",
        "\n",
        "# **v0.3**\n",
        "**Added:**\n",
        "* loadshedding\n",
        "* New reward structure\n",
        "* added Vec_env\n",
        "* added eval callbacks to validate training\n",
        "* added in logging\n",
        "\n",
        "**Parameters:**\n",
        "* Added in loadshedding forecast\n",
        "\n",
        "**To do:**\n",
        "* find out about battery charging rates  & impliment\n",
        "* Find out if I need to normalise\n",
        "* Try dqn\n",
        "* Find out how the bounds for the obs_space box effect things\n",
        "* Try play with DummyVec wrapper (didnt work in last version)\n",
        "\n",
        "# **v0.2_1**\n",
        "**Added:**\n",
        "*  Monitor wrapper\n",
        "*  DummyVec wrapper\n",
        "*  Wand (weights and bais) enabled\n",
        "\n",
        "**Parameters:**\n",
        "* lowered to 3 predictions  \n",
        "\n",
        "**To do:**\n",
        "* Try to use hyperparameter Optimisation - decided Im only going to do on the final version\n",
        "* Try normalise\n",
        "* Try differnet models\n",
        "* Find out how the bounds for the obs_space box effect things\n",
        "\n",
        "# **v0.2**\n",
        "**Added:**\n",
        "*  simplified load_forecast and gen_forecast to be power_bal_forecasts.\n",
        "*  combined current_load and current_gen to also show current_power_balance\n",
        "*  added proper evaluate call\n",
        "\n",
        "**Parameters:**\n",
        "* No changes  \n",
        "\n",
        "**Results:**\n",
        "* 5% savings on PPO deterministic = true\n",
        "* 4.3% savings on PPO determnistic = false\n",
        "\n",
        "**To do:**\n",
        "* Try to use hyperparameter Optimisation\n",
        "* Try normalise\n",
        "* Try differnet models\n",
        "* Try see if discount rate can be tweaked - at good level.\n",
        "* Find out how the bounds for the obs_space box effect things\n",
        "\n",
        "# **v0.1**\n",
        "**Added:**\n",
        "* added real loads, gen, tou_id's\n",
        "\n",
        "**Parameters:**\n",
        "* training episode = 6000 timesteps\n",
        "* testing episode  = 2760 timesteps\n",
        "* bat_threshold = 100\n",
        "* bat_cap = 500\n",
        "* battery_level at reset = bat_cap/2\n",
        "* num_preds = 24\n",
        "* Trained PPO for 1.65mil timesteps\n",
        "* Trained A2C for 1.2 mil timesteps\n",
        "\n",
        "**Results:**\n",
        "* PP0 - 3.7% improvement from standby mode Deterministic = False\n",
        "* PPO - 6.1% Deterministic =  True\n",
        "* A2C  - -0.3% improvement. And the models after this got worse as training progressed!\n",
        "**To do:**\n",
        "* Try lower num_preds\n",
        "* Try to use hyperparameter Optimisation\n",
        "* Try normalise\n",
        "* Try differnet models\n",
        "* Try see if discount rate can be tweaked\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5DZFnZnzStt1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "nI52iVVCCPaf"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "#install dependancies\n",
        "!pip install gymnasium\n",
        "!pip install stable_baselines3[extra]\n",
        "!pip install wandb\n",
        "%load_ext tensorboard\n",
        "\n",
        "#clone repository\n",
        "! git clone https://github.com/Julian-Banks/EEE4022S_BNKJUL001_Thesis\n",
        "\n",
        "#to update the rep\n",
        "%cd /content/EEE4022S_BNKJUL001_Thesis\n",
        "! git pull\n",
        "#import needed libarys\n",
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from gymnasium import spaces\n",
        "import datetime\n",
        "from stable_baselines3 import PPO, A2C, DQN\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from stable_baselines3.common.callbacks import EvalCallback\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.vec_env import VecVideoRecorder\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.animation import FuncAnimation\n",
        "from gym.wrappers import FlattenObservation\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "import wandb\n",
        "from wandb.integration.sb3 import WandbCallback\n",
        "from gymnasium.envs.registration import register\n",
        "\n",
        "\n",
        "\n",
        "#mount the drive\n",
        "drive.mount('/content/drive')\n",
        "#define paths to logs and model saves\n",
        "model_type = \"PPO_2\"\n",
        "version    = \"EMSv1_1\"\n",
        "model_dir = f\"/content/drive/MyDrive/Colab Notebooks/{version}/models/{model_type}/\"\n",
        "log_dir   = f\"/content/drive/MyDrive/Colab Notebooks/{version}/models/{model_type}logs/\"\n",
        "animation_dir = f\"/content/drive/MyDrive/Colab Notebooks/{version}/models/{model_type}/animation/\"\n",
        "\n",
        "#make the appropriate directory if it does not exist\n",
        "if not os.path.exists(model_dir):\n",
        "    os.makedirs(model_dir)\n",
        "if not os.path.exists(log_dir):\n",
        "    os.makedirs(log_dir)\n",
        "if not os.path.exists(animation_dir):\n",
        "    os.makedirs(animation_dir)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define our environment class!!**"
      ],
      "metadata": {
        "id": "Q99_jLMvwuZZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "s2iW-k26FIbm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "113ed43d-8fc4-4e57-ded1-46945a720fd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gymnasium/envs/registration.py:694: UserWarning:\n",
            "\n",
            "\u001b[33mWARN: Overriding environment EMSv1_1 already in registry.\u001b[0m\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/env_checker.py:244: UserWarning:\n",
            "\n",
            "Your observation current_power_bal has an unconventional shape (neither an image, nor a 1D vector). We recommend you to flatten the observation to have only a 1D vector or use a custom policy to properly process the data.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/env_checker.py:244: UserWarning:\n",
            "\n",
            "Your observation island_forecast has an unconventional shape (neither an image, nor a 1D vector). We recommend you to flatten the observation to have only a 1D vector or use a custom policy to properly process the data.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/env_checker.py:30: UserWarning:\n",
            "\n",
            "It seems that your observation power_bal_forecast is an image but its `dtype` is (float32) whereas it has to be `np.uint8`. If your observation is not an image, we recommend you to flatten the observation to have only a 1D vector\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/env_checker.py:38: UserWarning:\n",
            "\n",
            "It seems that your observation space power_bal_forecast is an image but the upper and lower bounds are not in [0, 255]. Because the CNN policy normalize automatically the observation you may encounter issue if the values are not in that range.\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/env_checker.py:51: UserWarning:\n",
            "\n",
            "The minimal resolution for an image is 36x36 for the default `CnnPolicy`. You might need to use a custom features extractor cf. https://stable-baselines3.readthedocs.io/en/master/guide/custom_policy.html\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/env_checker.py:244: UserWarning:\n",
            "\n",
            "Your observation price_forecast has an unconventional shape (neither an image, nor a 1D vector). We recommend you to flatten the observation to have only a 1D vector or use a custom policy to properly process the data.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "class EMSv1_1(gym.Env):\n",
        "    \"\"\"Custom Environment that follows gym interface.\"\"\"\n",
        "\n",
        "    metadata = {\"render_modes\": [\"human\",\"rgb_array\"], \"render_fps\": 30}\n",
        "\n",
        "    def __init__(self,bat_threshold = 0.1, bat_cap = 1, actual_load = \"none\", actual_gen = \"none\", purchase_price = [1,1,1,1,1,1,1,1,2,2,2,2] , episode_len = 8760,num_preds = 24,render_mode = \"rgb_array\", load_shedding = \"none\", wandb_log = False,train_log = True):\n",
        "\n",
        "        super(EMSv1_1, self).__init__()\n",
        "        #define render_mode\n",
        "        self.render_mode = render_mode\n",
        "        #define wandb\n",
        "        self.wandb_log = wandb_log\n",
        "        self.train_log = train_log\n",
        "        #define time frame\n",
        "        self.current_step = 0\n",
        "        self.final_step = int(episode_len)-num_preds-2 #one years worth of steps\n",
        "\n",
        "        #Might make a function for these\n",
        "        #fill all of the actual loads NB!!! is just random for now NB!!! is normalised 0-1\n",
        "        if isinstance(actual_load,str) :\n",
        "            self.actual_load = np.random.rand(self.final_step+num_preds+1,2).astype(np.float32) #will load from a file or something\n",
        "        else:\n",
        "           self.actual_load  = actual_load[:episode_len,:]\n",
        "\n",
        "        #fill all of the actual generation steps.\n",
        "        if isinstance(actual_gen,str):\n",
        "            self.actual_gen  = np.random.rand(self.final_step+num_preds+1,2).astype(np.float32) #will load from file or something\n",
        "        else:\n",
        "            self.actual_gen  = actual_gen[:episode_len,:]\n",
        "\n",
        "        #Fill the loadShedding indicator\n",
        "        if isinstance(load_shedding,str):\n",
        "            num_shedding   = np.random.randint(int(0.02*episode_len), int(0.05*episode_len))\n",
        "            load_shed      = np.array([1]*num_shedding + [0]*(episode_len - num_shedding))\n",
        "            np.random.shuffle(load_shed)\n",
        "            self.load_shed = load_shed\n",
        "        else:\n",
        "            self.load_shed = load_shedding[:episode_len]\n",
        "\n",
        "        #define vars for render\n",
        "        self.off_peak_purchases = np.zeros(self.final_step)\n",
        "        self.standard_purchases = np.zeros(self.final_step)\n",
        "        self.peak_purchases     = np.zeros(self.final_step)\n",
        "\n",
        "        self.off_peak_num       = 0\n",
        "        self.peak_num           = 0\n",
        "        self.standard           = 0\n",
        "\n",
        "        self.unmet_load_total   = 0\n",
        "        self.frames = []\n",
        "\n",
        "        #Define a var for unmet load no that there is loadshedding\n",
        "        self.step_unmet_load = np.zeros(self.final_step)\n",
        "\n",
        "        #define the purchase price for every step of the year\n",
        "        purchase_price = np.array(purchase_price).astype(np.float32)\n",
        "        repetitions    = (self.final_step+num_preds+1) // len(purchase_price)\n",
        "        remainder      = (self.final_step+num_preds+1) % len(purchase_price)\n",
        "        self.purchase_price =np.concatenate([purchase_price]*repetitions+[purchase_price[:remainder]])#need to read in from somewhere\n",
        "\n",
        "        #define var for storing the excess gen\n",
        "        self.excess_gen = np.zeros(self.final_step)\n",
        "        #define a var for determine amount purchased per step (dont want to make it total as this will incure growing penalties for the Agent if used in reward structure)\n",
        "        self.step_purchased = np.zeros(self.final_step)\n",
        "        self.purchased_total = 0\n",
        "        #define the battery max capacity\n",
        "        self.bat_cap = bat_cap\n",
        "        #define the battery low threshold\n",
        "        self.bat_threshold = np.float32(bat_threshold)\n",
        "        self.battery_level = np.zeros(self.final_step+1)\n",
        "        #define default action\n",
        "        self.default_action = 0\n",
        "        #define actions and observations space\n",
        "        n_actions = 2 # keeping it simple\n",
        "\n",
        "        self.num_preds = num_preds # day ahead predictions\n",
        "        #define how many different loads and generators there are\n",
        "        self.num_loads = self.actual_load.shape[1]\n",
        "        #define the size of the action space\n",
        "        self.action_space = spaces.Discrete(n_actions)\n",
        "        # Dict space to store all the different things\n",
        "        self.observation_space = spaces.Dict({\n",
        "                \"power_bal_forecast\": gym.spaces.Box(low=-np.inf, high=np.inf, shape=(1,num_preds,self.num_loads), dtype=np.float32),\n",
        "                \"price_forecast\": gym.spaces.Box(low=0, high=np.inf, shape=(1,num_preds+1), dtype=np.float32),\n",
        "                \"island_forecast\": gym.spaces.Box(low=0, high=1, shape=(1,num_preds+1), dtype=np.float32),\n",
        "                \"bat_level\": gym.spaces.Box(low=0, high=np.inf, shape=(1,), dtype=np.float32),\n",
        "                \"current_power_bal\": gym.spaces.Box(low=-np.inf, high=np.inf, shape=(1,self.num_loads), dtype=np.float32),\n",
        "                })\n",
        "\n",
        "    def step(self, action):\n",
        "\n",
        "        #update the current state with the action (needs to be done before current_step is inc since we want to apply the action to the previous step to get the current state)\n",
        "        self.update_state(action)\n",
        "        #Calculate reward from the action\n",
        "        self.reward[self.current_step] = self.calc_reward()\n",
        "        #print(f\"calc_reward: {self.calc_reward()}\")\n",
        "        #print(f\"self.reward[current_step]: {self.reward[self.current_step]}\")\n",
        "        reward = self.reward[self.current_step]\n",
        "        #inc time step into Future\n",
        "        self.current_step += 1\n",
        "        #get next observation (for next time step)\n",
        "        observation = self.get_obs()\n",
        "        #Set terminated to False since there are no failure states\n",
        "        self.terminated = False\n",
        "        #Check if timelimit reached\n",
        "        self.truncated = False if self.current_step<self.final_step else True\n",
        "        #Wand log, if its set to true(so that it only gets run when wandb is initialised)\n",
        "        if self.wandb_log == True:\n",
        "            #doing this for training logging\n",
        "            if self.train_log == True:\n",
        "                if self.current_step == self.final_step:\n",
        "                    self.wandb_logger()\n",
        "            else:\n",
        "                self.wandb_logger()\n",
        "        #dont know what to put into info for now\n",
        "        info = {}\n",
        "        return observation, reward, self.terminated, self.truncated, info\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        super().reset(seed = seed, options=options)\n",
        "\n",
        "        self.current_step = 0\n",
        "        self.terminated = False\n",
        "        self.truncated = False\n",
        "        #reset the state\n",
        "        self.battery_level[0]   = self.bat_cap/2\n",
        "        self.excess_gen         = np.zeros(self.final_step)\n",
        "        self.step_purchased     = np.zeros(self.final_step)\n",
        "        self.step_unmet_load    = np.zeros(self.final_step)\n",
        "        self.off_peak_purchases = np.zeros(self.final_step)\n",
        "        self.peak_purchases     = np.zeros(self.final_step)\n",
        "        self.standard_purchases = np.zeros(self.final_step)\n",
        "        self.purchase_count     = np.zeros(self.final_step)\n",
        "        self.standby_count      = np.zeros(self.final_step)\n",
        "        self.diesel_count       = np.zeros(self.final_step)\n",
        "        self.reward             = np.zeros(self.final_step+1)\n",
        "        self.step_invt          = np.zeros(self.final_step)\n",
        "        self.step_rect          = np.zeros(self.final_step)\n",
        "        self.diesel_gen         = np.zeros(self.final_step)\n",
        "        #get the first observation\n",
        "        observation = self.get_obs()\n",
        "        #Still don't know what to do with info\n",
        "        info = {}\n",
        "        return observation, info\n",
        "\n",
        "\n",
        "\n",
        "    def render(self, mode='rgb_array', save_path=None):\n",
        "\n",
        "        plt.clf()\n",
        "        values = [self.off_peak_purchases, self.standard_purchases, self.purchase_price[self.peak_purchases]]\n",
        "        colors = ['green', 'orange','red']\n",
        "        labels = ['Off Peak', 'Standard', 'Peak']\n",
        "        plt.xlim(0,1.6)\n",
        "        plt.ylim(0,100)\n",
        "        plt.bar(list(range(3)),values, color=colors, tick_label=labels)\n",
        "        self.frames.append(plt.gcf().canvas.tostring_rgb())\n",
        "        plt.pause(0.000001)\n",
        "\n",
        "    def wandb_logger(self):\n",
        "        train_log_dict={\n",
        "                    \"Excess Generation\"         :np.sum(self.excess_gen),\n",
        "                    \"Unmet Load\"                :np.sum(self.step_unmet_load),\n",
        "                    \"Off-Peak Purchases\"        :np.sum(self.off_peak_purchases),\n",
        "                    \"Standard Purchases\"        :np.sum(self.standard_purchases),\n",
        "                    \"Peak Purchases\"            :np.sum(self.peak_purchases),\n",
        "                    \"Num Off-Peak Purchases\"    :np.count_nonzero(self.off_peak_purchases),\n",
        "                    \"Num Standard Purchases\"    :np.count_nonzero(self.standard_purchases),\n",
        "                    \"Num Peak Purchases\"        :np.count_nonzero(self.peak_purchases),\n",
        "                    \"Num Standby Actions\"       :np.count_nonzero(self.standby_count),\n",
        "                    \"Num Purchase Actions\"      :np.count_nonzero(self.purchase_count),\n",
        "                    \"Num Diesel Gen Actions\"    :np.count_nonzero(self.diesel_count),\n",
        "                    \"Total Reward\"              :np.sum(self.reward),\n",
        "                    \"Rectifier total power flow\":np.sum(self.step_rect),\n",
        "                    \"Inverter total power flow\" :np.sum(self.step_invt),\n",
        "                    \"Diesel Generator\"          :np.sum(self.diesel_gen),\n",
        "\n",
        "\n",
        "                  }\n",
        "        eval_log_dict={\n",
        "                    \"battery_level\"             :self.battery_level[self.current_step],\n",
        "                    \"AC load\"                   :self.actual_load[self.current_step,0],\n",
        "                    \"DC load\"                   :self.actual_load[self.current_step,1],\n",
        "                    \"PV generation\"             :self.actual_gen[self.current_step,0],\n",
        "                    \"Wind generation\"           :self.actual_gen[self.current_step,1],\n",
        "                    \"Excess Generation\"         :np.sum(self.excess_gen),\n",
        "                    \"Unmet Load\"                :np.sum(self.step_unmet_load),\n",
        "                    \"LoadShedding\"              :self.load_shed[self.current_step],\n",
        "                    \"Off-Peak Purchases\"        :np.sum(self.off_peak_purchases),\n",
        "                    \"Standard Purchases\"        :np.sum(self.standard_purchases),\n",
        "                    \"Peak Purchases\"            :np.sum(self.peak_purchases),\n",
        "                    \"Num Off-Peak Purchases\"    :np.count_nonzero(self.off_peak_purchases),\n",
        "                    \"Num Standard Purchases\"    :np.count_nonzero(self.standard_purchases),\n",
        "                    \"Num Peak Purchases\"        :np.count_nonzero(self.peak_purchases),\n",
        "                    \"Num Standby Actions\"       :np.count_nonzero(self.standby_count),\n",
        "                    \"Num Purchase Actions\"      :np.count_nonzero(self.purchase_count),\n",
        "                    \"Num Diesel Gen Actions\"    :np.count_nonzero(self.diesel_count),\n",
        "                    \"Total Reward\"              :np.sum(self.reward),\n",
        "                    \"Rectifier total power flow\":np.sum(self.step_rect),\n",
        "                    \"Inverter total power flow\" :np.sum(self.step_invt),\n",
        "                    \"Diesel Generator\"          :np.sum(self.diesel_gen),\n",
        "\n",
        "                  }\n",
        "\n",
        "        if self.train_log:\n",
        "            wandb.log(train_log_dict)\n",
        "        else:\n",
        "            wandb.log(eval_log_dict)\n",
        "\n",
        "        if self.train_log == False and self.current_step == self.final_step:\n",
        "            plt.clf()\n",
        "            values = [np.sum(self.off_peak_purchases), np.sum(self.standard_purchases), np.sum(self.peak_purchases)]\n",
        "            colors = ['green', 'orange','red']\n",
        "            labels = ['Off Peak', 'Standard', 'Peak']\n",
        "            plt.xlim(0,2)\n",
        "            plt.ylim(0,120000)\n",
        "            plt.bar(list(range(3)),values, color=colors, tick_label=labels)\n",
        "            plt.xlabel('Tariff Rate')\n",
        "            plt.ylabel('Electricity Purchased (units)')\n",
        "            plt.title('Electricity Purchased per Tariff Rate')\n",
        "\n",
        "            save_name = animation_dir + \"TOU_purchases_\"+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")+\".png\"\n",
        "            plt.savefig(save_name)\n",
        "            wandb.log({\"Electricity purchased per Tariff rate\": wandb.Image(save_name)})\n",
        "\n",
        "    def close(self):\n",
        "        #don't think i need this for my application\n",
        "        pass\n",
        "\n",
        "    def update_state(self, action):\n",
        "        #reset step vars\n",
        "        self.step_purchased[self.current_step]  = 0\n",
        "        self.step_unmet_load[self.current_step] = 0\n",
        "        self.step_rect[self.current_step]       = 0\n",
        "        self.step_invt[self.current_step]       = 0\n",
        "        #Update current state with actions\n",
        "        if action == 0: #do nothing action\n",
        "            self.standby()\n",
        "            self.standby_count[self.current_step]=1\n",
        "        elif action == 1: #buy from Grid\n",
        "            self.purchase()\n",
        "            self.purchase_count[self.current_step]=1\n",
        "        elif action == 2:\n",
        "            self.diesel_gen()\n",
        "            self.diesel_count[self.current_step] =1\n",
        "        else:  #error case\n",
        "            raise ValueError(\n",
        "                f\"Received invalid action = {action} which is not part of the action space.\"\n",
        "            )\n",
        "\n",
        "        self.tou_purchase_inc()\n",
        "\n",
        "    def calc_reward(self):\n",
        "        #Calculate reward based on the state\n",
        "        reward = -self.step_purchased[self.current_step]*self.purchase_price[self.current_step] - self.step_unmet_load[self.current_step]*10 - self.diesel_gen[self.current_step]*10\n",
        "\n",
        "        return reward\n",
        "\n",
        "    def get_obs(self):\n",
        "        #Fill the observation space with the next observation\n",
        "\n",
        "        #Get Forecasts Will probaly write a function for this? idk maybe a schlep to return all the info\n",
        "        load_forecast  = np.array( [self.actual_load[self.current_step+1: self.current_step + self.num_preds+1,:]] , dtype = np.float32) #will load from a file or something\n",
        "        gen_forecast   = np.array( [self.actual_gen[self.current_step+1: self.current_step + self.num_preds+1,:]] , dtype = np.float32) #will load from a file or something\n",
        "        #calculate the power forecast\n",
        "        power_bal_forecast = gen_forecast-load_forecast\n",
        "        #get the prices for the current frame and the next 24 hours. Maybe will cut this down since that seems like a lot of info\n",
        "        price_forecast = np.array( [self.purchase_price[self.current_step:self.current_step+self.num_preds+1]] , dtype = np.float32)\n",
        "        #Just for readibility of the dict object\n",
        "        bat_level      = np.array([self.battery_level[self.current_step]] , dtype= np.float32)\n",
        "        #island forecasst, same as tou forecast\n",
        "        island_forecast =np.array( [self.load_shed[self.current_step:self.current_step+self.num_preds+1]] , dtype = np.float32)\n",
        "\n",
        "        #calculate the current power balance\n",
        "        current_load   = np.array([self.actual_load[self.current_step,:]], dtype = np.float32)\n",
        "        current_gen    = np.array([self.actual_gen[self.current_step,:]], dtype  = np.float32)\n",
        "        current_power_bal = current_gen - current_load\n",
        "\n",
        "\n",
        "\n",
        "        obs = dict({\n",
        "                \"bat_level\":      bat_level,\n",
        "                \"current_power_bal\" :   current_power_bal,\n",
        "                \"island_forecast\": island_forecast,\n",
        "                \"power_bal_forecast\":  power_bal_forecast,\n",
        "                \"price_forecast\": price_forecast,\n",
        "        })\n",
        "        return obs\n",
        "\n",
        "    def AC_bus(self):\n",
        "        #fill out info on the ac\n",
        "        ac_gen = self.actual_gen[self.current_step, 0]\n",
        "        ac_load = self.actual_load[self.current_step,0]\n",
        "        ac_power_bal = ac_gen - ac_load\n",
        "        #check if there is load shedding or not\n",
        "        avail_grid = not self.load_shed[self.current_step]\n",
        "        #ac_diesel = Don't know what yet but I do want to use it for something.\n",
        "        #return relevant values\n",
        "        return ac_power_bal,avail_grid\n",
        "\n",
        "    def DC_bus(self):\n",
        "        #fill in info for DC_bus\n",
        "        dc_gen       = self.actual_gen[self.current_step,1]\n",
        "        dc_load      = self.actual_load[self.current_step,1]\n",
        "        dc_power_bal = dc_gen - dc_load\n",
        "        #Haven't imposed limits here but I don't think I need to. Must check.\n",
        "        avail_bat  = self.battery_level[self.current_step] - self.bat_threshold\n",
        "        avail_stor = self.bat_cap       - self.battery_level[self.current_step]\n",
        "        return dc_power_bal, avail_bat, avail_stor\n",
        "\n",
        "    def standby(self):\n",
        "        #fetch info from grids\n",
        "        ac_power_bal, avail_grid = self.AC_bus()\n",
        "        dc_power_bal, avail_bat, avail_stor = self.DC_bus()\n",
        "\n",
        "        #calculate the immediate power_bal\n",
        "        grid_power_bal = ac_power_bal + dc_power_bal\n",
        "        #determine the flow of power:\n",
        "        if grid_power_bal > 0 :\n",
        "            #increments the battery level by the minimium between avail_stor and grid_power_bal ( always keeps it in range)\n",
        "            self.battery_level[self.current_step+1] = self.battery_level[self.current_step] + min(avail_stor, grid_power_bal)\n",
        "            #increments excess gen by the max ( if grid_power_bal - avail_stor is negative, there was no excess and it will add 0, else it will add the excess that wasn't stored)\n",
        "            self.excess_gen[self.current_step] = max((grid_power_bal - avail_stor), 0)\n",
        "        else:\n",
        "            #there is a shortage of power, see if we can take it from the battery.\n",
        "            # flipping the sign of the grid power balance, bacause it will be negative since we have a shortage of power.\n",
        "            self.battery_level[self.current_step+1] = self.battery_level[self.current_step] - min(avail_bat, -grid_power_bal)\n",
        "            #check if we are islanded and buy elec if we arent\n",
        "            if avail_grid:\n",
        "                #if the grid is available (make power bal positive, minus the amount we drew from batter and take the max between that and zero)\n",
        "                self.step_purchased[self.current_step] = max(-grid_power_bal- avail_bat, 0)\n",
        "            else:\n",
        "                #if not available add to the step un_met_load.\n",
        "                self.step_unmet_load[self.current_step] = max(-grid_power_bal- avail_bat, 0)\n",
        "\n",
        "        #Calculate the flow of power (this is max absorb, the min need is just dc_power_bal)\n",
        "        self.calc_power_flow(dc_power_bal,ac_power_bal,avail_stor)\n",
        "\n",
        "    def diesel_gen(self):\n",
        "        self.standby()\n",
        "        unmet_load = self.step_unmet_load[self.current_step]\n",
        "        if unmet_load > 0:\n",
        "            #something goes here\n",
        "            self.diesel_gen[self.current_step] = unmet_load\n",
        "            self.step_unmet_load[self.current_step] = self.step_unmet_load[self.current_step] - self.diesel_gen[self.current_step]\n",
        "\n",
        "    def calc_power_flow(self,dc_power_bal,ac_power_bal,avail_stor):\n",
        "\n",
        "        #Calculate the flow of power (this is max absorb, the min need is just dc_power_bal)\n",
        "        dc_power_absorb = max(-dc_power_bal+avail_stor,0)\n",
        "        #ac power excess will be the power balance added to the purchase amount\n",
        "        ac_power_excess = max(ac_power_bal+self.step_purchased[self.current_step],0)\n",
        "        #the power that will flow through the rectifier is the minimum between the amount the DC grid can absorb and the excess the ac_grid has\n",
        "        rect_power = min(dc_power_absorb,ac_power_excess)\n",
        "\n",
        "        dc_power_avail = max(dc_power_bal,0) #lol just defined a new var for readability.\n",
        "        ac_power_need   = max(-ac_power_bal-self.step_purchased[self.current_step], 0) # calculate how much power the ac grid needs.\n",
        "        dc_power_excess = max(dc_power_avail - ac_power_need - avail_stor,0) #calculate how much power would be in excess if there was to be excess.\n",
        "        #inverter power is equal to the minimum val between the avail dc power and the needed power. Then since all excess power needs to go to the grid, if there is any extra energy after the ac_need has been met and the battery is fully charged, it is also sent through the inverter\n",
        "        invt_power = min(ac_power_need, dc_power_avail) + dc_power_excess\n",
        "        #set the attributes.\n",
        "        self.step_invt[self.current_step] = invt_power\n",
        "        self.step_rect[self.current_step] = rect_power\n",
        "\n",
        "    def purchase(self):\n",
        "        self.purchase_count[self.current_step] =1\n",
        "        #fetch info from grids\n",
        "        ac_power_bal, avail_grid = self.AC_bus()\n",
        "        dc_power_bal, avail_bat, avail_stor = self.DC_bus()\n",
        "\n",
        "        if avail_grid:\n",
        "            grid_power_bal = ac_power_bal+dc_power_bal\n",
        "            #if we are grid connected purchase the max between the amount needed elec and 0\n",
        "            self.step_purchased[self.current_step] = max(-grid_power_bal + avail_stor,0)\n",
        "            #set Battery to full\n",
        "            self.battery_level[self.current_step+1] = self.bat_cap\n",
        "            #calculate and add the excess electricity generated.\n",
        "            self.excess_gen[self.current_step]= max((grid_power_bal - avail_stor), 0)\n",
        "            #only calculate it if we are actually doing anything in this function, otherwise it will get called twice if we call it here and then call standby because the grid is islanded.\n",
        "            self.calc_power_flow(dc_power_bal,ac_power_bal,avail_stor)\n",
        "        else:\n",
        "            #if the grid is not available then we can't purchase and standby can handle power flow ect\n",
        "            self.standby()\n",
        "\n",
        "\n",
        "    def tou_purchase_inc(self):\n",
        "        if self.step_purchased[self.current_step] != 0:\n",
        "            if self.purchase_price[self.current_step] == 1:\n",
        "                self.off_peak_purchases[self.current_step] = self.step_purchased[self.current_step]\n",
        "            elif self.purchase_price[self.current_step] == 2:\n",
        "                self.standard_purchases[self.current_step] = self.step_purchased[self.current_step]\n",
        "            elif self.purchase_price[self.current_step] == 3:\n",
        "                self.peak_purchases[self.current_step] = self.step_purchased[self.current_step]\n",
        "\n",
        "\n",
        "#define a pointer (kinda, don't actually know what its called) a\n",
        "EMS = EMSv1_1\n",
        "\n",
        "# Register environment so I can use make_vec_env\n",
        "register(\n",
        "# unique identifier for the env `name-version`\n",
        "id=f\"{version}\",\n",
        "# path to the class for creating the env\n",
        "# Note: entry_point also accept a class as input (and not only a string)\n",
        "entry_point= EMS(),\n",
        "\n",
        ")\n",
        "\n",
        "#Check the environment with stable_baselines3 check_env.\n",
        "from stable_baselines3.common.env_checker import check_env\n",
        "env = EMS()\n",
        "check_env(env,warn = True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DG4gB2cM7tDY"
      },
      "source": [
        "**Load in the data for our specific microgrid.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0X9RBdXC_2PD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49183a10-d25a-4b79-d197-62211f8c8e5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The reset observation space looks like: {'bat_level': array([250.], dtype=float32), 'current_power_bal': array([[-35.376823, -52.2     ]], dtype=float32), 'island_forecast': array([[1., 0., 0., 0.]], dtype=float32), 'power_bal_forecast': array([[[-60.104362, -52.      ],\n",
            "        [-55.141876, -52.2     ],\n",
            "        [-12.482445, -52.2     ]]], dtype=float32), 'price_forecast': array([[1., 1., 1., 1.]], dtype=float32)}\n",
            "Battery level is: 250.0kWh\n",
            "Current AC Power Balance -35.37682342529297, Current DC Power Balance-52.20000076293945\n",
            "Forecasted AC power 1 hour ahead: -60.10436248779297. Forecasted DC power 1 hour ahead: -52.0\n",
            "Forecasted AC power 2 hour ahead: -55.141876220703125. Forecasted DC power 2 hour ahead: -52.20000076293945\n",
            "Forecasted AC power 3 hour ahead: -12.482444763183594. Forecasted DC power 3 hour ahead: -52.20000076293945\n",
            "_________________________________________________________________________________________________________________\n",
            "\n",
            "After action 0: \n",
            "Battery level is: 162.4231719970703kWh\n",
            "Current AC Power Balance -60.10436248779297, Current DC Power Balance-52.0\n",
            "Forecasted AC power 1 hour ahead: -55.141876220703125. Forecasted DC power 1 hour ahead: -52.20000076293945\n",
            "Forecasted AC power 2 hour ahead: -12.482444763183594. Forecasted DC power 2 hour ahead: -52.20000076293945\n",
            "Forecasted AC power 3 hour ahead: 69.41790008544922. Forecasted DC power 3 hour ahead: -52.20000076293945\n",
            "The reward we recieved was -0.0\n",
            "_________________________________________________________________________________________________________________\n",
            "\n",
            "After action 0: \n",
            "Battery level is: 100.0kWh\n",
            "Current AC Power Balance -55.141876220703125, Current DC Power Balance-52.20000076293945\n",
            "Forecasted AC power 1 hour ahead: -12.482444763183594. Forecasted DC power 1 hour ahead: -52.20000076293945\n",
            "Forecasted AC power 2 hour ahead: 69.41790008544922. Forecasted DC power 2 hour ahead: -52.20000076293945\n",
            "Forecasted AC power 3 hour ahead: 141.04750061035156. Forecasted DC power 3 hour ahead: -51.5\n",
            "The reward we recieved was -49.681190490722656\n",
            "_________________________________________________________________________________________________________________\n",
            "\n",
            "After action 1 : \n",
            "Battery level is: 500.0kWh\n",
            "Current AC Power Balance -12.482444763183594, Current DC Power Balance-52.20000076293945\n",
            "Forecasted AC power 1 hour ahead: 69.41790008544922. Forecasted DC power 1 hour ahead: -52.20000076293945\n",
            "Forecasted AC power 2 hour ahead: 141.04750061035156. Forecasted DC power 2 hour ahead: -51.5\n",
            "Forecasted AC power 3 hour ahead: 286.2445068359375. Forecasted DC power 3 hour ahead: -24.50701141357422\n",
            "The reward we recieved was -507.3418731689453\n",
            "_________________________________________________________________________________________________________________\n",
            "\n",
            "Done iteration! Total reward accumulated is: -864219.8210525513\n"
          ]
        }
      ],
      "source": [
        "#need to import data from Github\n",
        "path_data = \"/content/EEE4022S_BNKJUL001_Thesis/PythonWorkspace/dataClean.csv\"\n",
        "data = pd.read_csv(path_data)\n",
        "\n",
        "path_pv_gen = \"/content/EEE4022S_BNKJUL001_Thesis/Generation/BNKJUL001_Thesis_solarGen500kWHomer.csv\"\n",
        "data_pv_gen = pd.read_csv(path_pv_gen)\n",
        "\n",
        "path_wind_gen = \"/content/EEE4022S_BNKJUL001_Thesis/Generation/BNKJUL001_Thesis_Wind500kGenHomer.csv\"\n",
        "data_wind_gen = pd.read_csv(path_wind_gen)\n",
        "\n",
        "#Not actually using this rn but will be soon :)\n",
        "path_shedding = \"/content/EEE4022S_BNKJUL001_Thesis/MatlabWorkSpace/loadShedding2022.csv\"\n",
        "data_shedding = pd.read_csv(path_shedding)\n",
        "load_shedding = data_shedding['LoadShedding'].values.astype(np.float32)\n",
        "\n",
        "wind_gen = data_wind_gen['Wind_Out'].values.astype(np.float32)\n",
        "PV_gen = data_pv_gen['PV_Out'].values.astype(np.float32)\n",
        "actual_gen = np.column_stack((wind_gen, PV_gen))\n",
        "#read in ac and DC load\n",
        "AC_load = data['AC'].values.astype(np.float32)\n",
        "DC_load = data['DC'].values.astype(np.float32)\n",
        "#stack em together for the input :)\n",
        "actual_load = np.column_stack((AC_load, DC_load))\n",
        "purchase_price = data['tou_id'].values.astype(np.float32)\n",
        "\n",
        "\n",
        "#define the base environment\n",
        "base_env = EMS(episode_len = 6000, actual_load = actual_load, actual_gen = actual_gen, bat_threshold = 100, bat_cap = 500, purchase_price = purchase_price,num_preds = 3)\n",
        "#going to print out a bunch of things to test the different spaces.\n",
        "obs,_    = base_env.reset()\n",
        "print(f\"The reset observation space looks like: {obs}\")\n",
        "battery_level = obs['bat_level']\n",
        "print(f\"Battery level is: {battery_level[0]}kWh\")\n",
        "current_power_bal = obs['current_power_bal']\n",
        "print(f\"Current AC Power Balance {current_power_bal[0,0]}, Current DC Power Balance{current_power_bal[0,1]}\")\n",
        "power_forecast = obs['power_bal_forecast']\n",
        "print(f\"Forecasted AC power 1 hour ahead: {power_forecast[0,0,0]}. Forecasted DC power 1 hour ahead: {power_forecast[0,0,1]}\")\n",
        "print(f\"Forecasted AC power 2 hour ahead: {power_forecast[0,1,0]}. Forecasted DC power 2 hour ahead: {power_forecast[0,1,1]}\")\n",
        "print(f\"Forecasted AC power 3 hour ahead: {power_forecast[0,2,0]}. Forecasted DC power 3 hour ahead: {power_forecast[0,2,1]}\")\n",
        "\n",
        "print(f\"_________________________________________________________________________________________________________________\")\n",
        "print(f\"\")\n",
        "\n",
        "\n",
        "action_standby = 0\n",
        "obs,reward,terminated,truncated,info = base_env.step(action_standby)\n",
        "print(f\"After action {action_standby}: \" )\n",
        "battery_level = obs['bat_level']\n",
        "print(f\"Battery level is: {battery_level[0]}kWh\")\n",
        "current_power_bal = obs['current_power_bal']\n",
        "print(f\"Current AC Power Balance {current_power_bal[0,0]}, Current DC Power Balance{current_power_bal[0,1]}\")\n",
        "power_forecast = obs['power_bal_forecast']\n",
        "print(f\"Forecasted AC power 1 hour ahead: {power_forecast[0,0,0]}. Forecasted DC power 1 hour ahead: {power_forecast[0,0,1]}\")\n",
        "print(f\"Forecasted AC power 2 hour ahead: {power_forecast[0,1,0]}. Forecasted DC power 2 hour ahead: {power_forecast[0,1,1]}\")\n",
        "print(f\"Forecasted AC power 3 hour ahead: {power_forecast[0,2,0]}. Forecasted DC power 3 hour ahead: {power_forecast[0,2,1]}\")\n",
        "print(f\"The reward we recieved was {reward}\")\n",
        "print(f\"_________________________________________________________________________________________________________________\")\n",
        "print(f\"\")\n",
        "action_standby = 0\n",
        "obs,reward,terminated,truncated,info = base_env.step(action_standby)\n",
        "print(f\"After action {action_standby}: \" )\n",
        "battery_level = obs['bat_level']\n",
        "print(f\"Battery level is: {battery_level[0]}kWh\")\n",
        "current_power_bal = obs['current_power_bal']\n",
        "print(f\"Current AC Power Balance {current_power_bal[0,0]}, Current DC Power Balance{current_power_bal[0,1]}\")\n",
        "power_forecast = obs['power_bal_forecast']\n",
        "print(f\"Forecasted AC power 1 hour ahead: {power_forecast[0,0,0]}. Forecasted DC power 1 hour ahead: {power_forecast[0,0,1]}\")\n",
        "print(f\"Forecasted AC power 2 hour ahead: {power_forecast[0,1,0]}. Forecasted DC power 2 hour ahead: {power_forecast[0,1,1]}\")\n",
        "print(f\"Forecasted AC power 3 hour ahead: {power_forecast[0,2,0]}. Forecasted DC power 3 hour ahead: {power_forecast[0,2,1]}\")\n",
        "print(f\"The reward we recieved was {reward}\")\n",
        "print(f\"_________________________________________________________________________________________________________________\")\n",
        "print(f\"\")\n",
        "obs,reward,terminated,truncated,info = base_env.step(1)\n",
        "print(f\"After action {1} : \" )\n",
        "battery_level = obs['bat_level']\n",
        "print(f\"Battery level is: {battery_level[0]}kWh\")\n",
        "current_power_bal = obs['current_power_bal']\n",
        "print(f\"Current AC Power Balance {current_power_bal[0,0]}, Current DC Power Balance{current_power_bal[0,1]}\")\n",
        "power_forecast = obs['power_bal_forecast']\n",
        "print(f\"Forecasted AC power 1 hour ahead: {power_forecast[0,0,0]}. Forecasted DC power 1 hour ahead: {power_forecast[0,0,1]}\")\n",
        "print(f\"Forecasted AC power 2 hour ahead: {power_forecast[0,1,0]}. Forecasted DC power 2 hour ahead: {power_forecast[0,1,1]}\")\n",
        "print(f\"Forecasted AC power 3 hour ahead: {power_forecast[0,2,0]}. Forecasted DC power 3 hour ahead: {power_forecast[0,2,1]}\")\n",
        "print(f\"The reward we recieved was {reward}\")\n",
        "print(f\"_________________________________________________________________________________________________________________\")\n",
        "print(f\"\")\n",
        "#Evaluate the base model (no EMS, just using standby mode)\n",
        "#A loop to get an average reward for the base model only perfoming the standby option\n",
        "#reset the environment and save the obs\n",
        "#going to run it 100 times to get a benchmark\n",
        "#reset score\n",
        "score = 0\n",
        "\n",
        "obs,_    = base_env.reset()\n",
        "#ensure that the exit condition is reset\n",
        "truncated = False\n",
        "#define the action to take\n",
        "action_standby = 0\n",
        "\n",
        "while not truncated:\n",
        "    obs,reward,terminated,truncated,info = base_env.step(action_standby)\n",
        "    score += reward\n",
        "\n",
        "print(f\"Done iteration! Total reward accumulated is: {score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pAj6-n04zyt"
      },
      "source": [
        "**LOAD OR MAKE MODEL HERE!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "gQDhUNGWeum4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7927f0bb-956c-4eb3-a849-49d8e222c5bf"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:lpv2ph46) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td></td></tr><tr><td>time/fps</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>10240</td></tr><tr><td>time/fps</td><td>2194.0</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">fine-rain-78</strong> at: <a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/lpv2ph46' target=\"_blank\">https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/lpv2ph46</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 2 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20231010_075714-lpv2ph46/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:lpv2ph46). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.12"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/EEE4022S_BNKJUL001_Thesis/wandb/run-20231010_075855-d2j4esv8</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/d2j4esv8' target=\"_blank\">serene-pine-79</a></strong> to <a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems' target=\"_blank\">https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/d2j4esv8' target=\"_blank\">https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/d2j4esv8</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Logging to runs/d2j4esv8/EMSv1_1_PPO_2_train20231010-075914_0\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 3305  |\n",
            "|    iterations      | 1     |\n",
            "|    time_elapsed    | 3     |\n",
            "|    total_timesteps | 10240 |\n",
            "------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 1190         |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 17           |\n",
            "|    total_timesteps      | 20480        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014111636 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.693       |\n",
            "|    explained_variance   | -1.23e-05    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.57e+06     |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -0.00114     |\n",
            "|    value_loss           | 4.15e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -9.04e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1036         |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 29           |\n",
            "|    total_timesteps      | 30720        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014472429 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.689       |\n",
            "|    explained_variance   | -0.000532    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.5e+06      |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -0.00128     |\n",
            "|    value_loss           | 9.85e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -9.04e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 984          |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 41           |\n",
            "|    total_timesteps      | 40960        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0010495742 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.688       |\n",
            "|    explained_variance   | 1.65e-05     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.34e+06     |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.00116     |\n",
            "|    value_loss           | 1.35e+07     |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 5.97e+03   |\n",
            "|    ep_rew_mean          | -9.04e+05  |\n",
            "| time/                   |            |\n",
            "|    fps                  | 938        |\n",
            "|    iterations           | 5          |\n",
            "|    time_elapsed         | 54         |\n",
            "|    total_timesteps      | 51200      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00358911 |\n",
            "|    clip_fraction        | 5.86e-05   |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.681     |\n",
            "|    explained_variance   | 5.77e-05   |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 2.11e+06   |\n",
            "|    n_updates            | 40         |\n",
            "|    policy_gradient_loss | -0.00211   |\n",
            "|    value_loss           | 4.51e+06   |\n",
            "----------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 5.97e+03      |\n",
            "|    ep_rew_mean          | -8.98e+05     |\n",
            "| time/                   |               |\n",
            "|    fps                  | 907           |\n",
            "|    iterations           | 6             |\n",
            "|    time_elapsed         | 67            |\n",
            "|    total_timesteps      | 61440         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00075394707 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.679        |\n",
            "|    explained_variance   | 6.85e-05      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 7.15e+06      |\n",
            "|    n_updates            | 50            |\n",
            "|    policy_gradient_loss | -0.00135      |\n",
            "|    value_loss           | 1.09e+07      |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 5.97e+03      |\n",
            "|    ep_rew_mean          | -8.98e+05     |\n",
            "| time/                   |               |\n",
            "|    fps                  | 886           |\n",
            "|    iterations           | 7             |\n",
            "|    time_elapsed         | 80            |\n",
            "|    total_timesteps      | 71680         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00046609426 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.675        |\n",
            "|    explained_variance   | 2.09e-06      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 4.71e+06      |\n",
            "|    n_updates            | 60            |\n",
            "|    policy_gradient_loss | -0.00139      |\n",
            "|    value_loss           | 1.11e+07      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.98e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 891          |\n",
            "|    iterations           | 8            |\n",
            "|    time_elapsed         | 91           |\n",
            "|    total_timesteps      | 81920        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013824463 |\n",
            "|    clip_fraction        | 1.95e-05     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.666       |\n",
            "|    explained_variance   | 4.33e-05     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.8e+06      |\n",
            "|    n_updates            | 70           |\n",
            "|    policy_gradient_loss | -0.00243     |\n",
            "|    value_loss           | 5.05e+06     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 5.97e+03      |\n",
            "|    ep_rew_mean          | -8.94e+05     |\n",
            "| time/                   |               |\n",
            "|    fps                  | 884           |\n",
            "|    iterations           | 9             |\n",
            "|    time_elapsed         | 104           |\n",
            "|    total_timesteps      | 92160         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00026338227 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.67         |\n",
            "|    explained_variance   | 6.08e-06      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 4.8e+06       |\n",
            "|    n_updates            | 80            |\n",
            "|    policy_gradient_loss | -0.00148      |\n",
            "|    value_loss           | 1.13e+07      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.94e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 875          |\n",
            "|    iterations           | 10           |\n",
            "|    time_elapsed         | 117          |\n",
            "|    total_timesteps      | 102400       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0005207399 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.664       |\n",
            "|    explained_variance   | 1.55e-06     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.63e+06     |\n",
            "|    n_updates            | 90           |\n",
            "|    policy_gradient_loss | -0.00192     |\n",
            "|    value_loss           | 9.64e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.94e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 840          |\n",
            "|    iterations           | 11           |\n",
            "|    time_elapsed         | 133          |\n",
            "|    total_timesteps      | 112640       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0007867234 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.656       |\n",
            "|    explained_variance   | 2.48e-05     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.27e+06     |\n",
            "|    n_updates            | 100          |\n",
            "|    policy_gradient_loss | -0.00225     |\n",
            "|    value_loss           | 4.98e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.92e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 836          |\n",
            "|    iterations           | 12           |\n",
            "|    time_elapsed         | 146          |\n",
            "|    total_timesteps      | 122880       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011019991 |\n",
            "|    clip_fraction        | 9.77e-06     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.66        |\n",
            "|    explained_variance   | 1.79e-07     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.12e+06     |\n",
            "|    n_updates            | 110          |\n",
            "|    policy_gradient_loss | -0.0028      |\n",
            "|    value_loss           | 1.2e+07      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.92e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 841          |\n",
            "|    iterations           | 13           |\n",
            "|    time_elapsed         | 158          |\n",
            "|    total_timesteps      | 133120       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0006291408 |\n",
            "|    clip_fraction        | 9.77e-06     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.643       |\n",
            "|    explained_variance   | 1.79e-07     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.74e+06     |\n",
            "|    n_updates            | 120          |\n",
            "|    policy_gradient_loss | -0.00236     |\n",
            "|    value_loss           | 8.92e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.92e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 841          |\n",
            "|    iterations           | 14           |\n",
            "|    time_elapsed         | 170          |\n",
            "|    total_timesteps      | 143360       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014037697 |\n",
            "|    clip_fraction        | 0.000234     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.638       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.91e+06     |\n",
            "|    n_updates            | 130          |\n",
            "|    policy_gradient_loss | -0.00337     |\n",
            "|    value_loss           | 5.29e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.89e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 838          |\n",
            "|    iterations           | 15           |\n",
            "|    time_elapsed         | 183          |\n",
            "|    total_timesteps      | 153600       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0005489366 |\n",
            "|    clip_fraction        | 0.000127     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.642       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.47e+06     |\n",
            "|    n_updates            | 140          |\n",
            "|    policy_gradient_loss | -0.00251     |\n",
            "|    value_loss           | 1.2e+07      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.89e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 830          |\n",
            "|    iterations           | 16           |\n",
            "|    time_elapsed         | 197          |\n",
            "|    total_timesteps      | 163840       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0007331877 |\n",
            "|    clip_fraction        | 8.79e-05     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.627       |\n",
            "|    explained_variance   | 5.36e-07     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.51e+06     |\n",
            "|    n_updates            | 150          |\n",
            "|    policy_gradient_loss | -0.00293     |\n",
            "|    value_loss           | 8.71e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.89e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 823          |\n",
            "|    iterations           | 17           |\n",
            "|    time_elapsed         | 211          |\n",
            "|    total_timesteps      | 174080       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015014063 |\n",
            "|    clip_fraction        | 0.00146      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.619       |\n",
            "|    explained_variance   | 4.35e-05     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2e+06        |\n",
            "|    n_updates            | 160          |\n",
            "|    policy_gradient_loss | -0.00428     |\n",
            "|    value_loss           | 5e+06        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.86e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 825          |\n",
            "|    iterations           | 18           |\n",
            "|    time_elapsed         | 223          |\n",
            "|    total_timesteps      | 184320       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0006543449 |\n",
            "|    clip_fraction        | 0.00041      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.626       |\n",
            "|    explained_variance   | -1.43e-06    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.67e+06     |\n",
            "|    n_updates            | 170          |\n",
            "|    policy_gradient_loss | -0.00322     |\n",
            "|    value_loss           | 1.2e+07      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.86e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 828          |\n",
            "|    iterations           | 19           |\n",
            "|    time_elapsed         | 234          |\n",
            "|    total_timesteps      | 194560       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0008070424 |\n",
            "|    clip_fraction        | 0.000898     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.608       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.75e+06     |\n",
            "|    n_updates            | 180          |\n",
            "|    policy_gradient_loss | -0.00367     |\n",
            "|    value_loss           | 8.08e+06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -8.86e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 826         |\n",
            "|    iterations           | 20          |\n",
            "|    time_elapsed         | 247         |\n",
            "|    total_timesteps      | 204800      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002315895 |\n",
            "|    clip_fraction        | 0.00301     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.592      |\n",
            "|    explained_variance   | 6.44e-06    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.43e+06    |\n",
            "|    n_updates            | 190         |\n",
            "|    policy_gradient_loss | -0.00409    |\n",
            "|    value_loss           | 5.24e+06    |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 5.97e+03      |\n",
            "|    ep_rew_mean          | -8.82e+05     |\n",
            "| time/                   |               |\n",
            "|    fps                  | 824           |\n",
            "|    iterations           | 21            |\n",
            "|    time_elapsed         | 260           |\n",
            "|    total_timesteps      | 215040        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00070834754 |\n",
            "|    clip_fraction        | 0.00083       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.599        |\n",
            "|    explained_variance   | 1.79e-07      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 5.81e+06      |\n",
            "|    n_updates            | 200           |\n",
            "|    policy_gradient_loss | -0.00304      |\n",
            "|    value_loss           | 1.18e+07      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.82e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 823          |\n",
            "|    iterations           | 22           |\n",
            "|    time_elapsed         | 273          |\n",
            "|    total_timesteps      | 225280       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0008776647 |\n",
            "|    clip_fraction        | 0.00303      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.572       |\n",
            "|    explained_variance   | 2.98e-07     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.05e+06     |\n",
            "|    n_updates            | 210          |\n",
            "|    policy_gradient_loss | -0.00403     |\n",
            "|    value_loss           | 6.9e+06      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.82e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 828          |\n",
            "|    iterations           | 23           |\n",
            "|    time_elapsed         | 284          |\n",
            "|    total_timesteps      | 235520       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017573759 |\n",
            "|    clip_fraction        | 0.00519      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.571       |\n",
            "|    explained_variance   | 1.49e-06     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.03e+06     |\n",
            "|    n_updates            | 220          |\n",
            "|    policy_gradient_loss | -0.0046      |\n",
            "|    value_loss           | 5.7e+06      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.79e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 827          |\n",
            "|    iterations           | 24           |\n",
            "|    time_elapsed         | 296          |\n",
            "|    total_timesteps      | 245760       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011924533 |\n",
            "|    clip_fraction        | 0.00284      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.582       |\n",
            "|    explained_variance   | 2.38e-07     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.72e+06     |\n",
            "|    n_updates            | 230          |\n",
            "|    policy_gradient_loss | -0.00472     |\n",
            "|    value_loss           | 1.16e+07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.79e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 827          |\n",
            "|    iterations           | 25           |\n",
            "|    time_elapsed         | 309          |\n",
            "|    total_timesteps      | 256000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023520594 |\n",
            "|    clip_fraction        | 0.0113       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.55        |\n",
            "|    explained_variance   | 5.96e-08     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.55e+06     |\n",
            "|    n_updates            | 240          |\n",
            "|    policy_gradient_loss | -0.00585     |\n",
            "|    value_loss           | 6.27e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.79e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 826          |\n",
            "|    iterations           | 26           |\n",
            "|    time_elapsed         | 322          |\n",
            "|    total_timesteps      | 266240       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013566439 |\n",
            "|    clip_fraction        | 0.00536      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.558       |\n",
            "|    explained_variance   | 1.91e-06     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.84e+06     |\n",
            "|    n_updates            | 250          |\n",
            "|    policy_gradient_loss | -0.00499     |\n",
            "|    value_loss           | 6.68e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.74e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 828          |\n",
            "|    iterations           | 27           |\n",
            "|    time_elapsed         | 333          |\n",
            "|    total_timesteps      | 276480       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011620455 |\n",
            "|    clip_fraction        | 0.00455      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.566       |\n",
            "|    explained_variance   | 1.79e-07     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.58e+06     |\n",
            "|    n_updates            | 260          |\n",
            "|    policy_gradient_loss | -0.00522     |\n",
            "|    value_loss           | 1.09e+07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.74e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 829          |\n",
            "|    iterations           | 28           |\n",
            "|    time_elapsed         | 345          |\n",
            "|    total_timesteps      | 286720       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016230397 |\n",
            "|    clip_fraction        | 0.00916      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.532       |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.13e+06     |\n",
            "|    n_updates            | 270          |\n",
            "|    policy_gradient_loss | -0.00523     |\n",
            "|    value_loss           | 5.14e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.74e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 828          |\n",
            "|    iterations           | 29           |\n",
            "|    time_elapsed         | 358          |\n",
            "|    total_timesteps      | 296960       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011012505 |\n",
            "|    clip_fraction        | 0.00583      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.55        |\n",
            "|    explained_variance   | 1.19e-07     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.99e+06     |\n",
            "|    n_updates            | 280          |\n",
            "|    policy_gradient_loss | -0.00504     |\n",
            "|    value_loss           | 7.17e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.71e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 827          |\n",
            "|    iterations           | 30           |\n",
            "|    time_elapsed         | 371          |\n",
            "|    total_timesteps      | 307200       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012845207 |\n",
            "|    clip_fraction        | 0.00349      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.559       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.7e+06      |\n",
            "|    n_updates            | 290          |\n",
            "|    policy_gradient_loss | -0.00495     |\n",
            "|    value_loss           | 1.12e+07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.71e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 828          |\n",
            "|    iterations           | 31           |\n",
            "|    time_elapsed         | 383          |\n",
            "|    total_timesteps      | 317440       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026862156 |\n",
            "|    clip_fraction        | 0.0171       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.507       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.74e+06     |\n",
            "|    n_updates            | 300          |\n",
            "|    policy_gradient_loss | -0.00636     |\n",
            "|    value_loss           | 4.86e+06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -8.71e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 830         |\n",
            "|    iterations           | 32          |\n",
            "|    time_elapsed         | 394         |\n",
            "|    total_timesteps      | 327680      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001160304 |\n",
            "|    clip_fraction        | 0.00736     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.526      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.04e+06    |\n",
            "|    n_updates            | 310         |\n",
            "|    policy_gradient_loss | -0.00438    |\n",
            "|    value_loss           | 7.3e+06     |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.68e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 829          |\n",
            "|    iterations           | 33           |\n",
            "|    time_elapsed         | 407          |\n",
            "|    total_timesteps      | 337920       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013523455 |\n",
            "|    clip_fraction        | 0.00696      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.532       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.94e+06     |\n",
            "|    n_updates            | 320          |\n",
            "|    policy_gradient_loss | -0.00539     |\n",
            "|    value_loss           | 1.1e+07      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.68e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 828          |\n",
            "|    iterations           | 34           |\n",
            "|    time_elapsed         | 419          |\n",
            "|    total_timesteps      | 348160       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019316301 |\n",
            "|    clip_fraction        | 0.0135       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.483       |\n",
            "|    explained_variance   | 5.96e-08     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.54e+06     |\n",
            "|    n_updates            | 330          |\n",
            "|    policy_gradient_loss | -0.00536     |\n",
            "|    value_loss           | 3.78e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.68e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 828          |\n",
            "|    iterations           | 35           |\n",
            "|    time_elapsed         | 432          |\n",
            "|    total_timesteps      | 358400       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027200715 |\n",
            "|    clip_fraction        | 0.0133       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.514       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.27e+06     |\n",
            "|    n_updates            | 340          |\n",
            "|    policy_gradient_loss | -0.00625     |\n",
            "|    value_loss           | 7.89e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.65e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 831          |\n",
            "|    iterations           | 36           |\n",
            "|    time_elapsed         | 443          |\n",
            "|    total_timesteps      | 368640       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013405737 |\n",
            "|    clip_fraction        | 0.00751      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.522       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.35e+06     |\n",
            "|    n_updates            | 350          |\n",
            "|    policy_gradient_loss | -0.00572     |\n",
            "|    value_loss           | 1.13e+07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.65e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 830          |\n",
            "|    iterations           | 37           |\n",
            "|    time_elapsed         | 456          |\n",
            "|    total_timesteps      | 378880       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023571372 |\n",
            "|    clip_fraction        | 0.0184       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.469       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.69e+06     |\n",
            "|    n_updates            | 360          |\n",
            "|    policy_gradient_loss | -0.00579     |\n",
            "|    value_loss           | 3.06e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.62e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 829          |\n",
            "|    iterations           | 38           |\n",
            "|    time_elapsed         | 468          |\n",
            "|    total_timesteps      | 389120       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017826215 |\n",
            "|    clip_fraction        | 0.0134       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.512       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.27e+06     |\n",
            "|    n_updates            | 370          |\n",
            "|    policy_gradient_loss | -0.00571     |\n",
            "|    value_loss           | 7.78e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.62e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 828          |\n",
            "|    iterations           | 39           |\n",
            "|    time_elapsed         | 481          |\n",
            "|    total_timesteps      | 399360       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020585698 |\n",
            "|    clip_fraction        | 0.0132       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.504       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.77e+06     |\n",
            "|    n_updates            | 380          |\n",
            "|    policy_gradient_loss | -0.00617     |\n",
            "|    value_loss           | 1.06e+07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.62e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 827          |\n",
            "|    iterations           | 40           |\n",
            "|    time_elapsed         | 495          |\n",
            "|    total_timesteps      | 409600       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027370937 |\n",
            "|    clip_fraction        | 0.0171       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.452       |\n",
            "|    explained_variance   | 5.96e-08     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.78e+06     |\n",
            "|    n_updates            | 390          |\n",
            "|    policy_gradient_loss | -0.00631     |\n",
            "|    value_loss           | 3.2e+06      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.6e+05     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 828          |\n",
            "|    iterations           | 41           |\n",
            "|    time_elapsed         | 506          |\n",
            "|    total_timesteps      | 419840       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014411155 |\n",
            "|    clip_fraction        | 0.0105       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.493       |\n",
            "|    explained_variance   | 1.79e-07     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.85e+06     |\n",
            "|    n_updates            | 400          |\n",
            "|    policy_gradient_loss | -0.00528     |\n",
            "|    value_loss           | 8.64e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.6e+05     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 827          |\n",
            "|    iterations           | 42           |\n",
            "|    time_elapsed         | 519          |\n",
            "|    total_timesteps      | 430080       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021293545 |\n",
            "|    clip_fraction        | 0.014        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.474       |\n",
            "|    explained_variance   | 1.19e-07     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.29e+06     |\n",
            "|    n_updates            | 410          |\n",
            "|    policy_gradient_loss | -0.00635     |\n",
            "|    value_loss           | 1.03e+07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.6e+05     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 827          |\n",
            "|    iterations           | 43           |\n",
            "|    time_elapsed         | 532          |\n",
            "|    total_timesteps      | 440320       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028994833 |\n",
            "|    clip_fraction        | 0.0194       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.437       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.77e+06     |\n",
            "|    n_updates            | 420          |\n",
            "|    policy_gradient_loss | -0.00678     |\n",
            "|    value_loss           | 3.54e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.57e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 825          |\n",
            "|    iterations           | 44           |\n",
            "|    time_elapsed         | 545          |\n",
            "|    total_timesteps      | 450560       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019541555 |\n",
            "|    clip_fraction        | 0.0146       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.479       |\n",
            "|    explained_variance   | 1.79e-07     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.78e+06     |\n",
            "|    n_updates            | 430          |\n",
            "|    policy_gradient_loss | -0.00618     |\n",
            "|    value_loss           | 9.23e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.57e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 812          |\n",
            "|    iterations           | 45           |\n",
            "|    time_elapsed         | 566          |\n",
            "|    total_timesteps      | 460800       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023415387 |\n",
            "|    clip_fraction        | 0.0208       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.438       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.46e+06     |\n",
            "|    n_updates            | 440          |\n",
            "|    policy_gradient_loss | -0.00595     |\n",
            "|    value_loss           | 8.3e+06      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.57e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 803          |\n",
            "|    iterations           | 46           |\n",
            "|    time_elapsed         | 586          |\n",
            "|    total_timesteps      | 471040       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037418506 |\n",
            "|    clip_fraction        | 0.0259       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.398       |\n",
            "|    explained_variance   | 5.36e-07     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.18e+06     |\n",
            "|    n_updates            | 450          |\n",
            "|    policy_gradient_loss | -0.00766     |\n",
            "|    value_loss           | 3.56e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.54e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 801          |\n",
            "|    iterations           | 47           |\n",
            "|    time_elapsed         | 600          |\n",
            "|    total_timesteps      | 481280       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020299857 |\n",
            "|    clip_fraction        | 0.0176       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.457       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.41e+06     |\n",
            "|    n_updates            | 460          |\n",
            "|    policy_gradient_loss | -0.0063      |\n",
            "|    value_loss           | 9.65e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.54e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 800          |\n",
            "|    iterations           | 48           |\n",
            "|    time_elapsed         | 613          |\n",
            "|    total_timesteps      | 491520       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025454008 |\n",
            "|    clip_fraction        | 0.0249       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.404       |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.01e+06     |\n",
            "|    n_updates            | 470          |\n",
            "|    policy_gradient_loss | -0.00805     |\n",
            "|    value_loss           | 7.16e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.54e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 800          |\n",
            "|    iterations           | 49           |\n",
            "|    time_elapsed         | 626          |\n",
            "|    total_timesteps      | 501760       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028267412 |\n",
            "|    clip_fraction        | 0.0227       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.385       |\n",
            "|    explained_variance   | 2.38e-06     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.49e+06     |\n",
            "|    n_updates            | 480          |\n",
            "|    policy_gradient_loss | -0.00739     |\n",
            "|    value_loss           | 3.75e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.52e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 801          |\n",
            "|    iterations           | 50           |\n",
            "|    time_elapsed         | 638          |\n",
            "|    total_timesteps      | 512000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024956856 |\n",
            "|    clip_fraction        | 0.0241       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.441       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.44e+06     |\n",
            "|    n_updates            | 490          |\n",
            "|    policy_gradient_loss | -0.00755     |\n",
            "|    value_loss           | 9.79e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.52e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 802          |\n",
            "|    iterations           | 51           |\n",
            "|    time_elapsed         | 650          |\n",
            "|    total_timesteps      | 522240       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024685296 |\n",
            "|    clip_fraction        | 0.0198       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.388       |\n",
            "|    explained_variance   | 5.96e-08     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.44e+06     |\n",
            "|    n_updates            | 500          |\n",
            "|    policy_gradient_loss | -0.00675     |\n",
            "|    value_loss           | 7.4e+06      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.52e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 801          |\n",
            "|    iterations           | 52           |\n",
            "|    time_elapsed         | 663          |\n",
            "|    total_timesteps      | 532480       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026853057 |\n",
            "|    clip_fraction        | 0.0234       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.379       |\n",
            "|    explained_variance   | 8.19e-05     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.67e+06     |\n",
            "|    n_updates            | 510          |\n",
            "|    policy_gradient_loss | -0.00722     |\n",
            "|    value_loss           | 3.81e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.5e+05     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 801          |\n",
            "|    iterations           | 53           |\n",
            "|    time_elapsed         | 677          |\n",
            "|    total_timesteps      | 542720       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017643806 |\n",
            "|    clip_fraction        | 0.0146       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.445       |\n",
            "|    explained_variance   | 7.93e-06     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.06e+06     |\n",
            "|    n_updates            | 520          |\n",
            "|    policy_gradient_loss | -0.0055      |\n",
            "|    value_loss           | 9.8e+06      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.5e+05     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 801          |\n",
            "|    iterations           | 54           |\n",
            "|    time_elapsed         | 689          |\n",
            "|    total_timesteps      | 552960       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027382064 |\n",
            "|    clip_fraction        | 0.0248       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.382       |\n",
            "|    explained_variance   | 2.09e-05     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.49e+06     |\n",
            "|    n_updates            | 530          |\n",
            "|    policy_gradient_loss | -0.00701     |\n",
            "|    value_loss           | 7.01e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.5e+05     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 794          |\n",
            "|    iterations           | 55           |\n",
            "|    time_elapsed         | 709          |\n",
            "|    total_timesteps      | 563200       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024751495 |\n",
            "|    clip_fraction        | 0.0235       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.378       |\n",
            "|    explained_variance   | 0.00047      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.61e+06     |\n",
            "|    n_updates            | 540          |\n",
            "|    policy_gradient_loss | -0.00598     |\n",
            "|    value_loss           | 4.07e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.47e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 794          |\n",
            "|    iterations           | 56           |\n",
            "|    time_elapsed         | 722          |\n",
            "|    total_timesteps      | 573440       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022093195 |\n",
            "|    clip_fraction        | 0.0194       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.435       |\n",
            "|    explained_variance   | 1.59e-05     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.99e+06     |\n",
            "|    n_updates            | 550          |\n",
            "|    policy_gradient_loss | -0.00713     |\n",
            "|    value_loss           | 9.72e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.47e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 795          |\n",
            "|    iterations           | 57           |\n",
            "|    time_elapsed         | 733          |\n",
            "|    total_timesteps      | 583680       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025357646 |\n",
            "|    clip_fraction        | 0.0254       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.36        |\n",
            "|    explained_variance   | 3.39e-05     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.07e+06     |\n",
            "|    n_updates            | 560          |\n",
            "|    policy_gradient_loss | -0.00604     |\n",
            "|    value_loss           | 5.69e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.47e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 796          |\n",
            "|    iterations           | 58           |\n",
            "|    time_elapsed         | 745          |\n",
            "|    total_timesteps      | 593920       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028246567 |\n",
            "|    clip_fraction        | 0.0256       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.379       |\n",
            "|    explained_variance   | 0.000439     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.04e+06     |\n",
            "|    n_updates            | 570          |\n",
            "|    policy_gradient_loss | -0.00647     |\n",
            "|    value_loss           | 4.61e+06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -8.45e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 796         |\n",
            "|    iterations           | 59          |\n",
            "|    time_elapsed         | 758         |\n",
            "|    total_timesteps      | 604160      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001933237 |\n",
            "|    clip_fraction        | 0.0169      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.419      |\n",
            "|    explained_variance   | 7.13e-05    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.38e+06    |\n",
            "|    n_updates            | 580         |\n",
            "|    policy_gradient_loss | -0.00565    |\n",
            "|    value_loss           | 9.39e+06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.45e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 796          |\n",
            "|    iterations           | 60           |\n",
            "|    time_elapsed         | 771          |\n",
            "|    total_timesteps      | 614400       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027893982 |\n",
            "|    clip_fraction        | 0.0259       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.337       |\n",
            "|    explained_variance   | 0.000186     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.81e+06     |\n",
            "|    n_updates            | 590          |\n",
            "|    policy_gradient_loss | -0.00616     |\n",
            "|    value_loss           | 5.36e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.45e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 797          |\n",
            "|    iterations           | 61           |\n",
            "|    time_elapsed         | 782          |\n",
            "|    total_timesteps      | 624640       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022956985 |\n",
            "|    clip_fraction        | 0.0204       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.383       |\n",
            "|    explained_variance   | 0.000669     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.63e+06     |\n",
            "|    n_updates            | 600          |\n",
            "|    policy_gradient_loss | -0.00519     |\n",
            "|    value_loss           | 5.47e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.4e+05     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 798          |\n",
            "|    iterations           | 62           |\n",
            "|    time_elapsed         | 794          |\n",
            "|    total_timesteps      | 634880       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022061188 |\n",
            "|    clip_fraction        | 0.0184       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.406       |\n",
            "|    explained_variance   | 2.03e-05     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.91e+06     |\n",
            "|    n_updates            | 610          |\n",
            "|    policy_gradient_loss | -0.00652     |\n",
            "|    value_loss           | 9.44e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.4e+05     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 798          |\n",
            "|    iterations           | 63           |\n",
            "|    time_elapsed         | 808          |\n",
            "|    total_timesteps      | 645120       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022264267 |\n",
            "|    clip_fraction        | 0.0221       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.324       |\n",
            "|    explained_variance   | 0.000219     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.68e+06     |\n",
            "|    n_updates            | 620          |\n",
            "|    policy_gradient_loss | -0.00569     |\n",
            "|    value_loss           | 4.46e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.4e+05     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 798          |\n",
            "|    iterations           | 64           |\n",
            "|    time_elapsed         | 820          |\n",
            "|    total_timesteps      | 655360       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023877062 |\n",
            "|    clip_fraction        | 0.0234       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.382       |\n",
            "|    explained_variance   | 0.0015       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.99e+06     |\n",
            "|    n_updates            | 630          |\n",
            "|    policy_gradient_loss | -0.00648     |\n",
            "|    value_loss           | 5.97e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.35e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 798          |\n",
            "|    iterations           | 65           |\n",
            "|    time_elapsed         | 833          |\n",
            "|    total_timesteps      | 665600       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021090813 |\n",
            "|    clip_fraction        | 0.0192       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.409       |\n",
            "|    explained_variance   | 0.00041      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.12e+06     |\n",
            "|    n_updates            | 640          |\n",
            "|    policy_gradient_loss | -0.00565     |\n",
            "|    value_loss           | 9.88e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.35e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 800          |\n",
            "|    iterations           | 66           |\n",
            "|    time_elapsed         | 844          |\n",
            "|    total_timesteps      | 675840       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023256682 |\n",
            "|    clip_fraction        | 0.0257       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.313       |\n",
            "|    explained_variance   | 0.000731     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.06e+06     |\n",
            "|    n_updates            | 650          |\n",
            "|    policy_gradient_loss | -0.00668     |\n",
            "|    value_loss           | 3.84e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.35e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 800          |\n",
            "|    iterations           | 67           |\n",
            "|    time_elapsed         | 857          |\n",
            "|    total_timesteps      | 686080       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023008627 |\n",
            "|    clip_fraction        | 0.0193       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.381       |\n",
            "|    explained_variance   | 0.00612      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.71e+06     |\n",
            "|    n_updates            | 660          |\n",
            "|    policy_gradient_loss | -0.00646     |\n",
            "|    value_loss           | 5.97e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.31e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 800          |\n",
            "|    iterations           | 68           |\n",
            "|    time_elapsed         | 869          |\n",
            "|    total_timesteps      | 696320       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021148901 |\n",
            "|    clip_fraction        | 0.0225       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.402       |\n",
            "|    explained_variance   | 0.00119      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.85e+06     |\n",
            "|    n_updates            | 670          |\n",
            "|    policy_gradient_loss | -0.00648     |\n",
            "|    value_loss           | 9.35e+06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -8.31e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 800         |\n",
            "|    iterations           | 69          |\n",
            "|    time_elapsed         | 882         |\n",
            "|    total_timesteps      | 706560      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002275853 |\n",
            "|    clip_fraction        | 0.0216      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.307      |\n",
            "|    explained_variance   | 0.000603    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.19e+06    |\n",
            "|    n_updates            | 680         |\n",
            "|    policy_gradient_loss | -0.00707    |\n",
            "|    value_loss           | 3.17e+06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.31e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 801          |\n",
            "|    iterations           | 70           |\n",
            "|    time_elapsed         | 894          |\n",
            "|    total_timesteps      | 716800       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026066597 |\n",
            "|    clip_fraction        | 0.0232       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.385       |\n",
            "|    explained_variance   | 0.00975      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.6e+06      |\n",
            "|    n_updates            | 690          |\n",
            "|    policy_gradient_loss | -0.00725     |\n",
            "|    value_loss           | 6.65e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.27e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 802          |\n",
            "|    iterations           | 71           |\n",
            "|    time_elapsed         | 906          |\n",
            "|    total_timesteps      | 727040       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015234262 |\n",
            "|    clip_fraction        | 0.0152       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.405       |\n",
            "|    explained_variance   | 0.000313     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.31e+06     |\n",
            "|    n_updates            | 700          |\n",
            "|    policy_gradient_loss | -0.00519     |\n",
            "|    value_loss           | 1.02e+07     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.27e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 801          |\n",
            "|    iterations           | 72           |\n",
            "|    time_elapsed         | 919          |\n",
            "|    total_timesteps      | 737280       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028663024 |\n",
            "|    clip_fraction        | 0.0258       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.292       |\n",
            "|    explained_variance   | 0.000227     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.28e+06     |\n",
            "|    n_updates            | 710          |\n",
            "|    policy_gradient_loss | -0.00523     |\n",
            "|    value_loss           | 2.38e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.22e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 801          |\n",
            "|    iterations           | 73           |\n",
            "|    time_elapsed         | 932          |\n",
            "|    total_timesteps      | 747520       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027953684 |\n",
            "|    clip_fraction        | 0.0258       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.392       |\n",
            "|    explained_variance   | 0.00869      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.95e+06     |\n",
            "|    n_updates            | 720          |\n",
            "|    policy_gradient_loss | -0.00706     |\n",
            "|    value_loss           | 6.35e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.22e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 801          |\n",
            "|    iterations           | 74           |\n",
            "|    time_elapsed         | 945          |\n",
            "|    total_timesteps      | 757760       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023491015 |\n",
            "|    clip_fraction        | 0.018        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.382       |\n",
            "|    explained_variance   | 0.00259      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.1e+06      |\n",
            "|    n_updates            | 730          |\n",
            "|    policy_gradient_loss | -0.00586     |\n",
            "|    value_loss           | 9.19e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.22e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 802          |\n",
            "|    iterations           | 75           |\n",
            "|    time_elapsed         | 956          |\n",
            "|    total_timesteps      | 768000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033008675 |\n",
            "|    clip_fraction        | 0.0297       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.304       |\n",
            "|    explained_variance   | 0.0154       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.64e+06     |\n",
            "|    n_updates            | 740          |\n",
            "|    policy_gradient_loss | -0.00603     |\n",
            "|    value_loss           | 2.55e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.18e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 802          |\n",
            "|    iterations           | 76           |\n",
            "|    time_elapsed         | 969          |\n",
            "|    total_timesteps      | 778240       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027505397 |\n",
            "|    clip_fraction        | 0.0247       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.396       |\n",
            "|    explained_variance   | 0.00617      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.7e+06      |\n",
            "|    n_updates            | 750          |\n",
            "|    policy_gradient_loss | -0.0067      |\n",
            "|    value_loss           | 7.33e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.18e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 802          |\n",
            "|    iterations           | 77           |\n",
            "|    time_elapsed         | 982          |\n",
            "|    total_timesteps      | 788480       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027149247 |\n",
            "|    clip_fraction        | 0.0226       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.355       |\n",
            "|    explained_variance   | 0.00468      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.94e+06     |\n",
            "|    n_updates            | 760          |\n",
            "|    policy_gradient_loss | -0.00652     |\n",
            "|    value_loss           | 8.34e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.18e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 802          |\n",
            "|    iterations           | 78           |\n",
            "|    time_elapsed         | 994          |\n",
            "|    total_timesteps      | 798720       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028867004 |\n",
            "|    clip_fraction        | 0.0217       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.307       |\n",
            "|    explained_variance   | 0.0221       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.49e+06     |\n",
            "|    n_updates            | 770          |\n",
            "|    policy_gradient_loss | -0.00631     |\n",
            "|    value_loss           | 2.78e+06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -8.15e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 803         |\n",
            "|    iterations           | 79          |\n",
            "|    time_elapsed         | 1007        |\n",
            "|    total_timesteps      | 808960      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002810598 |\n",
            "|    clip_fraction        | 0.0201      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.397      |\n",
            "|    explained_variance   | 0.00502     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.57e+06    |\n",
            "|    n_updates            | 780         |\n",
            "|    policy_gradient_loss | -0.00618    |\n",
            "|    value_loss           | 7.91e+06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.15e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 804          |\n",
            "|    iterations           | 80           |\n",
            "|    time_elapsed         | 1018         |\n",
            "|    total_timesteps      | 819200       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023363754 |\n",
            "|    clip_fraction        | 0.0181       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.346       |\n",
            "|    explained_variance   | 0.0119       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.96e+06     |\n",
            "|    n_updates            | 790          |\n",
            "|    policy_gradient_loss | -0.00546     |\n",
            "|    value_loss           | 7.17e+06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -8.15e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 803         |\n",
            "|    iterations           | 81          |\n",
            "|    time_elapsed         | 1031        |\n",
            "|    total_timesteps      | 829440      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002801469 |\n",
            "|    clip_fraction        | 0.0203      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.3        |\n",
            "|    explained_variance   | 0.0308      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.51e+06    |\n",
            "|    n_updates            | 800         |\n",
            "|    policy_gradient_loss | -0.00542    |\n",
            "|    value_loss           | 2.83e+06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.12e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 803          |\n",
            "|    iterations           | 82           |\n",
            "|    time_elapsed         | 1044         |\n",
            "|    total_timesteps      | 839680       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027877805 |\n",
            "|    clip_fraction        | 0.0299       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.396       |\n",
            "|    explained_variance   | 0.00497      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.13e+06     |\n",
            "|    n_updates            | 810          |\n",
            "|    policy_gradient_loss | -0.0069      |\n",
            "|    value_loss           | 8.25e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.12e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 803          |\n",
            "|    iterations           | 83           |\n",
            "|    time_elapsed         | 1057         |\n",
            "|    total_timesteps      | 849920       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020026085 |\n",
            "|    clip_fraction        | 0.0188       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.317       |\n",
            "|    explained_variance   | 0.0184       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.29e+06     |\n",
            "|    n_updates            | 820          |\n",
            "|    policy_gradient_loss | -0.00503     |\n",
            "|    value_loss           | 6.61e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.12e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 800          |\n",
            "|    iterations           | 84           |\n",
            "|    time_elapsed         | 1074         |\n",
            "|    total_timesteps      | 860160       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029666629 |\n",
            "|    clip_fraction        | 0.0214       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.297       |\n",
            "|    explained_variance   | 0.0393       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.41e+06     |\n",
            "|    n_updates            | 830          |\n",
            "|    policy_gradient_loss | -0.00556     |\n",
            "|    value_loss           | 3.16e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.09e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 800          |\n",
            "|    iterations           | 85           |\n",
            "|    time_elapsed         | 1087         |\n",
            "|    total_timesteps      | 870400       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025695816 |\n",
            "|    clip_fraction        | 0.0238       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.38        |\n",
            "|    explained_variance   | 0.00575      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.11e+06     |\n",
            "|    n_updates            | 840          |\n",
            "|    policy_gradient_loss | -0.00608     |\n",
            "|    value_loss           | 8.52e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.09e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 801          |\n",
            "|    iterations           | 86           |\n",
            "|    time_elapsed         | 1098         |\n",
            "|    total_timesteps      | 880640       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025588083 |\n",
            "|    clip_fraction        | 0.021        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.304       |\n",
            "|    explained_variance   | 0.0199       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.55e+06     |\n",
            "|    n_updates            | 850          |\n",
            "|    policy_gradient_loss | -0.00584     |\n",
            "|    value_loss           | 6.49e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.09e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 801          |\n",
            "|    iterations           | 87           |\n",
            "|    time_elapsed         | 1111         |\n",
            "|    total_timesteps      | 890880       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032576062 |\n",
            "|    clip_fraction        | 0.0255       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.291       |\n",
            "|    explained_variance   | 0.0479       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.14e+06     |\n",
            "|    n_updates            | 860          |\n",
            "|    policy_gradient_loss | -0.00552     |\n",
            "|    value_loss           | 3.1e+06      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.07e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 801          |\n",
            "|    iterations           | 88           |\n",
            "|    time_elapsed         | 1124         |\n",
            "|    total_timesteps      | 901120       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026930217 |\n",
            "|    clip_fraction        | 0.0265       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.379       |\n",
            "|    explained_variance   | 0.00821      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.9e+06      |\n",
            "|    n_updates            | 870          |\n",
            "|    policy_gradient_loss | -0.00734     |\n",
            "|    value_loss           | 8.5e+06      |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -8.07e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 801         |\n",
            "|    iterations           | 89          |\n",
            "|    time_elapsed         | 1137        |\n",
            "|    total_timesteps      | 911360      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002783597 |\n",
            "|    clip_fraction        | 0.0272      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.303      |\n",
            "|    explained_variance   | 0.0493      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.97e+06    |\n",
            "|    n_updates            | 880         |\n",
            "|    policy_gradient_loss | -0.00514    |\n",
            "|    value_loss           | 5.98e+06    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -8.07e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 801         |\n",
            "|    iterations           | 90          |\n",
            "|    time_elapsed         | 1149        |\n",
            "|    total_timesteps      | 921600      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003216271 |\n",
            "|    clip_fraction        | 0.0263      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.297      |\n",
            "|    explained_variance   | 0.0606      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.67e+06    |\n",
            "|    n_updates            | 890         |\n",
            "|    policy_gradient_loss | -0.00471    |\n",
            "|    value_loss           | 3.39e+06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.05e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 802          |\n",
            "|    iterations           | 91           |\n",
            "|    time_elapsed         | 1161         |\n",
            "|    total_timesteps      | 931840       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026081863 |\n",
            "|    clip_fraction        | 0.0228       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.373       |\n",
            "|    explained_variance   | 0.00846      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.46e+06     |\n",
            "|    n_updates            | 900          |\n",
            "|    policy_gradient_loss | -0.00686     |\n",
            "|    value_loss           | 8.5e+06      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.05e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 800          |\n",
            "|    iterations           | 92           |\n",
            "|    time_elapsed         | 1176         |\n",
            "|    total_timesteps      | 942080       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027460272 |\n",
            "|    clip_fraction        | 0.0226       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.284       |\n",
            "|    explained_variance   | 0.0493       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.69e+06     |\n",
            "|    n_updates            | 910          |\n",
            "|    policy_gradient_loss | -0.00507     |\n",
            "|    value_loss           | 5.38e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.05e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 794          |\n",
            "|    iterations           | 93           |\n",
            "|    time_elapsed         | 1198         |\n",
            "|    total_timesteps      | 952320       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029780497 |\n",
            "|    clip_fraction        | 0.0323       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.318       |\n",
            "|    explained_variance   | 0.0467       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.33e+06     |\n",
            "|    n_updates            | 920          |\n",
            "|    policy_gradient_loss | -0.00629     |\n",
            "|    value_loss           | 3.78e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.03e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 791          |\n",
            "|    iterations           | 94           |\n",
            "|    time_elapsed         | 1215         |\n",
            "|    total_timesteps      | 962560       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020192403 |\n",
            "|    clip_fraction        | 0.0202       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.37        |\n",
            "|    explained_variance   | 0.00885      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.09e+06     |\n",
            "|    n_updates            | 930          |\n",
            "|    policy_gradient_loss | -0.00588     |\n",
            "|    value_loss           | 8.56e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8.03e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 786          |\n",
            "|    iterations           | 95           |\n",
            "|    time_elapsed         | 1236         |\n",
            "|    total_timesteps      | 972800       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019115343 |\n",
            "|    clip_fraction        | 0.0181       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.268       |\n",
            "|    explained_variance   | 0.0632       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.08e+06     |\n",
            "|    n_updates            | 940          |\n",
            "|    policy_gradient_loss | -0.00393     |\n",
            "|    value_loss           | 4.5e+06      |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -8.03e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 783         |\n",
            "|    iterations           | 96          |\n",
            "|    time_elapsed         | 1255        |\n",
            "|    total_timesteps      | 983040      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002771246 |\n",
            "|    clip_fraction        | 0.0241      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.34       |\n",
            "|    explained_variance   | 0.0431      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.15e+06    |\n",
            "|    n_updates            | 950         |\n",
            "|    policy_gradient_loss | -0.00581    |\n",
            "|    value_loss           | 4.58e+06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8e+05       |\n",
            "| time/                   |              |\n",
            "|    fps                  | 781          |\n",
            "|    iterations           | 97           |\n",
            "|    time_elapsed         | 1270         |\n",
            "|    total_timesteps      | 993280       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029313038 |\n",
            "|    clip_fraction        | 0.0276       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.363       |\n",
            "|    explained_variance   | 0.00846      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.46e+06     |\n",
            "|    n_updates            | 960          |\n",
            "|    policy_gradient_loss | -0.00661     |\n",
            "|    value_loss           | 8e+06        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -8e+05      |\n",
            "| time/                   |             |\n",
            "|    fps                  | 781         |\n",
            "|    iterations           | 98          |\n",
            "|    time_elapsed         | 1284        |\n",
            "|    total_timesteps      | 1003520     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002348257 |\n",
            "|    clip_fraction        | 0.0165      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.256      |\n",
            "|    explained_variance   | 0.069       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.09e+06    |\n",
            "|    n_updates            | 970         |\n",
            "|    policy_gradient_loss | -0.00444    |\n",
            "|    value_loss           | 3.75e+06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -8e+05       |\n",
            "| time/                   |              |\n",
            "|    fps                  | 781          |\n",
            "|    iterations           | 99           |\n",
            "|    time_elapsed         | 1297         |\n",
            "|    total_timesteps      | 1013760      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034410418 |\n",
            "|    clip_fraction        | 0.0311       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.335       |\n",
            "|    explained_variance   | 0.0431       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.85e+06     |\n",
            "|    n_updates            | 980          |\n",
            "|    policy_gradient_loss | -0.00649     |\n",
            "|    value_loss           | 5.03e+06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -7.98e+05   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 781         |\n",
            "|    iterations           | 100         |\n",
            "|    time_elapsed         | 1309        |\n",
            "|    total_timesteps      | 1024000     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003016683 |\n",
            "|    clip_fraction        | 0.0237      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.358      |\n",
            "|    explained_variance   | 0.0157      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.99e+06    |\n",
            "|    n_updates            | 990         |\n",
            "|    policy_gradient_loss | -0.00641    |\n",
            "|    value_loss           | 8.56e+06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -7.98e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 781          |\n",
            "|    iterations           | 101          |\n",
            "|    time_elapsed         | 1322         |\n",
            "|    total_timesteps      | 1034240      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022528425 |\n",
            "|    clip_fraction        | 0.0208       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.237       |\n",
            "|    explained_variance   | 0.0562       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.43e+06     |\n",
            "|    n_updates            | 1000         |\n",
            "|    policy_gradient_loss | -0.00421     |\n",
            "|    value_loss           | 3.23e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -7.98e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 779          |\n",
            "|    iterations           | 102          |\n",
            "|    time_elapsed         | 1340         |\n",
            "|    total_timesteps      | 1044480      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034212111 |\n",
            "|    clip_fraction        | 0.0331       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.332       |\n",
            "|    explained_variance   | 0.0263       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.41e+06     |\n",
            "|    n_updates            | 1010         |\n",
            "|    policy_gradient_loss | -0.00573     |\n",
            "|    value_loss           | 5.07e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -7.97e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 779          |\n",
            "|    iterations           | 103          |\n",
            "|    time_elapsed         | 1353         |\n",
            "|    total_timesteps      | 1054720      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026119275 |\n",
            "|    clip_fraction        | 0.0251       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.362       |\n",
            "|    explained_variance   | 0.0147       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.64e+06     |\n",
            "|    n_updates            | 1020         |\n",
            "|    policy_gradient_loss | -0.00599     |\n",
            "|    value_loss           | 8.91e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -7.97e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 779          |\n",
            "|    iterations           | 104          |\n",
            "|    time_elapsed         | 1366         |\n",
            "|    total_timesteps      | 1064960      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023681049 |\n",
            "|    clip_fraction        | 0.0189       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.24        |\n",
            "|    explained_variance   | 0.0452       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.71e+06     |\n",
            "|    n_updates            | 1030         |\n",
            "|    policy_gradient_loss | -0.00506     |\n",
            "|    value_loss           | 2.91e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -7.97e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 779          |\n",
            "|    iterations           | 105          |\n",
            "|    time_elapsed         | 1380         |\n",
            "|    total_timesteps      | 1075200      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035963743 |\n",
            "|    clip_fraction        | 0.0279       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.341       |\n",
            "|    explained_variance   | 0.0287       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.13e+06     |\n",
            "|    n_updates            | 1040         |\n",
            "|    policy_gradient_loss | -0.00595     |\n",
            "|    value_loss           | 5.78e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -7.96e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 774          |\n",
            "|    iterations           | 106          |\n",
            "|    time_elapsed         | 1402         |\n",
            "|    total_timesteps      | 1085440      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023748032 |\n",
            "|    clip_fraction        | 0.0242       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.367       |\n",
            "|    explained_variance   | 0.0143       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.96e+06     |\n",
            "|    n_updates            | 1050         |\n",
            "|    policy_gradient_loss | -0.00542     |\n",
            "|    value_loss           | 9.27e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -7.96e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 766          |\n",
            "|    iterations           | 107          |\n",
            "|    time_elapsed         | 1429         |\n",
            "|    total_timesteps      | 1095680      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029309406 |\n",
            "|    clip_fraction        | 0.0213       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.229       |\n",
            "|    explained_variance   | 0.0543       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.17e+05     |\n",
            "|    n_updates            | 1060         |\n",
            "|    policy_gradient_loss | -0.00425     |\n",
            "|    value_loss           | 1.92e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -7.95e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 766          |\n",
            "|    iterations           | 108          |\n",
            "|    time_elapsed         | 1443         |\n",
            "|    total_timesteps      | 1105920      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032405346 |\n",
            "|    clip_fraction        | 0.0288       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.344       |\n",
            "|    explained_variance   | 0.0186       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.7e+06      |\n",
            "|    n_updates            | 1070         |\n",
            "|    policy_gradient_loss | -0.00671     |\n",
            "|    value_loss           | 5.57e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -7.95e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 766          |\n",
            "|    iterations           | 109          |\n",
            "|    time_elapsed         | 1456         |\n",
            "|    total_timesteps      | 1116160      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025507305 |\n",
            "|    clip_fraction        | 0.0212       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.339       |\n",
            "|    explained_variance   | 0.0351       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.37e+06     |\n",
            "|    n_updates            | 1080         |\n",
            "|    policy_gradient_loss | -0.00587     |\n",
            "|    value_loss           | 9.26e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -7.95e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 766          |\n",
            "|    iterations           | 110          |\n",
            "|    time_elapsed         | 1469         |\n",
            "|    total_timesteps      | 1126400      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020420565 |\n",
            "|    clip_fraction        | 0.0166       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.237       |\n",
            "|    explained_variance   | 0.0961       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.06e+05     |\n",
            "|    n_updates            | 1090         |\n",
            "|    policy_gradient_loss | -0.00486     |\n",
            "|    value_loss           | 2.07e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -7.94e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 766          |\n",
            "|    iterations           | 111          |\n",
            "|    time_elapsed         | 1482         |\n",
            "|    total_timesteps      | 1136640      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026751165 |\n",
            "|    clip_fraction        | 0.0244       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.357       |\n",
            "|    explained_variance   | 0.0155       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.59e+06     |\n",
            "|    n_updates            | 1100         |\n",
            "|    policy_gradient_loss | -0.00533     |\n",
            "|    value_loss           | 6.51e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -7.94e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 766          |\n",
            "|    iterations           | 112          |\n",
            "|    time_elapsed         | 1496         |\n",
            "|    total_timesteps      | 1146880      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023931498 |\n",
            "|    clip_fraction        | 0.0232       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.322       |\n",
            "|    explained_variance   | 0.0382       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.32e+06     |\n",
            "|    n_updates            | 1110         |\n",
            "|    policy_gradient_loss | -0.0055      |\n",
            "|    value_loss           | 7.62e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -7.94e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 767          |\n",
            "|    iterations           | 113          |\n",
            "|    time_elapsed         | 1508         |\n",
            "|    total_timesteps      | 1157120      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022717514 |\n",
            "|    clip_fraction        | 0.0182       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.251       |\n",
            "|    explained_variance   | 0.11         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.87e+05     |\n",
            "|    n_updates            | 1120         |\n",
            "|    policy_gradient_loss | -0.00515     |\n",
            "|    value_loss           | 2.32e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -7.92e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 767          |\n",
            "|    iterations           | 114          |\n",
            "|    time_elapsed         | 1521         |\n",
            "|    total_timesteps      | 1167360      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037088855 |\n",
            "|    clip_fraction        | 0.0304       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.365       |\n",
            "|    explained_variance   | 0.0128       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.53e+06     |\n",
            "|    n_updates            | 1130         |\n",
            "|    policy_gradient_loss | -0.00661     |\n",
            "|    value_loss           | 6.97e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -7.92e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 767          |\n",
            "|    iterations           | 115          |\n",
            "|    time_elapsed         | 1534         |\n",
            "|    total_timesteps      | 1177600      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025714852 |\n",
            "|    clip_fraction        | 0.0225       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.307       |\n",
            "|    explained_variance   | 0.0539       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.48e+06     |\n",
            "|    n_updates            | 1140         |\n",
            "|    policy_gradient_loss | -0.00491     |\n",
            "|    value_loss           | 6.62e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -7.92e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 767          |\n",
            "|    iterations           | 116          |\n",
            "|    time_elapsed         | 1546         |\n",
            "|    total_timesteps      | 1187840      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019436211 |\n",
            "|    clip_fraction        | 0.017        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.251       |\n",
            "|    explained_variance   | 0.124        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.25e+06     |\n",
            "|    n_updates            | 1150         |\n",
            "|    policy_gradient_loss | -0.00491     |\n",
            "|    value_loss           | 2.51e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -7.92e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 768          |\n",
            "|    iterations           | 117          |\n",
            "|    time_elapsed         | 1559         |\n",
            "|    total_timesteps      | 1198080      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033987842 |\n",
            "|    clip_fraction        | 0.0292       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.371       |\n",
            "|    explained_variance   | 0.0155       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.51e+06     |\n",
            "|    n_updates            | 1160         |\n",
            "|    policy_gradient_loss | -0.00651     |\n",
            "|    value_loss           | 7.68e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -7.92e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 769          |\n",
            "|    iterations           | 118          |\n",
            "|    time_elapsed         | 1570         |\n",
            "|    total_timesteps      | 1208320      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027613244 |\n",
            "|    clip_fraction        | 0.0206       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.282       |\n",
            "|    explained_variance   | 0.0756       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.92e+06     |\n",
            "|    n_updates            | 1170         |\n",
            "|    policy_gradient_loss | -0.00497     |\n",
            "|    value_loss           | 5.97e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -7.92e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 769          |\n",
            "|    iterations           | 119          |\n",
            "|    time_elapsed         | 1582         |\n",
            "|    total_timesteps      | 1218560      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025218439 |\n",
            "|    clip_fraction        | 0.0199       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.263       |\n",
            "|    explained_variance   | 0.115        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.44e+06     |\n",
            "|    n_updates            | 1180         |\n",
            "|    policy_gradient_loss | -0.00567     |\n",
            "|    value_loss           | 2.71e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -7.91e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 769          |\n",
            "|    iterations           | 120          |\n",
            "|    time_elapsed         | 1595         |\n",
            "|    total_timesteps      | 1228800      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022796493 |\n",
            "|    clip_fraction        | 0.0201       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.362       |\n",
            "|    explained_variance   | 0.0158       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.39e+06     |\n",
            "|    n_updates            | 1190         |\n",
            "|    policy_gradient_loss | -0.00634     |\n",
            "|    value_loss           | 7.53e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -7.91e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 769          |\n",
            "|    iterations           | 121          |\n",
            "|    time_elapsed         | 1610         |\n",
            "|    total_timesteps      | 1239040      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024971068 |\n",
            "|    clip_fraction        | 0.021        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.281       |\n",
            "|    explained_variance   | 0.0745       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.25e+06     |\n",
            "|    n_updates            | 1200         |\n",
            "|    policy_gradient_loss | -0.0042      |\n",
            "|    value_loss           | 5.79e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -7.91e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 764          |\n",
            "|    iterations           | 122          |\n",
            "|    time_elapsed         | 1633         |\n",
            "|    total_timesteps      | 1249280      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029329143 |\n",
            "|    clip_fraction        | 0.0212       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.263       |\n",
            "|    explained_variance   | 0.129        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.55e+05     |\n",
            "|    n_updates            | 1210         |\n",
            "|    policy_gradient_loss | -0.00497     |\n",
            "|    value_loss           | 2.62e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -7.9e+05     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 762          |\n",
            "|    iterations           | 123          |\n",
            "|    time_elapsed         | 1652         |\n",
            "|    total_timesteps      | 1259520      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026928436 |\n",
            "|    clip_fraction        | 0.027        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.367       |\n",
            "|    explained_variance   | 0.0234       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.93e+06     |\n",
            "|    n_updates            | 1220         |\n",
            "|    policy_gradient_loss | -0.00615     |\n",
            "|    value_loss           | 7.68e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -7.9e+05     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 758          |\n",
            "|    iterations           | 124          |\n",
            "|    time_elapsed         | 1674         |\n",
            "|    total_timesteps      | 1269760      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019984616 |\n",
            "|    clip_fraction        | 0.0184       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.285       |\n",
            "|    explained_variance   | 0.114        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.54e+06     |\n",
            "|    n_updates            | 1230         |\n",
            "|    policy_gradient_loss | -0.00537     |\n",
            "|    value_loss           | 5.38e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -7.9e+05     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 758          |\n",
            "|    iterations           | 125          |\n",
            "|    time_elapsed         | 1686         |\n",
            "|    total_timesteps      | 1280000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027334294 |\n",
            "|    clip_fraction        | 0.0223       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.27        |\n",
            "|    explained_variance   | 0.137        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.68e+06     |\n",
            "|    n_updates            | 1240         |\n",
            "|    policy_gradient_loss | -0.00426     |\n",
            "|    value_loss           | 2.87e+06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -7.9e+05    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 757         |\n",
            "|    iterations           | 126         |\n",
            "|    time_elapsed         | 1704        |\n",
            "|    total_timesteps      | 1290240     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003194182 |\n",
            "|    clip_fraction        | 0.033       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.361      |\n",
            "|    explained_variance   | 0.0249      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.23e+06    |\n",
            "|    n_updates            | 1250        |\n",
            "|    policy_gradient_loss | -0.00704    |\n",
            "|    value_loss           | 7.54e+06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -7.9e+05     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 754          |\n",
            "|    iterations           | 127          |\n",
            "|    time_elapsed         | 1723         |\n",
            "|    total_timesteps      | 1300480      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021194376 |\n",
            "|    clip_fraction        | 0.017        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.264       |\n",
            "|    explained_variance   | 0.112        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.72e+06     |\n",
            "|    n_updates            | 1260         |\n",
            "|    policy_gradient_loss | -0.00449     |\n",
            "|    value_loss           | 4.74e+06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -7.9e+05    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 754         |\n",
            "|    iterations           | 128         |\n",
            "|    time_elapsed         | 1736        |\n",
            "|    total_timesteps      | 1310720     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004183881 |\n",
            "|    clip_fraction        | 0.0307      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.291      |\n",
            "|    explained_variance   | 0.113       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.81e+06    |\n",
            "|    n_updates            | 1270        |\n",
            "|    policy_gradient_loss | -0.00554    |\n",
            "|    value_loss           | 3.3e+06     |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -7.89e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 752          |\n",
            "|    iterations           | 129          |\n",
            "|    time_elapsed         | 1756         |\n",
            "|    total_timesteps      | 1320960      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027042874 |\n",
            "|    clip_fraction        | 0.0237       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.352       |\n",
            "|    explained_variance   | 0.0325       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.84e+06     |\n",
            "|    n_updates            | 1280         |\n",
            "|    policy_gradient_loss | -0.00627     |\n",
            "|    value_loss           | 7.77e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -7.89e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 752          |\n",
            "|    iterations           | 130          |\n",
            "|    time_elapsed         | 1769         |\n",
            "|    total_timesteps      | 1331200      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018602405 |\n",
            "|    clip_fraction        | 0.015        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.241       |\n",
            "|    explained_variance   | 0.137        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.79e+06     |\n",
            "|    n_updates            | 1290         |\n",
            "|    policy_gradient_loss | -0.00419     |\n",
            "|    value_loss           | 4.4e+06      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -7.89e+05    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 751          |\n",
            "|    iterations           | 131          |\n",
            "|    time_elapsed         | 1785         |\n",
            "|    total_timesteps      | 1341440      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035202731 |\n",
            "|    clip_fraction        | 0.0285       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.32        |\n",
            "|    explained_variance   | 0.0938       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.35e+06     |\n",
            "|    n_updates            | 1300         |\n",
            "|    policy_gradient_loss | -0.00608     |\n",
            "|    value_loss           | 4.02e+06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -7.9e+05    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 752         |\n",
            "|    iterations           | 132         |\n",
            "|    time_elapsed         | 1796        |\n",
            "|    total_timesteps      | 1351680     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003050493 |\n",
            "|    clip_fraction        | 0.0265      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.349      |\n",
            "|    explained_variance   | 0.0315      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.32e+06    |\n",
            "|    n_updates            | 1310        |\n",
            "|    policy_gradient_loss | -0.00639    |\n",
            "|    value_loss           | 7.58e+06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -7.9e+05     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 752          |\n",
            "|    iterations           | 133          |\n",
            "|    time_elapsed         | 1809         |\n",
            "|    total_timesteps      | 1361920      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014417975 |\n",
            "|    clip_fraction        | 0.0104       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.232       |\n",
            "|    explained_variance   | 0.135        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.67e+06     |\n",
            "|    n_updates            | 1320         |\n",
            "|    policy_gradient_loss | -0.00384     |\n",
            "|    value_loss           | 3.99e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -7.9e+05     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 752          |\n",
            "|    iterations           | 134          |\n",
            "|    time_elapsed         | 1822         |\n",
            "|    total_timesteps      | 1372160      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032828823 |\n",
            "|    clip_fraction        | 0.0264       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.318       |\n",
            "|    explained_variance   | 0.0865       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.33e+06     |\n",
            "|    n_updates            | 1330         |\n",
            "|    policy_gradient_loss | -0.00508     |\n",
            "|    value_loss           | 4.47e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -7.9e+05     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 752          |\n",
            "|    iterations           | 135          |\n",
            "|    time_elapsed         | 1836         |\n",
            "|    total_timesteps      | 1382400      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028793947 |\n",
            "|    clip_fraction        | 0.0227       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.347       |\n",
            "|    explained_variance   | 0.0376       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.81e+06     |\n",
            "|    n_updates            | 1340         |\n",
            "|    policy_gradient_loss | -0.00548     |\n",
            "|    value_loss           | 8.17e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -7.9e+05     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 753          |\n",
            "|    iterations           | 136          |\n",
            "|    time_elapsed         | 1848         |\n",
            "|    total_timesteps      | 1392640      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014076714 |\n",
            "|    clip_fraction        | 0.0132       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.216       |\n",
            "|    explained_variance   | 0.153        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.58e+06     |\n",
            "|    n_updates            | 1350         |\n",
            "|    policy_gradient_loss | -0.00296     |\n",
            "|    value_loss           | 3.12e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -7.9e+05     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 753          |\n",
            "|    iterations           | 137          |\n",
            "|    time_elapsed         | 1860         |\n",
            "|    total_timesteps      | 1402880      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032741644 |\n",
            "|    clip_fraction        | 0.0251       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.32        |\n",
            "|    explained_variance   | 0.0536       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.59e+06     |\n",
            "|    n_updates            | 1360         |\n",
            "|    policy_gradient_loss | -0.00552     |\n",
            "|    value_loss           | 4.84e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -7.9e+05     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 753          |\n",
            "|    iterations           | 138          |\n",
            "|    time_elapsed         | 1874         |\n",
            "|    total_timesteps      | 1413120      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028470904 |\n",
            "|    clip_fraction        | 0.0238       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.351       |\n",
            "|    explained_variance   | 0.0372       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.33e+06     |\n",
            "|    n_updates            | 1370         |\n",
            "|    policy_gradient_loss | -0.00548     |\n",
            "|    value_loss           | 7.92e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -7.9e+05     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 754          |\n",
            "|    iterations           | 139          |\n",
            "|    time_elapsed         | 1887         |\n",
            "|    total_timesteps      | 1423360      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012133231 |\n",
            "|    clip_fraction        | 0.00844      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.212       |\n",
            "|    explained_variance   | 0.147        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.77e+05     |\n",
            "|    n_updates            | 1380         |\n",
            "|    policy_gradient_loss | -0.00327     |\n",
            "|    value_loss           | 2.67e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -7.9e+05     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 753          |\n",
            "|    iterations           | 140          |\n",
            "|    time_elapsed         | 1903         |\n",
            "|    total_timesteps      | 1433600      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027894038 |\n",
            "|    clip_fraction        | 0.0239       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.326       |\n",
            "|    explained_variance   | 0.0572       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.88e+06     |\n",
            "|    n_updates            | 1390         |\n",
            "|    policy_gradient_loss | -0.00494     |\n",
            "|    value_loss           | 5.16e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -7.9e+05     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 753          |\n",
            "|    iterations           | 141          |\n",
            "|    time_elapsed         | 1917         |\n",
            "|    total_timesteps      | 1443840      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031363969 |\n",
            "|    clip_fraction        | 0.0256       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.351       |\n",
            "|    explained_variance   | 0.0427       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.49e+06     |\n",
            "|    n_updates            | 1400         |\n",
            "|    policy_gradient_loss | -0.00477     |\n",
            "|    value_loss           | 8.84e+06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -7.9e+05    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 748         |\n",
            "|    iterations           | 142         |\n",
            "|    time_elapsed         | 1942        |\n",
            "|    total_timesteps      | 1454080     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001246076 |\n",
            "|    clip_fraction        | 0.00924     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.198      |\n",
            "|    explained_variance   | 0.182       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.14e+05    |\n",
            "|    n_updates            | 1410        |\n",
            "|    policy_gradient_loss | -0.00342    |\n",
            "|    value_loss           | 1.74e+06    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -7.9e+05     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 745          |\n",
            "|    iterations           | 143          |\n",
            "|    time_elapsed         | 1964         |\n",
            "|    total_timesteps      | 1464320      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031015356 |\n",
            "|    clip_fraction        | 0.0264       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.328       |\n",
            "|    explained_variance   | 0.0455       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.22e+06     |\n",
            "|    n_updates            | 1420         |\n",
            "|    policy_gradient_loss | -0.00603     |\n",
            "|    value_loss           | 5.18e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -7.9e+05     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 742          |\n",
            "|    iterations           | 144          |\n",
            "|    time_elapsed         | 1984         |\n",
            "|    total_timesteps      | 1474560      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029511848 |\n",
            "|    clip_fraction        | 0.0255       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.325       |\n",
            "|    explained_variance   | 0.0925       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.59e+06     |\n",
            "|    n_updates            | 1430         |\n",
            "|    policy_gradient_loss | -0.00545     |\n",
            "|    value_loss           | 8.03e+06     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 5.97e+03     |\n",
            "|    ep_rew_mean          | -7.9e+05     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 741          |\n",
            "|    iterations           | 145          |\n",
            "|    time_elapsed         | 2001         |\n",
            "|    total_timesteps      | 1484800      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017803411 |\n",
            "|    clip_fraction        | 0.00928      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.211       |\n",
            "|    explained_variance   | 0.225        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.1e+06      |\n",
            "|    n_updates            | 1440         |\n",
            "|    policy_gradient_loss | -0.00315     |\n",
            "|    value_loss           | 1.78e+06     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 5.97e+03    |\n",
            "|    ep_rew_mean          | -7.9e+05    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 740         |\n",
            "|    iterations           | 146         |\n",
            "|    time_elapsed         | 2019        |\n",
            "|    total_timesteps      | 1495040     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003072169 |\n",
            "|    clip_fraction        | 0.0276      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.341      |\n",
            "|    explained_variance   | 0.0367      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.79e+06    |\n",
            "|    n_updates            | 1450        |\n",
            "|    policy_gradient_loss | -0.0062     |\n",
            "|    value_loss           | 5.96e+06    |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 5.97e+03   |\n",
            "|    ep_rew_mean          | -7.9e+05   |\n",
            "| time/                   |            |\n",
            "|    fps                  | 740        |\n",
            "|    iterations           | 147        |\n",
            "|    time_elapsed         | 2034       |\n",
            "|    total_timesteps      | 1505280    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00243443 |\n",
            "|    clip_fraction        | 0.0191     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.302     |\n",
            "|    explained_variance   | 0.0955     |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 4.15e+06   |\n",
            "|    n_updates            | 1460       |\n",
            "|    policy_gradient_loss | -0.00477   |\n",
            "|    value_loss           | 7.32e+06   |\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Excess Generation</td><td></td></tr><tr><td>Inverter total power flow</td><td></td></tr><tr><td>Num Off-Peak Purchases</td><td></td></tr><tr><td>Num Peak Purchases</td><td></td></tr><tr><td>Num Purchase Actions</td><td></td></tr><tr><td>Num Standard Purchases</td><td></td></tr><tr><td>Num Standby Actions</td><td></td></tr><tr><td>Off-Peak Purchases</td><td></td></tr><tr><td>Peak Purchases</td><td></td></tr><tr><td>Rectifier total power flow</td><td></td></tr><tr><td>Standard Purchases</td><td></td></tr><tr><td>Total Reward</td><td></td></tr><tr><td>Unmet Load</td><td></td></tr><tr><td>global_step</td><td></td></tr><tr><td>rollout/ep_len_mean</td><td></td></tr><tr><td>rollout/ep_rew_mean</td><td></td></tr><tr><td>time/fps</td><td></td></tr><tr><td>train/approx_kl</td><td></td></tr><tr><td>train/clip_fraction</td><td></td></tr><tr><td>train/clip_range</td><td></td></tr><tr><td>train/entropy_loss</td><td></td></tr><tr><td>train/explained_variance</td><td></td></tr><tr><td>train/learning_rate</td><td></td></tr><tr><td>train/loss</td><td></td></tr><tr><td>train/policy_gradient_loss</td><td></td></tr><tr><td>train/value_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Excess Generation</td><td>546880.60838</td></tr><tr><td>Inverter total power flow</td><td>256699.60284</td></tr><tr><td>Num Off-Peak Purchases</td><td>1048</td></tr><tr><td>Num Peak Purchases</td><td>298</td></tr><tr><td>Num Purchase Actions</td><td>1129</td></tr><tr><td>Num Standard Purchases</td><td>457</td></tr><tr><td>Num Standby Actions</td><td>4895</td></tr><tr><td>Off-Peak Purchases</td><td>261145.06202</td></tr><tr><td>Peak Purchases</td><td>80124.31573</td></tr><tr><td>Rectifier total power flow</td><td>402320.2783</td></tr><tr><td>Standard Purchases</td><td>113531.12652</td></tr><tr><td>Total Reward</td><td>-776605.43911</td></tr><tr><td>Unmet Load</td><td>4802.51768</td></tr><tr><td>global_step</td><td>1505280</td></tr><tr><td>rollout/ep_len_mean</td><td>5974.0</td></tr><tr><td>rollout/ep_rew_mean</td><td>-789740.875</td></tr><tr><td>time/fps</td><td>740.0</td></tr><tr><td>train/approx_kl</td><td>0.00243</td></tr><tr><td>train/clip_fraction</td><td>0.01905</td></tr><tr><td>train/clip_range</td><td>0.2</td></tr><tr><td>train/entropy_loss</td><td>-0.3018</td></tr><tr><td>train/explained_variance</td><td>0.09547</td></tr><tr><td>train/learning_rate</td><td>0.0003</td></tr><tr><td>train/loss</td><td>4152676.0</td></tr><tr><td>train/policy_gradient_loss</td><td>-0.00477</td></tr><tr><td>train/value_loss</td><td>7319439.0</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">serene-pine-79</strong> at: <a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/d2j4esv8' target=\"_blank\">https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/d2j4esv8</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20231010_075855-d2j4esv8/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "config = {\n",
        "    \"policy_type\": \"MultiInputPolicy\",\n",
        "    \"total_timesteps\": 1_500_000,\n",
        "}\n",
        "\n",
        "run = wandb.init(\n",
        "    project=\"4022_intelligent_ems\",\n",
        "    config=config,\n",
        "    sync_tensorboard=True,  # auto-upload sb3's tensorboard metrics\n",
        "    monitor_gym=True,  # auto-upload the videos of agents playing the game\n",
        "    save_code=True,  # optional\n",
        ")\n",
        "\n",
        "train_args = {\n",
        "                \"episode_len\"   : 6000,\n",
        "                \"actual_load\"   : actual_load,\n",
        "                \"actual_gen\"    : actual_gen,\n",
        "                \"bat_threshold\" : 100,\n",
        "                \"bat_cap\"       : 500,\n",
        "                \"purchase_price\": purchase_price,\n",
        "                \"num_preds\"     : 24,\n",
        "                \"load_shedding\" : load_shedding[2760:],\n",
        "                \"render_mode\"   : \"rgb_array\",\n",
        "                \"wandb_log\"     : True,\n",
        "                \"train_log\"     : True,\n",
        "\n",
        "                }\n",
        "\n",
        "eval_args = {\n",
        "                \"episode_len\"   :2760,\n",
        "                \"actual_load\"   :actual_load[6001:],\n",
        "                \"actual_gen\"    :actual_gen[6001:],\n",
        "                \"bat_threshold\" :100,\n",
        "                \"bat_cap\"       :500,\n",
        "                \"purchase_price\":purchase_price[6001:],\n",
        "                \"num_preds\"     :24,\n",
        "                \"load_shedding\" :load_shedding[6001:],\n",
        "                \"wandb_log\"     : True,\n",
        "                \"train_log\"     : False\n",
        "}\n",
        "\n",
        "#define 5 environments   for training and eval\n",
        "n_envs = 5\n",
        "n_eval_episodes =1\n",
        "train_env = make_vec_env(EMS, n_envs = n_envs,env_kwargs = train_args )\n",
        "\n",
        "\n",
        "eval_env = make_vec_env(EMS, n_envs = n_envs,env_kwargs = eval_args )\n",
        "\n",
        "\n",
        "wand_eval = f\"{version}_{model_type}_eval\"+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "wand_train = f\"{version}_{model_type}_train\"+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "wandb_callback = WandbCallback(\n",
        "                gradient_save_freq=100,\n",
        "                model_save_path=f\"models/{run.id}.{datetime.datetime.now()}\",\n",
        "                model_save_freq= 30000,\n",
        "                verbose=2,\n",
        "                log = \"all\",\n",
        "               )\n",
        "eval_callback = EvalCallback(eval_env,\n",
        "                             best_model_save_path = f\"{model_dir}{version}_{model_type}\"+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"),\n",
        "                             log_path = wand_eval,\n",
        "                             eval_freq=300,\n",
        "                             n_eval_episodes = n_eval_episodes,\n",
        "                             deterministic = True,\n",
        "                             render = False,\n",
        "                             callback_after_eval = wandb_callback)\n",
        "\n",
        "\n",
        "model = PPO(\"MultiInputPolicy\",train_env, verbose = 1, tensorboard_log = f\"runs/{run.id}\") #log_dir\n",
        "\n",
        "model.learn(total_timesteps= config[\"total_timesteps\"],\n",
        "            tb_log_name = wand_train,\n",
        "            reset_num_timesteps=False,\n",
        "            callback = wandb_callback\n",
        "            )\n",
        "\n",
        "model.save(f\"{model_dir}{version}_{model_type}\"+datetime.datetime.now().strftime(\"%m%d-%H%M%S\"))\n",
        "run.finish()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run.finish()\n"
      ],
      "metadata": {
        "id": "o3qJfzD9pLT_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 929,
          "referenced_widgets": [
            "8cb895e4501c4ae691d1c0e16bbeff6e",
            "01bf93678a664549adaaf7a3de9c7c58",
            "e128a15f6eed43f088bac4b0f4774eaa",
            "e7fd497832354e66868a18ec4a8f67f3",
            "3fbea4ded8554ed0bd4e14450d2ead83",
            "40ef7a65c9ed4981b0e58c2dccee6a1e",
            "07d0d79e54164408a150353b22a987e8",
            "e88cb6c26134495ea358d489dfebe946"
          ]
        },
        "outputId": "ee9de952-14e7-4f8d-84eb-62839a63d476"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.013 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.098422"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8cb895e4501c4ae691d1c0e16bbeff6e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>AC load</td><td></td></tr><tr><td>DC load</td><td></td></tr><tr><td>Diesel Generator</td><td></td></tr><tr><td>Excess Generation</td><td></td></tr><tr><td>Inverter total power flow</td><td></td></tr><tr><td>LoadShedding</td><td></td></tr><tr><td>Num Diesel Gen Actions</td><td></td></tr><tr><td>Num Off-Peak Purchases</td><td></td></tr><tr><td>Num Peak Purchases</td><td></td></tr><tr><td>Num Purchase Actions</td><td></td></tr><tr><td>Num Standard Purchases</td><td></td></tr><tr><td>Num Standby Actions</td><td></td></tr><tr><td>Off-Peak Purchases</td><td></td></tr><tr><td>PV generation</td><td></td></tr><tr><td>Peak Purchases</td><td></td></tr><tr><td>Rectifier total power flow</td><td></td></tr><tr><td>Standard Purchases</td><td></td></tr><tr><td>Total Reward</td><td></td></tr><tr><td>Unmet Load</td><td></td></tr><tr><td>Wind generation</td><td></td></tr><tr><td>battery_level</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>AC load</td><td>113.37033</td></tr><tr><td>DC load</td><td>54.4</td></tr><tr><td>Diesel Generator</td><td>0.0</td></tr><tr><td>Excess Generation</td><td>316780.13809</td></tr><tr><td>Inverter total power flow</td><td>166690.98807</td></tr><tr><td>LoadShedding</td><td>0.0</td></tr><tr><td>Num Diesel Gen Actions</td><td>0</td></tr><tr><td>Num Off-Peak Purchases</td><td>559</td></tr><tr><td>Num Peak Purchases</td><td>125</td></tr><tr><td>Num Purchase Actions</td><td>0</td></tr><tr><td>Num Standard Purchases</td><td>137</td></tr><tr><td>Num Standby Actions</td><td>2734</td></tr><tr><td>Off-Peak Purchases</td><td>83614.33067</td></tr><tr><td>PV generation</td><td>84.94012</td></tr><tr><td>Peak Purchases</td><td>16638.24617</td></tr><tr><td>Rectifier total power flow</td><td>100149.31671</td></tr><tr><td>Standard Purchases</td><td>21632.66076</td></tr><tr><td>Total Reward</td><td>-273330.71434</td></tr><tr><td>Unmet Load</td><td>9653.63237</td></tr><tr><td>Wind generation</td><td>0.0</td></tr><tr><td>battery_level</td><td>100.0</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">likely-wave-88</strong> at: <a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/57h2xjel' target=\"_blank\">https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/57h2xjel</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20231010_090425-57h2xjel/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define a new test environment and load up the best performing model to test it.**"
      ],
      "metadata": {
        "id": "C9AGcLlsv4N7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "inDHszZaxBUS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "26e8e232-8d59-4e49-eec1-ac1e04ae68b9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.12"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/EEE4022S_BNKJUL001_Thesis/wandb/run-20231010_092758-9uzwns87</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/9uzwns87' target=\"_blank\">feasible-oath-94</a></strong> to <a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems' target=\"_blank\">https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/9uzwns87' target=\"_blank\">https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/9uzwns87</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>AC load</td><td></td></tr><tr><td>DC load</td><td></td></tr><tr><td>Diesel Generator</td><td></td></tr><tr><td>Excess Generation</td><td></td></tr><tr><td>Inverter total power flow</td><td></td></tr><tr><td>LoadShedding</td><td></td></tr><tr><td>Num Diesel Gen Actions</td><td></td></tr><tr><td>Num Off-Peak Purchases</td><td></td></tr><tr><td>Num Peak Purchases</td><td></td></tr><tr><td>Num Purchase Actions</td><td></td></tr><tr><td>Num Standard Purchases</td><td></td></tr><tr><td>Num Standby Actions</td><td></td></tr><tr><td>Off-Peak Purchases</td><td></td></tr><tr><td>PV generation</td><td></td></tr><tr><td>Peak Purchases</td><td></td></tr><tr><td>Rectifier total power flow</td><td></td></tr><tr><td>Standard Purchases</td><td></td></tr><tr><td>Total Reward</td><td></td></tr><tr><td>Unmet Load</td><td></td></tr><tr><td>Wind generation</td><td></td></tr><tr><td>battery_level</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>AC load</td><td>113.37033</td></tr><tr><td>DC load</td><td>54.4</td></tr><tr><td>Diesel Generator</td><td>0.0</td></tr><tr><td>Excess Generation</td><td>316780.13809</td></tr><tr><td>Inverter total power flow</td><td>166690.98807</td></tr><tr><td>LoadShedding</td><td>0.0</td></tr><tr><td>Num Diesel Gen Actions</td><td>0</td></tr><tr><td>Num Off-Peak Purchases</td><td>559</td></tr><tr><td>Num Peak Purchases</td><td>125</td></tr><tr><td>Num Purchase Actions</td><td>0</td></tr><tr><td>Num Standard Purchases</td><td>137</td></tr><tr><td>Num Standby Actions</td><td>2734</td></tr><tr><td>Off-Peak Purchases</td><td>83614.33067</td></tr><tr><td>PV generation</td><td>84.94012</td></tr><tr><td>Peak Purchases</td><td>16638.24617</td></tr><tr><td>Rectifier total power flow</td><td>100149.31671</td></tr><tr><td>Standard Purchases</td><td>21632.66076</td></tr><tr><td>Total Reward</td><td>-273330.71434</td></tr><tr><td>Unmet Load</td><td>9653.63237</td></tr><tr><td>Wind generation</td><td>0.0</td></tr><tr><td>battery_level</td><td>100.0</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">feasible-oath-94</strong> at: <a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/9uzwns87' target=\"_blank\">https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/9uzwns87</a><br/>Synced 4 W&B file(s), 5 media file(s), 2 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20231010_092758-9uzwns87/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.12"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/EEE4022S_BNKJUL001_Thesis/wandb/run-20231010_092854-ka25s91b</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/ka25s91b' target=\"_blank\">woven-plant-95</a></strong> to <a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems' target=\"_blank\">https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/ka25s91b' target=\"_blank\">https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/ka25s91b</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>AC load</td><td></td></tr><tr><td>DC load</td><td></td></tr><tr><td>Diesel Generator</td><td></td></tr><tr><td>Excess Generation</td><td></td></tr><tr><td>Inverter total power flow</td><td></td></tr><tr><td>LoadShedding</td><td></td></tr><tr><td>Num Diesel Gen Actions</td><td></td></tr><tr><td>Num Off-Peak Purchases</td><td></td></tr><tr><td>Num Peak Purchases</td><td></td></tr><tr><td>Num Purchase Actions</td><td></td></tr><tr><td>Num Standard Purchases</td><td></td></tr><tr><td>Num Standby Actions</td><td></td></tr><tr><td>Off-Peak Purchases</td><td></td></tr><tr><td>PV generation</td><td></td></tr><tr><td>Peak Purchases</td><td></td></tr><tr><td>Rectifier total power flow</td><td></td></tr><tr><td>Standard Purchases</td><td></td></tr><tr><td>Total Reward</td><td></td></tr><tr><td>Unmet Load</td><td></td></tr><tr><td>Wind generation</td><td></td></tr><tr><td>battery_level</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>AC load</td><td>113.37033</td></tr><tr><td>DC load</td><td>54.4</td></tr><tr><td>Diesel Generator</td><td>0.0</td></tr><tr><td>Excess Generation</td><td>316780.13809</td></tr><tr><td>Inverter total power flow</td><td>166690.98807</td></tr><tr><td>LoadShedding</td><td>0.0</td></tr><tr><td>Num Diesel Gen Actions</td><td>0</td></tr><tr><td>Num Off-Peak Purchases</td><td>559</td></tr><tr><td>Num Peak Purchases</td><td>125</td></tr><tr><td>Num Purchase Actions</td><td>0</td></tr><tr><td>Num Standard Purchases</td><td>137</td></tr><tr><td>Num Standby Actions</td><td>2734</td></tr><tr><td>Off-Peak Purchases</td><td>83614.33067</td></tr><tr><td>PV generation</td><td>84.94012</td></tr><tr><td>Peak Purchases</td><td>16638.24617</td></tr><tr><td>Rectifier total power flow</td><td>100149.31671</td></tr><tr><td>Standard Purchases</td><td>21632.66076</td></tr><tr><td>Total Reward</td><td>-273330.71434</td></tr><tr><td>Unmet Load</td><td>9653.63237</td></tr><tr><td>Wind generation</td><td>0.0</td></tr><tr><td>battery_level</td><td>100.0</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">woven-plant-95</strong> at: <a href='https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/ka25s91b' target=\"_blank\">https://wandb.ai/4022_intelligent_ems/4022_intelligent_ems/runs/ka25s91b</a><br/>Synced 4 W&B file(s), 5 media file(s), 2 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20231010_092854-ka25s91b/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Note: The term does not refer to the cost in rands but rather to the reward as defined by the reward function!\n",
            "Done the Standby Test! Total cost accumulated is: -273330.84375\n",
            "Done applying the trained model! Total cost accumulated is: -273330.71434 +- 0.0\n",
            "The amount that was saved by applying the EMS agent: 0.12940999999409541\n",
            "This was saved over a period of 115.0 days\n",
            "The savings represents 4.7345553183328004e-05 % of the cost if no EMS is installed\n",
            "And it represents 4.7345575599352674e-05 % of the cost if the EMS is installed\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmYAAAHHCAYAAAAVhJRcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABZYElEQVR4nO3deVxN+f8H8Ndtu6XcW2jRSEW2yBrJWEdcI0wjgzQKWQaNpTGD7wxi7DtjMMxMmcVYBjOGwbdJxtZYUnYxJjIoSyqFtvv5/eHb+bkK93LT5b6ej0ePR+dzPuec971u9XLO53yOTAghQERERETlzqS8CyAiIiKihxjMiIiIiAwEgxkRERGRgWAwIyIiIjIQDGZEREREBoLBjIiIiMhAMJgRERERGQgGMyIiIiIDwWBGREREZCAYzIh0IJPJEBkZWd5laBgwYADc3Nx03s7NzQ0DBgzQez2Grn379mjQoEF5l6GTS5cuQSaTITo6urxLMQilfXYvXLiAzp07Q6lUQiaT4ZdffgEAHDlyBK1atYK1tTVkMhmSkpJeer1EumAwI6MXHR0NmUz2xK+//vrrpdRx7949REZGYs+ePS/leI87c+YMIiMjcenSJb3ud8CAARrvp0KhQKNGjbBgwQLk5eXp9VhUvp72c/ToV1l8xkNDQ3Hy5EnMmDED33//Pby9vVFQUID33nsPGRkZWLRoEb7//nu4urqWuv2ePXs0ajQ1NYWDgwN69eqFs2fPPnddM2fOlEIikTbMyrsAIkMxbdo0uLu7l2j38PB4Kce/d+8epk6dCuDhWR1trV69Gmq1WufjJScnw8Tk//9vdubMGUydOhXt27d/rjNwTyOXy/H1118DADIzM7Fp0yaMGzcOR44cwbp16/R6LCo/33//vcbyd999h5iYmBLt9erVe6HjPP7ZvX//PuLj4/Hpp58iPDxcaj937hwuX76M1atXY/DgwVrte9SoUWjevDkKCgpw4sQJrFy5Env27MGpU6fg5OSkc60zZ85Er169EBAQoPO2ZJwYzIj+5+2334a3t3d5l6G13NxcWFtbw9zc/Lm2l8vleq7oyczMzPD+++9LyyNGjICPjw/Wr1+PhQsXwtnZ+YX2X/xe0MvxpPf70X9jAPjrr78QExNTov15CCHw4MEDWFlZlfjs3rx5EwBga2ur0X7jxo1S25+mTZs26NWrl7Rcp04dDB8+HN999x0++eST5yueSAe8lEn0gq5evYpBgwbB0dERcrkc9evXx7ffflui34MHDxAZGYnatWvD0tISVatWRc+ePXHx4kVcunQJ9vb2AICpU6dKl1OKx7MNGDAANjY2uHjxIrp27YqKFSsiODhYWvf4GS61Wo0lS5bAy8sLlpaWsLe3R5cuXXD06FGpz6PjdKKjo/Hee+8BADp06KBxySk0NBRVqlRBQUFBidfUuXNn1KlTR+f3zMTERDorWHzp9Enj9x4fT1R86fnPP//EiBEj4ODggGrVqknrd+zYgXbt2qFixYpQKBRo3rw51q5dW2K/Z86cQYcOHVChQgW88cYbmDt3rsb6/Px8TJ48Gc2aNYNSqYS1tTXatGmDuLi4Evtat24dmjVrJh3Ty8sLS5Ys0eiTmZmJMWPGwMXFBXK5HB4eHpgzZ06Js52ZmZkYMGAAlEolbG1tERoaiszMzKe8m/+v+L3Zu3cvhg0bhsqVK0OhUCAkJAR37twp0X/Hjh1o06YNrK2tUbFiRfj7++P06dMafZ722XseUVFReOutt+Dg4AC5XA5PT0+sWLGiRD83Nzd069YNu3btgre3N6ysrPDVV19J64o/E5GRkdLlyY8//hgymUxa365dOwDAe++9B5lMptOZ6GJt2rQBAFy8eFGjff78+WjVqhUqV64MKysrNGvWDD///LNGH5lMhtzcXKxZs0b6mXr0s6zt7w4yLjxjRvQ/WVlZuHXrlkabTCZD5cqVn7hNeno6WrZsCZlMhvDwcNjb22PHjh0ICwtDdnY2xowZAwAoKipCt27dEBsbi759+2L06NG4e/cuYmJicOrUKfj5+WHFihUYPnw43n33XfTs2RMA0LBhQ+lYhYWFUKlUaN26NebPn48KFSo8sa6wsDBER0fj7bffxuDBg1FYWIh9+/bhr7/+KvWsYNu2bTFq1CgsXboU//nPf6RLTfXq1UP//v3x3XffYdeuXejWrZu0TVpaGnbv3o0pU6Y8+80tRfEfuqe9v08zYsQI2NvbY/LkycjNzQXwMJgMGjQI9evXx8SJE2Fra4vExETs3LkT/fr1k7a9c+cOunTpgp49e6J37974+eefMX78eHh5eeHtt98GAGRnZ+Prr79GUFAQhgwZgrt37+Kbb76BSqXC4cOH0bhxYwBATEwMgoKC0LFjR8yZMwcAcPbsWRw4cACjR48G8PAydbt27XD16lUMGzYM1atXx8GDBzFx4kRcv34dixcvBvDwrNA777yD/fv344MPPkC9evWwZcsWhIaG6vTehIeHw9bWFpGRkUhOTsaKFStw+fJlaRwV8PCyY2hoKFQqFebMmYN79+5hxYoVaN26NRITEzXCvi6fvWdZsWIF6tevjx49esDMzAy//fYbRowYAbVajZEjR2r0TU5ORlBQEIYNG4YhQ4aU+p+Anj17wtbWFmPHjkVQUBC6du0KGxsbODo64o033sDMmTOly5OOjo4611v8Hwc7OzuN9iVLlqBHjx4IDg5Gfn4+1q1bh/feew/btm2Dv78/gIfv8eDBg9GiRQsMHToUAFCzZk0A2v/uICMkiIxcVFSUAFDql1wu1+gLQEyZMkVaDgsLE1WrVhW3bt3S6Ne3b1+hVCrFvXv3hBBCfPvttwKAWLhwYYnjq9VqIYQQN2/eLLH/YqGhoQKAmDBhQqnrXF1dpeXdu3cLAGLUqFFPPJYQQri6uorQ0FBpeePGjQKAiIuL09imqKhIVKtWTfTp00ejfeHChUImk4l//vmnxHEer8/a2lrcvHlT3Lx5U/z9999i5syZQiaTiYYNG0r9nvTaH6+z+N+rdevWorCwUGrPzMwUFStWFD4+PuL+/ftPfN3t2rUTAMR3330nteXl5QknJycRGBgotRUWFoq8vDyN/dy5c0c4OjqKQYMGSW2jR48WCoVCo5bHff7558La2lqcP39eo33ChAnC1NRUpKamCiGE+OWXXwQAMXfuXI062rRpIwCIqKioJx5DiP9/b5o1ayby8/Ol9rlz5woA4tdffxVCCHH37l1ha2srhgwZorF9WlqaUCqVGu1P++w9y8iRI8Xjf2aKfyYepVKpRI0aNTTaXF1dBQCxc+fOEv0f/0ykpKQIAGLevHka/eLi4gQAsXHjxmfWWtz322+/FTdv3hTXrl0TO3fuFB4eHkImk4nDhw8/9XXk5+eLBg0aiLfeekuj3draWqPWYtr+7iDjw0uZRP/z5ZdfIiYmRuNrx44dT+wvhMCmTZvQvXt3CCFw69Yt6UulUiErKwvHjh0DAGzatAlVqlTBhx9+WGI/xWcwtDF8+PBn9tm0aRNkMlmpZ7J0OVYxExMTBAcHY+vWrbh7967U/uOPP6JVq1al3jDxuNzcXNjb28Pe3h4eHh74z3/+A19fX2zZskXneooNGTIEpqam0nJMTAzu3r2LCRMmwNLSUqPv46/bxsZGY9yThYUFWrRogX/++UdqMzU1hYWFBYCHl4YzMjJQWFgIb29v6d8VeDh+KTc3FzExMU+sdePGjWjTpg3s7Ow0Pid+fn4oKirC3r17AQC///47zMzMNP6dTU1NS/3cPM3QoUM1xh4OHz4cZmZm+P333wE8fK8yMzMRFBSkUY+pqSl8fHxKvVyrzWdPG1ZWVtL3xWep27Vrh3/++QdZWVkafd3d3aFSqfRyXG0NGjQI9vb2cHZ2RpcuXZCVlYXvv/8ezZs31+j36Ou4c+cOsrKy0KZNG43PxpPo8ruDjA8vZRL9T4sWLXQa/H/z5k1kZmZi1apVWLVqVal9igcfX7x4EXXq1IGZ2fP/yJmZmWmMpXqSixcvwtnZGZUqVXruYz0uJCQEc+bMwZYtWxASEoLk5GQkJCRg5cqVWm1vaWmJ3377DcDDmw7c3d21ei1P83ggLL40qs0cZdWqVSsR1uzs7HDixAmNtjVr1mDBggU4d+6cxhi7R489YsQIbNiwAW+//TbeeOMNdO7cGb1790aXLl2kPhcuXMCJEyekcYSPK/6cXL58GVWrVoWNjY3Gel3H8dWqVUtj2cbGBlWrVpUuy124cAEA8NZbb5W6vUKh0FjW9rOnjQMHDmDKlCmIj4/HvXv3NNZlZWVBqVRKy9qEfn2bPHky2rRpg5ycHGzZsgXr1q3TuAO02LZt2zB9+nQkJSVpTPuizX9+dPndQcaHwYzoORUP2n7//fefOAbo0TFiL0oul5f6B+Jl8PT0RLNmzfDDDz8gJCQEP/zwAywsLNC7d2+ttjc1NYWfn99zHbuoqKjU9kfPWOjq0TNtjxJCSN//8MMPGDBgAAICAvDxxx/DwcEBpqammDVrlsZAcAcHByQlJWHXrl3YsWMHduzYgaioKISEhGDNmjUAHn5WOnXq9MS7+mrXrv3cr+V5FH92v//++1KngHj8PxD6+uxdvHgRHTt2RN26dbFw4UK4uLjAwsICv//+OxYtWlTiRogX+Td+Xl5eXtJnNSAgAPfu3cOQIUPQunVruLi4AAD27duHHj16oG3btli+fDmqVq0Kc3NzREVFlXqjyeNe9u8OerUwmBE9J3t7e1SsWBFFRUXPDB01a9bEoUOHUFBQ8MTpLZ7nMuOTjrVr1y5kZGTodNbsWccPCQlBREQErl+/jrVr18Lf37/EgOgXYWdnV+Luw/z8fFy/fl2r7YsHVZ86dUovc8/9/PPPqFGjBjZv3qzx3pR2idjCwgLdu3dH9+7doVarMWLECHz11VeYNGkSPDw8ULNmTeTk5Dzzc+Lq6orY2Fjk5ORonDVLTk7WqfYLFy6gQ4cO0nJOTg6uX7+Orl27Avj/98rBweG5A/Pz+O2335CXl4etW7eievXqUntpl04NxezZs7FlyxbMmDFDOkO8adMmWFpaYteuXRpTd0RFRZXYvrSfK11+d5Dx4RgzoudkamqKwMBAbNq0CadOnSqxvnhuJQAIDAzErVu3sGzZshL9is/SFN/ppu3UCE8SGBgIIYQ0WW1pxypN8bxUTzp+UFAQZDIZRo8ejX/++Ucvc1M9qmbNmtJYq2KrVq164hmzx3Xu3BkVK1bErFmz8ODBA411T3vdT1J8Vu3RbQ8dOoT4+HiNfrdv39ZYNjExkc52FF/i6t27N+Lj47Fr164Sx8nMzERhYSEAoGvXrigsLNSYPqKoqAhffPGFTrWvWrVK49LrihUrUFhYKN1xqlKpoFAoMHPmzFKnQXn0s6tPpb2nWVlZpQYaQ1GzZk0EBgYiOjoaaWlpAB6+DplMpvHZvHTpUqkz/FtbW5f4mdLldwcZH54xI/qfHTt24Ny5cyXaW7VqhRo1apS6zezZsxEXFwcfHx8MGTIEnp6eyMjIwLFjx/DHH38gIyMDwMOzTd999x0iIiJw+PBhtGnTBrm5ufjjjz8wYsQIvPPOO7CysoKnpyfWr1+P2rVro1KlSmjQoIHOz3Xs0KED+vfvj6VLl+LChQvo0qUL1Go19u3bhw4dOmjMjP6oxo0bw9TUFHPmzEFWVhbkcrk03xQAaS60jRs3wtbWVpoSQF8GDx6MDz74AIGBgejUqROOHz+OXbt2oUqVKlptr1AosGjRIgwePBjNmzdHv379YGdnh+PHj+PevXvSZUVtdevWDZs3b8a7774Lf39/pKSkYOXKlfD09EROTo5G3RkZGXjrrbdQrVo1XL58GV988QUaN24sTTvy8ccfY+vWrejWrRsGDBiAZs2aITc3FydPnsTPP/+MS5cuoUqVKujevTvefPNNTJgwAZcuXYKnpyc2b95cYlD8s+Tn56Njx47o3bs3kpOTsXz5crRu3Ro9evSQ3qsVK1agf//+aNq0Kfr27Qt7e3ukpqZi+/btePPNN0v9T8SL6ty5s3R2cdiwYcjJycHq1avh4OCg9ZnR8vDxxx9jw4YNWLx4MWbPng1/f38sXLgQXbp0Qb9+/XDjxg18+eWX8PDwKDFOsVmzZvjjjz+kiZTd3d3h4+Oj9e8OMkLldDcokcF42nQZeGyKApQypUN6eroYOXKkcHFxEebm5sLJyUl07NhRrFq1SqPfvXv3xKeffirc3d2lfr169RIXL16U+hw8eFA0a9ZMWFhYaByreMqJ0jw+XYYQD6dYmDdvnqhbt66wsLAQ9vb24u233xYJCQlSn8enHBBCiNWrV4saNWoIU1PTUqfO2LBhgwAghg4d+uQ3tJT6nlT7o4qKisT48eNFlSpVRIUKFYRKpRJ///33E6fLOHLkSKn72bp1q2jVqpWwsrISCoVCtGjRQvz000/S+nbt2on69euXWuej76NarRYzZ84Urq6uQi6XiyZNmoht27aV6Pfzzz+Lzp07CwcHB2FhYSGqV68uhg0bJq5fv66x/7t374qJEycKDw8PYWFhIapUqSJatWol5s+frzG1xe3bt0X//v2FQqEQSqVS9O/fXyQmJuo0Xcaff/4phg4dKuzs7ISNjY0IDg4Wt2/fLtE/Li5OqFQqoVQqhaWlpahZs6YYMGCAOHr0qMb7os2/X2lKmy5j69atomHDhsLS0lK4ubmJOXPmSNPJpKSkSP1cXV2Fv79/qfsty+kyntS3ffv2QqFQiMzMTCGEEN98842oVauWkMvlom7duiIqKkpMmTKlxOs9d+6caNu2rbCyshIANOrW9ncHGReZEM9xjp+IjNKvv/6KgIAA7N27V5oRnQxHdHQ0Bg4ciCNHjrxSjxcjov/HMWZEpLXVq1ejRo0aaN26dXmXQkT0WuIYMyJ6pnXr1uHEiRPYvn07lixZorc7SImISBODGRE9U1BQEGxsbBAWFoYRI0aUdzlERK+tcr2UuXfvXnTv3h3Ozs6QyWQatxoXFBRIDxW2traGs7MzQkJCcO3aNY19ZGRkIDg4GAqFAra2tggLC9O4YwoATpw4gTZt2sDS0hIuLi6YO3duiVo2btyIunXrwtLSEl5eXtKjS4oJITB58mRUrVoVVlZW8PPzk2bPJnrdCSFw9+5dfP311y/09AIqWwMGDIAQguPLiF5h5RrMcnNz0ahRI3z55Zcl1t27dw/Hjh3DpEmTcOzYMWzevBnJycnS7d7FgoODcfr0acTExGDbtm3Yu3cvhg4dKq3Pzs5G586d4erqioSEBMybNw+RkZEaj8E4ePAggoKCEBYWhsTERAQEBCAgIEBjfpm5c+di6dKlWLlyJQ4dOgRra2uoVKoS8yURERERPbdyvSf0EQDEli1bntrn8OHDAoC4fPmyEEKIM2fOlLhtfseOHUImk4mrV68KIYRYvny5sLOzE3l5eVKf8ePHizp16kjLvXv3LnFbto+Pjxg2bJgQ4uFt805OThq3YmdmZgq5XK5xGz4RERHRi3ilrklkZWVBJpPB1tYWABAfHw9bW1uN0/Z+fn4wMTHBoUOH8O677yI+Ph5t27aFhYWF1EelUmHOnDm4c+cO7OzsEB8fj4iICI1jqVQq6dJqSkoK0tLSNB6doVQq4ePjg/j4ePTt27fUevPy8jQebqtWq5GRkYHKlStz8DQREdErQvxvOIezs3OZP7P4lQlmDx48wPjx4xEUFASFQgEASEtLk2YlL2ZmZoZKlSpJj85IS0uDu7u7Rh9HR0dpnZ2dHdLS0qS2R/s8uo9HtyutT2lmzZpV6mNxiIiI6NVz5coVVKtWrUyP8UoEs4KCAvTu3RtCCI1nyBm6iRMnapyJy8rKQvXq1XHlyhUpXBIREZFhy87OhouLCypWrFjmxzL4YFYcyi5fvozdu3drBBonJyfcuHFDo39hYSEyMjLg5OQk9UlPT9foU7z8rD6Pri9uq1q1qkafxo0bP7F2uVwOuVxeol2hUDCYERERvWJexjAkg575vziUXbhwAX/88QcqV66ssd7X1xeZmZlISEiQ2nbv3g21Wg0fHx+pz969e1FQUCD1iYmJQZ06dWBnZyf1iY2N1dh3TEwMfH19AQDu7u5wcnLS6JOdnY1Dhw5JfYiIiIheVLkGs5ycHCQlJSEpKQnAw0H2SUlJSE1NRUFBAXr16oWjR4/ixx9/RFFREdLS0pCWlob8/HwAQL169dClSxcMGTIEhw8fxoEDBxAeHo6+ffvC2dkZANCvXz9YWFggLCwMp0+fxvr167FkyRKNS4yjR4/Gzp07sWDBApw7dw6RkZE4evQowsPDATxMyGPGjMH06dOxdetWnDx5EiEhIXB2dkZAQMBLfc+IiIjoNVaet4TGxcUJACW+QkNDRUpKSqnrAIi4uDhpH7dv3xZBQUHCxsZGKBQKMXDgQHH37l2N4xw/fly0bt1ayOVy8cYbb4jZs2eXqGXDhg2idu3awsLCQtSvX19s375dY71arRaTJk0Sjo6OQi6Xi44dO4rk5GSdXm9WVpYAILKysnTajoiIiMrPy/z7LRNCiHJJhEYoOzsbSqUSWVlZHGNGRET0iniZf78NeowZERERkTFhMCMiIiIyEAxmRERERAaCwYyIiIjIQDCYERERERkIBjMiIiIiA8FgRkRERGQgGMyIiIiIDASDGREREZGBYDAjIiIiMhAMZkREREQGgsGMiIiIyEAwmBEREREZCAYzIiIiIgPBYEZERERkIBjMiIiIiAwEgxkRERGRgWAwIyIiIjIQDGZEREREBoLBjIiIiMhAMJgRERERGQgGMyIiIiIDwWBGREREZCAYzIiIiIgMBIMZERERkYFgMCMiIiIyEAxmRERERAaCwYyIiIjIQDCYERERERkIBjMiIiIiA8FgRkRERGQgGMyIiIiIDASDGREREZGBYDAjIiIiMhAMZkREREQGgsGMiIiIyEAwmBEREREZCAYzIiIiIgPBYEZERERkIBjMiIiIiAwEgxkRERGRgWAwIyIiIjIQDGZEREREBoLBjIiIiMhAMJgRERERGQgGMyIiIiIDwWBGREREZCAYzIiIiIgMBIMZERERkYFgMCMiIiIyEOUazPbu3Yvu3bvD2dkZMpkMv/zyi8Z6IQQmT56MqlWrwsrKCn5+frhw4YJGn4yMDAQHB0OhUMDW1hZhYWHIycnR6HPixAm0adMGlpaWcHFxwdy5c0vUsnHjRtStWxeWlpbw8vLC77//rnMtRERERC+iXINZbm4uGjVqhC+//LLU9XPnzsXSpUuxcuVKHDp0CNbW1lCpVHjw4IHUJzg4GKdPn0ZMTAy2bduGvXv3YujQodL67OxsdO7cGa6urkhISMC8efMQGRmJVatWSX0OHjyIoKAghIWFITExEQEBAQgICMCpU6d0qoWIiIjohQgDAUBs2bJFWlar1cLJyUnMmzdPasvMzBRyuVz89NNPQgghzpw5IwCII0eOSH127NghZDKZuHr1qhBCiOXLlws7OzuRl5cn9Rk/fryoU6eOtNy7d2/h7++vUY+Pj48YNmyY1rVoIysrSwAQWVlZWm9DRERE5etl/v022DFmKSkpSEtLg5+fn9SmVCrh4+OD+Ph4AEB8fDxsbW3h7e0t9fHz84OJiQkOHTok9Wnbti0sLCykPiqVCsnJybhz547U59HjFPcpPo42tRARERG9KLPyLuBJ0tLSAACOjo4a7Y6OjtK6tLQ0ODg4aKw3MzNDpUqVNPq4u7uX2EfxOjs7O6SlpT3zOM+qpTR5eXnIy8uTlrOzs5/yiomIiMjYGewZs9fBrFmzoFQqpS8XF5fyLomIiIgMmMEGMycnJwBAenq6Rnt6erq0zsnJCTdu3NBYX1hYiIyMDI0+pe3j0WM8qc+j659VS2kmTpyIrKws6evKlSvPeNVERERkzAw2mLm7u8PJyQmxsbFSW3Z2Ng4dOgRfX18AgK+vLzIzM5GQkCD12b17N9RqNXx8fKQ+e/fuRUFBgdQnJiYGderUgZ2dndTn0eMU9yk+jja1lEYul0OhUGh8ERERET1Rmd9e8BR3794ViYmJIjExUQAQCxcuFImJieLy5ctCCCFmz54tbG1txa+//ipOnDgh3nnnHeHu7i7u378v7aNLly6iSZMm4tChQ2L//v2iVq1aIigoSFqfmZkpHB0dRf/+/cWpU6fEunXrRIUKFcRXX30l9Tlw4IAwMzMT8+fPF2fPnhVTpkwR5ubm4uTJk1IfbWp5Ft6VSURE9Op5mX+/yzWYxcXFCQAlvkJDQ4UQD6epmDRpknB0dBRyuVx07NhRJCcna+zj9u3bIigoSNjY2AiFQiEGDhwo7t69q9Hn+PHjonXr1kIul4s33nhDzJ49u0QtGzZsELVr1xYWFhaifv36Yvv27RrrtanlWRjMiIiIXj0v8++3TAghyutsnbHJzs6GUqlEVlYWL2sSERG9Il7m32+DHWNGREREZGwYzIiIiIgMBIMZERERkYFgMCMiIiIyEAxmRERERAaCwYyIiIjIQDCYERERERkIBjMiIiIiA8FgRkRERGQgGMyIiIiIDASDGREREZGBYDAjIiIiMhAMZkREREQGgsGMiIiIyEAwmBEREREZCAYzIiIiIgPBYEZERERkIBjMiIiIiAwEgxkRERGRgWAwIyIiIjIQDGZEREREBsJM1w3y8vJw6NAhXL58Gffu3YO9vT2aNGkCd3f3sqiPiIiIyGhoHcwOHDiAJUuW4LfffkNBQQGUSiWsrKyQkZGBvLw81KhRA0OHDsUHH3yAihUrlmXNRERERK8lrS5l9ujRA3369IGbmxv++9//4u7du7h9+zb+/fdf3Lt3DxcuXMBnn32G2NhY1K5dGzExMWVdNxEREdFrR6szZv7+/ti0aRPMzc1LXV+jRg3UqFEDoaGhOHPmDK5fv67XIomIiIiMgUwIIcq7CGORnZ0NpVKJrKwsKBSK8i6HiIiItPAy/37rfFfmlStX8O+//0rLhw8fxpgxY7Bq1Sq9FkZERERkbHQOZv369UNcXBwAIC0tDZ06dcLhw4fx6aefYtq0aXovkIiIiMhY6BzMTp06hRYtWgAANmzYgAYNGuDgwYP48ccfER0dre/6iIiIiIyGzsGsoKAAcrkcAPDHH3+gR48eAIC6dety0D8RERHRC9A5mNWvXx8rV67Evn37EBMTgy5dugAArl27hsqVK+u9QCIiIiJjoXMwmzNnDr766iu0b98eQUFBaNSoEQBg69at0iVOIiIiItLdc02XUVRUhOzsbNjZ2Ultly5dgrW1Nezt7fVa4OuE02UQERG9egx6uoy33noLd+/e1QhlAFCpUiX06dNHb4URERERGRudg9mePXuQn59fov3BgwfYt2+fXooiIiIiMkZaP8T8xIkT0vdnzpxBWlqatFxUVISdO3fijTfe0G91REREREZE62DWuHFjyGQyyGQyvPXWWyXWW1lZ4YsvvtBrcURERETGROtglpKSAiEEatSogcOHD2sM8rewsICDgwNMTU3LpEgiIiIiY6B1MHN1dQUAqNXqMiuGiIiIyJhpFcy2bt2Kt99+G+bm5ti6detT+xY/CYCIiIiIdKPVPGYmJiZIS0uDg4MDTEyefCOnTCZDUVGRXgt8nXAeMyIiolfPy/z7rdUZs0cvX/JSJhEREVHZ0HkeMyIiIiIqG1oP/n9UbGwsYmNjcePGjRJn0L799lu9FEZERERkbHQOZlOnTsW0adPg7e2NqlWrQiaTlUVdrzXlLCVgWd5VkJii82NiiYiIypTOwWzlypWIjo5G//79y6IeIiIiIqOl8xiz/Px8tGrVqixqISIiIjJqOgezwYMHY+3atWVRCxEREZFR0/lS5oMHD7Bq1Sr88ccfaNiwIczNzTXWL1y4UG/FERERERkTnYPZiRMn0LhxYwDAqVOnNNbxRgAiIiKi56dzMIuLiyuLOoiIiIiMnkFPMFtUVIRJkybB3d0dVlZWqFmzJj7//HM8+hQpIQQmT56MqlWrwsrKCn5+frhw4YLGfjIyMhAcHAyFQgFbW1uEhYUhJydHo8+JEyfQpk0bWFpawsXFBXPnzi1Rz8aNG1G3bl1YWlrCy8sLv//+e9m8cCIiIjJKOp8x69Chw1MvWe7evfuFCnrUnDlzsGLFCqxZswb169fH0aNHMXDgQCiVSowaNQoAMHfuXCxduhRr1qyBu7s7Jk2aBJVKhTNnzsDS8uFkYcHBwbh+/TpiYmJQUFCAgQMHYujQodJNDNnZ2ejcuTP8/PywcuVKnDx5EoMGDYKtrS2GDh0KADh48CCCgoIwa9YsdOvWDWvXrkVAQACOHTuGBg0a6O01ExERkfHS6iHmjxo7dqzGckFBAZKSknDq1CmEhoZiyZIleiuuW7ducHR0xDfffCO1BQYGwsrKCj/88AOEEHB2dsZHH32EcePGAQCysrLg6OiI6Oho9O3bF2fPnoWnpyeOHDkCb29vAMDOnTvRtWtX/Pvvv3B2dsaKFSvw6aefIi0tDRYWFgCACRMm4JdffsG5c+cAAH369EFubi62bdsm1dKyZUs0btwYK1eu1Or1FD8EFRPACWYNACeYJSIibRjcQ8wftWjRolLbIyMjS1wefFGtWrXCqlWrcP78edSuXRvHjx/H/v37pTs/U1JSkJaWBj8/P2kbpVIJHx8fxMfHo2/fvoiPj4etra0UygDAz88PJiYmOHToEN59913Ex8ejbdu2UigDAJVKhTlz5uDOnTuws7NDfHw8IiIiNOpTqVT45Zdfnlh/Xl4e8vLypOXs7OwXfUuIiIjoNaa3MWbvv/++3p+TOWHCBPTt2xd169aFubk5mjRpgjFjxiA4OBgAkJaWBgBwdHTU2M7R0VFal5aWBgcHB431ZmZmqFSpkkaf0vbx6DGe1Kd4fWlmzZoFpVIpfbm4uOj0+omIiMi46C2YxcfHS2O69GXDhg348ccfsXbtWhw7dgxr1qzB/PnzsWbNGr0ep6xMnDgRWVlZ0teVK1fKuyQiIiIyYDpfyuzZs6fGshAC169fx9GjRzFp0iS9FQYAH3/8sXTWDAC8vLxw+fJlzJo1C6GhoXBycgIApKeno2rVqtJ26enp0lxrTk5OuHHjhsZ+CwsLkZGRIW3v5OSE9PR0jT7Fy8/qU7y+NHK5HHK5XNeXTUREREZK5zNmj16aUyqVqFSpEtq3b4/ff/8dU6ZM0Wtx9+7dg4mJZommpqZQq9UAAHd3dzg5OSE2NlZan52djUOHDsHX1xcA4Ovri8zMTCQkJEh9du/eDbVaDR8fH6nP3r17UVBQIPWJiYlBnTp1YGdnJ/V59DjFfYqPQ0RERPSidD5jFhUVVRZ1lKp79+6YMWMGqlevjvr16yMxMRELFy7EoEGDADx80sCYMWMwffp01KpVS5ouw9nZGQEBAQCAevXqoUuXLhgyZAhWrlyJgoIChIeHo2/fvnB2dgYA9OvXD1OnTkVYWBjGjx+PU6dOYcmSJRo3OowePRrt2rXDggUL4O/vj3Xr1uHo0aNYtWrVS3s/iIiI6PWm1XQZQohyedzS3bt3MWnSJGzZsgU3btyAs7MzgoKCMHnyZOkOSiEEpkyZglWrViEzMxOtW7fG8uXLUbt2bWk/GRkZCA8Px2+//QYTExMEBgZi6dKlsLGxkfqcOHECI0eOxJEjR1ClShV8+OGHGD9+vEY9GzduxGeffYZLly6hVq1amDt3Lrp27ar16+F0GYaF02UQEZE2XuZ0GVoFM09PT0yePBk9e/bUmFLicRcuXMDChQvh6uqKCRMm6LXQ1wGDmWFhMCMiIm0Y3DxmX3zxBcaPH48RI0agU6dO8Pb2hrOzMywtLXHnzh2cOXMG+/fvx+nTpxEeHo7hw4eXadFEREREryOtglnHjh1x9OhR7N+/H+vXr8ePP/6Iy5cv4/79+6hSpQqaNGmCkJAQBAcHS4PliYiIiEg3Og3+b926NVq3bl1WtRAREREZNb1NMEtEREREL4bBjIiIiMhAMJgRERERGQgGMyIiIiIDwWBGREREZCC0uiszOztb6x2W9cRrRERERK8rrYKZra2t1o9kKioqeqGCiIiIiIyVVsEsLi5O+v7SpUuYMGECBgwYAF9fXwBAfHw81qxZg1mzZpVNlURERERGQKtnZT6qY8eOGDx4MIKCgjTa165di1WrVmHPnj36rO+1wmdlGhY+K5OIiLTxMp+VqfPg//j4eHh7e5do9/b2xuHDh/VSFBEREZEx0jmYubi4YPXq1SXav/76a7i4uOilKCIiIiJjpNOzMgFg0aJFCAwMxI4dO+Dj4wMAOHz4MC5cuIBNmzbpvUAiIiIiY6HzGbOuXbvi/Pnz6N69OzIyMpCRkYHu3bvj/Pnz6Nq1a1nUSERERGQUdD5jBjy8nDlz5kx910JERERk1J5r5v99+/bh/fffR6tWrXD16lUAwPfff4/9+/frtTgiIiIiY6JzMNu0aRNUKhWsrKxw7Ngx5OXlAQCysrJ4Fo2IiIjoBegczKZPn46VK1di9erVMDc3l9rffPNNHDt2TK/FERERERkTnYNZcnIy2rZtW6JdqVQiMzNTHzURERERGSWdg5mTkxP+/vvvEu379+9HjRo19FIUERERkTHSOZgNGTIEo0ePxqFDhyCTyXDt2jX8+OOPGDduHIYPH14WNRIREREZBZ2ny5gwYQLUajU6duyIe/fuoW3btpDL5Rg3bhw+/PDDsqiRiIiIyCjo/BDzYvn5+fj777+Rk5MDT09P2NjY6Lu21w4fYm5Y+BBzIiLShkE/xLyYhYUFPD09UbduXfzxxx84e/asPusiIiIiMjo6B7PevXtj2bJlAID79++jefPm6N27Nxo2bMhnZRIRERG9AJ2D2d69e9GmTRsAwJYtW6BWq5GZmYmlS5di+vTpei+QiIiIyFjoHMyysrJQqVIlAMDOnTsRGBiIChUqwN/fHxcuXNB7gURERETGQudg5uLigvj4eOTm5mLnzp3o3LkzAODOnTuwtOSIdiIiIqLnpfN0GWPGjEFwcDBsbGzg6uqK9u3bA3h4idPLy0vf9REREREZDZ2D2YgRI+Dj44PU1FR06tQJJiYPT7rVqFGDY8yIiIiIXsBzz2NGuuM8ZoaF85gREZE2XuY8ZjqfMQOAf//9F1u3bkVqairy8/M11i1cuFAvhREREREZG52DWWxsLHr06IEaNWrg3LlzaNCgAS5dugQhBJo2bVoWNRIREREZBZ3vypw4cSLGjRuHkydPwtLSEps2bcKVK1fQrl07vPfee2VRIxEREZFR0DmYnT17FiEhIQAAMzMz3L9/HzY2Npg2bRrmzJmj9wKJiIiIjIXOwcza2loaV1a1alVcvHhRWnfr1i39VUZERERkZHQeY9ayZUvs378f9erVQ9euXfHRRx/h5MmT2Lx5M1q2bFkWNRIREREZBZ2D2cKFC5GTkwMAmDp1KnJycrB+/XrUqlWLd2QSERERvQCdg1mNGjWk762trbFy5Uq9FkRERERkrJ5rHjMAyM/Px40bN6BWqzXaq1ev/sJFERERERkjnYPZ+fPnERYWhoMHD2q0CyEgk8lQVFSkt+KIiIiIjInOwWzgwIEwMzPDtm3bULVqVchksrKoi4iIiMjo6BzMkpKSkJCQgLp165ZFPURERERGS+d5zDw9PTlfGREREVEZ0CqYZWdnS19z5szBJ598gj179uD27dsa67Kzs8u6XiIiIqLXllaXMm1tbTXGkgkh0LFjR40+HPxPRERE9GK0CmZxcXFlXQcRERGR0dMqmLVr166s6yAiIiIyejoP/o+KisLGjRtLtG/cuBFr1qzRS1FERERExkjnYDZr1ixUqVKlRLuDgwNmzpypl6IedfXqVbz//vuoXLkyrKys4OXlhaNHj0rrhRCYPHkyqlatCisrK/j5+eHChQsa+8jIyEBwcDAUCgVsbW0RFhYmPe+z2IkTJ9CmTRtYWlrCxcUFc+fOLVHLxo0bUbduXVhaWsLLywu///673l8vERERGS+dg1lqairc3d1LtLu6uiI1NVUvRRW7c+cO3nzzTZibm2PHjh04c+YMFixYADs7O6nP3LlzsXTpUqxcuRKHDh2CtbU1VCoVHjx4IPUJDg7G6dOnERMTg23btmHv3r0YOnSotD47OxudO3eGq6srEhISMG/ePERGRmLVqlVSn4MHDyIoKAhhYWFITExEQEAAAgICcOrUKb2+ZiIiIjJeMiGE0GWD6tWrY9myZejRo4dG+6+//oqRI0fi33//1VtxEyZMwIEDB7Bv375S1wsh4OzsjI8++gjjxo0DAGRlZcHR0RHR0dHo27cvzp49C09PTxw5cgTe3t4AgJ07d6Jr1674999/4ezsjBUrVuDTTz9FWloaLCwspGP/8ssvOHfuHACgT58+yM3NxbZt26Tjt2zZEo0bN9b6Qe7Z2dlQKpXABACWz/uukL6IKTp99ImIyEgV//3OysqCQqEo02PpfMYsKCgIo0aNQlxcHIqKilBUVITdu3dj9OjR6Nu3r16L27p1K7y9vfHee+/BwcEBTZo0werVq6X1KSkpSEtLg5+fn9SmVCrh4+OD+Ph4AEB8fDxsbW2lUAYAfn5+MDExwaFDh6Q+bdu2lUIZAKhUKiQnJ+POnTtSn0ePU9yn+DilycvL4zxvREREpDWdg9nnn38OHx8fdOzYEVZWVrCyskLnzp3x1ltv6X2M2T///IMVK1agVq1a2LVrF4YPH45Ro0ZJNxmkpaUBABwdHTW2c3R0lNalpaXBwcFBY72ZmRkqVaqk0ae0fTx6jCf1KV5fmlmzZkGpVEpfLi4uOr1+IiIiMi46PStTCIG0tDRER0dj+vTpSEpKkgbku7q66r04tVoNb29vKfA1adIEp06dwsqVKxEaGqr34+nbxIkTERERIS1nZ2cznBEREdET6RzMPDw8cPr0adSqVQu1atUqq7oAAFWrVoWnp6dGW7169bBp0yYAgJOTEwAgPT0dVatWlfqkp6ejcePGUp8bN25o7KOwsBAZGRnS9k5OTkhPT9foU7z8rD7F60sjl8shl8u1eq1EREREOl3KNDExQa1atXD79u2yqkfDm2++ieTkZI228+fPS2fn3N3d4eTkhNjYWGl9dnY2Dh06BF9fXwCAr68vMjMzkZCQIPXZvXs31Go1fHx8pD579+5FQUGB1CcmJgZ16tSR7gD19fXVOE5xn+LjEBEREb0onceYzZ49Gx9//PFLmSZi7Nix+OuvvzBz5kz8/fffWLt2LVatWoWRI0cCAGQyGcaMGYPp06dj69atOHnyJEJCQuDs7IyAgAAAD8+wdenSBUOGDMHhw4dx4MABhIeHo2/fvnB2dgYA9OvXDxYWFggLC8Pp06exfv16LFmyROMy5OjRo7Fz504sWLAA586dQ2RkJI4ePYrw8PAyfx+IiIjIOOg8XYadnR3u3buHwsJCWFhYwMrKSmN9RkaGXgvctm0bJk6ciAsXLsDd3R0REREYMmSItF4IgSlTpmDVqlXIzMxE69atsXz5ctSuXVujpvDwcPz2228wMTFBYGAgli5dChsbG6nPiRMnMHLkSBw5cgRVqlTBhx9+iPHjx2vUsnHjRnz22We4dOkSatWqhblz56Jr165avxZOl2FYOF0GERFp42VOl6FzMHvWY5dehUH55YXBzLAwmBERkTZeZjDTafA/wOBFREREVFZ0DmbPeuxS9erVn7sYIiIiImOmczBzc3ODTCZ74vqioqIXKoiIiIjIWOkczBITEzWWCwoKkJiYiIULF2LGjBl6K4yIiIjI2OgczBo1alSizdvbG87Ozpg3bx569uypl8KIiIiIjI3O85g9SZ06dXDkyBF97Y6IiIjI6Oh8xiw7O1tjWQiB69evIzIysswf0URERET0OtM5mNna2pYY/C+EgIuLC9atW6e3woiIiIiMjc7BLC4uTmPZxMQE9vb28PDwgJmZzrsjIiIiov/RKUllZ2cjPz8f+fn5aNGiBezt7cuqLiIiIiKjo3UwS0pKQteuXZGeng4hBCpWrIgNGzZApVKVZX1ERERERkPruzLHjx8Pd3d37N+/HwkJCejYsSPCw8PLsjYiIiIio6L1GbOEhAT897//RdOmTQEA3377LSpVqoTs7Owyf6AnERERkTHQ+oxZRkYGqlWrJi3b2trC2toat2/fLpPCiIiIiIyNToP/z5w5g7S0NGlZCIGzZ8/i7t27UlvDhg31Vx0RERGREdEpmHXs2BFCCI22bt26QSaTQQgBmUzGh5gTERERPSetg1lKSkpZ1kFERERk9LQOZq6urmVZBxEREZHR09tDzImIiIjoxTCYERERERkIBjMiIiIiA8FgRkRERGQgdA5mU6ZMweXLl8uiFiIiIiKjpnMw+/XXX1GzZk107NgRa9euRV5eXlnURURERGR0dA5mSUlJOHLkCOrXr4/Ro0fDyckJw4cPx5EjR8qiPiIiIiKj8VxjzJo0aYKlS5fi2rVr+Oabb/Dvv//izTffRMOGDbFkyRJkZWXpu04iIiKi194LDf4XQqCgoAD5+fkQQsDOzg7Lli2Di4sL1q9fr68aiYiIiIzCcwWzhIQEhIeHo2rVqhg7diyaNGmCs2fP4s8//8SFCxcwY8YMjBo1St+1EhEREb3WdA5mXl5eaNmyJVJSUvDNN9/gypUrmD17Njw8PKQ+QUFBuHnzpl4LJSIiInrdaf2szGK9e/fGoEGD8MYbbzyxT5UqVaBWq1+oMCIiIiJjo/MZs+KxZI+7f/8+pk2bppeiiIiIiIyRTAghdNnA1NQU169fh4ODg0b77du34eDggKKiIr0W+DrJzs6GUqkEJgCwLO9qSEzR6aNPRERGqvjvd1ZWFhQKRZke67nOmMlkshLtx48fR6VKlfRSFBEREZEx0nqMmZ2dHWQyGWQyGWrXrq0RzoqKipCTk4MPPvigTIokIiIiMgZaB7PFixdDCIFBgwZh6tSpDy/J/Y+FhQXc3Nzg6+tbJkUSERERGQOtg1loaCgAwN3dHa1atYK5uXmZFUVERERkjLQKZtnZ2dJgtyZNmuD+/fu4f/9+qX3LelAcERER0etKq2BmZ2cn3Ylpa2tb6uD/4psCeFcmERER0fPRKpjt3r1buuNy9+7dpQYzIiIiInoxWgWzdu3aSd+3b9++rGohIiIiMmo6z2MWFRWFjRs3lmjfuHEj1qxZo5eiiIiIiIyRzsFs1qxZqFKlSol2BwcHzJw5Uy9FERERERkjnYNZamoq3N3dS7S7uroiNTVVL0URERERGSOdg5mDgwNOnDhRov348eOoXLmyXooiIiIiMkY6B7OgoCCMGjUKcXFxKCoqQlFREXbv3o3Ro0ejb9++ZVEjERERkVHQeub/Yp9//jkuXbqEjh07wszs4eZqtRohISEcY0ZERET0AmRCCPE8G54/fx7Hjx+HlZUVvLy84Orqqu/aXjvZ2dkPnzE6AYBleVdDYspzffSJiMjIFP/9zsrKKvMnHOl8xqxY7dq1Ubt2bX3WQkRERGTUtApmERER+Pzzz2FtbY2IiIin9l24cKFeCiMiIiIyNloFs8TERBQUFAAAjh079sRHMvFRTURERETPT6u7MuPi4mBrawsA2LNnD+Li4kr92r17d1nWitmzZ0Mmk2HMmDFS24MHDzBy5EhUrlwZNjY2CAwMRHp6usZ2qamp8Pf3R4UKFeDg4ICPP/4YhYWFGn327NmDpk2bQi6Xw8PDA9HR0SWO/+WXX8LNzQ2Wlpbw8fHB4cOHy+JlEhERkZHSabqMgoICmJmZ4dSpU2VVzxMdOXIEX331FRo2bKjRPnbsWPz222/YuHEj/vzzT1y7dg09e/aU1hcVFcHf3x/5+fk4ePAg1qxZg+joaEyePFnqk5KSAn9/f3To0AFJSUkYM2YMBg8ejF27dkl91q9fj4iICEyZMgXHjh1Do0aNoFKpcOPGjbJ/8URERGQUdL4rs0aNGtiyZQsaNWpUVjWVkJOTg6ZNm2L58uWYPn06GjdujMWLFyMrKwv29vZYu3YtevXqBQA4d+4c6tWrh/j4eLRs2RI7duxAt27dcO3aNTg6OgIAVq5cifHjx+PmzZuwsLDA+PHjsX37do3A2bdvX2RmZmLnzp0AAB8fHzRv3hzLli0D8HCKEBcXF3z44YeYMGGCVq+Dd2UaFt6VSURE2niZd2XqPMHsp59+iv/85z/IyMgoi3pKNXLkSPj7+8PPz0+jPSEhAQUFBRrtdevWRfXq1REfHw8AiI+Ph5eXlxTKAEClUiE7OxunT5+W+jy+b5VKJe0jPz8fCQkJGn1MTEzg5+cn9SEiIiJ6UTpPl7Fs2TL8/fffcHZ2hqurK6ytrTXWHzt2TG/FAcC6detw7NgxHDlypMS6tLQ0WFhYSOPfijk6OiItLU3q82goK15fvO5pfbKzs3H//n3cuXMHRUVFpfY5d+7cE2vPy8tDXl6etJydnf2MV0tERETGTOdg9s4777y0uy+vXLmC0aNHIyYmBpaWr961v1mzZmHq1KnlXQYRERG9InQOZpGRkWVQRukSEhJw48YNNG3aVGorKirC3r17sWzZMuzatQv5+fnIzMzUOGuWnp4OJycnAICTk1OJuyeL79p8tM/jd3Kmp6dDoVDAysoKpqamMDU1LbVP8T5KM3HiRI1537Kzs+Hi4qLDO0BERETGROcxZjVq1MDt27dLtGdmZqJGjRp6KapYx44dcfLkSSQlJUlf3t7eCA4Olr43NzdHbGystE1ycjJSU1Ph6+sLAPD19cXJkyc17p6MiYmBQqGAp6en1OfRfRT3Kd6HhYUFmjVrptFHrVYjNjZW6lMauVwOhUKh8UVERET0JDqfMbt06RKKiopKtOfl5eHff//VS1HFKlasiAYNGmi0WVtbo3LlylJ7WFgYIiIiUKlSJSgUCnz44Yfw9fVFy5YtAQCdO3eGp6cn+vfvj7lz5yItLQ2fffYZRo4cCblcDgD44IMPsGzZMnzyyScYNGgQdu/ejQ0bNmD79u3ScSMiIhAaGgpvb2+0aNECixcvRm5uLgYOHKjX10xERETGS+tgtnXrVun7Xbt2PZz24X+KiooQGxsLd3d3/VanhUWLFsHExASBgYHIy8uDSqXC8uXLpfWmpqbYtm0bhg8fDl9fX1hbWyM0NBTTpk2T+ri7u2P79u0YO3YslixZgmrVquHrr7+GSqWS+vTp0wc3b97E5MmTkZaWhsaNG2Pnzp0lbgggIiIiel5az2NmYvLwqqdMJsPjm5ibm8PNzQ0LFixAt27d9F/la4LzmBkWzmNGRETaeJnzmGl9xkytVgN4eHbpyJEjqFKlSpkVRURERGSMdB5jlpKSUhZ1EBERERk9ne/KHDVqFJYuXVqifdmyZRoPFyciIiIi3egczDZt2oQ333yzRHurVq3w888/66UoIiIiImOkczC7ffu2xh2ZxRQKBW7duqWXooiIiIiMkc7BzMPDAzt37izRvmPHDr1PMEtERERkTHQe/B8REYHw8HDcvHkTb731FgAgNjYWCxYswOLFi/VdHxEREZHR0DmYDRo0CHl5eZgxYwY+//xzAICbmxtWrFiBkJAQvRdIREREZCy0nmC2NDdv3oSVlRVsbGz0WdNrixPMGhZOMEtERNp4mRPM6jzGDAAKCwvxxx9/YPPmzdJTAK5du4acnBy9FkdERERkTHS+lHn58mV06dIFqampyMvLQ6dOnVCxYkXMmTMHeXl5WLlyZVnUSURERPTa0/mM2ejRo+Ht7Y07d+7AyspKan/33XcRGxur1+KIiIiIjInOZ8z27duHgwcPwsLCQqPdzc0NV69e1VthRERERMZG5zNmarUaRUVFJdr//fdfVKxYUS9FERERERkjnYNZ586dNeYrk8lkyMnJwZQpU9C1a1d91kZERERkVHS+lLlgwQKoVCp4enriwYMH6NevHy5cuIAqVargp59+KosaiYiIiIyCzsGsWrVqOH78ONatW4cTJ04gJycHYWFhCA4O1rgZgIiIiIh0o3MwAwAzMzO8//77+q6FiIiIyKhpFcy2bt2q9Q579Ojx3MUQERERGTOtgllAQIBWO5PJZKXesUlEREREz6ZVMFOr1WVdBxEREZHRe65nZRIRERGR/mkdzLp27YqsrCxpefbs2cjMzJSWb9++DU9PT70WR0RERGRMtA5mu3btQl5enrQ8c+ZMZGRkSMuFhYVITk7Wb3VERERERkTrYCaEeOoyEREREb0YjjEjIiIiMhBaBzOZTAaZTFaijYiIiIj0Q+uZ/4UQGDBgAORyOQDgwYMH+OCDD2BtbQ0AGuPPiIiIiEh3Wgez0NBQjeXSHskUEhLy4hURERERGSmtg1lUVFRZ1kFERERk9Dj4n4iIiMhAMJgRERERGQgGMyIiIiIDwWBGREREZCAYzIiIiIgMBIMZERERkYFgMCMiIiIyEAxmRERERAaCwYyIiIjIQDCYERERERkIBjMiIiIiA8FgRkRERGQgGMyIiIiIDASDGREREZGBYDAjIiIiMhAMZkREREQGgsGMiIiIyEAwmBEREREZCAYzIiIiIgPBYEZERERkIMzKuwAiekFrZeVdAZHh6SfKuwKi52LQZ8xmzZqF5s2bo2LFinBwcEBAQACSk5M1+jx48AAjR45E5cqVYWNjg8DAQKSnp2v0SU1Nhb+/PypUqAAHBwd8/PHHKCws1OizZ88eNG3aFHK5HB4eHoiOji5Rz5dffgk3NzdYWlrCx8cHhw8f1vtrJiIiIuNl0MHszz//xMiRI/HXX38hJiYGBQUF6Ny5M3Jzc6U+Y8eOxW+//YaNGzfizz//xLVr19CzZ09pfVFREfz9/ZGfn4+DBw9izZo1iI6OxuTJk6U+KSkp8Pf3R4cOHZCUlIQxY8Zg8ODB2LVrl9Rn/fr1iIiIwJQpU3Ds2DE0atQIKpUKN27ceDlvBhEREb32ZEKIV+Z8782bN+Hg4IA///wTbdu2RVZWFuzt7bF27Vr06tULAHDu3DnUq1cP8fHxaNmyJXbs2IFu3brh2rVrcHR0BACsXLkS48ePx82bN2FhYYHx48dj+/btOHXqlHSsvn37IjMzEzt37gQA+Pj4oHnz5li2bBkAQK1Ww8XFBR9++CEmTJigVf3Z2dlQKpXABACWenxj6LmIKa/MR//peCmTqCReyiQ9Kv77nZWVBYVCUabHMugzZo/LysoCAFSqVAkAkJCQgIKCAvj5+Ul96tati+rVqyM+Ph4AEB8fDy8vLymUAYBKpUJ2djZOnz4t9Xl0H8V9iveRn5+PhIQEjT4mJibw8/OT+pQmLy8P2dnZGl9ERERET/LKBDO1Wo0xY8bgzTffRIMGDQAAaWlpsLCwgK2trUZfR0dHpKWlSX0eDWXF64vXPa1PdnY27t+/j1u3bqGoqKjUPsX7KM2sWbOgVCqlLxcXF91fOBERERmNVyaYjRw5EqdOncK6devKuxStTZw4EVlZWdLXlStXyrskIiIiMmCvxHQZ4eHh2LZtG/bu3Ytq1apJ7U5OTsjPz0dmZqbGWbP09HQ4OTlJfR6/e7L4rs1H+zx+J2d6ejoUCgWsrKxgamoKU1PTUvsU76M0crkccrlc9xdMRERERsmgz5gJIRAeHo4tW7Zg9+7dcHd311jfrFkzmJubIzY2VmpLTk5GamoqfH19AQC+vr44efKkxt2TMTExUCgU8PT0lPo8uo/iPsX7sLCwQLNmzTT6qNVqxMbGSn2IiIiIXpRBnzEbOXIk1q5di19//RUVK1aUxnMplUpYWVlBqVQiLCwMERERqFSpEhQKBT788EP4+vqiZcuWAIDOnTvD09MT/fv3x9y5c5GWlobPPvsMI0eOlM5mffDBB1i2bBk++eQTDBo0CLt378aGDRuwfft2qZaIiAiEhobC29sbLVq0wOLFi5Gbm4uBAwe+/DeGiIiIXksGHcxWrFgBAGjfvr1Ge1RUFAYMGAAAWLRoEUxMTBAYGIi8vDyoVCosX75c6mtqaopt27Zh+PDh8PX1hbW1NUJDQzFt2jSpj7u7O7Zv346xY8diyZIlqFatGr7++muoVCqpT58+fXDz5k1MnjwZaWlpaNy4MXbu3FnihgAiIiKi5/VKzWP2quM8ZoaF85gRvcY4jxnpEecxIyIiIjJCDGZEREREBoLBjIiIiMhAGPTgfyIiIqMm4xhSY8MzZkREREQGgsGMiIiIyEAwmBEREREZCAYzIiIiIgPBYEZERERkIBjMiIiIiAwEgxkRERGRgWAwIyIiIjIQDGZEREREBoLBjIiIiMhAMJgRERERGQgGMyIiIiIDwWBGREREZCAYzIiIiIgMBIMZERERkYFgMCMiIiIyEAxmRERERAaCwYyIiIjIQDCYERERERkIBjMiIiIiA8FgRkRERGQgGMyIiIiIDASDGREREZGBYDAjIiIiMhAMZkREREQGgsGMiIiIyEAwmBEREREZCAYzIiIiIgPBYEZERERkIBjMiIiIiAwEgxkRERGRgWAwIyIiIjIQDGZEREREBoLBjIiIiMhAMJgRERERGQgGMyIiIiIDwWBGREREZCAYzIiIiIgMBIMZERERkYFgMCMiIiIyEAxmRERERAaCwYyIiIjIQDCYERERERkIBjMiIiIiA8FgRkRERGQgGMyIiIiIDASDmY6+/PJLuLm5wdLSEj4+Pjh8+HB5l0RERESvCQYzHaxfvx4RERGYMmUKjh07hkaNGkGlUuHGjRvlXRoRERG9BhjMdLBw4UIMGTIEAwcOhKenJ1auXIkKFSrg22+/Le/SiIiI6DXAYKal/Px8JCQkwM/PT2ozMTGBn58f4uPjy7EyIiIiel2YlXcBr4pbt26hqKgIjo6OGu2Ojo44d+5cqdvk5eUhLy9PWs7KyvrfijIrk3SQnZ1d3iXox73yLoDIAL0uP99kEIo/TUKIMj8Wg1kZmjVrFqZOnVpyxaKXXwuVpJytLO8SiKisDOHPN+nf7du3oVSW7WeLwUxLVapUgampKdLT0zXa09PT4eTkVOo2EydOREREhLScmZkJV1dXpKamlvk/LBG9XNnZ2XBxccGVK1egUCjKuxwi0qOsrCxUr14dlSpVKvNjMZhpycLCAs2aNUNsbCwCAgIAAGq1GrGxsQgPDy91G7lcDrlcXqJdqVTyFzfRa0qhUPDnm+g1ZWJS9kPzGcx0EBERgdDQUHh7e6NFixZYvHgxcnNzMXDgwPIujYiIiF4DDGY66NOnD27evInJkycjLS0NjRs3xs6dO0vcEEBERET0PBjMdBQeHv7ES5fPIpfLMWXKlFIvbxLRq40/30Svr5f58y0TL+PeTyIiIiJ6Jk4wS0RERGQgGMyIiIiIDASDGREREZGBYDDTwb179xAYGAiFQgGZTIbMzMxS28pDZGQkGjduXC7HJqInu3TpEmQyGZKSkl6pfROR7tq3b48xY8a80D4YzABcuXIFgwYNgrOzMywsLODq6orRo0fj9u3bGv3WrFmDffv24eDBg7h+/TqUSmWpbY+Ljo6GTCaDTCaDiYkJqlWrhoEDB+LGjRsv6yUSGZWbN29i+PDhqF69OuRyOZycnKBSqXDgwAEAgEwmwy+//FK+RRLRSzdgwADp77GFhQU8PDwwbdo0FBYWlndpEqOfLuOff/6Br68vateujZ9++gnu7u44ffo0Pv74Y+zYsQN//fWX9AiGixcvol69emjQoIG0fWltpVEoFEhOToZarcbx48cxcOBAXLt2Dbt27SrT10dkjAIDA5Gfn481a9agRo0aSE9PR2xsbIn/bL0q8vPzYWFhUd5lEL0WunTpgqioKOTl5eH333/HyJEjYW5ujokTJ5Z3aQ8JI9elSxdRrVo1ce/ePY3269eviwoVKogPPvhACCFEu3btBADpq127dqW2lSYqKkoolUqNthkzZggTExPpuKtXrxZ169YVcrlc1KlTR3z55Zca/T/55BNRq1YtYWVlJdzd3cVnn30m8vPzpfVTpkwRjRo1kpb//vtv4e7uLkaOHCnUavVzvjtEr547d+4IAGLPnj2lrnd1ddX4uXV1dRVCPPyZ6dGjh3BwcBDW1tbC29tbxMTElNh2xowZYuDAgcLGxka4uLiIr776SqPPoUOHROPGjYVcLhfNmjUTmzdvFgBEYmKiEEKIwsJCMWjQIOHm5iYsLS1F7dq1xeLFizX2ERoaKt555x0xffp0UbVqVeHm5qbVvono6Yp/th7VqVMn0bJlS/HgwQPx0UcfCWdnZ1GhQgXRokULERcXJ/W7deuW6Nu3r3B2dhZWVlaiQYMGYu3atRr7ateunRg9erS0vG3bNqFQKMQPP/ygdY1GfSkzIyMDu3btwogRI2BlZaWxzsnJCcHBwVi/fj2EENi8eTOGDBkCX19fXL9+HZs3by61TVtWVlZQq9UoLCzEjz/+iMmTJ2PGjBk4e/YsZs6ciUmTJmHNmjVS/4oVKyI6OhpnzpzBkiVLsHr1aixatKjUfZ84cQKtW7dGv379sGzZMshksud7g4heQTY2NrCxscEvv/yCvLy8EuuPHDkCAIiKisL169el5ZycHHTt2hWxsbFITExEly5d0L17d6Smpmpsv2DBAnh7eyMxMREjRozA8OHDkZycLO2jW7du8PT0REJCAiIjIzFu3DiN7dVqNapVq4aNGzfizJkzmDx5Mv7zn/9gw4YNGv1iY2ORnJyMmJgYbNu2Tat9E5HurKyskJ+fj/DwcMTHx2PdunU4ceIE3nvvPXTp0gUXLlwAADx48ADNmjXD9u3bcerUKQwdOhT9+/fH4cOHS93v2rVrERQUhB9//BHBwcHaF/QcgfO18ddffwkAYsuWLaWuX7hwoQAg0tPThRBCjB49usRZsdLaHvf4GbPz58+L2rVrC29vbyGEEDVr1iyRuj///HPh6+v7xH3OmzdPNGvWTFouPmN24MABYWdnJ+bPn//UmoheZz///LOws7MTlpaWolWrVmLixIni+PHj0vqn/dw/qn79+uKLL76Qll1dXcX7778vLavVauHg4CBWrFghhBDiq6++EpUrVxb379+X+qxYseKZZ7VGjhwpAgMDpeXQ0FDh6Ogo8vLypLbn3TcR/b9Hz5ip1WoRExMj5HK5GDBggDA1NRVXr17V6N+xY0cxceLEJ+7P399ffPTRR9Jy8RmzZcuWCaVS+cQz909j9GPMAEC8hIcfZGVlwcbGBmq1Gg8ePEDr1q3x9ddfIzc3FxcvXkRYWBiGDBki9S8sLNS4kWD9+vVYunQpLl68iJycHBQWFkKhUGgcIzU1FZ06dcKMGTNe+K4QoldZYGAg/P39sW/fPvz111/YsWMH5s6di6+//hoDBgwodZucnBxERkZi+/btuH79OgoLC3H//v0SZ8waNmwofS+TyeDk5CTdyHP27Fk0bNgQlpaWUh9fX98Sx/ryyy/x7bffIjU1Fffv30d+fn6Ju6q9vLw0xpVpu28ierpt27bBxsYGBQUFUKvV6NevH3r16oXo6GjUrl1bo29eXh4qV64MACgqKsLMmTOxYcMGXL16Ffn5+cjLy0OFChU0tvn5559x48YNHDhwAM2bN9e5PqMOZh4eHpDJZDh79izefffdEuvPnj0LOzs72Nvbv/CxKlasiGPHjsHExARVq1aVLp2mp6cDAFavXg0fHx+NbUxNTQEA8fHxCA4OxtSpU6FSqaBUKrFu3TosWLBAo7+9vT2cnZ3x008/YdCgQSWCG5ExsbS0RKdOndCpUydMmjQJgwcPxpQpU54YzMaNG4eYmBjMnz8fHh4esLKyQq9evZCfn6/Rz9zcXGNZJpNBrVZrXde6deswbtw4LFiwAL6+vqhYsSLmzZuHQ4cOafSztrbWep9EpL0OHTpgxYoVsLCwgLOzM8zMzLB+/XqYmpoiISFB+ttbzMbGBgAwb948LFmyBIsXL4aXlxesra0xZsyYEr8jmjRpgmPHjuHbb7+Ft7e3zsOJjDqYVa5cGZ06dcLy5csxduxYjXFmaWlp+PHHHxESEqKXMVomJibw8PAo0e7o6AhnZ2f8888/T7wGffDgQbi6uuLTTz+V2i5fvlyin5WVFbZt24auXbtCpVLhv//9LypWrPjCtRO9Djw9PaUpMszNzVFUVKSx/sCBAxgwYID0n7ScnBxcunRJp2PUq1cP33//PR48eCCd2frrr79KHKdVq1YYMWKE1Hbx4kW97JuIns3a2rrE3+MmTZqgqKgIN27cQJs2bUrd7sCBA3jnnXfw/vvvA3g4XvT8+fPw9PTU6FezZk0sWLAA7du3h6mpKZYtW6ZTfUY9+B8Ali1bhry8PKhUKuzduxdXrlzBzp070alTJ7zxxhuYMWNGmdcwdepUzJo1C0uXLsX58+dx8uRJREVFYeHChQCAWrVqITU1FevWrcPFixexdOlSbNmypdR9WVtbY/v27TAzM8Pbb7+NnJycMq+fyJDcvn0bb731Fn744QecOHECKSkp2LhxI+bOnYt33nkHAODm5obY2FikpaXhzp07AB7+nG3evBlJSUk4fvw4+vXrp9OZMADo168fZDIZhgwZgjNnzuD333/H/PnzNfrUqlULR48exa5du3D+/HlMmjRJugHhRfdNRM+ndu3aCA4ORkhICDZv3oyUlBQcPnwYs2bNwvbt2wE8/NmNiYnBwYMHcfbsWQwbNky66lXa/uLi4rBp0yadhxYZfTAr/iVZo0YN9O7dGzVr1sTQoUPRoUMHxMfHS3OYlaXBgwfj66+/RlRUFLy8vNCuXTtER0fD3d0dANCjRw+MHTsW4eHhaNy4MQ4ePIhJkyY9cX82NjbYsWMHhBDw9/dHbm5umb8GIkNhY2MDHx8fLFq0CG3btkWDBg0wadIkDBkyRPqf64IFCxATEwMXFxc0adIEALBw4ULY2dmhVatW6N69O1QqFZo2barzsX/77TecPHkSTZo0waeffoo5c+Zo9Bk2bBh69uyJPn36wMfHB7dv39Y4e/Yi+yai5xcVFYWQkBB89NFHqFOnDgICAnDkyBFUr14dAPDZZ5+hadOmUKlUaN++PZycnBAQEPDE/dWpUwe7d+/GTz/9hI8++kjrOmTiZYx8JyIiIqJnMvozZkRERESGgsGMiIiIyEAwmBEREREZCAYzIiIiIgPBYEZERERkIBjMiIiIiAwEgxkRERGRgWAwIyJ6xKVLlyCTyZCUlCS1HThwAF5eXjA3N5cmlCytjYjoRTGYEdErSyaTPfUrMjJS5326uLjg+vXraNCggdQWERGBxo0bIyUlBdHR0U9se1z79u2lWiwtLVG7dm3MmjULus7r7ebmhsWLF+v8Wojo1WPUDzEnolfb9evXpe/Xr1+PyZMnIzk5WWqzsbHRaX/5+fmwsLCAk5OTRvvFixfxwQcfoFq1ak9tK82QIUMwbdo05OXlYffu3Rg6dChsbW0xfPhwnWojIuPAM2ZE9MpycnKSvpRKJWQymbScm5uL4OBgODo6wsbGBs2bN8cff/yhsb2bmxs+//xzhISEQKFQYOjQoRqXMou/v337NgYNGgSZTIbo6OhS256kQoUKcHJygqurKwYOHIiGDRsiJiZGWn/x4kW88847T6yzffv2uHz5MsaOHSudfSu2f/9+tGnTBlZWVnBxccGoUaP4bFyiVxyDGRG9lnJyctC1a1fExsYiMTERXbp0Qffu3ZGamqrRb/78+WjUqBESExMxadIkjXXFlzUVCgUWL16M69ev47333ivR1qdPn2fWI4TAvn37cO7cOVhYWGhd5+bNm1GtWjVMmzYN169fl84SXrx4EV26dEFgYCBOnDiB9evXY//+/QgPD3/Rt46IypMgInoNREVFCaVS+dQ+9evXF1988YW07OrqKgICAjT6pKSkCAAiMTFRalMqlSIqKkqjX2ltj2vXrp0wNzcX1tbWwtzcXAAQlpaW4sCBAzrXuWjRIo0+YWFhYujQoRpt+/btEyYmJuL+/ftP3T8RGS6eMSOi11JOTg7GjRuHevXqwdbWFjY2Njh79myJM2be3t5lWkdwcDCSkpJw4MABvP322/j000/RqlUrnet83PHjxxEdHQ0bGxvpS6VSQa1WIyUlpUxfExGVHQ7+J6LX0rhx4xATE4P58+fDw8MDVlZW6NWrF/Lz8zX6WVtbl2kdSqUSHh4eAIANGzbAw8MDLVu2hJ+fn051Pi4nJwfDhg3DqFGjSqyrXr26/l8IEb0UDGZE9Fo6cOAABgwYgHfffRfAwyBz6dKlcq3JxsYGo0ePxrhx45CYmAiZTKZVnRYWFigqKtJoa9q0Kc6cOSOFPiJ6PfBSJhG9lmrVqoXNmzcjKSkJx48fR79+/aBWq8u7LAwbNgznz5/Hpk2bAGhXp5ubG/bu3YurV6/i1q1bAIDx48fj4MGDCA8PR1JSEi5cuIBff/2Vg/+JXnEMZkT0Wlq4cCHs7OzQqlUrdO/eHSqVCk2bNi3vslCpUiWEhIQgMjISarVaqzqnTZuGS5cuoWbNmrC3twcANGzYEH/++SfOnz+PNm3aoEmTJpg8eTKcnZ3L42URkZ7IhNBxCmoiIiIiKhM8Y0ZERERkIBjMiIiIiAwEgxkRERGRgWAwIyIiIjIQDGZEREREBoLBjIiIiMhAMJgRERERGQgGMyIiIiIDwWBGREREZCAYzIiIiIgMBIMZERERkYFgMCMiIiIyEP8HwRfihIq9uZMAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "config = {\n",
        "    \"policy_type\": \"MultiInputPolicy\",\n",
        "    \"total_timesteps\": 2760,\n",
        "}\n",
        "\n",
        "run = wandb.init(\n",
        "    project=\"4022_intelligent_ems\",\n",
        "    config=config,\n",
        "    sync_tensorboard=True,  # auto-upload sb3's tensorboard metrics\n",
        "    monitor_gym=True,  # auto-upload the videos of agents playing the game\n",
        "    save_code=True,  # optional\n",
        ")\n",
        "\n",
        "\n",
        "eval_args = {\n",
        "                \"episode_len\"   :2760,\n",
        "                \"actual_load\"   :actual_load[6001:],\n",
        "                \"actual_gen\"    :actual_gen[6001:],\n",
        "                \"bat_threshold\" :100,\n",
        "                \"bat_cap\"       :500,\n",
        "                \"purchase_price\":purchase_price[6001:],\n",
        "                \"num_preds\"     :24,\n",
        "                \"load_shedding\" :load_shedding[6001:],\n",
        "                \"wandb_log\"     : True,\n",
        "                \"train_log\"     : False\n",
        "}\n",
        "\n",
        "#define 5 environments   for training and eval\n",
        "n_envs = 5\n",
        "eval_env = make_vec_env(EMS, n_envs = n_envs,env_kwargs = eval_args )\n",
        "\n",
        "\n",
        "#first run it with only standby (default)\n",
        "obs   = eval_env.reset()\n",
        "#ensure that the exit condition is reset\n",
        "done = [False]*n_envs\n",
        "#define the action to take\n",
        "action_standby = [0]*n_envs\n",
        "#reset score\n",
        "standby_score = [0]*n_envs\n",
        "standby_score = np.array(standby_score).astype(np.float32)\n",
        "while not all(done):\n",
        "    #step the model with the action\n",
        "    obs,reward,done,info = eval_env.step(action_standby)\n",
        "    #accumulate the score\n",
        "    standby_score += reward\n",
        "\n",
        "avg_standby_score = standby_score.mean()\n",
        "\n",
        "run.finish()\n",
        "\n",
        "eval_args = {\n",
        "                \"episode_len\"   :2760,\n",
        "                \"actual_load\"   :actual_load[6001:],\n",
        "                \"actual_gen\"    :actual_gen[6001:],\n",
        "                \"bat_threshold\" :100,\n",
        "                \"bat_cap\"       :500,\n",
        "                \"purchase_price\":purchase_price[6001:],\n",
        "                \"num_preds\"     :24,\n",
        "                \"load_shedding\" :load_shedding[6001:],\n",
        "                \"wandb_log\"     : True,\n",
        "                \"train_log\"     : False\n",
        "}\n",
        "\n",
        "#define 5 environments   for training and eval\n",
        "n_envs = 5\n",
        "eval_env = make_vec_env(EMS, n_envs = n_envs,env_kwargs = eval_args )\n",
        "\n",
        "#Load model, fetch the latest (or whichever one you want from the model_dir)\n",
        "#Best A2C model:/content/drive/MyDrive/Colab Notebooks/EMSv1_1/models/A2C/EMSv1_1_A2C1010-081818.zip\n",
        "best_model = \"/content/drive/MyDrive/Colab Notebooks/EMSv1_1/models/A2C/EMSv1_1_A2C1010-081818.zip\"\n",
        "#best_model = \"/content/drive/MyDrive/Colab Notebooks/EMSv1_1/models/DQN/EMSv1_1_DQN1010-082002.zip\"\n",
        "#best_PPO_model\n",
        "model_load = f\"{best_model}\"\n",
        "\n",
        "model  = A2C.load(model_load, env = eval_env)\n",
        "\n",
        "run = wandb.init(\n",
        "    project=\"4022_intelligent_ems\",\n",
        "    config=config,\n",
        "    sync_tensorboard=True,  # auto-upload sb3's tensorboard metrics\n",
        "    monitor_gym=True,  # auto-upload the videos of agents playing the game\n",
        "    save_code=True,  # optional\n",
        ")\n",
        "obs   = eval_env.reset()\n",
        "EMS_reward,EMS_std_reward = evaluate_policy(model,eval_env,n_eval_episodes = 1,deterministic=True)# callback = wandb_callback\n",
        "run.finish()\n",
        "\n",
        "print(f\"Note: The term does not refer to the cost in rands but rather to the reward as defined by the reward function!\")\n",
        "print(f\"Done the Standby Test! Total cost accumulated is: {avg_standby_score}\")\n",
        "print(f\"Done applying the trained model! Total cost accumulated is: {EMS_reward} +- {EMS_std_reward}\")\n",
        "\n",
        "savings = EMS_reward - avg_standby_score\n",
        "print(f\"The amount that was saved by applying the EMS agent: {savings}\")\n",
        "print(f\"This was saved over a period of {2760/24} days\")\n",
        "print(f\"The savings represents {(savings/(-avg_standby_score))*100} % of the cost if no EMS is installed\")\n",
        "print(f\"And it represents {(savings/(-EMS_reward))*100} % of the cost if the EMS is installed\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8cb895e4501c4ae691d1c0e16bbeff6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_01bf93678a664549adaaf7a3de9c7c58",
              "IPY_MODEL_e128a15f6eed43f088bac4b0f4774eaa"
            ],
            "layout": "IPY_MODEL_e7fd497832354e66868a18ec4a8f67f3"
          }
        },
        "01bf93678a664549adaaf7a3de9c7c58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fbea4ded8554ed0bd4e14450d2ead83",
            "placeholder": "",
            "style": "IPY_MODEL_40ef7a65c9ed4981b0e58c2dccee6a1e",
            "value": "0.001 MB of 0.013 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "e128a15f6eed43f088bac4b0f4774eaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07d0d79e54164408a150353b22a987e8",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e88cb6c26134495ea358d489dfebe946",
            "value": 0.09842262121101984
          }
        },
        "e7fd497832354e66868a18ec4a8f67f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fbea4ded8554ed0bd4e14450d2ead83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40ef7a65c9ed4981b0e58c2dccee6a1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "07d0d79e54164408a150353b22a987e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e88cb6c26134495ea358d489dfebe946": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}